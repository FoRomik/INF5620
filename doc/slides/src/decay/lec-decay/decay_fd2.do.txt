
!split
======= Model extensions =======
label{decay:generalizations}

!split
===== Extension to a variable coefficient; Forward and Backward Euler =====

!bt
\begin{equation}
u'(t) = -a(t)u(t),\quad t\in (0,T],\quad u(0)=I \tp
label{decay:problem:a}
\end{equation}
!et


The Forward Euler scheme:

!bt
\begin{equation}
\frac{u^{n+1} - u^n}{\Delta t} = -a(t_n)u^n
\tp
\end{equation}
!et

The Backward Euler scheme:
!bt
\begin{equation}
\frac{u^{n} - u^{n-1}}{\Delta t} = -a(t_n)u^n
\tp
\end{equation}
!et

!split
===== Extension to a variable coefficient; Crank-Nicolson =====

Eevaluting $a(t_{n+\half})$ and
using an average for $u$:
!bt
\begin{equation}
\frac{u^{n+1} - u^{n}}{\Delta t} = -a(t_{n+\half})\half(u^n + u^{n+1})
\tp
\end{equation}
!et

Using an average for $a$ and $u$:
!bt
\begin{equation}
\frac{u^{n+1} - u^{n}}{\Delta t} = -\half(a(t_n)u^n + a(t_{n+1})u^{n+1})
\tp
\end{equation}
!et

!split
===== Extension to a variable coefficient; $\theta$-rule =====

The $\theta$-rule unifies the three mentioned schemes,

!bt
\begin{equation}
\frac{u^{n+1} - u^{n}}{\Delta t} = -a((1-\theta)t_n + \theta t_{n+1})((1-\theta) u^n + \theta u^{n+1})
\tp
\end{equation}
!et
or,
!bt
\begin{equation}
\frac{u^{n+1} - u^{n}}{\Delta t} = -(1-\theta) a(t_n)u^n - \theta
a(t_{n+1})u^{n+1}
\tp
\end{equation}
!et

!split
===== Extension to a variable coefficient; operator notation =====

!bt
\begin{align*}
\lbrack D^+_t u &= -au\rbrack^n,\\
\lbrack D^-_t u &= -au\rbrack^n,\\
\lbrack D_t u &= -a\overline{u}^t\rbrack^{n+\half},\\
\lbrack D_t u &= -\overline{au}^t\rbrack^{n+\half},\\
\tp
\end{align*}
!et


!split
===== Extension to a source term =====
label{decay:source}

!bt
\begin{equation}
u'(t) = -a(t)u(t) + b(t),\quad t\in (0,T],\quad u(0)=I
\tp
label{decay:problem:ab}
\end{equation}
!et

!bt
\begin{align*}
\lbrack D^+_t u &= -au + b\rbrack^n,\\
\lbrack D^-_t u &= -au + b\rbrack^n,\\
\lbrack D_t u   &= -a\overline{u}^t + b\rbrack^{n+\half},\\
\lbrack D_t u   &= \overline{-au+b}^t\rbrack^{n+\half}
\tp
\end{align*}
!et

!split
===== Implementation of the generalized model problem =====
label{decay:general}

!bt
\begin{equation}
u^{n+1} = ((1 - \Delta t(1-\theta)a^n)u^n
+ \Delta t(\theta b^{n+1} + (1-\theta)b^n))(1 + \Delta t\theta a^{n+1})^{-1}
\tp
\end{equation}
!et

Implementation where $a(t)$ and $b(t)$ are given as
Python functions (see file "`decay_vc.py`":
"https://github.com/hplgit/INF5620/blob/gh-pages/src/decay/decay_vc.py"):

@@@CODE src-decay/decay_vc.py def solver@import nose

!split
===== Implementations of variable coefficients; functions =====

Plain functions:

!bc pycod
def a(t):
    return a_0 if t < tp else k*a_0

def b(t):
    return 1
!ec

!split
===== Implementations of variable coefficients; classes =====

Better implementation: class with the parameters `a0`, `tp`, and `k`
as attributes and a *special method* `__call__` for evaluating $a(t)$:

!bc pycod
class A:
    def __init__(self, a0=1, k=2):
        self.a0, self.k = a0, k

    def __call__(self, t):
        return self.a0 if t < self.tp else self.k*self.a0

a = A(a0=2, k=1)  # a behaves as a function a(t)
!ec

!split
===== Implementations of variable coefficients; lambda function =====

idx{lambda functions}

Quick writing: a one-liner *lambda function*
!bc pycod
a = lambda t: a_0 if t < tp else k*a_0
!ec

In general,
!bc pycod
f = lambda arg1, arg2, ...: expressin
!ec
is equivalent to
!bc pycod
def f(arg1, arg2, ...):
    return expression
!ec

One can use lambda functions directly in calls:
!bc pycod
u, t = solver(1, lambda t: 1, lambda t: 1, T, dt, theta)
!ec
for a problem $u'=-u+1$, $u(0)=1$.

A lambda function can appear anywhere where a variable can appear.

!split
===== Verification via trivial solutions =====
label{decay:verify:trivial}

 * Start debugging of a new code with trying a problem
   where $u=\hbox{const} \neq 0$.
 * Choose $u=C$ (a constant). Choose any $a(t)$ and set
   $b=a(t)C$ and
   $I=C$.
 * "All" numerical methods will reproduce $u=_{\hbox{const}}$
   exactly (machine precision).
 * Often $u=C$ eases debugging.
 * In this example: *any error* in the formula for $u^{n+1}$
   make $u\neq C$!

!split
===== Verification via trivial solutions; nose test =====

@@@CODE src-decay/decay_vc.py fromto: import nose@test_linear


!split
===== Verification via manufactured solutions =====
label{decay:MMS}

idx{method of manufactured solutions}
idx{MMS (method of manufactured solutions)}

 * Choose *any* formula for $u(t)$.
 * Fit $I$, $a(t)$, and $b(t)$ in $u'=-au+b$, $u(0)=I$,
   to make the chosen formula a solution of the ODE problem.
 * Then we can always have an analytical solution (!).
 * Ideal for verification: testing convergence rates.
 * Called the *method of manufactured solutions* (MMS)
 * Special case: $u$ linear in $t$, because all sound numerical
   methods will reproduce a linear $u$ exactly (machine precision).
 * $u(t) = ct + d$. $u(0)=0$ means $d=I$.
 * ODE implies $c = -a(t)u + b(t)$.
 * Choose $a(t)$ and $c$, and set $b(t) = c + a(t)(ct + I)$.
 * Any error in the formula for $u^{n+1}$ makes $u\neq ct+I$!

!split
===== Linear manufactured solution =====

$u^n = ct_n+I$ fulfills the discrete
equations!

First,
!bt
\begin{align}
\lbrack D_t^+ t\rbrack^n &= \frac{t_{n+1}-t_n}{\Delta t}=1,
label{decay:fd2:Dop:tn:fw}\\
\lbrack D_t^- t\rbrack^n &= \frac{t_{n}-t_{n-1}}{\Delta t}=1,
label{decay:fd2:Dop:tn:bw}\\
\lbrack D_t t\rbrack^n &= \frac{t_{n+\half}-t_{n-\half}}{\Delta t}=\frac{(n+\half)\Delta t - (n-\half)\Delta t}{\Delta t}=1\label{decay:fd2:Dop:tn:cn}
\tp
\end{align}
!et

Forward Euler:

!bt
\[ [D^+ u = -au + b]^n, \]
!et

$a^n=a(t_n)$, $b^n=c + a(t_n)(ct_n + I)$, and $u^n=ct_n + I$
results in

!bt
\[ c = -a(t_n)(ct_n+I) + c + a(t_n)(ct_n + I) = c \]
!et

!split
===== Nose test for linear manufactured solution =====

@@@CODE src-decay/decay_vc.py def test_linear@if __name

!split
===== Extension to systems of ODEs =====

Sample system:

!bt
\begin{align}
u' &= a u + bv,\\
v' &= cu +  dv,
\end{align}
!et

The Forward Euler method:

!bt
\begin{align}
u^{n+1} &= u^n + \Delta t (a u^n + b v^n),\\
v^{n+1} &= u^n + \Delta t (cu^n + dv^n)
\tp
\end{align}
!et


!split
===== The Backward Euler method gives a system of algebraic equations =====

The Backward Euler scheme:

!bt
\begin{align}
u^{n+1} &= u^n + \Delta t (a u^{n+1} + b v^{n+1}),\\
v^{n+1} &= v^n + \Delta t (c u^{n+1} + d v^{n+1})\tp
\end{align}
!et
which is a $2\times 2$ linear system:

!bt
\begin{align}
(1 - \Delta t a)u^{n+1} + bv^{n+1} &= u^n ,\\
c u^{n+1} + (1 - \Delta t d) v^{n+1} &= v^n ,
\end{align}
!et

Crank-Nicolson also gives a $2\times 2$ linear system.

!split
======= General first-order ODEs =======
label{decay:1stODEs}

!split
===== Generic form =====

The standard form for ODEs:
!bt
\begin{equation}
u' = f(u,t),\quad u(0)=I,
label{decay:ode:general}
\end{equation}
!et

$u$ and $f$: scalar or vector.

Vectors in case of ODE systems:
!bt
\[ u(t) = (u^{(0)}(t),u^{(1)}(t),\ldots,u^{(m-1)}(t)) \tp  \]
!et

!bt
\begin{align*}
f(u, t) = ( & f^{(0)}(u^{(0)},\ldots,u^{(m-1)}),\\
            & f^{(1)}(u^{(0)},\ldots,u^{(m-1)}),\\
            & \vdots\\
            & f^{(m-1)}(u^{(0)}(t),\ldots,u^{(m-1)}(t)))
\tp
\end{align*}
!et

!split
===== The $\theta$-rule =====

!bt
\begin{equation}
\frac{u^{n+1}-u^n}{\Delta t} = \theta f(u^{n+1},t_{n+1}) +
(1-\theta)f(u^n, t_n)\tp
label{decay:fd2:theta}
\end{equation}
!et
Bringing the unknown $u^{n+1}$ to the left-hand side and the known terms
on the right-hand side gives

idx{implicit schemes} idx{explicit schemes} idx{theta-rule} idx{$\theta$-rule}

!bt
\begin{equation}
u^{n+1} - \Delta t \theta f(u^{n+1},t_{n+1}) =
u^n + \Delta t(1-\theta)f(u^n, t_n)\tp
\end{equation}
!et
This is a *nonlinear* equation in $u^{n+1}$ (unless $f$ is linear in $u$)!


!split
===== Implicit 2-step backward scheme =====

idx{backward scheme, 2-step} idx{BDF2 scheme}

!bt
\[ u'(t_{n+1}) \approx \frac{3u^{n+1} - 4u^{n} + u^{n-1}}{2\Delta t},\]
!et

Scheme:
!bt
\[ u^{n+1} = \frac{4}{3}u^n - \frac{1}{3}u^{n-1} +
\frac{2}{3}\Delta t f(u^{n+1}, t_{n+1})
\tp
label{decay:fd2:bw:2step}
\]
!et
Nonlinear equation for $u^{n+1}$.


===== The Leapfrog scheme =====

idx{Leapfrog scheme}

Idea:
!bt
\begin{equation}
u'(t_n)\approx \frac{u^{n+1}-u^{n-1}}{2\Delta t} = [D_{2t} u]^n,
\end{equation}
!et

Scheme:

!bt
\[ [D_{2t} u = f(u,t)]^n,\]
!et
or written out,
!bt
\begin{equation}
u^{n+1} = u^{n-1} + \Delta t f(u^n, t_n)
\tp
label{decay:fd2:leapfrog}
\end{equation}
!et

 * Some other scheme must be used as starter ($u^1$).
 * Explicit scheme - a nonlinear $f$ (in $u$) is trivial to handle.
 * Downside: Leapfrog is always unstable after some time.

!split
===== The filtered Leapfrog scheme =====

idx{Leapfrog scheme, filtered}

After computing $u^{n+1}$, stabilize Leapfrog by
!bt
\begin{equation}
u^n\ \leftarrow\ u^n + \gamma (u^{n-1} - 2u^n + u^{n+1})
label{decay:fd2:leapfrog:filtered}
\tp
\end{equation}
!et

!split
===== 2nd-order Runge-Kutta scheme =====

idx{Heun's method}
idx{Runge-Kutta, 2nd-order scheme}

Forward-Euler + approximate Crank-Nicolson:
!bt
\begin{align}
u^* &= u^n + \Delta t f(u^n, t_n),
label{decay:fd2:RK2:s1}\\
u^{n+1} &= u^n + \Delta t \half \left( f(u^n, t_n) + f(u^*, t_{n+1})
\right),
label{decay:fd2:RK2:s2}
\end{align}
!et

!split
===== 4th-order Runge-Kutta scheme =====
label{decay:fd2:RK4}

 * The most famous and widely used ODE method
 * 4 evaluations of $f$ per time step
 * Its "derivation": "${doc_notes}/decay-sphinx/._main_decay007.html#th-order-runge-kutta-scheme" is a very good illustration of numerical thinking!


!split
===== 2nd-order Adams-Bashforth scheme =====

idx{Adams-Bashforth scheme, 2nd order}

!bt
\begin{equation}
u^{n+1} = u^n + \half\Delta t\left( 3f(u^n, t_n) - f(u^{n-1}, t_{n-1})
\right)
\tp
label{decay:fd2:AB2}
\end{equation}
!et

!split
===== 3rd-order Adams-Bashforth scheme =====
idx{Adams-Bashforth scheme, 3rd order}

!bt
\begin{equation}
u^{n+1} = u^n + \frac{1}{12}\left( 23f(u^n, t_n) - 16 f(u^{n-1},t_{n-1})
+ 5f(u^{n-2}, t_{n-2})\right)
\tp
label{decay:fd2:AB3}
\end{equation}
!et

!split
===== The Odespy software =====

"Odespy": "https://github.com/hplgit/odespy"
features simple Python implementations of the most fundamental
schemes as well as Python interfaces to several famous packages for
solving ODEs: "ODEPACK": "https://computation.llnl.gov/casc/odepack/odepack_home.html",
"Vode": "https://computation.llnl.gov/casc/odepack/odepack_home.html",
"rkc.f": "http://www.netlib.org/ode/rkc.f",
"rkf45.f": "http://www.netlib.org/ode/rkf45.f",
"Radau5": "http://www.unige.ch/~hairer/software.html", as well
as the ODE solvers in
"SciPy": "http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html",
"SymPy": "http://docs.sympy.org/dev/modules/mpmath/calculus/odes.html", and
"odelab": "http://olivierverdier.github.com/odelab/".

Typical usage:

!bc
# Define right-hand side of ODE
def f(u, t):
    return -a*u

import odespy
import numpy as np

# Set parameters and time mesh
I = 1; a = 2; T = 6; dt = 1.0
Nt = int(round(T/dt))
t_mesh = np.linspace(0, T, Nt+1)

# Use a 4th-order Runge-Kutta method
solver = odespy.RK4(f)
solver.set_initial_condition(I)
u, t = solver.solve(t_mesh)
!ec

!split
===== Example: Runge-Kutta methods  =====


!bc pycod
solvers = [odespy.RK2(f),
           odespy.RK3(f),
           odespy.RK4(f),
           odespy.BackwardEuler(f, nonlinear_solver='Newton')]

for solver in solvers:
    solver.set_initial_condition(I)
    u, t = solver.solve(t)

# + lots of plot code...
!ec

!split
===== Plots from the experiments =====

FIGURE: [fig-decay/decay_odespy1_png.png, width=800]

The 4-th order Runge-Kutta method (`RK4`) is the method of choice!


!split
===== Example: Adaptive Runge-Kutta methods  =====

 * Adaptive methods find "optimal" locations of the mesh points
   to ensure that the error is less than a given tolerance.
 * Downside: approximate error estimation, not always optimal
   location of points.
 * "Industry standard ODE solver": Dormand-Prince 4/5-th order
   Runge-Kutta (MATLAB's famous `ode45`).


FIGURE: [fig-decay/decay_DormandPrince_adaptivity.png, width=800]





