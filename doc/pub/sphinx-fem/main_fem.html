

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Introduction to finite element methods</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Introduction to finite element methods" href="index.html" /> 
  
   <style type=text/css>
     div.admonition {
       background-color: whiteSmoke;
       border: 1px solid #bababa;
     }
   </style>
  </head>

  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li><a href="index.html">Introduction to finite element methods</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="introduction-to-finite-element-methods">
<h1>Introduction to finite element methods<a class="headerlink" href="#introduction-to-finite-element-methods" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Hans Petter Langtangen</td>
</tr>
<tr class="field-even field"><th class="field-name">Date:</th><td class="field-body">Oct 30, 2013</td>
</tr>
</tbody>
</table>
<p><strong>PRELIMINARY VERSION</strong></p>
<p>The finite element method is a powerful tool for solving differential
equations. The method can easily deal with complex geometries and
higher-order approximations of the solution.
Figure <a class="reference internal" href="#fem-motivation-fig-dolfin"><em>Domain for flow around a dolphin</em></a> shows
a two-dimensional domain with a non-trivial geometry. The idea is to
divide the domain into triangles (elements) and seek a polynomial approximations
to the unknown functions on each triangle. The method glues these
piecewise approximations together to find a global solution.
Linear and quadratic polynomials over the triangles are particularly
popular.</p>
<div class="figure" id="fem-motivation-fig-dolfin">
<img alt="_images/dolfin_mesh1.png" src="_images/dolfin_mesh1.png" style="width: 400px;" />
<p class="caption"><em>Domain for flow around a dolphin</em></p>
</div>
<p>Many successful numerical methods for differential equations,
including the finite element method,
aim at approximating the unknown function by a sum</p>
<div class="math" id="equation-fem:u">
<span class="eqno">(1)</span>\[      u(x) = \sum_{i=0}^N c_i{\psi}_i(x),\]</div>
<p>where <span class="math">\({\psi}_i(x)\)</span> are prescribed functions and <span class="math">\(c_0,\ldots,c_N\)</span>
are unknown coefficients to be determined.
Solution methods for differential equations
utilizing <a href="#equation-fem:u">(1)</a> must
have a <em>principle</em> for constructing <span class="math">\(N+1\)</span> equations to
determine <span class="math">\(c_0,\ldots,c_N\)</span>. Then there is a <em>machinery</em> regarding
the actual constructions of the equations for <span class="math">\(c_0,\ldots,c_N\)</span>, in a
particular problem. Finally, there is a <em>solve</em> phase for computing
the solution <span class="math">\(c_0,\ldots,c_N\)</span> of the <span class="math">\(N+1\)</span> equations.</p>
<p>Especially in the finite element method, the machinery for constructing
the discrete equations to be implemented on a computer is quite
comprehensive, with many mathematical and implementational
details entering the scene at the
same time. From an ease-of-learning perspective it can therefore be
wise to introduce the computational machinery for a trivial equation:
<span class="math">\(u=f\)</span>. Solving this equation with <span class="math">\(f\)</span> given and <span class="math">\(u\)</span> on the form
<a href="#equation-fem:u">(1)</a> means that we seek an approximation
<span class="math">\(u\)</span> to <span class="math">\(f\)</span>.
This approximation problem has the advantage of introducing most of the
finite element toolbox, but with postponing demanding topics related to
differential equations (e.g., integration by parts, boundary conditions,
and coordinate mappings).
This is the reason why we shall first become familiar
with finite element <em>approximation</em> before addressing
finite element methods for differential equations.</p>
<p>First, we refresh some linear algebra concepts about approximating
vectors in vector spaces. Second, we extend these concepts to
approximating functions in function spaces, using the same
principles and the same notation.
We present examples on approximating functions by  global basis functions with
support throughout the entire domain.
Third, we introduce the finite element type of local basis functions
and explain the computational algorithms for working with such functions.
Three types of approximation principles are covered: 1) the least squares
method, 2) the <span class="math">\(L_2\)</span> projection or Galerkin method,
and 3) interpolation or collocation.</p>
</div>
<div class="section" id="approximation-of-vectors">
<span id="fem-approx-vec"></span><h1>Approximation of vectors<a class="headerlink" href="#approximation-of-vectors" title="Permalink to this headline">¶</a></h1>
<p>We shall start with introducing two fundamental methods for
determining the coefficients <span class="math">\(c_i\)</span> in <a href="#equation-fem:u">(1)</a> and illustrate
the methods on approximation of vectors, because vectors in vector
spaces give a more intuitive understanding than starting directly
with approximation of functions in function spaces.
The extension from vectors to functions will be trivial as soon as
the fundamental ideas are understood.</p>
<p>The first method of approximation is called the <em>least squares method</em>
and consists in finding <span class="math">\(c_i\)</span> such that the difference <span class="math">\(u-f\)</span>, measured
in some norm, is minimized. That is, we aim at finding the best
approximation <span class="math">\(u\)</span> to <span class="math">\(f\)</span> (in some norm). The second method is not
as intuitive: we find <span class="math">\(u\)</span> such that the error <span class="math">\(u-f\)</span> is orthogonal to
the space where we seek <span class="math">\(u\)</span>. This is known as <em>projection</em>, or
we may also call it a <em>Galerkin method</em>.
When approximating vectors and functions, the two methods are
equivalent, but this is no longer the case when applying the
principles to differential equations.</p>
<div class="section" id="approximation-of-planar-vectors">
<span id="fem-approx-vec-plane"></span><h2>Approximation of planar vectors<a class="headerlink" href="#approximation-of-planar-vectors" title="Permalink to this headline">¶</a></h2>
<p id="index-0">Suppose we have given a vector <span class="math">\(\boldsymbol{f} = (3,5)\)</span> in the <span class="math">\(xy\)</span> plane
and that we want to approximate this vector by a vector aligned
in the direction of the vector <span class="math">\((a,b)\)</span>. Figure <a class="reference internal" href="#fem-approx-vec-plane-fig"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></a>
depicts the situation.</p>
<div class="figure" id="fem-approx-vec-plane-fig">
<img alt="_images/vecapprox_plane1.png" src="_images/vecapprox_plane1.png" style="width: 400px;" />
<p class="caption"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></p>
</div>
<p>We introduce the vector space <span class="math">\(V\)</span>
spanned by the vector <span class="math">\(\boldsymbol{\psi}_0=(a,b)\)</span>:</p>
<div class="math">
\[V = \mbox{span}\,\{ \boldsymbol{\psi}_0\}{\thinspace .}\]</div>
<p>We say that <span class="math">\(\boldsymbol{\psi}_0\)</span> is a basis vector in the space <span class="math">\(V\)</span>.
Our aim is to find the vector <span class="math">\(\boldsymbol{u} = c_0\boldsymbol{\psi}_0\in V\)</span> which best approximates
the given vector <span class="math">\(\boldsymbol{f} = (3,5)\)</span>. A reasonable criterion for a best
approximation could be to minimize the length of the difference between
the approximate <span class="math">\(\boldsymbol{u}\)</span> and the given <span class="math">\(\boldsymbol{f}\)</span>. The difference, or error
<span class="math">\(\boldsymbol{e} = \boldsymbol{f} -\boldsymbol{u}\)</span>, has its length given by the <em>norm</em></p>
<div class="math">
\[||\boldsymbol{e}|| = (\boldsymbol{e},\boldsymbol{e})^{\frac{1}{2}},\]</div>
<p>where <span class="math">\((\boldsymbol{e},\boldsymbol{e})\)</span> is the <em>inner product</em> of <span class="math">\(\boldsymbol{e}\)</span> and itself. The inner
product, also called <em>scalar product</em> or <em>dot product</em>, of two vectors
<span class="math">\(\boldsymbol{u}=(u_0,u_1)\)</span> and <span class="math">\(\boldsymbol{v} =(v_0,v_1)\)</span> is defined as</p>
<div class="math">
\[(\boldsymbol{u}, \boldsymbol{v}) = u_0v_0 + u_1v_1{\thinspace .}\]</div>
<p><strong>Remark 1.</strong>
We should point out that we use the notation
<span class="math">\((\cdot,\cdot)\)</span> for two different things: <span class="math">\((a,b)\)</span> for scalar
quantities <span class="math">\(a\)</span> and <span class="math">\(b\)</span> means the vector starting in the origin and
ending in the point <span class="math">\((a,b)\)</span>, while <span class="math">\((\boldsymbol{u},\boldsymbol{v})\)</span> with vectors <span class="math">\(\boldsymbol{u}\)</span> and
<span class="math">\(\boldsymbol{v}\)</span> means the inner product of these vectors.  Since vectors are here
written in boldface font there should be no confusion.  We may add
that the norm associated with this inner product is the usual
Eucledian length of a vector.</p>
<p><strong>Remark 2.</strong>
It might be wise to refresh some basic linear algebra by consulting a
textbook.  <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a> and
<a class="reference internal" href="#fem-approx-exer-linalg2"><em>Exercise 2: Linear algebra refresher II</em></a> suggest specific tasks to regain
familiarity with fundamental operations on inner product vector
spaces.</p>
<div class="section" id="the-least-squares-method-1">
<span id="index-1"></span><h3>The least squares method  (1)<a class="headerlink" href="#the-least-squares-method-1" title="Permalink to this headline">¶</a></h3>
<p>We now want to find <span class="math">\(c_0\)</span> such that it minimizes <span class="math">\(||\boldsymbol{e}||\)</span>. The algebra
is simplified if we minimize the square of the norm, <span class="math">\(||\boldsymbol{e}||^2 = (\boldsymbol{e}, \boldsymbol{e})\)</span>,
instead of the norm itself.
Define the function</p>
<div class="math">
\[E(c_0) = (\boldsymbol{e},\boldsymbol{e}) = (\boldsymbol{f} - c_0\boldsymbol{\psi}_0, \boldsymbol{f} - c_0\boldsymbol{\psi}_0)
{\thinspace .}\]</div>
<p>We can rewrite the expressions of the right-hand side in a more
convenient form for further work:</p>
<div class="math" id="equation-fem:vec:E">
<span class="eqno">(2)</span>\[     E(c_0) = (\boldsymbol{f},\boldsymbol{f}) - 2c_0(\boldsymbol{f},\boldsymbol{\psi}_0) + c_0^2(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0){\thinspace .}\]</div>
<p>The rewrite results from using the following fundamental rules for inner
product spaces:</p>
<div class="math" id="equation-fem:vec:rule:scalarmult">
<span class="eqno">(3)</span>\[     (\alpha\boldsymbol{u},\boldsymbol{v})=\alpha(\boldsymbol{u},\boldsymbol{v}),\quad \alpha\in\mathbb{R},\]</div>
<div class="math" id="equation-fem:vec:rule:sum">
<span class="eqno">(4)</span>\[     (\boldsymbol{u} +\boldsymbol{v},\boldsymbol{w}) = (\boldsymbol{u},\boldsymbol{w}) + (\boldsymbol{v}, \boldsymbol{w}),\]</div>
<div class="math" id="equation-fem:vec:rule:symmetry">
<span class="eqno">(5)</span>\[     (\boldsymbol{u}, \boldsymbol{v}) = (\boldsymbol{v}, \boldsymbol{u}){\thinspace .}\]</div>
<p>Minimizing <span class="math">\(E(c_0)\)</span> implies finding <span class="math">\(c_0\)</span> such that</p>
<div class="math">
\[\frac{\partial E}{\partial c_0} = 0{\thinspace .}\]</div>
<p>Differentiating <a href="#equation-fem:vec:E">(2)</a> with respect to <span class="math">\(c_0\)</span> gives</p>
<div class="math" id="equation-fem:vec:dEdc0:v1">
<span class="eqno">(6)</span>\[     \frac{\partial E}{\partial c_0} = -2(\boldsymbol{f},\boldsymbol{\psi}_0) + 2c_0 (\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)
     {\thinspace .}\]</div>
<p>Setting the above expression equal to zero and solving for <span class="math">\(c_0\)</span> gives</p>
<div class="math" id="equation-fem:vec:c0">
<span class="eqno">(7)</span>\[     c_0 = \frac{(\boldsymbol{f},\boldsymbol{\psi}_0)}{(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)},\]</div>
<p>which in the present case with <span class="math">\(\boldsymbol{\psi}_0=(a,b)\)</span> results in</p>
<div class="math">
\[c_0 = \frac{3a + 5b}{a^2 + b^2}{\thinspace .}\]</div>
<p>For later, it is worth mentioning that setting
the key equation <a href="#equation-fem:vec:dEdc0:v1">(6)</a> to zero can be rewritten
as</p>
<div class="math">
\[(\boldsymbol{f}-c0\boldsymbol{\psi}_0,\boldsymbol{\psi}_0) = 0,\]</div>
<p>or</p>
<div class="math" id="equation-fem:vec:dEdc0:Galerkin">
<span class="eqno">(8)</span>\[     (\boldsymbol{e}, \boldsymbol{\psi}_0) = 0
     {\thinspace .}\]</div>
<span class="target" id="index-2"></span></div>
<div class="section" id="the-projection-method">
<span id="index-3"></span><h3>The projection method<a class="headerlink" href="#the-projection-method" title="Permalink to this headline">¶</a></h3>
<p>We shall now show that minimizing <span class="math">\(||\boldsymbol{e}||^2\)</span> implies that <span class="math">\(\boldsymbol{e}\)</span> is
orthogonal to <em>any</em> vector <span class="math">\(\boldsymbol{v}\)</span> in the space <span class="math">\(V\)</span>. This result is
visually quite clear from Figure <a class="reference internal" href="#fem-approx-vec-plane-fig"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></a> (think of
other vectors along the line <span class="math">\((a,b)\)</span>: all of them will lead to
a larger distance between the approximation and <span class="math">\(\boldsymbol{f}\)</span>).
To see this result mathematically, we
express any <span class="math">\(\boldsymbol{v}\in V\)</span> as <span class="math">\(\boldsymbol{v}=s\boldsymbol{\psi}_0\)</span> for any scalar parameter <span class="math">\(s\)</span>,
recall that two vectors are orthogonal when their inner product vanishes,
and calculate the inner product</p>
<div class="math">
\[\begin{split}(\boldsymbol{e}, s\boldsymbol{\psi}_0) &amp;= (\boldsymbol{f} - c_0\boldsymbol{\psi}_0, s\boldsymbol{\psi}_0)\\
&amp;= (\boldsymbol{f},s\boldsymbol{\psi}_0) - (c_0\boldsymbol{\psi}_0, s\boldsymbol{\psi}_0)\\
&amp;= s(\boldsymbol{f},\boldsymbol{\psi}_0) - sc_0(\boldsymbol{\psi}_0, \boldsymbol{\psi}_0)\\
&amp;= s(\boldsymbol{f},\boldsymbol{\psi}_0) - s\frac{(\boldsymbol{f},\boldsymbol{\psi}_0)}{(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)}(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)\\
&amp;= s\left( (\boldsymbol{f},\boldsymbol{\psi}_0) - (\boldsymbol{f},\boldsymbol{\psi}_0)\right)\\
&amp;=0{\thinspace .}\end{split}\]</div>
<p>Therefore, instead of minimizing the square of the norm, we could
demand that <span class="math">\(\boldsymbol{e}\)</span> is orthogonal to any vector in <span class="math">\(V\)</span>.
This method is known as <em>projection</em>, because it is the same as
projecting the vector onto the subspace.
(The approach can also be referred to as a Galerkin method as
explained at the end of the section <em class="xref std std-ref">approximation!of general vectors</em>.)</p>
<p>Mathematically the projection method is stated
by the equation</p>
<div class="math" id="equation-fem:vec:Galerkin1">
<span class="eqno">(9)</span>\[     (\boldsymbol{e}, \boldsymbol{v}) = 0,\quad\forall\boldsymbol{v}\in V{\thinspace .}\]</div>
<p>An arbitrary <span class="math">\(\boldsymbol{v}\in V\)</span> can be expressed as
<span class="math">\(s\boldsymbol{\psi}_0\)</span>, <span class="math">\(s\in\mathbb{R}\)</span>, and therefore
<a href="#equation-fem:vec:Galerkin1">(9)</a> implies</p>
<div class="math">
\[(\boldsymbol{e},s\boldsymbol{\psi}_0) = s(\boldsymbol{e}, \boldsymbol{\psi}_0) = 0,\]</div>
<p>which means that the error must be orthogonal to the basis vector in
the space <span class="math">\(V\)</span>:</p>
<div class="math">
\[(\boldsymbol{e}, \boldsymbol{\psi}_0)=0\quad\hbox{or}\quad
(\boldsymbol{f} - c_0\boldsymbol{\psi}_0, \boldsymbol{\psi}_0)=0
{\thinspace .}\]</div>
<p>The latter equation gives <a href="#equation-fem:vec:c0">(7)</a> and it
also arose from least squares computations in
<a href="#equation-fem:vec:dEdc0:Galerkin">(8)</a>.</p>
</div>
</div>
<div class="section" id="approximation-of-general-vectors">
<span id="fem-approx-vec-np1dim"></span><h2>Approximation of general vectors<a class="headerlink" href="#approximation-of-general-vectors" title="Permalink to this headline">¶</a></h2>
<p id="index-4">Let us generalize the vector approximation from the previous section
to vectors in spaces with arbitrary dimension. Given some vector <span class="math">\(\boldsymbol{f}\)</span>,
we want to find the best approximation to this vector in
the space</p>
<div class="math">
\[V = \hbox{span}\,\{\boldsymbol{\psi}_0,\ldots,\boldsymbol{\psi}_N\}
{\thinspace .}\]</div>
<p>We assume that the <em>basis vectors</em> <span class="math">\(\boldsymbol{\psi}_0,\ldots,\boldsymbol{\psi}_N\)</span> are
linearly independent so that none of them are redundant and
the space has dimension <span class="math">\(N+1\)</span>.
Any vector <span class="math">\(\boldsymbol{u}\in V\)</span> can be written as a linear combination
of the basis vectors,</p>
<div class="math">
\[\boldsymbol{u} = \sum_{j=0}^N c_j\boldsymbol{\psi}_j,\]</div>
<p>where <span class="math">\(c_j\in\mathbb{R}\)</span> are scalar coefficients to be determined.</p>
<div class="section" id="the-least-squares-method-2">
<h3>The least squares method  (2)<a class="headerlink" href="#the-least-squares-method-2" title="Permalink to this headline">¶</a></h3>
<p>Now we want to find <span class="math">\(c_0,\ldots,c_N\)</span>, such that <span class="math">\(\boldsymbol{u}\)</span> is the best
approximation to <span class="math">\(\boldsymbol{f}\)</span> in the sense that the distance (error)
<span class="math">\(\boldsymbol{e} = \boldsymbol{f} - \boldsymbol{u}\)</span> is minimized. Again, we define
the squared distance as a function of the free parameters
<span class="math">\(c_0,\ldots,c_N\)</span>,</p>
<div class="math">
\[E(c_0,\ldots,c_N) = (\boldsymbol{e},\boldsymbol{e}) = (\boldsymbol{f} -\sum_jc_j\boldsymbol{\psi}_j,\boldsymbol{f} -\sum_jc_j\boldsymbol{\psi}_j)
\nonumber\]</div>
<div class="math" id="equation-fem:vec:genE">
<span class="eqno">(10)</span>\[     = (\boldsymbol{f},\boldsymbol{f}) - 2\sum_{j=0}^N c_j(\boldsymbol{f},\boldsymbol{\psi}_j) +
     \sum_{p=0}^N\sum_{q=0}^N c_pc_q(\boldsymbol{\psi}_p,\boldsymbol{\psi}_q){\thinspace .}\]</div>
<p>Minimizing this <span class="math">\(E\)</span> with respect to the independent variables
<span class="math">\(c_0,\ldots,c_N\)</span> is obtained by requiring</p>
<div class="math">
\[\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N
{\thinspace .}\]</div>
<p>The second term in <a href="#equation-fem:vec:genE">(10)</a> is differentiated as follows:</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{j=0}^N c_j(\boldsymbol{f},\boldsymbol{\psi}_j) = (\boldsymbol{f},\boldsymbol{\psi}_i),\]</div>
<p>since the expression to be differentiated is a sum and only one term,
<span class="math">\(c_i(\boldsymbol{f},\boldsymbol{\psi}_i)\)</span>,
contains <span class="math">\(c_i\)</span> and this term is linear in <span class="math">\(c_i\)</span>.
To understand this differentiation in detail, write out the sum specifically for,
e.g, <span class="math">\(N=3\)</span> and <span class="math">\(i=1\)</span>.</p>
<p>The last term in <a href="#equation-fem:vec:genE">(10)</a>
is more tedious to differentiate. We start with</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
c_pc_q =
\left\lbrace\begin{array}{ll}
0,  \hbox{ if } p\neq i\hbox{ and } q\neq i,\]</div>
<div class="math">
\[c_q,  \hbox{ if } p=i\hbox{ and } q\neq i,\]</div>
<div class="math">
\[c_p,  \hbox{ if } p\neq i\hbox{ and } q=i,\]</div>
<div class="math">
\[2c_i,  \hbox{ if } p=q= i,\]</div>
<div class="math">
\[\end{array}\right.\]</div>
<p>Then</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\boldsymbol{\psi}_p,\boldsymbol{\psi}_q)
= \sum_{p=0, p\neq i}^N c_p(\boldsymbol{\psi}_p,\boldsymbol{\psi}_i)
+ \sum_{q=0, q\neq i}^N c_q(\boldsymbol{\psi}_q,\boldsymbol{\psi}_i)
+2c_i(\boldsymbol{\psi}_i,\boldsymbol{\psi}_i){\thinspace .}\]</div>
<p>The last term can be included in the other two sums, resulting in</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\boldsymbol{\psi}_p,\boldsymbol{\psi}_q)
= 2\sum_{j=0}^N c_i(\boldsymbol{\psi}_j,\boldsymbol{\psi}_i){\thinspace .}\]</div>
<p>It then follows that setting</p>
<div class="math">
\[\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N,\]</div>
<p>leads to a linear system
for <span class="math">\(c_0,\ldots,c_N\)</span>:</p>
<div class="math" id="equation-fem:approx:vec:Np1dim:eqsys">
<span class="eqno">(11)</span>\[     \sum_{j=0}^N A_{i,j} c_j = b_i, \quad i=0,\ldots,N,\]</div>
<p>where</p>
<div class="math">
\[A_{i,j} = (\boldsymbol{\psi}_i,\boldsymbol{\psi}_j),\]</div>
<div class="math">
\[b_i = (\boldsymbol{\psi}_i, \boldsymbol{f}){\thinspace .}\]</div>
<p>We have changed the order of the two vectors in the inner
product according to <a href="#equation-fem:vec:rule:symmetry">(5)</a>:</p>
<div class="math">
\[A_{i,j} = (\boldsymbol{\psi}_j,\boldsymbol{\psi}_i) = (\boldsymbol{\psi}_i,\boldsymbol{\psi}_j),\]</div>
<p>simply because the sequence <span class="math">\(i\)</span>-$j$ looks more aesthetic.</p>
</div>
<div class="section" id="the-galerkin-or-projection-method">
<h3>The Galerkin or projection method<a class="headerlink" href="#the-galerkin-or-projection-method" title="Permalink to this headline">¶</a></h3>
<p>In analogy with the &#8220;one-dimensional&#8221; example in
the section <a class="reference internal" href="#fem-approx-vec-plane"><em>Approximation of planar vectors</em></a>, it holds also here in the general
case that minimizing the distance
(error) <span class="math">\(\boldsymbol{e}\)</span> is equivalent to demanding that <span class="math">\(\boldsymbol{e}\)</span> is orthogonal to
all <span class="math">\(\boldsymbol{v}\in V\)</span>:</p>
<span class="target" id="index-5"></span><div class="math" id="equation-fem:approx:vec:Np1dim:Galerkin">
<span id="index-6"></span><span class="eqno">(12)</span>\[     (\boldsymbol{e},\boldsymbol{v})=0,\quad \forall\boldsymbol{v}\in V{\thinspace .}\]</div>
<p>Since any <span class="math">\(\boldsymbol{v}\in V\)</span> can be written as <span class="math">\(\boldsymbol{v} =\sum_{i=0}^N c_i\boldsymbol{\psi}_i\)</span>,
the statement <a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a> is equivalent to
saying that</p>
<div class="math">
\[(\boldsymbol{e}, \sum_{i=0}^N c_i\boldsymbol{\psi}_i) = 0,\]</div>
<p>for any choice of coefficients <span class="math">\(c_0,\ldots,c_N\)</span>.
The latter equation can be rewritten as</p>
<div class="math">
\[\sum_{i=0}^N c_i (\boldsymbol{e},\boldsymbol{\psi}_i) =0{\thinspace .}\]</div>
<p>If this is to hold for arbitrary values of <span class="math">\(c_0,\ldots,c_N\)</span>
we must require that each term in the sum vanishes,</p>
<div class="math" id="equation-fem:approx:vec:Np1dim:Galerkin0">
<span class="eqno">(13)</span>\[     (\boldsymbol{e},\boldsymbol{\psi}_i)=0,\quad i=0,\ldots,N{\thinspace .}\]</div>
<p>These <span class="math">\(N+1\)</span> equations result in the same linear system as
<a href="#equation-fem:approx:vec:Np1dim:eqsys">(11)</a>:</p>
<div class="math">
\[(\boldsymbol{f} - \sum_{j=0}^N c_j\boldsymbol{\psi}_j, \boldsymbol{\psi}_i) = (\boldsymbol{f}, \boldsymbol{\psi}_i) - \sum_{j\in{I}}
(\boldsymbol{\psi}_i,\boldsymbol{\psi}_j)c_j = 0,\]</div>
<p>and hence</p>
<div class="math">
\[\sum_{j=0}^N (\boldsymbol{\psi}_i,\boldsymbol{\psi}_j)c_j = (\boldsymbol{f}, \boldsymbol{\psi}_i),\quad i=0,\ldots, N
{\thinspace .}\]</div>
<p>So, instead of differentiating the
<span class="math">\(E(c_0,\ldots,c_N)\)</span> function, we could simply use
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a> as the principle for
determining <span class="math">\(c_0,\ldots,c_N\)</span>, resulting in the <span class="math">\(N+1\)</span>
equations <a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(13)</a>.</p>
<p>The names <em>least squares method</em> or <em>least squares approximation</em>
are natural since the calculations consists of
minimizing <span class="math">\(||\boldsymbol{e}||^2\)</span>, and <span class="math">\(||\boldsymbol{e}||^2\)</span> is a sum of squares
of differences between the components in <span class="math">\(\boldsymbol{f}\)</span> and <span class="math">\(\boldsymbol{u}\)</span>.
We find <span class="math">\(\boldsymbol{u}\)</span> such that this sum of squares is minimized.</p>
<p>The principle <a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a>,
or the equivalent form <a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(13)</a>,
is known as <em>projection</em>. Almost the same mathematical idea
was used by the Russian mathematician <a class="reference external" href="http://en.wikipedia.org/wiki/Boris_Galerkin">Boris Galerkin</a> to solve
differential equations, resulting in what is widely known as
<em>Galerkin&#8217;s method</em>.</p>
</div>
</div>
</div>
<div class="section" id="approximation-of-functions">
<span id="fem-approx-global"></span><h1>Approximation of functions<a class="headerlink" href="#approximation-of-functions" title="Permalink to this headline">¶</a></h1>
<p id="index-7">Let <span class="math">\(V\)</span> be a function space spanned by a set of <em>basis functions</em>
<span class="math">\({\psi}_0,\ldots,{\psi}_N\)</span>,</p>
<div class="math">
\[V = \hbox{span}\,\{{\psi}_0,\ldots,{\psi}_N\},\]</div>
<p>such that any function <span class="math">\(u\in V\)</span> can be written as a linear
combination of the basis functions:</p>
<div class="math" id="equation-fem:approx:ufem">
<span class="eqno">(14)</span>\[     u = \sum_{j\in{I}} c_j{\psi}_j{\thinspace .}\]</div>
<p>The index set <span class="math">\({I}\)</span> is defined as <span class="math">\({I} =\{0,\ldots,N\}\)</span> and is used
both for compact notation and for flexibility in the numbering of
elements in sequences.</p>
<p>For now, in this introduction, we shall look at functions of a
single variable <span class="math">\(x\)</span>:
<span class="math">\(u=u(x)\)</span>, <span class="math">\({\psi}_i={\psi}_i(x)\)</span>, <span class="math">\(i\in{I}\)</span>. Later, we will almost
trivially extend the mathematical details
to functions of two- or three-dimensional physical spaces.
The approximation <a href="#equation-fem:approx:ufem">(14)</a> is typically used
to discretize a problem in space. Other methods, most notably
finite differences, are common for time discretization, although the
form <a href="#equation-fem:approx:ufem">(14)</a> can be used in time as well.</p>
<div class="section" id="the-least-squares-method-3">
<span id="fem-approx-ls"></span><h2>The least squares method  (3)<a class="headerlink" href="#the-least-squares-method-3" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span>, how can we determine its best approximation
<span class="math">\(u(x)\in V\)</span>? A natural starting point is to apply the same reasoning
as we did for vectors in the section <a class="reference internal" href="#fem-approx-vec-np1dim"><em>Approximation of general vectors</em></a>. That is,
we minimize the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span>. However, this requires
a norm for measuring distances, and a norm is most conveniently
defined through an
inner product. Viewing a function as a vector of infinitely
many point values, one for each value of <span class="math">\(x\)</span>, the inner product could
intuitively be defined as the usual summation of
pairwise components, with summation replaced by integration:</p>
<div class="math">
\[(f,g) = \int f(x)g(x)\, {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>To fix the integration domain, we let <span class="math">\(f(x)\)</span> and <span class="math">\({\psi}_i(x)\)</span>
be defined for a domain <span class="math">\(\Omega\subset\mathbb{R}\)</span>.
The inner product of two functions <span class="math">\(f(x)\)</span> and <span class="math">\(g(x)\)</span> is then</p>
<div class="math" id="equation-fem:approx:LS:innerprod">
<span class="eqno">(15)</span>\[     (f,g) = \int_\Omega f(x)g(x)\, {\, \mathrm{d}x}\]\[     {\thinspace .}\]</div>
<p>The distance between <span class="math">\(f\)</span> and any function <span class="math">\(u\in V\)</span> is simply
<span class="math">\(f-u\)</span>, and the squared norm of this distance is</p>
<div class="math" id="equation-fem:approx:LS:E">
<span class="eqno">(16)</span>\[     E = (f(x)-\sum_{j\in{I}} c_j{\psi}_j(x), f(x)-\sum_{j\in{I}} c_j{\psi}_j(x)){\thinspace .}\]</div>
<p>Note the analogy with <a href="#equation-fem:vec:genE">(10)</a>: the given function
<span class="math">\(f\)</span> plays the role of the given vector <span class="math">\(\boldsymbol{f}\)</span>, and the basis function
<span class="math">\({\psi}_i\)</span> plays the role of the basis vector <span class="math">\(\boldsymbol{\psi}_i\)</span>.
We can rewrite <a href="#equation-fem:approx:LS:E">(16)</a>,
through similar steps as used for the result
<a href="#equation-fem:vec:genE">(10)</a>, leading to</p>
<div class="math">
\[E(c_i, \ldots, c_N) = (f,f) -2\sum_{j\in{I}} c_j(f,{\psi}_i)
+ \sum_{p\in{I}}\sum_{q\in{I}} c_pc_q({\psi}_p,{\psi}_q){\thinspace .}\]</div>
<p>Minimizing this function of <span class="math">\(N+1\)</span> scalar variables
<span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>, requires differentiation
with respect to <span class="math">\(c_i\)</span>, for all <span class="math">\(i\in{I}\)</span>. The resulting
equations are very similar to those we had in the vector case,
and we hence end up with a
linear system of the form <a href="#equation-fem:approx:vec:Np1dim:eqsys">(11)</a>, with
basically the same expressions:</p>
<div class="math" id="equation-fem:approx:Aij">
<span class="eqno">(17)</span>\[     A_{i,j} = ({\psi}_i,{\psi}_j),\]</div>
<div class="math" id="equation-fem:approx:bi">
<span class="eqno">(18)</span>\[     b_i = (f,{\psi}_i){\thinspace .}\]</div>
</div>
<div class="section" id="the-projection-or-galerkin-method">
<h2>The projection (or Galerkin) method<a class="headerlink" href="#the-projection-or-galerkin-method" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-8"></span><p id="index-9">As in the section <a class="reference internal" href="#fem-approx-vec-np1dim"><em>Approximation of general vectors</em></a>, the minimization of <span class="math">\((e,e)\)</span>
is equivalent to</p>
<div class="math" id="equation-fem:approx:Galerkin">
<span class="eqno">(19)</span>\[     (e,v)=0,\quad\forall v\in V{\thinspace .}\]</div>
<p>This is known as a projection of a function <span class="math">\(f\)</span> onto the subspace <span class="math">\(V\)</span>.
We may also call it a Galerkin method for approximating functions.
Using the same reasoning as
in
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a>-<a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(13)</a>,
it follows that <a href="#equation-fem:approx:Galerkin">(19)</a> is equivalent to</p>
<div class="math" id="equation-fem:approx:Galerkin0">
<span class="eqno">(20)</span>\[     (e,{\psi}_i)=0,\quad i\in{I}{\thinspace .}\]</div>
<p>Inserting <span class="math">\(e=f-u\)</span> in this equation and ordering terms, as in the
multi-dimensional vector case, we end up with a linear
system with a coefficient matrix <a href="#equation-fem:approx:Aij">(17)</a> and
right-hand side vector <a href="#equation-fem:approx:bi">(18)</a>.</p>
<p>Whether we work with vectors in the plane, general vectors, or
functions in function spaces, the least squares principle and
the projection or Galerkin method are equivalent.</p>
</div>
<div class="section" id="example-linear-approximation">
<span id="fem-approx-global-linear"></span><h2>Example: linear approximation<a class="headerlink" href="#example-linear-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us apply the theory in the previous section to a simple problem:
given a parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> for <span class="math">\(x\in\Omega=[1,2]\)</span>, find
the best approximation <span class="math">\(u(x)\)</span> in the space of all linear functions:</p>
<div class="math">
\[V = \hbox{span}\,\{1, x\}{\thinspace .}\]</div>
<p>With our notation, <span class="math">\({\psi}_0(x)=1\)</span>, <span class="math">\({\psi}_1(x)=x\)</span>, and <span class="math">\(N=1\)</span>.
We seek</p>
<div class="math">
\[u=c_0{\psi}_0(x) + c_1{\psi}_1(x) = c_0 + c_1x,\]</div>
<p>where
<span class="math">\(c_0\)</span> and <span class="math">\(c_1\)</span> are found by solving a <span class="math">\(2\times 2\)</span> the linear system.
The coefficient matrix has elements</p>
<div class="math">
\[A_{0,0} = ({\psi}_0,{\psi}_0) = \int_1^21\cdot 1\, {\, \mathrm{d}x} = 1,\]</div>
<div class="math">
\[A_{0,1} = ({\psi}_0,{\psi}_1) = \int_1^2 1\cdot x\, {\, \mathrm{d}x} = 3/2,\]</div>
<div class="math">
\[A_{1,0} = A_{0,1} = 3/2,\]</div>
<div class="math">
\[A_{1,1} = ({\psi}_1,{\psi}_1) = \int_1^2 x\cdot x\,{\, \mathrm{d}x} = 7/3{\thinspace .}\]</div>
<p>The corresponding right-hand side is</p>
<div class="math">
\[b_1 = (f,{\psi}_0) = \int_1^2 (10(x-1)^2 - 1)\cdot 1 \, {\, \mathrm{d}x} = 7/3,\]</div>
<div class="math">
\[b_2 = (f,{\psi}_1) = \int_1^2 (10(x-1)^2 - 1)\cdot x\, {\, \mathrm{d}x} = 13/3{\thinspace .}\]</div>
<p>Solving the linear system results in</p>
<div class="math">
\[c_0 = -38/3,\quad c_1 = 10,\]</div>
<p>and consequently</p>
<div class="math">
\[u(x) = 10x - \frac{38}{3}{\thinspace .}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-linear"><em>Best approximation of a parabola by a straight line</em></a> displays the
parabola and its best approximation in the space of all linear functions.</p>
<div class="figure" id="fem-approx-global-fig-parabola-linear">
<img alt="_images/parabola_ls_linear1.png" src="_images/parabola_ls_linear1.png" style="width: 400px;" />
<p class="caption"><em>Best approximation of a parabola by a straight line</em></p>
</div>
</div>
<div class="section" id="implementation-of-the-least-squares-method">
<span id="fem-approx-global-ls-code"></span><h2>Implementation of the least squares method<a class="headerlink" href="#implementation-of-the-least-squares-method" title="Permalink to this headline">¶</a></h2>
<p>The linear system can be computed either symbolically or
numerically (a numerical integration rule is needed in the latter case).
Here is a function for symbolic computation of the linear system,
where <span class="math">\(f(x)\)</span> is given as a <tt class="docutils literal"><span class="pre">sympy</span></tt> expression <tt class="docutils literal"><span class="pre">f</span></tt> involving
the symbol <tt class="docutils literal"><span class="pre">x</span></tt>, <tt class="docutils literal"><span class="pre">psi</span></tt> is a list of expressions for <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{I}}\)</span>,
and <tt class="docutils literal"><span class="pre">Omega</span></tt> is a 2-tuple/list holding the limits of the domain <span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                                  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
<p>Observe that we exploit the symmetry of the coefficient matrix:
only the upper triangular part is computed. Symbolic integration in
<tt class="docutils literal"><span class="pre">sympy</span></tt> is often time consuming, and (roughly) halving the
work has noticeable effect on the waiting time for the function to
finish execution.</p>
<p>Comparing the given <span class="math">\(f(x)\)</span> and the approximate <span class="math">\(u(x)\)</span> visually is
done by the following function, which with the aid of
<tt class="docutils literal"><span class="pre">sympy</span></tt>&#8216;s <tt class="docutils literal"><span class="pre">lambdify</span></tt> tool converts a <tt class="docutils literal"><span class="pre">sympy</span></tt>
expression to a Python function for numerical
computations:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&#39;tmp.pdf&#39;</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">u</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">resolution</span> <span class="o">=</span> <span class="mi">401</span>  <span class="c"># no of points in plot</span>
    <span class="n">xcoor</span>  <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">resolution</span><span class="p">)</span>
    <span class="n">exact</span>  <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">approx</span> <span class="o">=</span> <span class="n">u</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">approx</span><span class="p">)</span>
    <span class="n">hold</span><span class="p">(</span><span class="s">&#39;on&#39;</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">exact</span><span class="p">)</span>
    <span class="n">legend</span><span class="p">([</span><span class="s">&#39;approximation&#39;</span><span class="p">,</span> <span class="s">&#39;exact&#39;</span><span class="p">])</span>
    <span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">modules='numpy'</span></tt> argument to <tt class="docutils literal"><span class="pre">lambdify</span></tt> is important
if there are mathematical functions, such as <tt class="docutils literal"><span class="pre">sin</span></tt> or <tt class="docutils literal"><span class="pre">exp</span></tt>
in the symbolic expressions in <tt class="docutils literal"><span class="pre">f</span></tt> or <tt class="docutils literal"><span class="pre">u</span></tt>, and these
mathematical functions are to be used with vector arguments, like
<tt class="docutils literal"><span class="pre">xcoor</span></tt> above.</p>
<p>Both the <tt class="docutils literal"><span class="pre">least_squares</span></tt> and
<tt class="docutils literal"><span class="pre">comparison_plot</span></tt>
are found and coded in the file
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/approx1D.py">approx1D.py</a>.
The forthcoming examples on their use appear in
<tt class="docutils literal"><span class="pre">ex_approx1D.py</span></tt>.</p>
</div>
<div class="section" id="perfect-approximation">
<span id="fem-approx-global-exact"></span><h2>Perfect approximation<a class="headerlink" href="#perfect-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us use the code above to recompute the problem from
the section <a class="reference internal" href="#fem-approx-global-linear"><em>Example: linear approximation</em></a> where we want to approximate
a parabola. What happens if we add an element <span class="math">\(x^2\)</span> to the basis and test what
the best approximation is if <span class="math">\(V\)</span> is the space of all parabolic functions?
The answer is quickly found by running</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">10*x**2 - 20*x + 9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">10*x**2 - 20*x + 9</span>
</pre></div>
</div>
<p>Now, what if we use <span class="math">\({\psi}_i(x)=x^i\)</span> for <span class="math">\(i=0,1,\ldots,N=40\)</span>?
The output from <tt class="docutils literal"><span class="pre">least_squares</span></tt> gives <span class="math">\(c_i=0\)</span> for <span class="math">\(i&gt;2\)</span>, which
means that the method finds the perfect approximation.</p>
<p>In fact, we have a general result that
if <span class="math">\(f\in V\)</span>, the least squares and projection/Galerkin methods compute
the exact solution <span class="math">\(u=f\)</span>.
The proof is straightforward: if <span class="math">\(f\in V\)</span>, <span class="math">\(f\)</span> can be expanded in
terms of the basis functions, <span class="math">\(f=\sum_{j\in{I}} d_j{\psi}_j\)</span>, for
some coefficients <span class="math">\(\left\{ {d}_i \right\}_{i\in{I}}\)</span>,
and the right-hand side then has entries</p>
<div class="math">
\[b_i = (f,{\psi}_i) = \sum_{j\in{I}} d_j({\psi}_j, {\psi}_i) = \sum_{j\in{I}} d_jA_{i,j}
{\thinspace .}\]</div>
<p>The linear system <span class="math">\(\sum_jA_{i,j}c_j = b_i\)</span>, <span class="math">\(i\in{I}\)</span>, is then</p>
<div class="math">
\[\sum_{j\in{I}} c_jA_{i,j} = \sum_{j\in{I}}d_jA_{i,j},
\quad i\in{I},\]</div>
<p>which implies that <span class="math">\(c_i=d_i\)</span> for <span class="math">\(i\in{I}\)</span>.</p>
</div>
<div class="section" id="ill-conditioning">
<span id="fem-approx-global-illconditioning"></span><h2>Ill-conditioning<a class="headerlink" href="#ill-conditioning" title="Permalink to this headline">¶</a></h2>
<p>The computational example in the section <a class="reference internal" href="#fem-approx-global-exact"><em>Perfect approximation</em></a>
applies the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function which invokes symbolic
methods to calculate and solve the linear system. The correct
solution <span class="math">\(c_0=9, c_1=-20, c_2=10, c_i=0\)</span> for <span class="math">\(i\geq 3\)</span> is perfectly
recovered.</p>
<p>Suppose we
convert the matrix and right-hand side to floating-point arrays
and then solve the system using finite-precision arithmetics, which
is what one will (almost) always do in real life. This time we
get astonishing results! Up to about <span class="math">\(N=7\)</span> we get a solution that
is reasonably close to the exact one. Increasing <span class="math">\(N\)</span> shows that
seriously wrong coefficients are computed.
Below is a table showing the solution of the linear system arising from
approximating a parabola
by functions on the form <span class="math">\(u(x)=c_0 + c_1x + c_2x^2 + \cdots + c_{10}x^{10}\)</span>.
Analytically, we know that <span class="math">\(c_j=0\)</span> for <span class="math">\(j&gt;2\)</span>, but numerically we may get
<span class="math">\(c_j\neq 0\)</span> for <span class="math">\(j&gt;2\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">exact</th>
<th class="head"><tt class="docutils literal"><span class="pre">sympy</span></tt></th>
<th class="head"><tt class="docutils literal"><span class="pre">numpy32</span></tt></th>
<th class="head"><tt class="docutils literal"><span class="pre">numpy64</span></tt></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>9</td>
<td>9.62</td>
<td>5.57</td>
<td>8.98</td>
</tr>
<tr class="row-odd"><td>-20</td>
<td>-23.39</td>
<td>-7.65</td>
<td>-19.93</td>
</tr>
<tr class="row-even"><td>10</td>
<td>17.74</td>
<td>-4.50</td>
<td>9.96</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>-9.19</td>
<td>4.13</td>
<td>-0.26</td>
</tr>
<tr class="row-even"><td>0</td>
<td>5.25</td>
<td>2.99</td>
<td>0.72</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>0.18</td>
<td>-1.21</td>
<td>-0.93</td>
</tr>
<tr class="row-even"><td>0</td>
<td>-2.48</td>
<td>-0.41</td>
<td>0.73</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>1.81</td>
<td>-0.013</td>
<td>-0.36</td>
</tr>
<tr class="row-even"><td>0</td>
<td>-0.66</td>
<td>0.08</td>
<td>0.11</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>0.12</td>
<td>0.04</td>
<td>-0.02</td>
</tr>
<tr class="row-even"><td>0</td>
<td>-0.001</td>
<td>-0.02</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<p>The exact value of <span class="math">\(c_j\)</span>, <span class="math">\(j=0,1,\ldots,10\)</span>, appears in the first
column while the other columns correspond to results obtained
by three different methods:</p>
<blockquote>
<div><ul class="simple">
<li>Column 2: The matrix and vector are converted to
the data structure  <tt class="docutils literal"><span class="pre">sympy.mpmath.fp.matrix</span></tt> and the
<tt class="docutils literal"><span class="pre">sympy.mpmath.fp.lu_solve</span></tt> function is used to solve the system.</li>
<li>Column 3: The matrix and vector are converted to
<tt class="docutils literal"><span class="pre">numpy</span></tt> arrays with data type <tt class="docutils literal"><span class="pre">numpy.float32</span></tt>
(single precision floating-point number) and solved by
the <tt class="docutils literal"><span class="pre">numpy.linalg.solve</span></tt> function.</li>
<li>Column 4: As column 3, but the data type is
<tt class="docutils literal"><span class="pre">numpy.float64</span></tt> (double
precision floating-point number).</li>
</ul>
</div></blockquote>
<p>We see from the numbers in the table that
double precision performs much better than single precision.
Nevertheless, when plotting all these solutions the curves cannot be
visually distinguished (!). This means that the approximations look
perfect, despite the partially very wrong values of the coefficients.</p>
<p>Increasing <span class="math">\(N\)</span> to 12 makes the numerical solver in <tt class="docutils literal"><span class="pre">numpy</span></tt>
abort with the message: &#8220;matrix is numerically singular&#8221;.
A matrix has to be non-singular to be invertible, which is a requirement
when solving a linear system. Already when the matrix is close to
singular, it is <em>ill-conditioned</em>, which here implies that
the numerical solution algorithms are sensitive to round-off
errors and may produce (very) inaccurate results.</p>
<p>The reason why the coefficient matrix is nearly singular and
ill-conditioned is that our basis functions <span class="math">\({\psi}_i(x)=x^i\)</span> are
nearly linearly dependent for large <span class="math">\(i\)</span>.  That is, <span class="math">\(x^i\)</span> and <span class="math">\(x^{i+1}\)</span>
are very close for <span class="math">\(i\)</span> not very small. This phenomenon is
illustrated in Figure <a class="reference internal" href="#fem-approx-global-fig-illconditioning"><em>The 15 first basis functions , </em></a>.
There are 15 lines in this figure, but only half of them are
visually distinguishable.
Almost linearly dependent basis functions give rise to an
ill-conditioned and almost singular matrix.  This fact can be
illustrated by computing the determinant, which is indeed very close
to zero (recall that a zero determinant implies a singular and
non-invertible matrix): <span class="math">\(10^{-65}\)</span> for <span class="math">\(N=10\)</span> and <span class="math">\(10^{-92}\)</span> for
<span class="math">\(N=12\)</span>. Already for <span class="math">\(N=28\)</span> the numerical determinant computation
returns a plain zero.</p>
<div class="figure" id="fem-approx-global-fig-illconditioning">
<img alt="_images/ill_conditioning1.png" src="_images/ill_conditioning1.png" style="width: 600px;" />
<p class="caption">The 15 first basis functions <span class="math">\(x^i\)</span>, <span class="math">\(i=0,\ldots,14\)</span></p>
</div>
<p>On the other hand, the double precision <tt class="docutils literal"><span class="pre">numpy</span></tt> solver do run for
<span class="math">\(N=100\)</span>, resulting in answers that are not significantly worse than
those in the table above, and large powers are
associated with small coefficients (e.g., <span class="math">\(c_j&lt;10^{-2}\)</span> for <span class="math">\(10\leq
j\leq 20\)</span> and <span class="math">\(c&lt;10^{-5}\)</span> for <span class="math">\(j&gt;20\)</span>). Even for <span class="math">\(N=100\)</span> the
approximation still lies on top of the exact curve in a plot (!).</p>
<p>The conclusion is that visual inspection of the quality of the approximation
may not uncover fundamental numerical problems with the computations.
However, numerical analysts have studied approximations and ill-conditioning
for decades, and it is well known that the basis <span class="math">\(\{1,x,x^2,x^3,\ldots,\}\)</span>
is a bad basis. The best basis from a matrix conditioning point of view
is to have orthogonal functions such that <span class="math">\((\psi_i,\psi_j)=0\)</span> for
<span class="math">\(i\neq j\)</span>. There are many known sets of orthogonal polynomials and
other functions.
The functions used in the finite element methods are almost orthogonal,
and this property helps to avoid problems with solving matrix systems.
Almost orthogonal is helpful, but not enough when it comes to
partial differential equations, and ill-conditioning
of the coefficient matrix is a theme when solving large-scale matrix
systems arising from finite element discretizations.</p>
</div>
<div class="section" id="fourier-series">
<span id="fem-approx-global-fourier"></span><h2>Fourier series<a class="headerlink" href="#fourier-series" title="Permalink to this headline">¶</a></h2>
<p id="index-10">A set of sine functions is widely used for approximating functions
(the sines are also orthogonal as explained more in the section <a class="reference internal" href="#fem-approx-global-illconditioning"><em>Ill-conditioning</em></a>).  Let us take</p>
<div class="math">
\[V = \hbox{span}\,\{ \sin \pi x, \sin 2\pi x,\ldots,\sin (N+1)\pi x\}
{\thinspace .}\]</div>
<p>That is,</p>
<div class="math">
\[{\psi}_i(x) = \sin ((i+1)\pi x),\quad i\in{I}{\thinspace .}\]</div>
<p>An approximation to the <span class="math">\(f(x)\)</span> function from
the section <a class="reference internal" href="#fem-approx-global-linear"><em>Example: linear approximation</em></a> can then be computed by the
<tt class="docutils literal"><span class="pre">least_squares</span></tt> function from the section <a class="reference internal" href="#fem-approx-global-ls-code"><em>Implementation of the least squares method</em></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">pi</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sin</span><span class="p">(</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> (left) shows the oscillatory approximation
of <span class="math">\(\sum_{j=0}^Nc_j\sin ((j+1)\pi x)\)</span> when <span class="math">\(N=3\)</span>.
Changing <span class="math">\(N\)</span> to 11 improves the approximation considerably, see
Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> (right).</p>
<div class="figure" id="fem-approx-global-fig-parabola-sine1">
<img alt="_images/parabola_ls_sines4_121.png" src="_images/parabola_ls_sines4_121.png" style="width: 800px;" />
<p class="caption"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></p>
</div>
<p>There is an error <span class="math">\(f(0)-u(0)=9\)</span> at <span class="math">\(x=0\)</span> in Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> regardless of how large <span class="math">\(N\)</span> is, because all <span class="math">\({\psi}_i(0)=0\)</span> and hence
<span class="math">\(u(0)=0\)</span>. We may help the approximation to be correct at <span class="math">\(x=0\)</span> by
seeking</p>
<div class="math">
\[u(x) = f(0) + \sum_{j\in{I}} c_j{\psi}_j(x)
{\thinspace .}\]</div>
<p>However, this adjustment introduces a new problem at <span class="math">\(x=1\)</span> since
we now get an error <span class="math">\(f(1)-u(1)=f(1)-0=-1\)</span> at this point. A more
clever adjustment is to replace the <span class="math">\(f(0)\)</span> term by a term that
is <span class="math">\(f(0)\)</span> at <span class="math">\(x=0\)</span> and <span class="math">\(f(1)\)</span> at <span class="math">\(x=1\)</span>. A simple linear combination
<span class="math">\(f(0)(1-x) + xf(1)\)</span> does the job:</p>
<div class="math">
\[u(x) = f(0)(1-x) + xf(1) + \sum_{j\in{I}} c_j{\psi}_j(x)
{\thinspace .}\]</div>
<p>This adjustment of <span class="math">\(u\)</span> alters the linear system slightly as we get an extra
term <span class="math">\(-(f(0)(1-x) + xf(1),{\psi}_i)\)</span> on the right-hand side.
Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine2"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term</em></a> shows the result
of this technique for
ensuring right boundary values: even 3 sines can now adjust the
<span class="math">\(f(0)(1-x) + xf(1)\)</span> term such that <span class="math">\(u\)</span> approximates the parabola really
well, at least visually.</p>
<div class="figure" id="fem-approx-global-fig-parabola-sine2">
<img alt="_images/parabola_ls_sines4_12_wfterm1.png" src="_images/parabola_ls_sines4_12_wfterm1.png" style="width: 800px;" />
<p class="caption"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term</em></p>
</div>
</div>
<div class="section" id="orthogonal-basis-functions">
<span id="fem-approx-global-orth"></span><h2>Orthogonal basis functions<a class="headerlink" href="#orthogonal-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>The choice of sine functions <span class="math">\({\psi}_i(x)=\sin ((i+1)\pi x)\)</span> has a great
computational advantage: on <span class="math">\(\Omega=[0,1]\)</span> these basis functions are
<em>orthogonal</em>, implying that <span class="math">\(A_{i,j}=0\)</span> if <span class="math">\(i\neq j\)</span>. This
result is realized by trying</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">integrate</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">j</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>in <a class="reference external" href="http://wolframalpha.com">WolframAlpha</a>
(avoid <tt class="docutils literal"><span class="pre">i</span></tt> in the integrand as this symbol means
the imaginary unit <span class="math">\(\sqrt{-1}\)</span>).
Also by asking WolframAlpha
about <span class="math">\(\int_0^1\sin^2 (j\pi x) {\, \mathrm{d}x}\)</span>, we find it
to equal 1/2.
With a diagonal matrix we can easily solve for the coefficients
by hand:</p>
<div class="math">
\[c_i = 2\int_0^1 f(x)\sin ((i+1)\pi x) {\, \mathrm{d}x},\quad i\in{I},\]</div>
<p>which is nothing but the classical formula for the coefficients of
the Fourier sine series of <span class="math">\(f(x)\)</span> on <span class="math">\([0,1]\)</span>. In fact, when
<span class="math">\(V\)</span> contains the basic functions used in a Fourier series expansion,
the approximation method derived in the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a>
results in the classical Fourier series for <span class="math">\(f(x)\)</span> (see <a class="reference internal" href="#fem-approx-exer-fourier"><em>Exercise 8: Fourier series as a least squares approximation</em></a>
for details).</p>
<p>With orthogonal basis functions we can make the
<tt class="docutils literal"><span class="pre">least_squares</span></tt> function (much) more efficient since we know that
the matrix is diagonal and only the diagonal elements need to be computed:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares_orth</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span>  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">))]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>
</pre></div>
</div>
<p>This function is found in the file <tt class="docutils literal"><span class="pre">approx1D.py</span></tt>.</p>
</div>
<div class="section" id="numerical-computations">
<h2>Numerical computations<a class="headerlink" href="#numerical-computations" title="Permalink to this headline">¶</a></h2>
<p>Sometimes the basis functions <span class="math">\({\psi}_i\)</span> and/or the function <span class="math">\(f\)</span>
have a nature that makes symbolic integration CPU-time
consuming or impossible.
Even though we implemented a fallback on numerical integration
of <span class="math">\(\int f{\varphi}_i dx\)</span> considerable time might be required
by <tt class="docutils literal"><span class="pre">sympy</span></tt> in the attempt to integrate symbolically.
Therefore, it will be handy to have function for fast
<em>numerical</em> integration and <em>numerical</em> solution
of the linear system. Below is such a method. It requires
Python functions <tt class="docutils literal"><span class="pre">f(x)</span></tt> and <tt class="docutils literal"><span class="pre">psi(x,i)</span></tt> for <span class="math">\(f(x)\)</span> and <span class="math">\({\psi}_i(x)\)</span>
as input. The output is a mesh function
with values <tt class="docutils literal"><span class="pre">u</span></tt> on the mesh with points in the array <tt class="docutils literal"><span class="pre">x</span></tt>.
Three numerical integration methods are offered:
<tt class="docutils literal"><span class="pre">scipy.integrate.quad</span></tt> (precision set to <span class="math">\(10^{-8}\)</span>),
<tt class="docutils literal"><span class="pre">sympy.mpmath.quad</span></tt> (high precision), and a Trapezoidal
rule based on the points in <tt class="docutils literal"><span class="pre">x</span></tt>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares_numerical</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>
                            <span class="n">integration_method</span><span class="o">=</span><span class="s">&#39;scipy&#39;</span><span class="p">,</span>
                            <span class="n">orthogonal_basis</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">scipy.integrate</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">j_limit</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="n">orthogonal_basis</span> <span class="k">else</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j_limit</span><span class="p">):</span>
            <span class="k">print</span> <span class="s">&#39;(</span><span class="si">%d</span><span class="s">,</span><span class="si">%d</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">integration_method</span> <span class="o">==</span> <span class="s">&#39;scipy&#39;</span><span class="p">:</span>
                <span class="n">A_ij</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">j</span><span class="p">),</span>
                    <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">epsabs</span><span class="o">=</span><span class="mf">1E-9</span><span class="p">,</span> <span class="n">epsrel</span><span class="o">=</span><span class="mf">1E-9</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">integration_method</span> <span class="o">==</span> <span class="s">&#39;sympy&#39;</span><span class="p">:</span>
                <span class="n">A_ij</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">j</span><span class="p">),</span>
                    <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
                <span class="n">A_ij</span> <span class="o">=</span> <span class="n">trapezoidal</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_ij</span>

        <span class="k">if</span> <span class="n">integration_method</span> <span class="o">==</span> <span class="s">&#39;scipy&#39;</span><span class="p">:</span>
            <span class="n">b_i</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">i</span><span class="p">),</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">epsabs</span><span class="o">=</span><span class="mf">1E-9</span><span class="p">,</span> <span class="n">epsrel</span><span class="o">=</span><span class="mf">1E-9</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">integration_method</span> <span class="o">==</span> <span class="s">&#39;sympy&#39;</span><span class="p">:</span>
            <span class="n">b_i</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">i</span><span class="p">),</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
            <span class="n">b_i</span> <span class="o">=</span> <span class="n">trapezoidal</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b_i</span>

    <span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="k">if</span> <span class="n">orthogonal_basis</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">c</span>

<span class="k">def</span> <span class="nf">trapezoidal</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dx</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Integrate values by the Trapezoidal rule (mesh size dx).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">dx</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Here is an example on calling the function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">linspace</span><span class="p">,</span> <span class="n">tanh</span><span class="p">,</span> <span class="n">pi</span>

<span class="k">def</span> <span class="nf">psi</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sin</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">pi</span><span class="p">,</span> <span class="mi">501</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">least_squares_numerical</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">pi</span><span class="p">),</span> <span class="n">psi</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>
                               <span class="n">orthogonal_basis</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="the-interpolation-or-collocation-method">
<span id="fem-approx-global-interp"></span><h2>The interpolation (or collocation) method<a class="headerlink" href="#the-interpolation-or-collocation-method" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-11"></span><p id="index-12">The principle of minimizing the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span> is
an intuitive way of computing a best approximation <span class="math">\(u\in V\)</span> to <span class="math">\(f\)</span>.
However, there are other approaches as well.
One is to demand that <span class="math">\(u(x_{i}) = f(x_{i})\)</span> at some selected points
<span class="math">\(x_{i}\)</span>, <span class="math">\(i\in{I}\)</span>:</p>
<div class="math">
\[u(x_{i}) = \sum_{j\in{I}} c_j {\psi}_j(x_{i}) = f(x_{i}),
\quad i\in{I}{\thinspace .}\]</div>
<p>This criterion also gives a linear system
with <span class="math">\(N+1\)</span> unknown coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>:</p>
<div class="math">
\[\sum_{j\in{I}} A_{i,j}c_j = b_i,\quad i\in{I},\]</div>
<p>with</p>
<div class="math">
\[A_{i,j} = {\psi}_j(x_{i}),\]</div>
<div class="math">
\[b_i = f(x_{i}){\thinspace .}\]</div>
<p>This time the coefficient matrix is not symmetric because
<span class="math">\({\psi}_j(x_{i})\neq {\psi}_i(x_{j})\)</span> in general.
The method is often referred to as an <em>interpolation method</em>
since some point values of <span class="math">\(f\)</span> are given (<span class="math">\(f(x_{i})\)</span>) and we
fit a continuous function <span class="math">\(u\)</span> that goes through the <span class="math">\(f(x_{i})\)</span> points.
In this case the <span class="math">\(x_{i}\)</span> points are called <em>interpolation points</em>.
When the same approach is used to approximate differential equations,
one usually applies the name <em>collocation method</em> and
<span class="math">\(x_{i}\)</span> are known as <em>collocation points</em>.</p>
<span class="target" id="index-13"></span><p id="index-14">Given <span class="math">\(f\)</span>  as a <tt class="docutils literal"><span class="pre">sympy</span></tt> symbolic expression <tt class="docutils literal"><span class="pre">f</span></tt>, <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{I}}\)</span>
as a list <tt class="docutils literal"><span class="pre">psi</span></tt>, and a set of points <span class="math">\(\left\{ {x}_i \right\}_{i\in{I}}\)</span>  as a list or array
<tt class="docutils literal"><span class="pre">points</span></tt>, the following Python function sets up and solves the matrix system
for the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="c"># Turn psi and f into Python functions</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">interpolation</span></tt> function is a part of the <tt class="docutils literal"><span class="pre">approx1D</span></tt>
module.</p>
<p>We found it convenient in the above function to turn the expressions <tt class="docutils literal"><span class="pre">f</span></tt> and
<tt class="docutils literal"><span class="pre">psi</span></tt> into ordinary Python functions of <tt class="docutils literal"><span class="pre">x</span></tt>, which can be called with
<tt class="docutils literal"><span class="pre">float</span></tt> values in the list <tt class="docutils literal"><span class="pre">points</span></tt> when building the matrix and
the right-hand side. The alternative is to use the <tt class="docutils literal"><span class="pre">subs</span></tt> method
to substitute the <tt class="docutils literal"><span class="pre">x</span></tt> variable in an expression by an element from
the <tt class="docutils literal"><span class="pre">points</span></tt> list. The following session illustrates both approaches
in a simple setting:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>              <span class="c"># symbolic expression involving x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>               <span class="c"># a value of x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>      <span class="c"># evaluate e for x=p</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>
<span class="go">0.250000000000000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="go">sympy.core.numbers.Float</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">e</span><span class="p">)</span>  <span class="c"># make Python function of e</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">e</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>              <span class="c"># evaluate e(x) for x=p</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="go">float</span>
</pre></div>
</div>
<p>A nice feature of the interpolation or collocation method is that it
avoids computing integrals. However, one has to decide on the location
of the <span class="math">\(x_{i}\)</span> points.  A simple, yet common choice, is to
distribute them uniformly throughout <span class="math">\(\Omega\)</span>.</p>
<div class="section" id="example-1">
<h3>Example  (1)<a class="headerlink" href="#example-1" title="Permalink to this headline">¶</a></h3>
<p>Let us illustrate the interpolation or collocation method by approximating
our parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> by a linear function on <span class="math">\(\Omega=[1,2]\)</span>,
using two collocation points <span class="math">\(x_0=1+1/3\)</span> and <span class="math">\(x_1=1+2/3\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting linear system becomes</p>
<div class="math">
\[\begin{split}\left(\begin{array}{ll}
1 &amp; 4/3\\
1 &amp; 5/3\\
\end{array}\right)
\left(\begin{array}{l}
c_0\\
c_1\\
\end{array}\right)
=
\left(\begin{array}{l}
1/9\\
31/9\\
\end{array}\right)\end{split}\]</div>
<p>with solution <span class="math">\(c_0=-119/9\)</span> and <span class="math">\(c_1=10\)</span>.
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></a> (left) shows the resulting
approximation <span class="math">\(u=-119/9 + 10x\)</span>.
We can easily test other interpolation points, say <span class="math">\(x_0=1\)</span> and <span class="math">\(x_1=2\)</span>.
This changes the line quite significantly, see
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></a> (right).</p>
<div class="figure" id="fem-approx-global-linear-interp-fig1">
<img alt="_images/parabola_inter1.png" src="_images/parabola_inter1.png" style="width: 800px;" />
<p class="caption"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></p>
</div>
</div>
</div>
<div class="section" id="lagrange-polynomials">
<span id="fem-approx-global-lagrange"></span><h2>Lagrange polynomials<a class="headerlink" href="#lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-15">In the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a> we explain the advantage with having
a diagonal matrix: formulas for the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> can
then be derived by hand. For an interpolation/collocation method a
diagonal matrix implies that
<span class="math">\({\psi}_j(x_{i}) = 0\)</span> if <span class="math">\(i\neq j\)</span>. One set of basis functions <span class="math">\({\psi}_i(x)\)</span>
with this property is the <em>Lagrange interpolating polynomials</em>,
or just <em>Lagrange polynomials</em>. (Although the functions are named
after Lagrange, they were first discovered by Waring in 1779,
rediscovered by Euler in 1783, and published by Lagrange in 1795.)
The Lagrange polynomials have the form</p>
<div class="math" id="equation-fem:approx:global:Lagrange:poly">
<span class="eqno">(21)</span>\[     {\psi}_i(x) =
     \prod_{j=0,j\neq i}^N
     \frac{x-x_{j}}{x_{i}-x_{j}}
     = \frac{x-x_0}{x_{i}-x_0}\cdots\frac{x-x_{i-1}}{x_{i}-x_{i-1}}\frac{x-x_{i+1}}{x_{i}-x_{i+1}}
     \cdots\frac{x-x_N}{x_{i}-x_N},\]</div>
<p>for <span class="math">\(i\in{I}\)</span>.
We see from <a href="#equation-fem:approx:global:Lagrange:poly">(21)</a> that all the <span class="math">\({\psi}_i\)</span>
functions are polynomials of degree <span class="math">\(N\)</span> which have the property</p>
<div class="math" id="equation-fem:inter:prop">
<span id="index-16"></span><span class="eqno">(22)</span>\[\begin{split}     {\psi}_i(x_s) = \delta_{is},\quad \delta_{is} =
     \left\lbrace\begin{array}{ll}
     1, &amp; i=s,\\
     0, &amp; i\neq s,
     \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_s\)</span> is an interpolation/collocation point.
Here we have used the <em>Kronecker delta</em> symbol <span class="math">\(\delta_{is}\)</span>.
This property implies that <span class="math">\(A_{i,j}=0\)</span> for <span class="math">\(i\neq j\)</span> and
<span class="math">\(A_{i,j}=1\)</span> when <span class="math">\(i=j\)</span>. The solution of the linear system is
them simply</p>
<div class="math">
\[c_i = f(x_{i}),\quad i\in{I},\]</div>
<p>and</p>
<div class="math">
\[u(x) = \sum_{j\in{I}} f(x_{i}){\psi}_i(x){\thinspace .}\]</div>
<p>The following function computes the Lagrange interpolating polynomial
<span class="math">\({\psi}_i(x)\)</span>, given the interpolation points <span class="math">\(x_{0},\ldots,x_{N}\)</span> in
the list or array <tt class="docutils literal"><span class="pre">points</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>The next function computes a complete basis using equidistant points throughout
<span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span>
</pre></div>
</div>
<p>When <tt class="docutils literal"><span class="pre">x</span></tt> is an <tt class="docutils literal"><span class="pre">sm.Symbol</span></tt> object, we let the
spacing between
the interpolation points, <tt class="docutils literal"><span class="pre">h</span></tt>, be a <tt class="docutils literal"><span class="pre">sympy</span></tt> rational number
for nice end results in the formulas for <span class="math">\({\psi}_i\)</span>.
The other case, when <tt class="docutils literal"><span class="pre">x</span></tt> is a plain Python <tt class="docutils literal"><span class="pre">float</span></tt>,
signifies numerical computing, and then we let <tt class="docutils literal"><span class="pre">h</span></tt> be a floating-point
number.
Observe that the <tt class="docutils literal"><span class="pre">Lagrange_polynomial</span></tt> function works equally well
in the symbolic and numerical case - just think of <tt class="docutils literal"><span class="pre">x</span></tt> being an
<tt class="docutils literal"><span class="pre">sm.Symbol</span></tt> object or a Python <tt class="docutils literal"><span class="pre">float</span></tt>.
A little interactive session illustrates the difference between symbolic
and numerical computing of the basis functions and points:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">points</span>
<span class="go">[0, 1/2, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span>
<span class="go">[(1 - x)*(1 - 2*x), 2*x*(2 - 2*x), -x*(1 - 2*x)]</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c"># numerical computing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">points</span>
<span class="go">[0.0, 0.5, 1.0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span>
<span class="go">[-0.0, 1.0, 0.0]</span>
</pre></div>
</div>
<p>The Lagrange polynomials are very much used in finite element methods
because of their property <a href="#equation-fem:inter:prop">(22)</a>.</p>
<div class="section" id="approximation-of-a-polynomial">
<h3>Approximation of a polynomial<a class="headerlink" href="#approximation-of-a-polynomial" title="Permalink to this headline">¶</a></h3>
<p>The Galerkin or least squares method lead to an exact approximation
if <span class="math">\(f\)</span> lies in the space spanned by the basis functions. It could be
interest to see how the interpolation method with Lagrange
polynomials as basis is able to approximate a polynomial, e.g.,
a parabola. Running</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
</pre></div>
</div>
<p>shows the result that up to <tt class="docutils literal"><span class="pre">N=4</span></tt> we achieve an exact approximation,
and then round-off errors start to grow, such that
<tt class="docutils literal"><span class="pre">N=15</span></tt> leads to a 15-degree polynomial for <span class="math">\(u\)</span> where
the coefficients in front of <span class="math">\(x^r\)</span> for <span class="math">\(r&gt;2\)</span> are
of size <span class="math">\(10^{-5}\)</span> and smaller.</p>
</div>
<div class="section" id="successful-example">
<h3>Successful example<a class="headerlink" href="#successful-example" title="Permalink to this headline">¶</a></h3>
<p>Trying out the Lagrange polynomial basis for approximating
<span class="math">\(f(x)=\sin 2\pi x\)</span> on <span class="math">\(\Omega =[0,1]\)</span> with the least squares
and the interpolation techniques can be done by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-sine-ls-colloc"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3</em></a> shows the results.
There is little difference between the least squares and the interpolation
technique. Increasing <span class="math">\(N\)</span> gives visually better approximations.</p>
<div class="figure" id="fem-approx-global-lagrange-fig-sine-ls-colloc">
<img alt="_images/Lagrange_ls_interp_sin_41.png" src="_images/Lagrange_ls_interp_sin_41.png" style="width: 800px;" />
<p class="caption"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3</em></p>
</div>
</div>
<div class="section" id="less-successful-example">
<span id="index-17"></span><h3>Less successful example<a class="headerlink" href="#less-successful-example" title="Permalink to this headline">¶</a></h3>
<p>The next example concerns interpolating <span class="math">\(f(x)=|1-2x|\)</span> on
<span class="math">\(\Omega =[0,1]\)</span> using Lagrange polynomials. Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></a> shows a peculiar effect: the approximation starts to oscillate
more and more as <span class="math">\(N\)</span> grows. This numerical artifact is not surprising
when looking at the individual Lagrange polynomials. Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></a> shows two such polynomials, <span class="math">\(\psi_2(x)\)</span> and
<span class="math">\(\psi_7(x)\)</span>, both of degree 11 and computed from uniformly spaced
points <span class="math">\(x_{x_i}=i/11\)</span>, <span class="math">\(i=0,\ldots,11\)</span>, marked with circles.
We clearly see the property of Lagrange polynomials:
<span class="math">\(\psi_2(x_{i})=0\)</span> and <span class="math">\(\psi_7(x_{i})=0\)</span> for all <span class="math">\(i\)</span>,
except <span class="math">\(\psi_2(x_{2})=1\)</span> and <span class="math">\(\psi_7(x_{7})=1\)</span>.
The most striking feature, however, is the significant oscillation
near the boundary. The reason is easy to understand:
since we force the functions to zero at so many points,
a polynomial of high degree is forced to oscillate between
the points.
The phenomenon is named <em>Runge&#8217;s phenomenon</em> and you can read
a more detailed explanation on <a class="reference external" href="http://en.wikipedia.org/wiki/Runge%27s_phenomenon">Wikipedia</a>.</p>
</div>
<div class="section" id="remedy-for-strong-oscillations">
<span id="index-18"></span><h3>Remedy for strong oscillations<a class="headerlink" href="#remedy-for-strong-oscillations" title="Permalink to this headline">¶</a></h3>
<p>The oscillations can be reduced by a more clever choice of
interpolation points, called the <em>Chebyshev nodes</em>:</p>
<div class="math">
\[x_{i} = \frac{1}{2} (a+b) + \frac{1}{2}(b-a)\cos\left( \frac{2i+1}{2(N+1)}pi\right),\quad i=0\ldots,N,\]</div>
<p>on the interval <span class="math">\(\Omega = [a,b]\)</span>.
Here is a flexible version of the <tt class="docutils literal"><span class="pre">Lagrange_polynomials_01</span></tt> function above,
valid for any interval <span class="math">\(\Omega =[a,b]\)</span> and with the possibility to generate
both uniformly distributed points and Chebyshev nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">point_distribution</span><span class="o">=</span><span class="s">&#39;uniform&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s">&#39;uniform&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s">&#39;Chebyshev&#39;</span><span class="p">:</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">Chebyshev_nodes</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span>

<span class="k">def</span> <span class="nf">Chebyshev_nodes</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">cos</span><span class="p">,</span> <span class="n">pi</span>
    <span class="k">return</span> <span class="p">[</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">cos</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">pi</span><span class="p">)</span> \
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>All the functions computing Lagrange polynomials listed
above are found in the module file <tt class="docutils literal"><span class="pre">Lagrange.py</span></tt>.
Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></a> shows the improvement of
using Chebyshev nodes (compared with Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></a>). The reason is that the corresponding Lagrange
polynomials have much smaller oscillations as seen in
Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-osc"><em>Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles)</em></a>
(compare with Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></a>).</p>
<p>Another cure for undesired oscillation of higher-degree interpolating
polynomials is to use lower-degree Lagrange
polynomials on many small patches of the domain, which is the idea
pursued in the finite element method. For instance, linear Lagrange
polynomials on <span class="math">\([0,1/2]\)</span> and <span class="math">\([1/2,1]\)</span> would yield a perfect
approximation to <span class="math">\(f(x)=|1-2x|\)</span> on <span class="math">\(\Omega = [0,1]\)</span>
since <span class="math">\(f\)</span> is piecewise linear.</p>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-unif-7-14">
<img alt="_images/Lagrange_interp_abs_8_151.png" src="_images/Lagrange_interp_abs_8_151.png" style="width: 800px;" />
<p class="caption"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-unif-osc">
<img alt="_images/Lagrange_basis_121.png" src="_images/Lagrange_basis_121.png" style="width: 400px;" />
<p class="caption"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-cheb-7-14">
<img alt="_images/Lagrange_interp_abs_Cheb_8_151.png" src="_images/Lagrange_interp_abs_Cheb_8_151.png" style="width: 800px;" />
<p class="caption"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-cheb-osc">
<img alt="_images/Lagrange_basis_121.png" src="_images/Lagrange_basis_121.png" style="width: 400px;" />
<p class="caption"><em>Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles)</em></p>
</div>
<p>How does the least squares or projection methods work with Lagrange
polynomials?
Unfortunately, <tt class="docutils literal"><span class="pre">sympy</span></tt> has problems integrating the <span class="math">\(f(x)=|1-2x|\)</span>
function times a polynomial. Other choices of <span class="math">\(f(x)\)</span> can also
make the symbolic integration fail. Therefore, we should extend
the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function such that it falls back on
numerical integration if the symbolic integration is unsuccessful.
In the latter case, the returned value from <tt class="docutils literal"><span class="pre">sympy</span></tt>&#8216;s
<tt class="docutils literal"><span class="pre">integrate</span></tt> function is an object of type <tt class="docutils literal"><span class="pre">Integral</span></tt>.
We can test on this type and utilize the <tt class="docutils literal"><span class="pre">mpmath</span></tt> module in
<tt class="docutils literal"><span class="pre">sympy</span></tt> to perform numerical integration of high precision.
Here is the code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="c"># Could not integrate symbolically, fallback</span>
                <span class="c"># on numerical integration with mpmath.quad</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="finite-element-basis-functions">
<span id="fem-approx-fe"></span><h1>Finite element basis functions<a class="headerlink" href="#finite-element-basis-functions" title="Permalink to this headline">¶</a></h1>
<p>The specific basis functions exemplified in the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> are in general nonzero on the entire domain
<span class="math">\(\Omega\)</span>, see Figure <a class="reference internal" href="#fem-approx-fe-fig-u-sin"><em>A function resulting from adding two sine basis functions</em></a> for an example
where we plot <span class="math">\(\psi_0(x)=\sin\frac{1}{2}\pi x\)</span> and
<span class="math">\(\psi_1(x)=\sin 2\pi x\)</span> together with a possible sum
<span class="math">\(u(x)=4\psi_0(x) - \frac{1}{2}\psi_1(x)\)</span>. We shall
now turn the attention to basis functions that have <em>compact support</em>,
meaning that they are nonzero on only a small portion of
<span class="math">\(\Omega\)</span>. Moreover, we shall restrict the functions to be <em>piecewise
polynomials</em>. This means that the domain is split into subdomains and
the function is a polynomial on one or more subdomains, see Figure
<a class="reference internal" href="#fem-approx-fe-fig-u-fe"><em>A function resulting from adding three local piecewise linear (hat) functions</em></a> for a sketch involving locally defined
hat functions that make <span class="math">\(u=\sum_jc_j{\psi}_j\)</span> piecewise linear. At
the boundaries between subdomains one normally forces continuity of
the function only so that when connecting two polynomials from two
subdomains, the derivative becomes discontinuous. These type
of basis functions are fundamental in the finite element method.</p>
<div class="figure" id="fem-approx-fe-fig-u-sin">
<img alt="_images/u_example_sin1.png" src="_images/u_example_sin1.png" style="width: 600px;" />
<p class="caption"><em>A function resulting from adding two sine basis functions</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-u-fe">
<img alt="_images/u_example_P11.png" src="_images/u_example_P11.png" style="width: 600px;" />
<p class="caption"><em>A function resulting from adding three local piecewise linear (hat) functions</em></p>
</div>
<p>We first introduce the concepts of elements and nodes in a simplistic fashion
as often met in the literature. Later, we shall generalize the concept
of an element, which is a necessary step to treat a wider class of
approximations within the family of finite element methods.
The generalization is also compatible with
the concepts used in the <a class="reference external" href="http://fenicsproject.org">FEniCS</a> finite
element software.</p>
<div class="section" id="elements-and-nodes">
<span id="fem-approx-fe-def-elements-nodes"></span><h2>Elements and nodes<a class="headerlink" href="#elements-and-nodes" title="Permalink to this headline">¶</a></h2>
<p>Let us divide the interval <span class="math">\(\Omega\)</span> on which <span class="math">\(f\)</span> and <span class="math">\(u\)</span> are defined
into non-overlapping subintervals <span class="math">\(\Omega^{(e)}\)</span>, <span class="math">\(e=0,\ldots,N_e\)</span>:</p>
<div class="math">
\[\Omega = \Omega^{(0)}\cup \cdots \cup \Omega^{(N_e)}{\thinspace .}\]</div>
<p>We shall for now
refer to <span class="math">\(\Omega^{(e)}\)</span> as an <em>element</em>, having number <span class="math">\(e\)</span>.
On each element we introduce a set of points called <em>nodes</em>.
For now we assume that the nodes are uniformly spaced throughout the
element and that the boundary points of the elements are also nodes.
The nodes are given numbers both within an element and in the global
domain. These are
referred to as <em>local</em> and <em>global</em> node numbers, respectively.
Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p1"><em>Finite element mesh with 5 elements and 6 nodes</em></a> shows
element boundaries with small vertical lines, nodes as small disks,
element numbers in circles, and global node numbers under the nodes.</p>
<div class="figure" id="fem-approx-fe-def-elements-nodes-fig-p1">
<img alt="_images/fe_mesh1D1.png" src="_images/fe_mesh1D1.png" style="width: 500px;" />
<p class="caption"><em>Finite element mesh with 5 elements and 6 nodes</em></p>
</div>
<span class="target" id="index-19"></span><p id="index-20">Nodes and elements uniquely define a <em>finite element mesh</em>, which is our
discrete representation of the domain in the computations.
A common special case is that of a <em>uniformly partitioned mesh</em> where
each element has the same length and the distance between nodes is constant.</p>
<div class="section" id="example-2">
<h3>Example  (2)<a class="headerlink" href="#example-2" title="Permalink to this headline">¶</a></h3>
<p>On <span class="math">\(\Omega =[0,1]\)</span> we may introduce two elements,
<span class="math">\(\Omega^{(0)}=[0,0.4]\)</span> and <span class="math">\(\Omega^{(1)}=[0.4,1]\)</span>. Furthermore,
let us introduce three nodes
per element, equally spaced within each element.
Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p2"><em>Finite element mesh with 2 elements and 5 nodes</em></a> shows the
mesh.
The three nodes in element number 0 are <span class="math">\(x_0=0\)</span>, <span class="math">\(x_1=0.2\)</span>, and <span class="math">\(x_2=0.4\)</span>.
The local and global node numbers are here equal.
In element number 1, we have the local nodes <span class="math">\(x_0=0.4\)</span>, <span class="math">\(x_1=0.7\)</span>, and <span class="math">\(x_2=1\)</span>
and the corresponding
global nodes <span class="math">\(x_2=0.4\)</span>, <span class="math">\(x_3=0.7\)</span>, and <span class="math">\(x_4=1\)</span>. Note that
the global node <span class="math">\(x_2=0.4\)</span> is shared by the two elements.</p>
<div class="figure" id="fem-approx-fe-def-elements-nodes-fig-p2">
<img alt="_images/fe_mesh1D_P21.png" src="_images/fe_mesh1D_P21.png" style="width: 500px;" />
<p class="caption"><em>Finite element mesh with 2 elements and 5 nodes</em></p>
</div>
<p>For the purpose of implementation, we introduce two lists or arrays:
<tt class="docutils literal"><span class="pre">nodes</span></tt> for storing the coordinates of the nodes, with the
global node numbers as indices, and <tt class="docutils literal"><span class="pre">elements</span></tt> for holding
the global node numbers in each element, with the local node numbers
as indices. The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists for the sample mesh
above take the form</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
</pre></div>
</div>
<p>Looking up the coordinate of local node number 2 in element 1
is here done by <tt class="docutils literal"><span class="pre">nodes[elements[1][2]]</span></tt> (recall that nodes and
elements start their numbering at 0).</p>
<p>The numbering of elements and nodes does not need to be regular.
Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p1-irregular"><em>Example on irregular numbering of elements and nodes</em></a> shows
and example corresponding to</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<div class="figure" id="fem-approx-fe-def-elements-nodes-fig-p1-irregular">
<img alt="_images/fe_mesh1D_random_numbering1.png" src="_images/fe_mesh1D_random_numbering1.png" style="width: 500px;" />
<p class="caption"><em>Example on irregular numbering of elements and nodes</em></p>
</div>
</div>
</div>
<div class="section" id="the-basis-functions">
<h2>The basis functions<a class="headerlink" href="#the-basis-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="construction-principles">
<h3>Construction principles<a class="headerlink" href="#construction-principles" title="Permalink to this headline">¶</a></h3>
<p>Finite element basis functions are in this text recognized by
the notation <span class="math">\({\varphi}_i(x)\)</span>, where the index now in the beginning corresponds to
a global node number. In the current approximation problem we shall
simply take <span class="math">\({\psi}_i = {\varphi}_i\)</span>.</p>
<p>Let <span class="math">\(i\)</span> be the global node number corresponding to local node <span class="math">\(r\)</span> in
element number <span class="math">\(e\)</span>.  The finite element basis functions <span class="math">\({\varphi}_i\)</span>
are now defined as follows.</p>
<blockquote>
<div><ul class="simple">
<li>If local node number <span class="math">\(r\)</span> is not on the boundary of the element,
take <span class="math">\({\varphi}_i(x)\)</span> to be the Lagrange
polynomial that is 1 at the local node number <span class="math">\(r\)</span> and zero
at all other nodes in the element. On all other elements, <span class="math">\({\varphi}_i=0\)</span>.</li>
<li>If local node number <span class="math">\(r\)</span> is on the boundary of the element,
let <span class="math">\({\varphi}_i\)</span> be made up of the Lagrange polynomial that is 1 at this node
in element number <span class="math">\(e\)</span> and its neighboring element.
On all other elements, <span class="math">\({\varphi}_i=0\)</span>.</li>
</ul>
</div></blockquote>
<p>A visual impression of three such basis functions are given in
Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>.</p>
<div class="figure" id="fem-approx-fe-fig-p2">
<img alt="_images/mpl_fe_basis_p2_4e_lab1.png" src="_images/mpl_fe_basis_p2_4e_lab1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise quadratic basis functions associated with nodes in element 1</em></p>
</div>
</div>
<div class="section" id="properties-of">
<h3>Properties of <span class="math">\({\varphi}_i\)</span><a class="headerlink" href="#properties-of" title="Permalink to this headline">¶</a></h3>
<p>The construction of basis functions according to the principles above
lead to two important properties of <span class="math">\({\varphi}_i(x)\)</span>. First,</p>
<div class="math" id="equation-fem:approx:fe:phi:prop1">
<span id="index-21"></span><span class="eqno">(23)</span>\[\begin{split}     {\varphi}_i(x_{j}) =\delta_{ij},\quad \delta_{ij} =
     \left\lbrace\begin{array}{ll}
     1, &amp; i=j,\\
     0, &amp; i\neq j,
     \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_{j}\)</span> is a node in the mesh with global node number <span class="math">\(j\)</span>.
The
result <span class="math">\({\varphi}_i(x_{j}) =\delta_{ij}\)</span> arises
because the Lagrange polynomials are constructed to have
exactly this property.
The property also implies a convenient interpretation of <span class="math">\(c_i\)</span>
as the value of <span class="math">\(u\)</span> at node <span class="math">\(i\)</span>. To show this, we expand <span class="math">\(u\)</span>
in the usual way as <span class="math">\(\sum_jc_j{\psi}_j\)</span> and choose <span class="math">\({\psi}_i = {\varphi}_i\)</span>:</p>
<div class="math">
\[u(x_{i}) = \sum_{j\in{I}} c_j {\psi}_j (x_{i}) =
\sum_{j\in{I}} c_j {\varphi}_j (x_{i}) = c_i {\varphi}_i (x_{i}) = c_i
{\thinspace .}\]</div>
<p>Because of this interpretation,
the coefficient <span class="math">\(c_i\)</span> is by many named <span class="math">\(u_i\)</span> or <span class="math">\(U_i\)</span>.</p>
<p>Second,
<span class="math">\({\varphi}_i(x)\)</span> is mostly zero throughout the domain:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\({\varphi}_i(x) \neq 0\)</span> only on those elements that contain global node <span class="math">\(i\)</span>,</li>
<li><span class="math">\({\varphi}_i(x){\varphi}_j(x) \neq 0\)</span> if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are global node
numbers in the same element.</li>
</ul>
</div></blockquote>
<p>Since <span class="math">\(A_{i,j}\)</span> is the integral of
<span class="math">\({\varphi}_i{\varphi}_j\)</span> it means that
<em>most of the elements in the coefficient matrix will be zero</em>.
We will come back to these properties and use
them actively in computations to save memory and CPU time.</p>
<p>We let each element have <span class="math">\(d+1\)</span> nodes, resulting in local Lagrange
polynomials of degree <span class="math">\(d\)</span>. It is not a requirement to have the same
<span class="math">\(d\)</span> value in each element, but for now we will assume so.</p>
</div>
</div>
<div class="section" id="example-on-piecewise-quadratic-finite-element-functions">
<h2>Example on piecewise quadratic finite element functions<a class="headerlink" href="#example-on-piecewise-quadratic-finite-element-functions" title="Permalink to this headline">¶</a></h2>
<p>Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em> illustrates how piecewise
quadratic basis functions can look like (<span class="math">\(d=2\)</span>). We work with the
domain <span class="math">\(\Omega = [0,1]\)</span> divided into four equal-sized elements, each having
three nodes.
The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists in this particular example become</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.375</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.625</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.875</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-p2-mesh"><em>Sketch of mesh with 4 elements and 3 nodes per element</em></a> sketches the mesh and the
numbering.
Nodes are marked with circles on the <span class="math">\(x\)</span> axis and
element boundaries are marked with vertical dashed lines
in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>.</p>
<div class="figure" id="id1">
<img alt="_images/mpl_fe_basis_p2_4e_lab1.png" src="_images/mpl_fe_basis_p2_4e_lab1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise quadratic basis functions associated with nodes in element 1</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-p2-mesh">
<img alt="_images/fe_mesh1D_P21.png" src="_images/fe_mesh1D_P21.png" style="width: 500px;" />
<p class="caption"><em>Sketch of mesh with 4 elements and 3 nodes per element</em></p>
</div>
<p>Let us explain in detail how the basis functions are constructed
according to the principles.
Consider element number 1 in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>,
<span class="math">\(\Omega^{(1)}=[0.25, 0.5]\)</span>, with local nodes
0, 1, and 2 corresponding to global nodes 2, 3, and 4.
The coordinates of these nodes are
<span class="math">\(0.25\)</span>, <span class="math">\(0.375\)</span>, and <span class="math">\(0.5\)</span>, respectively.
We define three Lagrange
polynomials on this element:</p>
<ol class="arabic simple">
<li>The polynomial that is 1 at local node 1
(<span class="math">\(x=0.375\)</span>, global node 3) makes up the basis function
<span class="math">\({\varphi}_3(x)\)</span> over this element,
with <span class="math">\({\varphi}_3(x)=0\)</span> outside the element.</li>
<li>The Lagrange polynomial that is 1 at local node 0 is the &#8220;right
part&#8221; of the global basis function
<span class="math">\({\varphi}_2(x)\)</span>. The &#8220;left part&#8221; of <span class="math">\({\varphi}_2(x)\)</span> consists of
a Lagrange polynomial associated with local node 2 in
the neighboring element <span class="math">\(\Omega^{(0)}=[0, 0.25]\)</span>.</li>
<li>Finally, the polynomial that is 1 at local node 2 (global node 4)
is the &#8220;left part&#8221; of the global basis function <span class="math">\({\varphi}_4(x)\)</span>.
The &#8220;right part&#8221; comes from the Lagrange polynomial that is 1 at
local node 0 in the neighboring element <span class="math">\(\Omega^{(2)}=[0.5, 0.75]\)</span>.</li>
</ol>
<p>As mentioned earlier,
any global basis function <span class="math">\({\varphi}_i(x)\)</span> is zero on elements that
do not contain the node with global node number <span class="math">\(i\)</span>.</p>
<p>The other global functions associated with internal
nodes, <span class="math">\({\varphi}_1\)</span>, <span class="math">\({\varphi}_5\)</span>, and <span class="math">\({\varphi}_7\)</span>, are all of the
same shape as the drawn <span class="math">\({\varphi}_3\)</span>, while the global basis functions
associated with shared nodes also have the same shape, provided the
elements are of the same length.</p>
<div class="figure" id="fem-approx-fe-fig-p1">
<img alt="_images/mpl_fe_basis_p1_4e_lab1.png" src="_images/mpl_fe_basis_p1_4e_lab1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></p>
</div>
</div>
<div class="section" id="example-on-piecewise-linear-finite-element-functions">
<h2>Example on piecewise linear finite element functions<a class="headerlink" href="#example-on-piecewise-linear-finite-element-functions" title="Permalink to this headline">¶</a></h2>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a> shows
piecewise linear basis functions (<span class="math">\(d=1\)</span>). Also here we have four elements on
<span class="math">\(\Omega = [0,1]\)</span>. Consider the element <span class="math">\(\Omega^{(1)}=[0.25,0.5]\)</span>.
Now there are no internal nodes in the elements so that all basis
functions are associated with nodes at the element boundaries and hence
made up of two Lagrange polynomials from neighboring elements.
For example, <span class="math">\({\varphi}_1(x)\)</span> results from the Lagrange polynomial in
element 0 that is 1 at local node 1 and 0 at local node 0, combined with
the Lagrange polynomial in
element 1 that is 1 at local node 0 and 0 at local node 1.
The other basis functions are constructed similarly.</p>
<p>Explicit mathematical formulas are needed for <span class="math">\({\varphi}_i(x)\)</span> in computations.
In the
piecewise linear case, one can show that</p>
<div class="math" id="equation-fem:approx:fe:phi:1:formula1">
<span class="eqno">(24)</span>\[\begin{split}     {\varphi}_i(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     (x - x_{i-1})/(x_{i} - x_{i-1}),
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     1 -
     (x - x_{i})/(x_{i+1} - x_{i}),
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}{\thinspace .}  \end{array}
     \right.\end{split}\]</div>
<p>Here, <span class="math">\(x_{j}\)</span>, <span class="math">\(j=i-1,i,i+1\)</span>, denotes the coordinate of node <span class="math">\(j\)</span>.
For elements of equal length <span class="math">\(h\)</span> the formulas can be simplified to</p>
<div class="math" id="equation-fem:approx:fe:phi:1:formula2">
<span class="eqno">(25)</span>\[\begin{split}     {\varphi}_i(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     (x - x_{i-1})/h,
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     1 -
     (x - x_{i})/h,
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}
     \end{array}
     \right.\end{split}\]</div>
</div>
<div class="section" id="example-on-piecewise-cubic-finite-element-basis-functions">
<h2>Example on piecewise cubic finite element basis functions<a class="headerlink" href="#example-on-piecewise-cubic-finite-element-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>Piecewise cubic basis functions can be defined by introducing four
nodes per element. Figure <a class="reference internal" href="#fem-approx-fe-fig-p3"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></a> shows
examples on <span class="math">\({\varphi}_i(x)\)</span>, <span class="math">\(i=3,4,5,6\)</span>, associated with element number 1.
Note that <span class="math">\({\varphi}_4\)</span> and <span class="math">\({\varphi}_5\)</span> are nonzero on element number 1,
while
<span class="math">\({\varphi}_3\)</span> and <span class="math">\({\varphi}_6\)</span> are made up of Lagrange polynomials on two
neighboring elements.</p>
<div class="figure" id="fem-approx-fe-fig-p3">
<img alt="_images/mpl_fe_basis_p3_4e1.png" src="_images/mpl_fe_basis_p3_4e1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></p>
</div>
<span class="target" id="index-22"></span><span class="target" id="index-23"></span><p id="index-24">We see that all the piecewise linear basis functions have the same
&#8220;hat&#8221; shape. They are naturally referred to as <em>hat functions</em>,
also called <em>chapeau functions</em>.
The piecewise quadratic functions in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>
are seen to be of two types. &#8220;Rounded hats&#8221; associated with internal
nodes in the elements and some more &#8220;sombrero&#8221; shaped hats associated
with element boundary nodes. Higher-order basis functions also have
hat-like shapes, but the functions have pronounced oscillations in addition,
as illustrated in Figure <a class="reference internal" href="#fem-approx-fe-fig-p3"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></a>.</p>
<span class="target" id="index-25"></span><span class="target" id="index-26"></span><span class="target" id="index-27"></span><p id="index-28">A common terminology is to speak about <em>linear elements</em> as
elements with two local nodes associated with
piecewise linear basis functions. Similarly, <em>quadratic elements</em> and
<em>cubic elements</em> refer to piecewise quadratic or cubic functions
over elements with three or four local nodes, respectively.
Alternative names, frequently used later, are P1 elements for linear
elements, P2 for quadratic elements, and so forth: Pd signifies
degree <span class="math">\(d\)</span> of the polynomial basis functions.</p>
</div>
<div class="section" id="calculating-the-linear-system">
<span id="fem-approx-global-linearsystem"></span><h2>Calculating the linear system<a class="headerlink" href="#calculating-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>The elements in the coefficient matrix and right-hand side are given
by the formulas <a href="#equation-fem:approx:Aij">(17)</a> and <a href="#equation-fem:approx:bi">(18)</a>, but
now the choice of <span class="math">\({\psi}_i\)</span> is <span class="math">\({\varphi}_i\)</span>.
Consider P1 elements where <span class="math">\({\varphi}_i(x)\)</span> piecewise linear. Nodes and elements
numbered consecutively from left to right in a uniformly partitioned
mesh imply the nodes</p>
<div class="math">
\[x_i=i h,\quad i=0,\ldots,N,\]</div>
<p>and the elements</p>
<div class="math">
\[\Omega^{(i)} = [x_{i},x_{i+1}] = [i h, (i+1)h],\quad
i=0,\ldots,N_e=N-1
{\thinspace .}\]</div>
<p>We have in this case <span class="math">\(N\)</span> elements and <span class="math">\(N+1\)</span> nodes,
and <span class="math">\(\Omega=[x_{0},x_{N}]\)</span>.
The formula for <span class="math">\({\varphi}_i(x)\)</span> is given by
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a> and a graphical illustration is
provided in Figures <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a> and
<a class="reference internal" href="#fem-approx-fe-fig-phi-i-im1"><em>Illustration of two neighboring linear (hat) functions with general node numbers</em></a>. First we clearly see
from the figures the very important property
<span class="math">\({\varphi}_i(x){\varphi}_j(x)\neq 0\)</span> if and only if <span class="math">\(j=i-1\)</span>, <span class="math">\(j=i\)</span>, or
<span class="math">\(j=i+1\)</span>, or alternatively expressed, if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are
nodes in the same element. Otherwise, <span class="math">\({\varphi}_i\)</span> and <span class="math">\({\varphi}_j\)</span> are
too distant to have an overlap and consequently their product vanishes.</p>
<div class="figure" id="fem-approx-fe-fig-phi-2-3">
<img alt="_images/fe_mesh1D_phi_2_31.png" src="_images/fe_mesh1D_phi_2_31.png" style="width: 500px;" />
<p class="caption"><em>Illustration of the piecewise linear basis functions corresponding to global node 2 and 3</em></p>
</div>
<div class="section" id="calculating-a-specific-matrix-entry">
<h3>Calculating a specific matrix entry<a class="headerlink" href="#calculating-a-specific-matrix-entry" title="Permalink to this headline">¶</a></h3>
<p>Let us calculate the specific matrix entry <span class="math">\(A_{2,3} = \int_\Omega
{\varphi}_2{\varphi}_3{\, \mathrm{d}x}\)</span>. Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-2-3"><em>Illustration of the piecewise linear basis functions corresponding to global node 2 and 3</em></a>
shows how <span class="math">\({\varphi}_2\)</span> and <span class="math">\({\varphi}_3\)</span> look like. We realize
from this figure that the product <span class="math">\({\varphi}_2{\varphi}_3\neq 0\)</span>
only over element 2, which contains node 2 and 3.
The particular formulas for <span class="math">\({\varphi}_{2}(x)\)</span> and <span class="math">\({\varphi}_3(x)\)</span> on
<span class="math">\([x_{2},x_{3}]\)</span> are found from <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>.
The function
<span class="math">\({\varphi}_3\)</span> has positive slope over <span class="math">\([x_{2},x_{3}]\)</span> and corresponds
to the interval <span class="math">\([x_{i-1},x_{i}]\)</span> in
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>. With <span class="math">\(i=3\)</span> we get</p>
<div class="math">
\[{\varphi}_3(x) = (x-x_2)/h,\]</div>
<p>while <span class="math">\({\varphi}_2(x)\)</span> has negative slope over <span class="math">\([x_{2},x_{3}]\)</span>
and corresponds to setting <span class="math">\(i=2\)</span> in <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>,</p>
<div class="math">
\[{\varphi}_2(x) = 1- (x-x_2)/h{\thinspace .}\]</div>
<p>We can now easily integrate,</p>
<div class="math">
\[A_{2,3} = \int_\Omega {\varphi}_2{\varphi}_{3}{\, \mathrm{d}x} =
\int_{x_{2}}^{x_{3}}
\left(1 - \frac{x - x_{2}}{h}\right) \frac{x - x_{2}}{h}
 {\, \mathrm{d}x} = \frac{h}{6}{\thinspace .}\]</div>
<p>The diagonal entry in the coefficient matrix becomes</p>
<div class="math">
\[A_{2,2} =
\int_{x_{1}}^{x_{2}}
\left(\frac{x - x_{1}}{h}\right)^2{\, \mathrm{d}x} +
\int_{x_{2}}^{x_{3}}
\left(1 - \frac{x - x_{2}}{h}\right)^2{\, \mathrm{d}x}
= \frac{h}{3}{\thinspace .}\]</div>
<p>The entry <span class="math">\(A_{2,1}\)</span> has an
the integral that is geometrically similar to the situation in
Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-2-3"><em>Illustration of the piecewise linear basis functions corresponding to global node 2 and 3</em></a>, so we get
<span class="math">\(A_{2,1}=h/6\)</span>.</p>
</div>
<div class="section" id="calculating-a-general-row-in-the-matrix">
<h3>Calculating a general row in the matrix<a class="headerlink" href="#calculating-a-general-row-in-the-matrix" title="Permalink to this headline">¶</a></h3>
<p>We can now generalize the calculation of matrix entries to
a general row number <span class="math">\(i\)</span>. The entry
<span class="math">\(A_{i,i-1}=\int_\Omega{\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}\)</span> involves
hat functions as depicted in
Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-i-im1"><em>Illustration of two neighboring linear (hat) functions with general node numbers</em></a>. Since the integral
is geometrically identical to the situation with specific nodes
2 and 3, we realize that <span class="math">\(A_{i,i-1}=A_{i,i+1}=h/6\)</span> and
<span class="math">\(A_{i,i}=h/3\)</span>. However, we can compute the integral directly
too:</p>
<div class="math">
\[\begin{split}A_{i,i-1} &amp;= \int_\Omega {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}\\
&amp;=
\underbrace{\int_{x_{i-2}}^{x_{i-1}} {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}}_{{\varphi}_i=0} +
\int_{x_{i-1}}^{x_{i}} {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x} +
\underbrace{\int_{x_{i}}^{x_{i+1}} {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}}_{{\varphi}_{i-1}=0}\\
&amp;= \int_{x_{i-1}}^{x_{i}}
\underbrace{\left(\frac{x - x_{i}}{h}\right)}_{{\varphi}_i(x)}
\underbrace{\left(1 - \frac{x - x_{i-1}}{h}\right)}_{{\varphi}_{i-1}(x)} {\, \mathrm{d}x} =
\frac{h}{6}
{\thinspace .}\end{split}\]</div>
<p>The particular formulas for <span class="math">\({\varphi}_{i-1}(x)\)</span> and <span class="math">\({\varphi}_i(x)\)</span> on
<span class="math">\([x_{i-1},x_{i}]\)</span> are found from <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>:
<span class="math">\({\varphi}_i\)</span> is the linear function with positive slope, corresponding
to the interval <span class="math">\([x_{i-1},x_{i}]\)</span> in
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>, while <span class="math">\(\phi_{i-1}\)</span> has a
negative slope so the definition in interval
<span class="math">\([x_{i},x_{i+1}]\)</span> in <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a> must be
used. (The appearance of <span class="math">\(i\)</span> in <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>
and the integral might be confusing, as we speak about two different
<span class="math">\(i\)</span> indices.)</p>
<div class="figure" id="fem-approx-fe-fig-phi-i-im1">
<img alt="_images/fe_mesh1D_phi_i_im11.png" src="_images/fe_mesh1D_phi_i_im11.png" style="width: 500px;" />
<p class="caption"><em>Illustration of two neighboring linear (hat) functions with general node numbers</em></p>
</div>
<p>The first and last row of the coefficient matrix lead to slightly
different integrals:</p>
<div class="math">
\[A_{0,0} = \int_\Omega {\varphi}_0^2{\, \mathrm{d}x} = \int_{x_{0}}^{x_{1}}
\left(1 - \frac{x-x_0}{h}\right)^2{\, \mathrm{d}x} = \frac{h}{3}{\thinspace .}\]</div>
<p>Similarly, <span class="math">\(A_{N,N}\)</span> involves an integral over only one element
and equals hence <span class="math">\(h/3\)</span>.</p>
<div class="figure" id="fem-approx-fe-fig-phi-i-f">
<img alt="_images/fe_mesh1D_phi_i_f1.png" src="_images/fe_mesh1D_phi_i_f1.png" style="width: 500px;" />
<p class="caption"><em>Right-hand side integral with the product of a basis function and the given function to approximate</em></p>
</div>
<p>The general formula for <span class="math">\(b_i\)</span>,
see Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-i-f"><em>Right-hand side integral with the product of a basis function and the given function to approximate</em></a>, is now easy to set up</p>
<div class="math" id="equation-fem:approx:fe:bi:formula1">
<span class="eqno">(26)</span>\[     b_i = \int_\Omega{\varphi}_i(x)f(x){\, \mathrm{d}x}
     = \int_{x_{i-1}}^{x_{i}} \frac{x - x_{i-1}}{h} f(x){\, \mathrm{d}x}
     + \int_{x_{i}}^{x_{i+1}} \left(1 - \frac{x - x_{i}}{h}\right) f(x)
     {\, \mathrm{d}x}{\thinspace .}\]</div>
<p>We need a specific <span class="math">\(f(x)\)</span> function to compute these integrals.
With two equal-sized elements in <span class="math">\(\Omega=[0,1]\)</span> and <span class="math">\(f(x)=x(1-x)\)</span>, one gets</p>
<div class="math">
\[\begin{split}A = \frac{h}{6}\left(\begin{array}{ccc}
2 &amp; 1 &amp; 0\\
1 &amp; 4 &amp; 1\\
0 &amp; 1 &amp; 2
\end{array}\right),\quad
b = \frac{h^2}{12}\left(\begin{array}{c}
2 - 3h\\
12 - 14h\\
10 -17h
\end{array}\right){\thinspace .}\end{split}\]</div>
<p>The solution becomes</p>
<div class="math">
\[c_0 = \frac{h^2}{6},\quad c_1 = h - \frac{5}{6}h^2,\quad
c_2 = 2h - \frac{23}{6}h^2{\thinspace .}\]</div>
<p>The resulting function</p>
<div class="math">
\[u(x)=c_0{\varphi}_0(x) + c_1{\varphi}_1(x) + c_2{\varphi}_2(x)\]</div>
<p>is displayed in Figure <a class="reference internal" href="#fem-approx-fe-fig-ls-p1-2-4"><em>Least squares approximation of a parabola using 2 (left) and 4 (right) P1 elements</em></a> (left).
Doubling the number of elements to four leads to the improved
approximation in the right part of Figure <a class="reference internal" href="#fem-approx-fe-fig-ls-p1-2-4"><em>Least squares approximation of a parabola using 2 (left) and 4 (right) P1 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-fig-ls-p1-2-4">
<img alt="_images/fe_p1_x2_2e_4e1.png" src="_images/fe_p1_x2_2e_4e1.png" style="width: 800px;" />
<p class="caption"><em>Least squares approximation of a parabola using 2 (left) and 4 (right) P1 elements</em></p>
</div>
</div>
</div>
<div class="section" id="assembly-of-elementwise-computations">
<span id="fem-approx-fe-elementwise"></span><h2>Assembly of elementwise computations<a class="headerlink" href="#assembly-of-elementwise-computations" title="Permalink to this headline">¶</a></h2>
<p>The integrals above are naturally split into integrals over individual elements
since the formulas change with the elements. This idea of splitting the
integral is fundamental in all practical implementations of the finite
element method.</p>
<p>Let us split the integral over <span class="math">\(\Omega\)</span> into a sum of contributions from
each element:</p>
<div class="math" id="equation-fem:approx:fe:elementwise:Asplit">
<span class="eqno">(27)</span>\[     A_{i,j} = \int_\Omega{\varphi}_i{\varphi}_j {\, \mathrm{d}x} = \sum_{e} A^{(e)}_{i,j},\quad
     A^{(e)}_{i,j}=\int_{\Omega^{(e)}} {\varphi}_i{\varphi}_j {\, \mathrm{d}x}
     {\thinspace .}\]</div>
<p>Now, <span class="math">\(A^{(e)}_{i,j}\neq 0\)</span> if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in element
<span class="math">\(e\)</span>. Introduce <span class="math">\(i=q(e,r)\)</span> as the mapping of local node number <span class="math">\(r\)</span> in element
<span class="math">\(e\)</span> to the global node number <span class="math">\(i\)</span>. This is just a short mathematical notation
for the expression <tt class="docutils literal"><span class="pre">i=elements[e][r]</span></tt> in a program.
Let <span class="math">\(r\)</span> and <span class="math">\(s\)</span> be the local node numbers corresponding to the global
node numbers <span class="math">\(i=q(e,r)\)</span> and
<span class="math">\(j=q(e,s)\)</span>. With <span class="math">\(d\)</span> nodes per element, all the nonzero elements
in <span class="math">\(A^{(e)}_{i,j}\)</span> arise from the integrals involving basis functions with
indices corresponding to the global node numbers in element number <span class="math">\(e\)</span>:</p>
<div class="math" id="index-29">
\[\int_{\Omega^{(e)}}{\varphi}_{q(e,r)}{\varphi}_{q(e,s)} {\, \mathrm{d}x},
\quad r,s=0,\ldots, d{\thinspace .}\]</div>
<p>These contributions can be collected in a <span class="math">\((d+1)\times (d+1)\)</span> matrix known as
the <em>element matrix</em>. Let <span class="math">\({I_d}=\{0,\ldots,d\}\)</span> be the valid indices
of <span class="math">\(r\)</span> and <span class="math">\(s\)</span>.
We introduce the notation</p>
<div class="math">
\[\tilde A^{(e)} = \{ \tilde A^{(e)}_{r,s}\},\quad
r,s\in{I_d},\]</div>
<p>for the element matrix. For the case <span class="math">\(d=2\)</span> we have</p>
<div class="math">
\[\begin{split}\tilde A^{(e)} = \left\lbrack\begin{array}{lllll}
\tilde A^{(e)}_{0,0} &amp; \tilde A^{(e)}_{0,1} &amp; \tilde A^{(e)}_{0,2}\\
\tilde A^{(e)}_{1,0} &amp; \tilde A^{(e)}_{1,1} &amp; \tilde A^{(e)}_{1,2}\\
\tilde A^{(e)}_{2,0} &amp; \tilde A^{(e)}_{2,1} &amp; \tilde A^{(e)}_{2,2}
\end{array}\right\rbrack
{\thinspace .}\end{split}\]</div>
<p>Given the numbers <span class="math">\(\tilde A^{(e)}_{r,s}\)</span>,
we should according to <a href="#equation-fem:approx:fe:elementwise:Asplit">(27)</a>
add the contributions to the global coefficient matrix by</p>
<div class="math" id="index-30">
\[ A_{q(e,r),q(e,s)} := A_{q(e,r),q(e,s)} + \tilde A^{(e)}_{r,s},\quad
r,s\in{I_d}{\thinspace .}\]</div>
<p>This process of adding in elementwise contributions to the global matrix
is called <em>finite element assembly</em> or simply <em>assembly</em>.
Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly-2x2"><em>Illustration of matrix assembly: regularly numbered P1 elements</em></a> illustrates how element matrices
for elements with two nodes are added into the global matrix.
More specifically, the figure shows how the element matrix associated with
elements 1 and 2 assembled, assuming that global nodes are numbered
from left to right in the domain. With regularly numbered P3 elements, where
the element matrices have size <span class="math">\(4\times 4\)</span>, the assembly of elements 1 and 2
are sketched in Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly-4x4"><em>Illustration of matrix assembly: regularly numbered P3 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-fig-assembly-2x2">
<img alt="_images/fe_assembly_regular_2x21.png" src="_images/fe_assembly_regular_2x21.png" style="width: 700px;" />
<p class="caption"><em>Illustration of matrix assembly: regularly numbered P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-assembly-4x4">
<img alt="_images/fe_assembly_regular_4x41.png" src="_images/fe_assembly_regular_4x41.png" style="width: 700px;" />
<p class="caption"><em>Illustration of matrix assembly: regularly numbered P3 elements</em></p>
</div>
<p>After assembly of element matrices corresponding to regularly numbered elements
and nodes are understood, it is wise to study the assembly process for
irregularly numbered elements and nodes. Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p1-irregular"><em>Example on irregular numbering of elements and nodes</em></a> shows a mesh where the <tt class="docutils literal"><span class="pre">elements</span></tt> array, or <span class="math">\(q(e,r)\)</span>
mapping in mathematical notation, is given as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>The associated assembly of element matrices 1 and 2 is sketched in
Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly-irr2x2"><em>Illustration of matrix assembly: irregularly numbered P1 elements</em></a>.</p>
<p>These three assembly processes can also be <a class="reference external" href="http://tinyurl.com/k3sdbuv/pub/mov-fem/fe_assembly.html">animated</a>.</p>
<div class="figure" id="fem-approx-fe-fig-assembly-irr2x2">
<img alt="_images/fe_assembly_irregular1.png" src="_images/fe_assembly_irregular1.png" style="width: 700px;" />
<p class="caption"><em>Illustration of matrix assembly: irregularly numbered P1 elements</em></p>
</div>
<p>The right-hand side of the linear system is also computed elementwise:</p>
<div class="math">
\[b_i = \int_\Omega f(x){\varphi}_i(x) {\, \mathrm{d}x} = \sum_{e} b^{(e)}_{i},\quad
b^{(e)}_{i}=\int_{\Omega^{(e)}} f(x){\varphi}_i(x){\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>We observe that
<span class="math">\(b_i^{(e)}\neq 0\)</span> if and only if global node <span class="math">\(i\)</span> is a node in element <span class="math">\(e\)</span>.
With <span class="math">\(d\)</span> nodes per element we can collect the <span class="math">\(d+1\)</span> nonzero contributions
<span class="math">\(b_i^{(e)}\)</span>, for <span class="math">\(i=q(e,r)\)</span>, <span class="math">\(r\in{I_d}\)</span>, in an <em>element vector</em></p>
<div class="math">
\[\tilde b_r^{(e)}=\{ \tilde b_r^{(e)}\},\quad r\in{I_d}{\thinspace .}\]</div>
<p>These contributions are added to the
global right-hand side by an assembly process similar to that for the
element matrices:</p>
<div class="math">
\[b_{q(e,r)} := b_{q(e,r)} + \tilde b^{(e)}_{r},\quad
r\in{I_d}{\thinspace .}\]</div>
</div>
<div class="section" id="mapping-to-a-reference-element">
<span id="fem-approx-fe-mapping"></span><h2>Mapping to a reference element<a class="headerlink" href="#mapping-to-a-reference-element" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-31"></span><p id="index-32">Instead of computing the integrals</p>
<div class="math">
\[\tilde A^{(e)}_{r,s} = \int_{\Omega^{(e)}}{\varphi}_{q(e,r)}(x){\varphi}_{q(e,s)}(x){\, \mathrm{d}x}\]</div>
<p>over some element
<span class="math">\(\Omega^{(e)} = [x_L, x_R]\)</span>,
it is convenient to map the element domain <span class="math">\([x_L, x_R]\)</span>
to a standardized reference element domain <span class="math">\([-1,1]\)</span>.
(We have now introduced
<span class="math">\(x_L\)</span> and <span class="math">\(x_R\)</span> as the left and right boundary points of an arbitrary element.
With a natural, regular numbering of nodes and elements from left to right
through the domain, we have <span class="math">\(x_L=x_{e}\)</span> and <span class="math">\(x_R=x_{e+1}\)</span> for P1 elements.)</p>
<p>Let <span class="math">\(X\in [-1,1]\)</span> be the coordinate
in the reference element. A linear or <em>affine mapping</em> from <span class="math">\(X\)</span> to <span class="math">\(x\)</span> reads</p>
<div class="math" id="equation-fem:approx:fe:affine:mapping">
<span class="eqno">(28)</span>\[     x = \frac{1}{2} (x_L + x_R) + \frac{1}{2} (x_R - x_L)X{\thinspace .}\]</div>
<p>This relation can alternatively be expressed by</p>
<div class="math" id="equation-fem:approx:fe:affine:mapping2">
<span class="eqno">(29)</span>\[     x = x_m + \frac{1}{2}hX,\]</div>
<p>where we have introduced the element midpoint <span class="math">\(x_m=(x_L+x_R)/2\)</span> and
the element length <span class="math">\(h=x_R-x_L\)</span>.</p>
<p>Integrating on
the reference element is a matter of just changing the integration
variable from <span class="math">\(x\)</span> to <span class="math">\(X\)</span>. Let</p>
<div class="math">
\[{\tilde{\varphi}}_r(X) = {\varphi}_{q(e,r)}(x(X))\]</div>
<p>be the basis function associated with local node number <span class="math">\(r\)</span> in the
reference element. The integral transformation reads</p>
<div class="math">
\[\tilde A^{(e)}_{r,s} =
\int_{\Omega^{(e)}}{\varphi}_{q(e,r)}(x){\varphi}_{q(e,s)}(x){\, \mathrm{d}x}
= \int_{-1}^1 {\tilde{\varphi}}_r(X){\tilde{\varphi}}_s(X)\frac{dx}{dX}{\, \mathrm{d}X}
{\thinspace .}\]</div>
<p>The stretch factor <span class="math">\(dx/dX\)</span> between the <span class="math">\(x\)</span> and <span class="math">\(X\)</span> coordinates
becomes the determinant of the Jacobian matrix of the mapping
between the coordinate systems in 2D and 3D. To obtain a uniform
notation for 1D, 2D, and 3D problems we therefore replace
<span class="math">\(dx/dX\)</span> by <span class="math">\(\det J\)</span> already now. In 1D, <span class="math">\(\det J = dx/dX = h/2\)</span>.
The integration over the reference element is then written as</p>
<div class="math" id="equation-fem:approx:fe:mapping:Ae">
<span class="eqno">(30)</span>\[     \tilde A^{(e)}_{r,s}
     = \int_{-1}^1 {\tilde{\varphi}}_r(X){\tilde{\varphi}}_s(X)\det J\,dX\]\[     {\thinspace .}\]</div>
<p>The corresponding formula for the element vector entries becomes</p>
<div class="math" id="equation-fem:approx:fe:mapping:be">
<span class="eqno">(31)</span>\[     \tilde b^{(e)}_{r} = \int_{\Omega^{(e)}}f(x){\varphi}_{q(e,r)}(x)dx
     = \int_{-1}^1 f(x(X)){\tilde{\varphi}}_r(X)\det J\,dX\]\[     {\thinspace .}\]</div>
<p>Since we from now on will work in the reference
element, we need explicit mathematical formulas for the basis
functions <span class="math">\({\varphi}_i(x)\)</span> in the reference element only, i.e., we only need
to specify formulas for <span class="math">\({\tilde{\varphi}}_r(X)\)</span>.
This is a very convenient simplification compared to specifying
piecewise polynomials in the physical domain.</p>
<p>The <span class="math">\({\tilde{\varphi}}_r(x)\)</span> functions are simply the Lagrange
polynomials defined through the local nodes in the reference element.
For <span class="math">\(d=1\)</span> and two nodes per element, we have the linear Lagrange
polynomials</p>
<div class="math" id="equation-fem:approx:fe:mapping:P1:phi0">
<span class="eqno">(32)</span>\[     {\tilde{\varphi}}_0(X) = \frac{1}{2} (1 - X)\]</div>
<div class="math" id="equation-fem:approx:fe:mapping:P1:phi1">
<span class="eqno">(33)</span>\[     {\tilde{\varphi}}_1(X) = \frac{1}{2} (1 + X)\]</div>
<p>Quadratic polynomials, <span class="math">\(d=2\)</span>, have the formulas</p>
<div class="math">
\[{\tilde{\varphi}}_0(X) = \frac{1}{2} (X-1)X\]</div>
<div class="math">
\[{\tilde{\varphi}}_1(X) = 1 - X^2\]</div>
<div class="math">
\[{\tilde{\varphi}}_2(X) = \frac{1}{2} (X+1)X\]</div>
<p>In general,</p>
<div class="math">
\[{\tilde{\varphi}}_r(X) = \prod_{s=0,s\neq r}^d \frac{X-X_{(s)}}{X_{(r)}-X_{(s)}},\]</div>
<p>where <span class="math">\(X_{(0)},\ldots,X_{(d)}\)</span> are the coordinates of the local nodes in
the reference element.
These are normally uniformly spaced: <span class="math">\(X_{(r)} = -1 + 2r/d\)</span>,
<span class="math">\(r\in{I_d}\)</span>.</p>
<div class="admonition-why-reference-elements admonition">
<p class="first admonition-title">Why reference elements</p>
<p class="last">The great advantage of using reference elements is that
the formulas for the basis functions, <span class="math">\({\tilde{\varphi}}_r(X)\)</span>, are the
same for all elements and independent of the element geometry
(length and location in the mesh). The geometric information
is &#8220;factored out&#8221; in the simple mapping formula and the associated
<span class="math">\(\det J\)</span> quantity, but this information is (here taken as) the same for
element types. Also, the integration domain is the same for
all elements.</p>
</div>
</div>
<div class="section" id="example-integration-over-a-reference-element">
<span id="fem-approx-fe-intg-ref"></span><h2>Example: Integration over a reference element<a class="headerlink" href="#example-integration-over-a-reference-element" title="Permalink to this headline">¶</a></h2>
<p>To illustrate the concepts from the previous section in a specific
example, we now
consider calculation of the element matrix and vector for a specific choice of
<span class="math">\(d\)</span> and <span class="math">\(f(x)\)</span>. A simple choice is <span class="math">\(d=1\)</span> (P1 elements) and <span class="math">\(f(x)=x(1-x)\)</span>
on <span class="math">\(\Omega =[0,1]\)</span>. We have the general expressions
<a href="#equation-fem:approx:fe:mapping:Ae">(30)</a> and <a href="#equation-fem:approx:fe:mapping:be">(31)</a>
for <span class="math">\(\tilde A^{(e)}_{r,s}\)</span> and <span class="math">\(\tilde b^{(e)}_{r}\)</span>.
Writing these out for the choices <a href="#equation-fem:approx:fe:mapping:P1:phi0">(32)</a>
and <a href="#equation-fem:approx:fe:mapping:P1:phi1">(33)</a>, and using that <span class="math">\(\det J = h/2\)</span>,
we can do the following calculations of the element matrix entries:</p>
<div class="math">
\[\tilde A^{(e)}_{0,0}
= \int_{-1}^1 {\tilde{\varphi}}_0(X){\tilde{\varphi}}_0(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:Ae00">
<span class="eqno">(34)</span>\[     =\int_{-1}^1 \frac{1}{2}(1-X)\frac{1}{2}(1-X) \frac{h}{2} dX =
     \frac{h}{8}\int_{-1}^1 (1-X)^2 dX = \frac{h}{3},\]</div>
<div class="math">
\[\tilde A^{(e)}_{1,0}
= \int_{-1}^1 {\tilde{\varphi}}_1(X){\tilde{\varphi}}_0(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math">
\[=\int_{-1}^1 \frac{1}{2}(1+X)\frac{1}{2}(1-X) \frac{h}{2} dX =
\frac{h}{8}\int_{-1}^1 (1-X^2) dX = \frac{h}{6},\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:Ae10">
<span class="eqno">(35)</span>\[     \tilde A^{(e)}_{0,1} = \tilde A^{(e)}_{1,0},\]</div>
<div class="math">
\[\tilde A^{(e)}_{1,1}
= \int_{-1}^1 {\tilde{\varphi}}_1(X){\tilde{\varphi}}_1(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:Ae11">
<span class="eqno">(36)</span>\[     =\int_{-1}^1 \frac{1}{2}(1+X)\frac{1}{2}(1+X) \frac{h}{2} dX =
     \frac{h}{8}\int_{-1}^1 (1+X)^2 dX = \frac{h}{3}\]\[     {\thinspace .}\]</div>
<p>The corresponding entries in the element vector becomes</p>
<div class="math">
\[\tilde b^{(e)}_{0}
= \int_{-1}^1 f(x(X)){\tilde{\varphi}}_0(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math">
\[= \int_{-1}^1 (x_m + \frac{1}{2} hX)(1-(x_m + \frac{1}{2} hX))
\frac{1}{2}(1-X)\frac{h}{2} dX \nonumber\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:be0">
<span class="eqno">(37)</span>\[     = - \frac{1}{24} h^{3} + \frac{1}{6} h^{2} x_{m} - \frac{1}{12} h^{2} - \frac{1}{2} h x_{m}^{2} + \frac{1}{2} h x_{m}\]</div>
<div class="math">
\[\tilde b^{(e)}_{1}
= \int_{-1}^1 f(x(X)){\tilde{\varphi}}_1(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math">
\[= \int_{-1}^1 (x_m + \frac{1}{2} hX)(1-(x_m + \frac{1}{2} hX))
\frac{1}{2}(1+X)\frac{h}{2} dX \nonumber\]</div>
<div class="math">
\[= - \frac{1}{24} h^{3} - \frac{1}{6} h^{2} x_{m} + \frac{1}{12} h^{2} -
\frac{1}{2} h x_{m}^{2} + \frac{1}{2} h x_{m}
{\thinspace .}\]</div>
<p>In the last two expressions we have used the element midpoint <span class="math">\(x_m\)</span>.</p>
<p>Integration of lower-degree polynomials above is tedious,
and higher-degree polynomials involve very much more algebra, but <tt class="docutils literal"><span class="pre">sympy</span></tt>
may help. For example, we can easily calculate
<a href="#equation-fem:approx:fe:intg:ref:Ae00">(34)</a>,
<a href="#equation-fem:approx:fe:intg:ref:Ae00">(34)</a>, and
<a href="#equation-fem:approx:fe:intg:ref:be0">(37)</a> by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">x_m</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;x x_m h X&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">8</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">h/3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">8</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">h/6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x_m</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_0</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">b_0</span>
<span class="go">-h**3/24 + h**2*x_m/6 - h**2/12 - h*x_m**2/2 + h*x_m/2</span>
</pre></div>
</div>
<p>For inclusion of formulas in documents (like the present one), <tt class="docutils literal"><span class="pre">sympy</span></tt> can print
expressions in LaTeX format:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">latex</span><span class="p">(</span><span class="n">b_0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;plain&#39;</span><span class="p">)</span>
<span class="go">- \frac{1}{24} h^{3} + \frac{1}{6} h^{2} x_{m}</span>
<span class="go">- \frac{1}{12} h^{2} - \frac{1}{2} h x_{m}^{2}</span>
<span class="go">+ \frac{1}{2} h x_{m}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="implementation-1">
<span id="fem-approx-fe-impl"></span><h1>Implementation  (1)<a class="headerlink" href="#implementation-1" title="Permalink to this headline">¶</a></h1>
<p>Based on the experience from the previous example, it makes
sense to write some code to automate the analytical integration process
for any choice of finite element basis functions. In addition,
we can automate the assembly process and linear system
solution. Appropriate
functions for this purpose document all details of all
steps in the finite element computations and can found in the module file
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx1D.py">fe_approx1D.py</a>.
The key steps in the computational machinery are now explained in
detail in terms of code and text.</p>
<div class="section" id="integration">
<span id="fem-approx-fe-impl-intg"></span><h2>Integration<a class="headerlink" href="#integration" title="Permalink to this headline">¶</a></h2>
<p>First we need a Python function for
defining <span class="math">\({\tilde{\varphi}}_r(X)\)</span> in terms of a Lagrange polynomial
of degree <tt class="docutils literal"><span class="pre">d</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">phi_r</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>  <span class="c"># node spacing</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c"># assume X is numeric: use floats for nodes</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>Observe how we construct the <tt class="docutils literal"><span class="pre">phi_r</span></tt> function to be
a symbolic expression for <span class="math">\({\tilde{\varphi}}_r(X)\)</span> if <tt class="docutils literal"><span class="pre">X</span></tt> is a
<tt class="docutils literal"><span class="pre">Symbol</span></tt> object from <tt class="docutils literal"><span class="pre">sympy</span></tt>. Otherwise, we assume that <tt class="docutils literal"><span class="pre">X</span></tt>
is a <tt class="docutils literal"><span class="pre">float</span></tt> object and compute the corresponding
floating-point value of <span class="math">\({\tilde{\varphi}}_r(X)\)</span>. Recall that the
<tt class="docutils literal"><span class="pre">Lagrange_polynomial</span></tt> function, here simply copied
from the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>,
works with both symbolic and
numeric variables.</p>
<p>The complete basis <span class="math">\({\tilde{\varphi}}_0(X),\ldots,{\tilde{\varphi}}_d(X)\)</span>
on the reference element, represented as a list of
symbolic expressions, is constructed by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">phi_r</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">phi</span>
</pre></div>
</div>
<p>Now we are in a position to write the function for computing
the element matrix:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
    <span class="n">A_e</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;h&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>  <span class="c"># dx/dX</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">s</span><span class="p">,</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">A_e</span>
</pre></div>
</div>
<p>In the symbolic case (<tt class="docutils literal"><span class="pre">symbolic</span></tt> is <tt class="docutils literal"><span class="pre">True</span></tt>),
we introduce the element length as a symbol
<tt class="docutils literal"><span class="pre">h</span></tt> in the computations. Otherwise, the real numerical value
of the element interval <tt class="docutils literal"><span class="pre">Omega_e</span></tt>
is used and the final matrix elements are numbers,
not symbols.
This functionality can be demonstrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fe_approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span>
<span class="go">[1/2 - X/2, 1/2 + X/2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="go">[h/3, h/6]</span>
<span class="go">[h/6, h/3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="go">[0.0333333333333333, 0.0166666666666667]</span>
<span class="go">[0.0166666666666667, 0.0333333333333333]</span>
</pre></div>
</div>
<p>The computation of the element vector is done by a similar
procedure:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
    <span class="n">b_e</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c"># Make f a function of X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;h&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span>  <span class="c"># mapping</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="c"># substitute mapping formula for x</span>
    <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>  <span class="c"># dx/dX</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">b_e</span>
</pre></div>
</div>
<p>Here we need to replace the symbol <tt class="docutils literal"><span class="pre">x</span></tt> in the expression for <tt class="docutils literal"><span class="pre">f</span></tt>
by the mapping formula such that <tt class="docutils literal"><span class="pre">f</span></tt> can be integrated
in terms of <span class="math">\(X\)</span>, cf. the formula
<span class="math">\(\tilde b^{(e)}_{r} = \int_{-1}^1 f(x(X)){\tilde{\varphi}}_r(X)\frac{h}{2}dX\)</span>.</p>
<p>The integration in the element matrix function involves only products
of polynomials, which <tt class="docutils literal"><span class="pre">sympy</span></tt> can easily deal with, but for the
right-hand side <tt class="docutils literal"><span class="pre">sympy</span></tt> may face difficulties with certain types of
expressions <tt class="docutils literal"><span class="pre">f</span></tt>. The result of the integral is then an <tt class="docutils literal"><span class="pre">Integral</span></tt>
object and not a number or expression
as when symbolic integration is successful.
It may therefore be wise to introduce a fallback on numerical
integration. The symbolic integration can also take much time
before an unsuccessful conclusion so we may also introduce a parameter
<tt class="docutils literal"><span class="pre">symbolic</span></tt> and set it to <tt class="docutils literal"><span class="pre">False</span></tt> to avoid symbolic integration:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># Ensure h is numerical</span>
            <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">X</span><span class="p">],</span> <span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Numerical integration requires that the symbolic
integrand is converted
to a plain Python function (<tt class="docutils literal"><span class="pre">integrand</span></tt>) and that
the element length <tt class="docutils literal"><span class="pre">h</span></tt> is a real number.</p>
</div>
<div class="section" id="linear-system-assembly-and-solution">
<span id="fem-approx-fe-impl-linsys"></span><h2>Linear system assembly and solution<a class="headerlink" href="#linear-system-assembly-and-solution" title="Permalink to this headline">¶</a></h2>
<p>The complete algorithm
for computing and assembling the elementwise contributions
takes the following form</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">N_n</span><span class="p">,</span> <span class="n">N_e</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_n</span><span class="p">,</span> <span class="n">N_n</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>    <span class="c"># note: (N_n, 1) matrix</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_n</span><span class="p">,</span> <span class="n">N_n</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_e</span><span class="p">):</span>
        <span class="n">Omega_e</span> <span class="o">=</span> <span class="p">[</span><span class="n">nodes</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="n">nodes</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]]]</span>

        <span class="n">A_e</span> <span class="o">=</span> <span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="p">)</span>
        <span class="n">b_e</span> <span class="o">=</span> <span class="n">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">])):</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">])):</span>
                <span class="n">A</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
            <span class="n">b</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> variables represent the finite
element mesh as explained earlier.</p>
<p>Given the coefficient matrix <tt class="docutils literal"><span class="pre">A</span></tt> and the right-hand side <tt class="docutils literal"><span class="pre">b</span></tt>,
we can compute the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> in the expansion
<span class="math">\(u(x)=\sum_jc_j{\varphi}_j\)</span> as the solution vector <tt class="docutils literal"><span class="pre">c</span></tt> of the linear
system:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>When <tt class="docutils literal"><span class="pre">A</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are <tt class="docutils literal"><span class="pre">sympy</span></tt> arrays,
the solution procedure implied by <tt class="docutils literal"><span class="pre">A.LUsolve</span></tt> is symbolic.
Otherwise, <tt class="docutils literal"><span class="pre">A</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are <tt class="docutils literal"><span class="pre">numpy</span></tt> arrays and a standard
numerical solver is called.
The symbolic version is suited for small problems only
(small <span class="math">\(N\)</span> values) since the calculation time becomes prohibitively large
otherwise. Normally, the symbolic <em>integration</em> will be more time
consuming in small problems than the symbolic <em>solution</em> of the linear system.</p>
</div>
<div class="section" id="example-on-computing-symbolic-approximations">
<span id="fem-approx-fe-impl-ex1-symbolic"></span><h2>Example on computing symbolic approximations<a class="headerlink" href="#example-on-computing-symbolic-approximations" title="Permalink to this headline">¶</a></h2>
<p>We can exemplify the use of <tt class="docutils literal"><span class="pre">assemble</span></tt> on the computational
case from the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> with
two P1 elements (linear basis functions) on the domain <span class="math">\(\Omega=[0,1]\)</span>.
Let us first work with a symbolic element length:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;h x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[h/3,   h/6,   0]</span>
<span class="go">[h/6, 2*h/3, h/6]</span>
<span class="go">[  0,   h/6, h/3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[     h**2/6 - h**3/12]</span>
<span class="go">[      h**2 - 7*h**3/6]</span>
<span class="go">[5*h**2/6 - 17*h**3/12]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[                           h**2/6]</span>
<span class="go">[12*(7*h**2/12 - 35*h**3/72)/(7*h)]</span>
<span class="go">[  7*(4*h**2/7 - 23*h**3/21)/(2*h)]</span>
</pre></div>
</div>
</div>
<div class="section" id="comparison-with-finite-elements-and-interpolation-collocation">
<span id="fem-approx-fe-impl-ex1-collocation"></span><h2>Comparison with finite elements and interpolation/collocation<a class="headerlink" href="#comparison-with-finite-elements-and-interpolation-collocation" title="Permalink to this headline">¶</a></h2>
<p>We may, for comparison, compute the <tt class="docutils literal"><span class="pre">c</span></tt> vector corresponding to
an interpolation/collocation method with finite element basis functions.
Choosing the nodes as points, the principle is</p>
<div class="math">
\[u(x_{i}) = \sum_{j\in{I}} c_j{\varphi}_j(x_{i}) = f(x_{i}),\quad
i\in{I}{\thinspace .}\]</div>
<p>The coefficient matrix <span class="math">\(A_{i,j}={\varphi}_j(x_{i})\)</span> becomes
the identity matrix because basis function number <span class="math">\(j\)</span> vanishes
at all nodes, except node <span class="math">\(j\)</span>: <span class="math">\({\varphi}_j(x_{i}=\delta_{ij}\)</span>.
Therefore, <span class="math">\(c_i = f(x_{i}\)</span>.</p>
<p>The associated <tt class="docutils literal"><span class="pre">sympy</span></tt> calculations are</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">fn</span><span class="p">(</span><span class="n">xc</span><span class="p">)</span> <span class="k">for</span> <span class="n">xc</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[0, h*(1 - h), 2*h*(1 - 2*h)]</span>
</pre></div>
</div>
<p>These expressions are much simpler than those based on least squares
or projection in combination with finite element basis functions.</p>
</div>
<div class="section" id="example-on-computing-numerical-approximations">
<span id="fem-approx-fe-impl-ex1-numeric"></span><h2>Example on computing numerical approximations<a class="headerlink" href="#example-on-computing-numerical-approximations" title="Permalink to this headline">¶</a></h2>
<p>The numerical computations corresponding to the
symbolic ones in the section <a class="reference internal" href="#fem-approx-fe-impl-ex1-symbolic"><em>Example on computing symbolic approximations</em></a>,
and still done by <tt class="docutils literal"><span class="pre">sympy</span></tt> and the <tt class="docutils literal"><span class="pre">assemble</span></tt> function, go as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[ 0.166666666666667, 0.0833333333333333,                  0]</span>
<span class="go">[0.0833333333333333,  0.333333333333333, 0.0833333333333333]</span>
<span class="go">[                 0, 0.0833333333333333,  0.166666666666667]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[          0.03125]</span>
<span class="go">[0.104166666666667]</span>
<span class="go">[          0.03125]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[0.0416666666666666]</span>
<span class="go">[ 0.291666666666667]</span>
<span class="go">[0.0416666666666666]</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">fe_approx1D</span></tt> module contains functions for generating the
<tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists for equal-sized elements with
any number of nodes per element. The coordinates in <tt class="docutils literal"><span class="pre">nodes</span></tt>
can be expressed either through the element length symbol <tt class="docutils literal"><span class="pre">h</span></tt>
(<tt class="docutils literal"><span class="pre">symbolic=True</span></tt>) or by real numbers (<tt class="docutils literal"><span class="pre">symbolic=False</span></tt>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span> <span class="o">=</span> <span class="n">mesh_uniform</span><span class="p">(</span><span class="n">N_e</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
                               <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>There is also a function</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">approximate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&#39;tmp.pdf&#39;</span><span class="p">):</span>
</pre></div>
</div>
<p>which computes a mesh with <tt class="docutils literal"><span class="pre">N_e</span></tt> elements, basis functions of
degree <tt class="docutils literal"><span class="pre">d</span></tt>, and approximates a given symbolic expression
<tt class="docutils literal"><span class="pre">f</span></tt> by a finite element expansion <span class="math">\(u(x) = \sum_jc_j{\varphi}_j(x)\)</span>.
When <tt class="docutils literal"><span class="pre">symbolic</span></tt> is <tt class="docutils literal"><span class="pre">False</span></tt>, <span class="math">\(u(x) = \sum_jc_j{\varphi}_j(x)\)</span>
can be computed at a (large)
number of points and plotted together with <span class="math">\(f(x)\)</span>. The construction
of <span class="math">\(u\)</span> points from the solution vector <tt class="docutils literal"><span class="pre">c</span></tt> is done
elementwise by evaluating <span class="math">\(\sum_rc_r{\tilde{\varphi}}_r(X)\)</span> at a (large)
number of points in each element in the local coordinate system,
and the discrete <span class="math">\((x,u)\)</span> values on
each element are stored in separate arrays that are finally
concatenated to form a global array for <span class="math">\(x\)</span> and for <span class="math">\(u\)</span>.
The details are found in the <tt class="docutils literal"><span class="pre">u_glob</span></tt> function in
<tt class="docutils literal"><span class="pre">fe_approx1D.py</span></tt>.</p>
</div>
<div class="section" id="the-structure-of-the-coefficient-matrix">
<span id="fem-approx-fe-a-structure"></span><h2>The structure of the coefficient matrix<a class="headerlink" href="#the-structure-of-the-coefficient-matrix" title="Permalink to this headline">¶</a></h2>
<p>Let us first see how the global matrix looks like if we assemble
symbolic element matrices, expressed in terms of <tt class="docutils literal"><span class="pre">h</span></tt>, from
several elements:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">8</span><span class="p">;</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>  <span class="c"># 8 linear elements on [0,1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span> <span class="o">=</span> <span class="n">mesh_symbolic</span><span class="p">(</span><span class="n">N_e</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[h/3,   h/6,     0,     0,     0,     0,     0,     0,   0]</span>
<span class="go">[h/6, 2*h/3,   h/6,     0,     0,     0,     0,     0,   0]</span>
<span class="go">[  0,   h/6, 2*h/3,   h/6,     0,     0,     0,     0,   0]</span>
<span class="go">[  0,     0,   h/6, 2*h/3,   h/6,     0,     0,     0,   0]</span>
<span class="go">[  0,     0,     0,   h/6, 2*h/3,   h/6,     0,     0,   0]</span>
<span class="go">[  0,     0,     0,     0,   h/6, 2*h/3,   h/6,     0,   0]</span>
<span class="go">[  0,     0,     0,     0,     0,   h/6, 2*h/3,   h/6,   0]</span>
<span class="go">[  0,     0,     0,     0,     0,     0,   h/6, 2*h/3, h/6]</span>
<span class="go">[  0,     0,     0,     0,     0,     0,     0,   h/6, h/3]</span>
</pre></div>
</div>
<p>The reader is encouraged to assemble the element matrices by hand and verify
this result, as this exercise will give a hands-on understanding of
what the assembly is about. In general we have a coefficient matrix that is
tridiagonal:</p>
<div class="math">
\[\begin{split}A = \frac{h}{6}
\left(
\begin{array}{cccccccccc}
2 &amp; 1 &amp; 0
&amp;\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; 0 \\
1 &amp; 4 &amp; 1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
0 &amp; 1 &amp; 4 &amp; 1 &amp;
\ddots &amp; &amp;  &amp;  &amp; \vdots \\
\vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
\vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; &amp;  &amp; 0 &amp; 1 &amp; 4 &amp; 1 &amp; \ddots &amp; \vdots \\
\vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
\vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; 1  &amp; 4  &amp; 1 \\
0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 1 &amp; 2
\end{array}
\right)\end{split}\]</div>
<p>The structure of the right-hand side is more difficult to reveal since
it involves an assembly of elementwise integrals of
<span class="math">\(f(x(X)){\tilde{\varphi}}_r(X)h/2\)</span>, which obviously depend on the
particular choice of <span class="math">\(f(x)\)</span>.
Numerical integration can give some insight into the nature of
the right-hand side. For this purpose it
is easier to look at the integration in <span class="math">\(x\)</span> coordinates, which
gives the general formula <a href="#equation-fem:approx:fe:bi:formula1">(26)</a>.
For equal-sized elements of length <span class="math">\(h\)</span>, we can apply the
Trapezoidal rule at the global node points to arrive at</p>
<div class="math">
\[b_i = h\left( \frac{1}{2} {\varphi}_i(x_{0})f(x_{0}) +
\frac{1}{2} {\varphi}_i(x_{N})f(x_{N}) + \sum_{j=1}^{N-1}
{\varphi}_i(x_{j})f(x_{j})\right)\]</div>
<div class="math">
\[ =
\left\lbrace\begin{array}{ll}
\frac{1}{2} hf(x_i), i=0\hbox{ or }i=N,\]</div>
<div class="math">
\[h f(x_i),  1 \leq i \leq N-1
\end{array}\right.\]</div>
<p>The reason for this simple formula is simply that <span class="math">\({\varphi}_i\)</span> is either
0 or 1 at the nodes and 0 at all but one of them.</p>
<p>Going to P2 elements (<tt class="docutils literal"><span class="pre">d=2</span></tt>) leads
to the element matrix</p>
<div class="math">
\[\begin{split}A^{(e)} = \frac{h}{30}
\left(\begin{array}{ccc}
4 &amp; 2 &amp; -1\\
2 &amp; 16 &amp; 2\\
-1 &amp; 2 &amp; 4
\end{array}\right)\end{split}\]</div>
<p>and the following global assembled matrix from four elements:</p>
<div class="math">
\[\begin{split}A = \frac{h}{30}
\left(
\begin{array}{ccccccccc}
4 &amp; 2 &amp; - 1 &amp; 0
  &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
  2 &amp; 16 &amp; 2
  &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\- 1 &amp; 2 &amp;
  8 &amp; 2 &amp; - 1 &amp; 0 &amp; 0 &amp; 0 &amp;
  0\\0 &amp; 0 &amp; 2 &amp; 16 &amp; 2 &amp; 0 &amp; 0
  &amp; 0 &amp; 0\\0 &amp; 0 &amp; - 1 &amp; 2 &amp; 8
  &amp; 2 &amp; - 1 &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 0 &amp;
  2 &amp; 16 &amp; 2 &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0
  &amp; 0 &amp; - 1 &amp; 2 &amp; 8 &amp;
  2 &amp; - 1\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;
  2 &amp; 16 &amp; 2\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
  &amp; 0 &amp; - 1 &amp; 2 &amp; 4
\end{array}
\right)\end{split}\]</div>
<p>In general, for <span class="math">\(i\)</span> odd we have the nonzeroes</p>
<div class="math">
\[A_{i,i-2} = -1,\quad A_{i-1,i}=2,\quad A_{i,i} = 8,\quad A_{i+1,i}=2,
\quad A_{i+2,i}=-1,\]</div>
<p>multiplied by <span class="math">\(h/30\)</span>, and for <span class="math">\(i\)</span> even we have the nonzeros</p>
<div class="math">
\[A_{i-1,i}=2,\quad A_{i,i} = 16,\quad A_{i+1,i}=2,\]</div>
<p>multiplied by <span class="math">\(h/30\)</span>. The rows with odd numbers correspond to
nodes at the element boundaries and get contributions from two
neighboring elements in the assembly process,
while the even numbered rows correspond to
internal nodes in the elements where the only one element contributes
to the values in the global matrix.</p>
</div>
<div class="section" id="applications">
<span id="fem-approx-fe-impl-ex2"></span><h2>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<p>With the aid of the <tt class="docutils literal"><span class="pre">approximate</span></tt> function in the <tt class="docutils literal"><span class="pre">fe_approx1D</span></tt>
module we can easily investigate the quality of various finite element
approximations to some given functions. Figure <a class="reference internal" href="#fem-approx-fe-x9-sin"><em>Comparison of the finite element approximations: 4 P1 elements with 5 nodes (upper left), 2 P2 elements with 5 nodes (upper right), 8 P1 elements with 9 nodes (lower left), and 4 P2 elements with 9 nodes (lower right)</em></a>
shows how linear and quadratic elements approximates the polynomial
<span class="math">\(f(x)=x(1-x)^8\)</span> on <span class="math">\(\Omega =[0,1]\)</span>, using equal-sized elements.
The results arise from the program</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">fe_approx1D</span> <span class="kn">import</span> <span class="n">approximate</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>

<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>The quadratic functions are seen to be better than the linear ones for the same
value of <span class="math">\(N\)</span>, as we increase <span class="math">\(N\)</span>. This observation has some generality:
higher degree is not necessarily better on a coarse mesh, but it is as
we refined the mesh.</p>
<div class="figure" id="fem-approx-fe-x9-sin">
<img alt="_images/fe_p1_p2_x9_248e1.png" src="_images/fe_p1_p2_x9_248e1.png" style="width: 800px;" />
<p class="caption"><em>Comparison of the finite element approximations: 4 P1 elements with 5 nodes (upper left), 2 P2 elements with 5 nodes (upper right), 8 P1 elements with 9 nodes (lower left), and 4 P2 elements with 9 nodes (lower right)</em></p>
</div>
</div>
<div class="section" id="sparse-matrix-storage-and-solution">
<span id="fem-approx-fe-impl-sparse"></span><h2>Sparse matrix storage and solution<a class="headerlink" href="#sparse-matrix-storage-and-solution" title="Permalink to this headline">¶</a></h2>
<p id="index-33">Some of the examples in the preceding section took several minutes to
compute, even on small meshes consisting of up to eight elements.
The main explanation for slow computations is unsuccessful
symbolic integration: <tt class="docutils literal"><span class="pre">sympy</span></tt> may use a lot of energy on
integrals like <span class="math">\(\int f(x(X)){\tilde{\varphi}}_r(X)h/2 dx\)</span> before
giving up, and the program then resorts to numerical integration.
Codes that can deal with a large number of basis functions and
accept flexible choices of <span class="math">\(f(x)\)</span> should compute all integrals
numerically and replace the matrix objects from <tt class="docutils literal"><span class="pre">sympy</span></tt> by
the far more efficient array objects from <tt class="docutils literal"><span class="pre">numpy</span></tt>.</p>
<p>Another reason for slow code is related to the fact that most of the
matrix entries <span class="math">\(A_{i,j}\)</span> are zero, because <span class="math">\(({\varphi}_i,{\varphi}_j)=0\)</span>
unless <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in the same element.  A matrix whose
majority of entries are zeros, is known as a <em>sparse</em> matrix.  The
sparsity should be utilized in software as it dramatically decreases
the storage demands and the CPU-time needed to compute the solution of
the linear system. This optimization is not critical in 1D problems
where modern computers can afford computing with all the zeros in the
complete square matrix, but in 2D and especially in 3D, sparse
matrices are fundamental for feasible finite element computations.</p>
<p>In 1D problems, using a
numbering of nodes and elements from left to right over the domain,
the assembled coefficient matrix has only a few diagonals different
from zero. More precisely, <span class="math">\(2d+1\)</span> diagonals are different from
zero. With a different numbering of global nodes, say a random
ordering, the diagonal structure is lost, but the number of
nonzero elements is unaltered. Figures <a class="reference internal" href="#fem-approx-fe-sparsity-p1"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P1 elements</em></a>
and <a class="reference internal" href="#fem-approx-fe-sparsity-p3"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P3 elements</em></a> exemplify sparsity patterns.</p>
<div class="figure" id="fem-approx-fe-sparsity-p1">
<img alt="_images/sparsity_pattern_1D_301.png" src="_images/sparsity_pattern_1D_301.png" style="width: 800px;" />
<p class="caption"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-sparsity-p3">
<img alt="_images/sparsity_pattern_1DP3_301.png" src="_images/sparsity_pattern_1DP3_301.png" style="width: 800px;" />
<p class="caption"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P3 elements</em></p>
</div>
<p>The <tt class="docutils literal"><span class="pre">scipy.sparse</span></tt> library supports creation of sparse matrices
and linear system solution.</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">scipy.sparse.diags</span></tt> for matrix defined via diagonals</li>
<li><tt class="docutils literal"><span class="pre">scipy.sparse.lil_matrix</span></tt> for creation via setting matrix entries</li>
<li><tt class="docutils literal"><span class="pre">scipy.sparse.dok_matrix</span></tt> for creation via setting matrix entries</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="comparison-of-finite-element-and-finite-difference-approximation">
<span id="fem-approx-fe-fd"></span><h1>Comparison of finite element and finite difference approximation<a class="headerlink" href="#comparison-of-finite-element-and-finite-difference-approximation" title="Permalink to this headline">¶</a></h1>
<p>The previous sections on approximating <span class="math">\(f\)</span> by a finite element function <span class="math">\(u\)</span>
utilize the projection/Galerkin or
least squares approaches to minimize the approximation
error. We may, alternatively, use the collocation/interpolation method
as described in the section <a class="reference internal" href="#fem-approx-fe-impl-ex1-collocation"><em>Comparison with finite elements and interpolation/collocation</em></a>.
Here we shall compare these three approaches with what one does in
the finite difference method when representing a given function on a mesh.</p>
<div class="section" id="finite-difference-approximation-of-given-functions">
<span id="fem-approx-fe-fd-fdproj"></span><h2>Finite difference approximation of given functions<a class="headerlink" href="#finite-difference-approximation-of-given-functions" title="Permalink to this headline">¶</a></h2>
<p>Approximating a given function <span class="math">\(f(x)\)</span> on a mesh in a finite difference
context will typically just sample <span class="math">\(f\)</span> at the mesh points. If <span class="math">\(u_i\)</span>
is the value of the approximate <span class="math">\(u\)</span> at the mesh point <span class="math">\(x_{i}\)</span>, we have
<span class="math">\(u_i = f(x_{i})\)</span>.
The collocation/interpolation method using finite element basis
functions gives exactly the same representation,
as shown the section <a class="reference internal" href="#fem-approx-fe-impl-ex1-collocation"><em>Comparison with finite elements and interpolation/collocation</em></a>,</p>
<div class="math">
\[u(x_{i}) = c_i = f(x_{i}){\thinspace .}\]</div>
<p>How does a finite element Galerkin or least squares approximation differ
from this straightforward interpolation of <span class="math">\(f\)</span>? This is the question
to be addressed next.
We now limit the scope to P1 elements since this is the element type
that gives formulas closest to those arising in the finite difference
method.</p>
</div>
<div class="section" id="finite-difference-interpretation-of-a-finite-element-approximation">
<span id="fem-approx-fe-fd-feproj"></span><h2>Finite difference interpretation of a finite element approximation<a class="headerlink" href="#finite-difference-interpretation-of-a-finite-element-approximation" title="Permalink to this headline">¶</a></h2>
<p>The linear system arising from a Galerkin or least squares approximation
reads in general</p>
<div class="math">
\[\sum_{j\in{I}} c_j ({\psi}_i,{\psi}_j) = (f,{\psi}_i),\quad i\in{I}{\thinspace .}\]</div>
<p>In the finite element approximation we choose <span class="math">\({\psi}_i ={\varphi}_i\)</span>.
With <span class="math">\({\varphi}_i\)</span> corresponding to P1 elements and a uniform mesh of
element length <span class="math">\(h\)</span> we have in the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> calculated the matrix with entries
<span class="math">\(({\varphi}_i,{\varphi}_j)\)</span>.  Equation number <span class="math">\(i\)</span> reads</p>
<div class="math" id="equation-fem:deq:1D:approx:deq:massmat:diffeq2">
<span class="eqno">(38)</span>\[     \frac{h}{6}(u_{i-1} + 4u_i + u_{i+1}) = (f,{\varphi}_i)
     {\thinspace .}\]</div>
<p>The first and last equation, corresponding to <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span> are slightly
different, see the section <a class="reference internal" href="#fem-approx-fe-a-structure"><em>The structure of the coefficient matrix</em></a>.</p>
<p>The finite difference counterpart to
<a href="#equation-fem:deq:1D:approx:deq:massmat:diffeq2">(38)</a> is just <span class="math">\(u_i=f_i\)</span>
as explained in the section <a class="reference internal" href="#fem-approx-fe-fd-fdproj"><em>Finite difference approximation of given functions</em></a>.
To easier compare this result to
the finite element approach to approximating functions, we can rewrite
the left-hand side of <a href="#equation-fem:deq:1D:approx:deq:massmat:diffeq2">(38)</a>
as</p>
<div class="math">
\[h(u_i + \frac{1}{6}(u_{i-1} - 2u_i + u_{i+1}))
{\thinspace .}\]</div>
<p>Thinking in terms of finite differences, we can write this expression
using finite difference operator notation:</p>
<div class="math">
\[[h(u + \frac{h^2}{6}D_x D_x u)]_i,\]</div>
<p>which is nothing but the standard discretization of</p>
<div class="math">
\[h(u + \frac{h^2}{6}u''){\thinspace .}\]</div>
<p>Before interpreting the approximation procedure as solving a
differential equation, we need to work out what the right-hand side is
in the context of P1 elements.
Since <span class="math">\({\varphi}_i\)</span> is the linear function that is 1 at
<span class="math">\(x_{i}\)</span> and zero at all other nodes, only the interval <span class="math">\([x_{i-1},x_{i+1}]\)</span>
contribute to the integral on the right-hand side. This integral is
naturally split into two parts according to
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>:</p>
<div class="math">
\[(f,{\varphi}_i) = \int_{x_{i-1}}^{x_{i}} f(x)\frac{1}{h} (x - x_{i-1}) dx
+ \int_{x_{i}}^{x_{i+1}} f(x)\frac{1}{h}(1 - (x - x_{i})) dx
{\thinspace .}\]</div>
<p>However, if <span class="math">\(f\)</span> is not known we cannot do much else with this expression.
It is clear that many values of
<span class="math">\(f\)</span> around <span class="math">\(x_{i}\)</span> contributes to the right-hand side, not just
the single point value <span class="math">\(f(x_{i})\)</span>
as in the finite difference method.</p>
<p>To proceed with the right-hand side, we can
turn to numerical integration schemes.
The Trapezoidal method for <span class="math">\((f,{\varphi}_i)\)</span>, based on
sampling the integrand <span class="math">\(f{\varphi}_i\)</span> at the node points <span class="math">\(x_{i}=i h\)</span>
gives</p>
<div class="math">
\[(f,{\varphi}_i) = \int_\Omega f{\varphi}_i dx\approx h\frac{1}{2}(
f(x_{0}){\varphi}_i(x_{0}) + f(x_{N}){\varphi}_i(x_{N}))
+ h\sum_{j=1}^{N-1} f(x_{j}){\varphi}_i(x_{j})
{\thinspace .}\]</div>
<p>Since <span class="math">\({\varphi}_i\)</span> is zero at all these points, except at <span class="math">\(x_{i}\)</span>, the
Trapezoidal rule collapses to one term:</p>
<div class="math">
\[(f,{\varphi}_i) \approx hf(x_{i}),\]</div>
<p>for <span class="math">\(i=1,\ldots,N-1\)</span>,
which is the same result as with collocation/interpolation, and of course
the same result as in the finite difference method.
For <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span> we get contribution from only one element so</p>
<div class="math">
\[(f,{\varphi}_i) \approx \frac{1}{2}hf(x_{i}),\quad i=0,\ i=N
{\thinspace .}\]</div>
<p>Simpson&#8217;s rule with sample points also in the middle of
the elements, at <span class="math">\(x_{i+\frac{1}{2}}=(x_{i} + x_{i+1})/2\)</span>,
can be written as</p>
<div class="math">
\[\int_\Omega g(x)dx \approx \frac{\tilde h}{3}\left( g(x_{0}) +
2\sum_{j=1}^{N-1} g(x_{j})
+ 4\sum_{j=0}^{N-1} g(x_{j+\frac{1}{2}}) + f(x_{2N})\right),\]</div>
<p>where <span class="math">\(\tilde h= h/2\)</span> is the spacing between the sample points.
Our integrand is <span class="math">\(g=f{\varphi}_i\)</span>. For all the node points,
<span class="math">\({\varphi}_i(x_{j})=\delta_{ij}\)</span>, and therefore
<span class="math">\(\sum_{j=1}^{N-1} f(x_{j}){\varphi}_i(x_{j})=f(x_{i})\)</span>.
At the midpoints, <span class="math">\({\varphi}_i(x_{i\pm\frac{1}{2}})=1/2\)</span> and
<span class="math">\({\varphi}_i(x_{j+\frac{1}{2}})=0\)</span> for <span class="math">\(j&gt;1\)</span> and <span class="math">\(j&lt;i-1\)</span>.
Consequently,</p>
<div class="math">
\[\sum_{j=0}^{N-1} f(x_{j+\frac{1}{2}}){\varphi}_i(x_{j+\frac{1}{2}})
= \frac{1}{2}(fx_{j-\frac{1}{2}} + x_{j+\frac{1}{2}}){\thinspace .}\]</div>
<p>When <span class="math">\(1\leq i\leq N-1\)</span> we then get</p>
<div class="math">
\[(f,{\varphi}_i) \approx
\frac{h}{3}(f_{i-\frac{1}{2}} + f_i + f_{i+\frac{1}{2}})
{\thinspace .}\]</div>
<p>This result shows that, with Simpson&#8217;s rule, the finite element method
operates with the average of <span class="math">\(f\)</span> over three points, while the finite difference
method just applies <span class="math">\(f\)</span> at one point. We may interpret this as
a &#8220;smearing&#8221; or smoothing of <span class="math">\(f\)</span> by the finite element method.</p>
<p>We can now summarize our findings. With the approximation of
<span class="math">\((f,{\varphi}_i)\)</span> by the Trapezoidal rule, P1 elements give rise
to equations that can be expressed as a finite difference
discretization of</p>
<div class="math">
\[u + \frac{h^2}{6} u'' = f,\quad u'(0)=u'(L)=0,\]</div>
<p>expressed with operator notation as</p>
<div class="math">
\[[u + \frac{h^2}{6} D_x D_x u = f]_i{\thinspace .}\]</div>
<p>As <span class="math">\(h\rightarrow 0\)</span>, the extra term proportional to <span class="math">\(u''\)</span> goes to zero,
and the two methods are then equal.</p>
<p>With the Simpson&#8217;s rule, we may say that we solve</p>
<div class="math">
\[[u + \frac{h^2}{6} D_x D_x u = \bar f]_i,\]</div>
<p>where <span class="math">\(\bar f_i\)</span> means the average <span class="math">\(\frac{1}{3}(f_{i-1/2} + f_i + f_{i+1/2})\)</span>.</p>
<p>The extra term <span class="math">\(\frac{h^2}{6} u''\)</span> represents a smoothing effect: with
just this term, we would find <span class="math">\(u\)</span> by integrating <span class="math">\(f\)</span> twice and thereby
smooth <span class="math">\(f\)</span> considerably. In addition, the finite element
representation of <span class="math">\(f\)</span> involves an average, or a smoothing, of <span class="math">\(f\)</span> on
the right-hand side of the equation system. If <span class="math">\(f\)</span> is a noisy
function, direct interpolation <span class="math">\(u_i=f_i\)</span> may result in a noisy <span class="math">\(u\)</span>
too, but with a Galerkin or least squares formulation and P1 elements,
we should expect that <span class="math">\(u\)</span> is smoother than <span class="math">\(f\)</span> unless <span class="math">\(h\)</span> is very
small.</p>
<p>The interpretation that finite elements tend to smooth the solution
is valid in applications far beyond approximation of 1D functions.</p>
</div>
<div class="section" id="making-finite-elements-behave-as-finite-differences">
<h2>Making finite elements behave as finite differences<a class="headerlink" href="#making-finite-elements-behave-as-finite-differences" title="Permalink to this headline">¶</a></h2>
<p>With a simple trick, using numerical integration, we can easily produce
the result <span class="math">\(u_i=f_i\)</span> with the Galerkin or least square formulation
with P1 elements. This is useful in many occasions when we deal
with more difficult differential equations and want the finite element
method to have properties like the finite difference method (solving
standard linear wave equations is one primary example).</p>
<div class="section" id="computations-in-physical-space">
<h3>Computations in physical space<a class="headerlink" href="#computations-in-physical-space" title="Permalink to this headline">¶</a></h3>
<p>We have already seen that applying the Trapezoidal rule to the
right-hand side <span class="math">\((f,{\varphi}_i)\)</span> simply gives <span class="math">\(f\)</span> sampled at <span class="math">\(x_{i}\)</span>.
Using the Trapezoidal rule on the  matrix entries
<span class="math">\(A_{i,j}=({\varphi}_i,{\varphi}_j)\)</span> involves a sum</p>
<div class="math">
\[\sum_k {\varphi}_i(x_{k}){\varphi}_j(x_{k}),\]</div>
<p>but <span class="math">\({\varphi}_i(x_{k})=\delta_{ik}\)</span> and
<span class="math">\({\varphi}_j(x_{k})=\delta_{jk}\)</span>.
The product <span class="math">\({\varphi}_i{\varphi}_j\)</span> is then different from zero only
when sampled at <span class="math">\(x_{i}\)</span> and <span class="math">\(i=j\)</span>. The Trapezoidal
approximation to the integral
is then</p>
<div class="math">
\[({\varphi}_i,{\varphi}_j) \approx h,\quad i=j,\]</div>
<p>and zero if <span class="math">\(i\neq j\)</span>. This means that we have obtained a diagonal matrix!
The first and last diagonal elements, <span class="math">\(({\varphi}_0,{\varphi}_0)\)</span> and
<span class="math">\(({\varphi}_N,{\varphi}_N)\)</span> get contribution only from the first and last
element, respectively, resulting in the approximate integral value <span class="math">\(h/2\)</span>.
The corresponding right-hand side also has a factor <span class="math">\(1/2\)</span> for <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span>.
Therefore, the least squares or Galerkin approach with P1 elements and
Trapezoidal integration results in</p>
<div class="math">
\[c_i = f_i,\quad i\in{I}{\thinspace .}\]</div>
<p>Simpsons&#8217;s rule can be used to achieve a similar result for P2 elements, i.e,
a diagonal coefficient matrix, but with the previously derived
average of <span class="math">\(f\)</span> on the right-hand side.</p>
</div>
<div class="section" id="elementwise-computations">
<h3>Elementwise computations<a class="headerlink" href="#elementwise-computations" title="Permalink to this headline">¶</a></h3>
<p>Identical results to those above will arise if we perform elementwise
computations. The idea is to use the Trapezoidal rule on the reference
element for computing the element matrix and vector. When assembled,
the same equations <span class="math">\(c_i=f(x_{i})\)</span> arise. <a class="reference internal" href="#fem-approx-fe-exer-1d-trapez"><em>Exercise 19: Use the Trapezoidal rule and P1 elements</em></a> encourages you to carry out the
details.</p>
<span class="target" id="index-34"></span><span class="target" id="index-35"></span></div>
<div class="section" id="terminology">
<span id="index-36"></span><h3>Terminology<a class="headerlink" href="#terminology" title="Permalink to this headline">¶</a></h3>
<p>The matrix with entries <span class="math">\(({\varphi}_i,{\varphi}_j)\)</span> typically arises from
terms proportional to <span class="math">\(u\)</span> in a differential equation where <span class="math">\(u\)</span> is the
unknown function. This matrix is often called the <em>mass matrix</em>,
because in the early days of the finite element method, the matrix
arose from the mass times acceleration term in Newton&#8217;s second law of
motion. Making the mass matrix diagonal by, e.g., numerical
integration, as demonstrated above, is a widely used technique and is
called <em>mass lumping</em>. In time-dependent problems it can sometimes
enhance the numerical accuracy and computational efficiency of the
finite element method.  However, there are also examples where mass
lumping destroys accuracy.</p>
</div>
</div>
</div>
<div class="section" id="a-generalized-element-concept">
<span id="fem-approx-fe-element"></span><h1>A generalized element concept<a class="headerlink" href="#a-generalized-element-concept" title="Permalink to this headline">¶</a></h1>
<p>So far, finite element computing has employed the <tt class="docutils literal"><span class="pre">nodes</span></tt> and
<tt class="docutils literal"><span class="pre">element</span></tt> lists together with the definition of the basis functions
in the reference element. Suppose we want to introduce a piecewise
constant approximation with one basis function <span class="math">\({\tilde{\varphi}}_0(x)=1\)</span> in
the reference element, corresponding to a <span class="math">\({\varphi}_i(x)\)</span> function that
is 1 on element number <span class="math">\(i\)</span> and zero on all other elements.
Although we could associate the function value
with a node in the middle of the elements, there are no nodes at the
ends, and the previous code snippets will not work because we
cannot find the element boundaries from the <tt class="docutils literal"><span class="pre">nodes</span></tt> list.</p>
<div class="section" id="cells-vertices-and-degrees-of-freedom">
<span id="fem-approx-fe-element-terminology"></span><h2>Cells, vertices, and degrees of freedom<a class="headerlink" href="#cells-vertices-and-degrees-of-freedom" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-37"></span><span class="target" id="index-38"></span><span class="target" id="index-39"></span><p id="index-40">We now introduce <em>cells</em> as the subdomains <span class="math">\(\Omega^{(e)}\)</span> previously
referred as elements. The cell boundaries are denoted as <em>vertices</em>.
The reason for this name is that cells are recognized by their vertices
in 2D and 3D. We also define a set of <em>degrees of freedom</em>, which are
the quantities we aim to compute. The most common type of degree
of freedom is the value of the unknown function <span class="math">\(u\)</span> at some point.
(For example, we can introduce nodes as before and say the degrees of
freedom are the values of <span class="math">\(u\)</span> at the nodes.) The basis functions are
constructed so that they equal unity for one particular degree of
freedom and zero for the rest. This property ensures that when
we evaluate <span class="math">\(u=\sum_j c_j{\varphi}_j\)</span> for degree of freedom number <span class="math">\(i\)</span>,
we get <span class="math">\(u=c_i\)</span>. Integrals are performed over cells, usually by
mapping the cell of interest to a <em>reference cell</em>.</p>
<p>With the concepts of cells, vertices, and degrees of freedom we
increase the decoupling of the geometry (cell, vertices) from the
space of basis functions. We will associate different
sets of basis functions with a cell. In 1D, all cells are intervals,
while in 2D we can have cells that are triangles with straight sides,
or any polygon, or in fact any two-dimensional geometry. Triangles and
quadrilaterals are most common, though. The popular cell types in 3D
are tetrahedra and hexahedra.</p>
</div>
<div class="section" id="extended-finite-element-concept">
<span id="fem-approx-fe-element-def"></span><h2>Extended finite element concept<a class="headerlink" href="#extended-finite-element-concept" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-41"></span><p id="index-42">The concept of a <em>finite element</em> is now</p>
<blockquote>
<div><ul class="simple">
<li>a <em>reference cell</em> in a local reference coordinate system;</li>
<li>a set of <em>basis functions</em> <span class="math">\({\tilde{\varphi}}_i\)</span> defined on the cell;</li>
<li>a set of <em>degrees of freedom</em> that uniquely determines
the basis functions such that <span class="math">\({\tilde{\varphi}}_i=1\)</span> for degree of freedom
number <span class="math">\(i\)</span> and <span class="math">\({\tilde{\varphi}}_i=0\)</span> for all other degrees of freedom;</li>
<li>a mapping between local and global degree of freedom numbers,
here called the <em>dof map</em>;</li>
<li>a geometric <em>mapping</em> of the reference cell onto to cell in the physical
domain.</li>
</ul>
</div></blockquote>
<p>There must be a geometric description of a cell. This is trivial in 1D
since the cell is an interval and is described by the interval limits,
here called vertices. If the cell is <span class="math">\(\Omega^{(e)}=[x_L,x_R]\)</span>,
vertex 0 is <span class="math">\(x_L\)</span> and vertex 1 is <span class="math">\(x_R\)</span>. The reference cell in 1D
is <span class="math">\([-1,1]\)</span> in the reference coordinate system <span class="math">\(X\)</span>.</p>
<p id="index-43">The expansion of <span class="math">\(u\)</span> over one cell is often used:</p>
<div class="math">
\[u(x) = \tilde u(X) = \sum_{r} c_r{\tilde{\varphi}}_r(X),\quad x\in\Omega^{(e)},\
X\in [-1,1],\]</div>
<p>where the sum is taken over the numbers of the degrees of freedom and
<span class="math">\(c_r\)</span> is the value of <span class="math">\(u\)</span> for degree of freedom number <span class="math">\(r\)</span>.</p>
<p>Our previous P1, P2, etc., elements are defined by introducing <span class="math">\(d+1\)</span>
equally spaced nodes in the reference cell and saying that the degrees
of freedom are the <span class="math">\(d+1\)</span> function values at these nodes.  The basis
functions must be 1 at one node and 0 at the others, and the Lagrange
polynomials have exactly this property.  The nodes can be numbered
from left to right with associated degrees of freedom that are
numbered in the same way.  The degree of freedom mapping becomes what
was previously represented by the <tt class="docutils literal"><span class="pre">elements</span></tt> lists.  The cell mapping
is the same affine mapping <a href="#equation-fem:approx:fe:affine:mapping">(28)</a> as
before.</p>
</div>
<div class="section" id="implementation-2">
<span id="fem-approx-fe-element-impl"></span><h2>Implementation  (2)<a class="headerlink" href="#implementation-2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-44"></span><span class="target" id="index-45"></span><p id="index-46">Implementationwise,</p>
<blockquote>
<div><ul class="simple">
<li>we replace <tt class="docutils literal"><span class="pre">nodes</span></tt> by <tt class="docutils literal"><span class="pre">vertices</span></tt>;</li>
<li>we introduce <tt class="docutils literal"><span class="pre">cells</span></tt> such that <tt class="docutils literal"><span class="pre">cell[e][r]</span></tt> gives the mapping
from local vertex <tt class="docutils literal"><span class="pre">r</span></tt> in cell <tt class="docutils literal"><span class="pre">e</span></tt> to the global vertex number
in <tt class="docutils literal"><span class="pre">vertices</span></tt>;</li>
<li>we replace <tt class="docutils literal"><span class="pre">elements</span></tt> by <tt class="docutils literal"><span class="pre">dof_map</span></tt> (the contents are the same
for Pd elements).</li>
</ul>
</div></blockquote>
<p>Consider the example from the section <a class="reference internal" href="#fem-approx-fe-def-elements-nodes"><em>Elements and nodes</em></a>
where <span class="math">\(\Omega =[0,1]\)</span> is divided into two cells,
<span class="math">\(\Omega^{(0)}=[0,0.4]\)</span> and <span class="math">\(\Omega^{(1)}=[0.4,1]\)</span>, as
depicted in Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p2"><em>Finite element mesh with 2 elements and 5 nodes</em></a>.
The vertices are <span class="math">\([0,0.4,1]\)</span>. Local vertex 0 and 1 are
<span class="math">\(0\)</span> and <span class="math">\(0.4\)</span> in cell 0 and <span class="math">\(0.4\)</span> and <span class="math">\(1\)</span> in cell 1.
A P2 element means that the degrees of freedom are
the value of <span class="math">\(u\)</span> at three equally spaced points (nodes) in each
cell. The data structures become</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">cells</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
</pre></div>
</div>
<p>If we would approximate <span class="math">\(f\)</span> by piecewise constants, known as
P0 elements, we simply
introduce one point or node in an element, preferably <span class="math">\(X=0\)</span>,
and define one degree of freedom, which is the function value
at this node. Moreover, we set <span class="math">\({\tilde{\varphi}}_0(X)=1\)</span>.
The <tt class="docutils literal"><span class="pre">cells</span></tt> and <tt class="docutils literal"><span class="pre">vertices</span></tt> arrays remain the same, but
<tt class="docutils literal"><span class="pre">dof_map</span></tt> is altered:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
<p>We use the <tt class="docutils literal"><span class="pre">cells</span></tt> and <tt class="docutils literal"><span class="pre">vertices</span></tt> lists to retrieve information
on the geometry of a cell, while <tt class="docutils literal"><span class="pre">dof_map</span></tt> is the
<span class="math">\(q(e,r)\)</span> mapping introduced earlier in the
assembly of element matrices and vectors.
For example, the <tt class="docutils literal"><span class="pre">Omega_e</span></tt> variable (representing the cell interval)
in previous code snippets must now be computed as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">Omega_e</span> <span class="o">=</span> <span class="p">[</span><span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
<p>The assembly is done by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">A</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span> <span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
<span class="n">b</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
</pre></div>
</div>
<p>We will hereafter drop the <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> arrays
and work exculsively with <tt class="docutils literal"><span class="pre">cells</span></tt>, <tt class="docutils literal"><span class="pre">vertices</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt>.
The module <tt class="docutils literal"><span class="pre">fe_approx1D_numint.py</span></tt> now replaces the module
<tt class="docutils literal"><span class="pre">fe_approx1D</span></tt> and offers similar functions that work with
the new concepts:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">fe_approx1D_numint</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
<span class="n">N_e</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span> <span class="o">=</span> <span class="n">mesh_uniform</span><span class="p">(</span><span class="n">N_e</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">basis</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_e</span><span class="p">)]</span>
<span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="c"># Make very fine mesh and sample u(x) on this mesh for plotting</span>
<span class="n">x_u</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">u_glob</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span><span class="p">,</span>
                <span class="n">resolution_per_element</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x_u</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
</pre></div>
</div>
<p>These steps are offered in the <tt class="docutils literal"><span class="pre">approximate</span></tt> function, which we here
apply to see how well four P0 elements (piecewise constants)
can approximate a parabola:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">fe_approx1D_numint</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">x</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&quot;x&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">N_e</span> <span class="ow">in</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span>
    <span class="n">approximate</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">),</span> <span class="n">d</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="n">N_e</span><span class="p">,</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-element-impl-fig-p0-x2"><em>Approximation of a parabola by 4 (left) and 8 (right) P0 elements</em></a> shows the result.</p>
<div class="figure" id="fem-approx-fe-element-impl-fig-p0-x2">
<img alt="_images/fe_p0_x2_4e_8e1.png" src="_images/fe_p0_x2_4e_8e1.png" style="width: 600px;" />
<p class="caption"><em>Approximation of a parabola by 4 (left) and 8 (right) P0 elements</em></p>
</div>
</div>
<div class="section" id="computing-the-error-of-the-approximation">
<span id="fem-approx-fe-element-impl-error"></span><h2>Computing the error of the approximation<a class="headerlink" href="#computing-the-error-of-the-approximation" title="Permalink to this headline">¶</a></h2>
<p>So far we have focused on computing the coefficients <span class="math">\(c_j\)</span> in the
approximation <span class="math">\(u(x)=\sum_jc_j{\varphi}_j\)</span> as well as on plotting <span class="math">\(u\)</span> and
<span class="math">\(f\)</span> for visual comparison. A more quantitative comparison needs to
investigate the error <span class="math">\(e(x)=f(x)-u(x)\)</span>. We mostly want a single number to
reflect the error and use a norm for this purpose, usually the <span class="math">\(L^2\)</span> norm</p>
<div class="math">
\[||e||_{L^2} = \left(\int_{\Omega} e^2 dx\right)^{1/2}{\thinspace .}\]</div>
<p>Since the finite element approximation is defined for all <span class="math">\(x\in\Omega\)</span>,
and we are interested in how <span class="math">\(u(x)\)</span> deviates from <span class="math">\(f(x)\)</span> through all
the elements,
we can either integrate analytically or use an accurate numerical
approximation. The latter is more convenient as it is a generally
feasible and simple approach. The idea is to sample <span class="math">\(e(x)\)</span>
at a large number of points in each element. The function <tt class="docutils literal"><span class="pre">u_glob</span></tt>
in the <tt class="docutils literal"><span class="pre">fe_approx1D_numint</span></tt> module does this for <span class="math">\(u(x)\)</span> and returns
an array <tt class="docutils literal"><span class="pre">x</span></tt> with coordinates and an array <tt class="docutils literal"><span class="pre">u</span></tt> with the <span class="math">\(u\)</span> values:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">u_glob</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span><span class="p">,</span>
              <span class="n">resolution_per_element</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">u</span>
</pre></div>
</div>
<p>Let us use the Trapezoidal method to approximate the integral. Because
different elements may have different lengths, the <tt class="docutils literal"><span class="pre">x</span></tt> array has
a non-uniformly distributed set of coordinates. Also, the <tt class="docutils literal"><span class="pre">u_glob</span></tt>
function works in an element by element fashion such that coordinates
at the boundaries between elements appear twice. We therefore need
to use a &#8220;raw&#8221; version of the Trapezoidal rule where we just add up
all the trapezoids:</p>
<div class="math">
\[\int_\Omega g(x) dx \approx \sum_{j=0}^{n-1} \frac{1}{2}(g(x_j) +
g(x_{j+1}))(x_{j+1}-x_j),\]</div>
<p>if <span class="math">\(x_0,\ldots,x_n\)</span> are all the coordinates in <tt class="docutils literal"><span class="pre">x</span></tt>. In
vectorized Python code,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">g_x</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">integral</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">g_x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">g_x</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>Computing the <span class="math">\(L^2\)</span> norm of the error, here named <tt class="docutils literal"><span class="pre">E</span></tt>, is now achieved by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">e2</span> <span class="o">=</span> <span class="n">e</span><span class="o">**</span><span class="mi">2</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">e2</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">e2</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<div class="admonition-how-does-the-error-depend-on-math-h-and-math-d admonition">
<p class="first admonition-title">How does the error depend on <span class="math">\(h\)</span> and <span class="math">\(d\)</span></p>
<p>Theory and experiments show that the least squares or projection/Galerkin
method in combination with Pd elements of equal length <span class="math">\(h\)</span> has an error</p>
<div class="math" id="equation-fem:approx:fe:error:theorem">
<span class="eqno">(39)</span>\[     ||e||_{L^2} = Ch^{d+1},\]</div>
<p class="last">where <span class="math">\(C\)</span> is a constant depending on <span class="math">\(f\)</span>, but not on <span class="math">\(h\)</span> or <span class="math">\(d\)</span>.</p>
</div>
</div>
<div class="section" id="example-cubic-hermite-polynomials">
<span id="fem-approx-fe-element-impl-hermite"></span><h2>Example: Cubic Hermite polynomials<a class="headerlink" href="#example-cubic-hermite-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-47">The finite elements considered so far represent <span class="math">\(u\)</span> as piecewise
polynomials with discontinuous derivatives at the cell boundaries.
Sometimes it is desirable to have continuous derivatives. A primary
examples is the solution of differential equations with fourth-order
derivatives where standard finite element formulations lead to
a need for basis functions with continuous first-order derivatives.
The most common type of such basis functions in 1D is the
so-called cubic Hermite polynomials.
The construction of such polynomials, as explained next, will further
exemplify the concepts of a cell, vertex, degree of freedom, and dof map.</p>
<p>Given a reference cell <span class="math">\([-1,1]\)</span>, we seek cubic polynomials
with the values of the <em>function</em> and its <em>first-order derivative</em> at
<span class="math">\(X=-1\)</span> and <span class="math">\(X=1\)</span> as the four degrees of freedom. Let us number
the degrees of freedom as</p>
<blockquote>
<div><ul class="simple">
<li>0: value of function at <span class="math">\(X=-1\)</span></li>
<li>1: value of first derivative at <span class="math">\(X=-1\)</span></li>
<li>2: value of function at <span class="math">\(X=1\)</span></li>
<li>3: value of first derivative at <span class="math">\(X=1\)</span></li>
</ul>
</div></blockquote>
<p>By having the derivatives as unknowns, we ensure that
the derivative of a basis function in two neighboring elements
is the same at the node points.</p>
<p>The four basis functions can be written in a general form</p>
<div class="math">
\[{\tilde{\varphi}}_i (X) = \sum_{j=0}^3 C_{i,j}X^j,\]</div>
<p>with four coefficients <span class="math">\(C_{i,j}\)</span>, <span class="math">\(j=0,1,2,3\)</span>, to be determined for
each <span class="math">\(i\)</span>. The constraints
that basis function number <span class="math">\(i\)</span> must be 1 for degree of
freedom number <span class="math">\(i\)</span> and zero for the other three degrees of freedom,
gives four equations to determine <span class="math">\(C_{i,j}\)</span> for each <span class="math">\(i\)</span>. In mathematical
detail,</p>
<div class="math">
\[\begin{split}{\tilde{\varphi}}_0 (-1) &amp;= 1,\quad {\tilde{\varphi}}_0 (1)={\tilde{\varphi}}_0'(-1)={\tilde{\varphi}}_i' (1)=0,\\
{\tilde{\varphi}}_1' (-1) &amp;= 1,\quad {\tilde{\varphi}}_1 (-1)={\tilde{\varphi}}_1(1)={\tilde{\varphi}}_1' (1)=0,\\
{\tilde{\varphi}}_2 (1) &amp;= 1,\quad {\tilde{\varphi}}_2 (-1)={\tilde{\varphi}}_2'(-1)={\tilde{\varphi}}_2' (1)=0,\\
{\tilde{\varphi}}_3' (1) &amp;= 1,\quad {\tilde{\varphi}}_3 (-1)={\tilde{\varphi}}_3'(-1)={\tilde{\varphi}}_3 (1)=0
{\thinspace .}\end{split}\]</div>
<p>These four <span class="math">\(4\times 4\)</span> linear equations can be solved, yielding the
following formulas
for the cubic basis functions:</p>
<div class="math">
\[{\tilde{\varphi}}_0(X) = 1 - \frac{3}{4}(X+1)^2 + \frac{1}{4}(X+1)^3\]</div>
<div class="math">
\[{\tilde{\varphi}}_1(X) = -(X+1)(1 - \frac{1}{2}(X+1))^2\]</div>
<div class="math">
\[{\tilde{\varphi}}_2(X) = \frac{3}{4}(X+1)^2 - \frac{1}{2}(X+1)^3\]</div>
<div class="math">
\[{\tilde{\varphi}}_3(X) = -\frac{1}{2}(X+1)(\frac{1}{2}(X+1)^2 - (X+1))\]</div>
<div class="math">
</div>
<p>The construction of the dof map needs a scheme for numbering the
global degrees of freedom. A natural left-to-right numbering
has the function value at vertex <span class="math">\(x_{i}\)</span>
as degree of freedom number <span class="math">\(2i\)</span> and the value of the derivative
at <span class="math">\(x_{i}\)</span> as degree of freedom number <span class="math">\(2i+1\)</span>, <span class="math">\(i=0,\ldots,N_e+1\)</span>.</p>
</div>
</div>
<div class="section" id="numerical-integration-1">
<h1>Numerical integration  (1)<a class="headerlink" href="#numerical-integration-1" title="Permalink to this headline">¶</a></h1>
<p>Finite element codes usually apply numerical approximations to
integrals. Since the integrands in the coefficient matrix often
are (lower-order) polynomials, integration rules that can
integrate polynomials exactly are popular.</p>
<p>The numerical integration rules can be expressed in a common form,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx \sum_{j=0}^M w_j g(\bar X_j),\]</div>
<p>where <span class="math">\(\bar X_j\)</span> are <em>integration points</em> and <span class="math">\(w_j\)</span> are
<em>integration weights</em>, <span class="math">\(j=0,\ldots,M\)</span>.
Different rules correspond to different choices of points and weights.</p>
<p>The very simplest method is the <em>Midpoint rule</em>,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx 2g(0),\quad \bar X_0=0,\ w_0=2,\]</div>
<p>which integrates linear functions exactly.</p>
<div class="section" id="newton-cotes-rules">
<span id="fem-approx-fe-numint1"></span><h2>Newton-Cotes rules<a class="headerlink" href="#newton-cotes-rules" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-48"></span><span class="target" id="index-49"></span><span class="target" id="index-50"></span><span class="target" id="index-51"></span><span class="target" id="index-52"></span><span class="target" id="index-53"></span><span class="target" id="index-54"></span><p id="index-55">The <a class="reference external" href="http://en.wikipedia.org/wiki/Newton%E2%80%93Cotes_formulas">Newton-Cotes</a>
rules are based on a fixed uniform distribution of the integration points.
The first two formulas in this family are the well-known
<em>Trapezoidal rule</em>,</p>
<div class="math" id="equation-fem:approx:fe:numint1:trapez">
<span class="eqno">(40)</span>\[     \int_{-1}^{1} g(X)dX \approx g(-1) + g(1),\quad \bar X_0=-1,\ \bar X_1=1,\ w_0=w_1=1,\]</div>
<p>and <em>Simpson&#8217;s rule</em>,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx \frac{1}{3}\left(g(-1) + 4g(0)
+ g(1)\right),\]</div>
<p>where</p>
<div class="math">
\[\bar X_0=-1,\ \bar X_1=0,\ \bar X_2=1,\ w_0=w_2=\frac{1}{3},\ w_1=\frac{4}{3}{\thinspace .}\]</div>
<p>Newton-Cotes rules up to five points is supported in the
module file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/numint.py">numint.py</a>.</p>
<p>For higher accuracy one can divide the reference cell into a set of
subintervals and use the rules above on each subinterval. This approach
results in <em>composite</em> rules, well-known from basic introductions
to numerical integration of <span class="math">\(\int_{a}^{b}f(x)dx\)</span>.</p>
</div>
<div class="section" id="gauss-legendre-rules-with-optimized-points">
<h2>Gauss-Legendre rules with optimized points<a class="headerlink" href="#gauss-legendre-rules-with-optimized-points" title="Permalink to this headline">¶</a></h2>
<p id="index-56">More accurate rules, for a given <span class="math">\(M\)</span>, arise if the location of the
integration points are optimized for polynomial integrands.  The
<a class="reference external" href="http://en.wikipedia.org/wiki/Gaussian_quadrature">Gauss-Legendre rules</a> (also known as
Gauss-Legendre quadrature or Gaussian quadrature) constitute one such
class of integration methods. Two widely applied Gauss-Legendre rules
in this family have the choice</p>
<div class="math">
\[M=1:\quad \bar X_0=-\frac{1}{\sqrt{3}},\
\bar X_1=\frac{1}{\sqrt{3}},\ w_0=w_1=1\]</div>
<div class="math">
\[M=2:\quad \bar X_0=-\sqrt{\frac{3}{{5}}},\ \bar X_0=0,\
\bar X_2= \sqrt{\frac{3}{{5}}},\ w_0=w_2=\frac{5}{9},\ w_1=\frac{8}{9}{\thinspace .}\]</div>
<p>These rules integrate 3rd and 5th degree polynomials exactly.
In general, an <span class="math">\(M\)</span>-point Gauss-Legendre rule integrates a polynomial
of degree <span class="math">\(2M+1\)</span> exactly.
The code <tt class="docutils literal"><span class="pre">numint.py</span></tt> contains a large collection of Gauss-Legendre rules.</p>
</div>
</div>
<div class="section" id="approximation-of-functions-in-2d">
<span id="fem-approx-2d"></span><h1>Approximation of functions in 2D<a class="headerlink" href="#approximation-of-functions-in-2d" title="Permalink to this headline">¶</a></h1>
<p>All the concepts and algorithms developed for approximation of 1D functions
<span class="math">\(f(x)\)</span> can readily be extended to 2D functions <span class="math">\(f(x,y)\)</span> and 3D functions
<span class="math">\(f(x,y,z)\)</span>. Basically, the extensions consists of defining basis functions
<span class="math">\({\psi}_i(x,y)\)</span> or <span class="math">\({\psi}_i(x,y,z)\)</span> over some domain <span class="math">\(\Omega\)</span>, and
for the least squares and Galerkin methods, the integration is done over
<span class="math">\(\Omega\)</span>.</p>
<p>As in 1D, the least squares and projection/Galerkin methods
two lead to linear systems</p>
<div class="math">
\[\begin{split}\sum_{j\in{I}} A_{i,j}c_j &amp;= b_i,\quad i\in{I},\\
A_{i,j} &amp;= ({\psi}_i,{\psi}_j),\\
b_i &amp;= (f,{\psi}_i),\end{split}\]</div>
<p>where the inner product of two functions <span class="math">\(f(x,y)\)</span> and <span class="math">\(g(x,y)\)</span> is defined
completely analogously to the 1D case <a href="#equation-fem:approx:LS:innerprod">(15)</a>:</p>
<div class="math">
\[(f,g) = \int_\Omega f(x,y)g(x,y) dx dy\]</div>
<div class="section" id="d-basis-functions-as-tensor-products-of-1d-functions">
<span id="fem-approx-2d-global"></span><h2>2D basis functions as tensor products of 1D functions<a class="headerlink" href="#d-basis-functions-as-tensor-products-of-1d-functions" title="Permalink to this headline">¶</a></h2>
<p id="index-57">One straightforward
way to construct a basis in 2D is to combine
1D basis functions. Say we have the 1D vector space</p>
<div class="math" id="equation-fem:approx:2D:Vx">
<span class="eqno">(41)</span>\[     V_x = \mbox{span}\{ \hat{\psi}_0(x),\ldots,\hat{\psi}_{N_x}(x)\}\]\[     {\thinspace .}\]</div>
<p>A similar space for variation in <span class="math">\(y\)</span> can be defined,</p>
<div class="math" id="equation-fem:approx:2D:Vy">
<span class="eqno">(42)</span>\[     V_y = \mbox{span}\{ \hat{\psi}_0(y),\ldots,\hat{\psi}_{N_y}(y)\}\]\[     {\thinspace .}\]</div>
<p>We can then form 2D basis functions as <em>tensor products</em> of 1D basis functions.</p>
<div class="admonition-tensor-products admonition">
<p class="first admonition-title">Tensor products</p>
<p>Given two vectors <span class="math">\(a=(a_0,\ldots,a_M)\)</span> and <span class="math">\(b=(b_0,\ldots,b_N)\)</span>,
their <em>outer tensor product</em>, also called the <em>dyadic product</em>,
is <span class="math">\(p=a\otimes b\)</span>, defined through</p>
<div class="math">
\[p_{i,j}=a_ib_j,\quad i=0,\ldots,M,\ j=0,\ldots,N{\thinspace .}\]</div>
<p>In the tensor terminology,
<span class="math">\(a\)</span> and <span class="math">\(b\)</span> are first-order tensors (vectors with one index, also termed
rank-1 tensors), and then their outer
tensor product is a second-order tensor (matrix with two indices, also
termed rank-2 tensor). The
corresponding <em>inner tensor product</em> is the well-known scalar or dot
product of two vectors: <span class="math">\(p=a\cdot b = \sum_{j=0}^N a_jb_j\)</span>. Now,
<span class="math">\(p\)</span> is a rank-0 tensor.</p>
<p>Tensors are typically represented by arrays in computer code.
In the above example, <span class="math">\(a\)</span> and <span class="math">\(b\)</span> are represented by
one-dimensional arrays of length
<span class="math">\(M\)</span> and <span class="math">\(N\)</span>, respectively, while <span class="math">\(p=a\otimes b\)</span> must be represented
by a two-dimensional array of size <span class="math">\(M\times N\)</span>.</p>
<p class="last"><a class="reference external" href="http://en.wikipedia.org/wiki/Tensor_product">Tensor products</a> can
be used in a variety of context.</p>
</div>
<p>Given the vector spaces <span class="math">\(V_x\)</span> and <span class="math">\(V_y\)</span> as defined
in <a href="#equation-fem:approx:2D:Vx">(41)</a> and <a href="#equation-fem:approx:2D:Vy">(42)</a>, the
tensor product space <span class="math">\(V=V_x\otimes V_y\)</span> has a basis formed
as the tensor product of the basis for <span class="math">\(V_x\)</span> and <span class="math">\(V_y\)</span>.
That is, if <span class="math">\(\left\{ {\varphi}_i(x) \right\}_{i\in{I_x}}\)</span>
and <span class="math">\(\left\{ {\varphi}_i(y) \right\}_{i\in {I_y}}\)</span> are basis for
<span class="math">\(V_x\)</span> and <span class="math">\(V_y\)</span>, respectively, the elements in the basis for <span class="math">\(V\)</span> arise
from the tensor product:
<span class="math">\(\left\{ {\varphi}_i(x){\varphi}_j(y) \right\}_{i\in {I_x},j\in {I_y}}\)</span>.
The index sets are <span class="math">\(I_x=\{0,\ldots,N_x\}\)</span> and <span class="math">\(I_y=\{0,\ldots,N_y\}\)</span>.</p>
<p>The notation for a basis function in 2D can employ a double index as in</p>
<div class="math">
\[{\psi}_{p,q}(x,y) = \hat{\psi}_p(x)\hat{\psi}_q(y),
\quad p\in{I_x},q\in{I_y}{\thinspace .}\]</div>
<p>The expansion for <span class="math">\(u\)</span> is then written as a double sum</p>
<div class="math">
\[u = \sum_{p\in{I_x}}\sum_{q\in{I_y}} c_{p,q}{\psi}_{p,q}(x,y){\thinspace .}\]</div>
<p>Alternatively, we may employ a single index,</p>
<div class="math">
\[{\psi}_i(x,y) = \hat{\psi}_p(x)\hat{\psi}_q(y),\]</div>
<p>and use the standard form for <span class="math">\(u\)</span>,</p>
<div class="math">
\[u = \sum_{j\in{I}} c_j{\psi}_j(x,y){\thinspace .}\]</div>
<p>The single index is related to the double index through
<span class="math">\(i=p N_y + q\)</span> or <span class="math">\(i=q N_x + p\)</span>.</p>
</div>
<div class="section" id="example-polynomial-basis-in-2d">
<h2>Example: Polynomial basis in 2D<a class="headerlink" href="#example-polynomial-basis-in-2d" title="Permalink to this headline">¶</a></h2>
<p>Suppose we choose <span class="math">\(\hat{\psi}_p(x)=x^p\)</span>, and try an approximation with
<span class="math">\(N_x=N_y=1\)</span>:</p>
<div class="math">
\[{\psi}_{0,0}=1,\quad {\psi}_{1,0}=x, \quad {\psi}_{0,1}=y,
\quad {\psi}_{1,1}=xy
{\thinspace .}\]</div>
<p>Using a mapping to one index like <span class="math">\(i=q N_x + p\)</span>, we get</p>
<div class="math">
\[{\psi}_0=1,\quad {\psi}_1=x, \quad {\psi}_2=y,\quad{\psi}_3 =xy
{\thinspace .}\]</div>
<p>With the specific choice <span class="math">\(f(x,y) = (1+x^2)(1+2y^2)\)</span> on
<span class="math">\(\Omega = [0,L_x]\times [0,L_y]\)</span>, we can perform actual calculations:</p>
<div class="math">
\[\begin{split}A_{0,0} &amp;= ({\psi}_0,{\psi}_0) = \int_0^{L_y}\int_{0}^{L_x}
{\psi}_0(x,y)^2 dx dy = \int_0^{L_y}\int_{0}^{L_x}dx dy = L_xL_y,\\
A_{1,0} &amp;= ({\psi}_1,{\psi}_0) = \int_0^{L_y}\int_{0}^{L_x} x dxdy =
\frac{1}{2}L_x^2L_y,\\
A_{0,1} &amp;= ({\psi}_0,{\psi}_1) = \int_0^{L_y}\int_{0}^{L_x} y dxdy =
\frac{1}{2}L_y^2L_x,\\
A_{0,1} &amp;= ({\psi}_0,{\psi}_1) = \int_0^{L_y}\int_{0}^{L_x} xy dxdy =
\int_0^{L_y}ydy \int_{0}^{L_x} xdx =
\frac{1}{4}L_y^2L_x^2
{\thinspace .}\end{split}\]</div>
<p>The right-hand side vector has the entries</p>
<div class="math">
\[\begin{split}b_{0} &amp;= ({\psi}_0,f) = \int_0^{L_y}\int_{0}^{L_x}1\cdot (1+x^2)(1+2y^2) dxdy\\
&amp;= \int_0^{L_y}(1+2y^2)dy \int_{0}^{L_x} (1+x^2)dx
= (L_y + \frac{2}{3}L_y^3)(L_x + \frac{1}{3}L_x^3)\\
b_{1} &amp;= ({\psi}_1,f) = \int_0^{L_y}\int_{0}^{L_x} x(1+x^2)(1+2y^2) dxdy\\
&amp;=\int_0^{L_y}(1+2y^2)dy \int_{0}^{L_x} x(1+x^2)dx
= (L_y + \frac{2}{3}L_y^3)(\frac{1}{2}L_x^2 + \frac{1}{4}L_x^4)\\
b_{2} &amp;= ({\psi}_2,f) = \int_0^{L_y}\int_{0}^{L_x} y(1+x^2)(1+2y^2) dxdy\\
&amp;= \int_0^{L_y}y(1+2y^2)dy \int_{0}^{L_x} (1+x^2)dx
= (\frac{1}{2}L_y + \frac{1}{2}L_y^4)(L_x + \frac{1}{3}L_x^3)\\
b_{3} &amp;= ({\psi}_2,f) = \int_0^{L_y}\int_{0}^{L_x} xy(1+x^2)(1+2y^2) dxdy\\
&amp;= \int_0^{L_y}y(1+2y^2)dy \int_{0}^{L_x} x(1+x^2)dx
= (\frac{1}{2}L_y^2 + \frac{1}{2}L_y^4)(\frac{1}{2}L_x^2 + \frac{1}{4}L_x^4)
{\thinspace .}\end{split}\]</div>
<p>There is a general pattern in these calculations that we can explore.
An arbitrary matrix entry has the formula</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= ({\psi}_i,{\psi}_j) = \int_0^{L_y}\int_{0}^{L_x}
{\psi}_i{\psi}_j dx dy \\
&amp;= \int_0^{L_y}\int_{0}^{L_x}
{\psi}_{p,q}{\psi}_{r,s} dx dy
= \int_0^{L_y}\int_{0}^{L_x}
\hat{\psi}_p(x)\hat{\psi}_q(y)\hat{\psi}_r(x)\hat{\psi}_s(y) dx dy\\
&amp;= \int_0^{L_y} \hat{\psi}_q(y)\hat{\psi}_s(y)dy
\int_{0}^{L_x} \hat{\psi}_p(x) \hat{\psi}_r(x) dx\\
&amp;= \hat A^{(x)}_{p,r}\hat A^{(y)}_{q,s},\end{split}\]</div>
<p>where</p>
<div class="math">
\[\hat A^{(x)}_{p,r} = \int_{0}^{L_x} \hat{\psi}_p(x) \hat{\psi}_r(x) dx,
\quad
\hat A^{(y)}_{q,s} = \int_0^{L_y} \hat{\psi}_q(y)\hat{\psi}_s(y)dy,\]</div>
<p>are matrix entries for one-dimensional approximations. Moreover,
<span class="math">\(i=q N_y+q\)</span> and <span class="math">\(j=s N_y+r\)</span>.</p>
<p>With <span class="math">\(\hat{\psi}_p(x)=x^p\)</span> we have</p>
<div class="math">
\[\hat A^{(x)}_{p,r} = \frac{1}{p+r+1}L_x^{p+r+1},\quad
\hat A^{(y)}_{q,s} = \frac{1}{q+s+1}L_y^{q+s+1},\]</div>
<p>and</p>
<div class="math">
\[A_{i,j} = \hat A^{(x)}_{p,r} \hat A^{(y)}_{q,s} =
\frac{1}{p+r+1}L_x^{p+r+1} \frac{1}{q+s+1}L_y^{q+s+1},\]</div>
<p>for <span class="math">\(p,r\in{I_x}\)</span> and <span class="math">\(q,s\in{I_y}\)</span>.</p>
<p>Corresponding reasoning for the right-hand side leads to</p>
<div class="math">
\[\begin{split}b_i &amp;= ({\psi}_i,f) = \int_0^{L_y}\int_{0}^{L_x}{\psi}_i f\,dxdx\\
&amp;= \int_0^{L_y}\int_{0}^{L_x}\hat{\psi}_p(x)\hat{\psi}_q(y) f\,dxdx\\
&amp;= \int_0^{L_y}\hat{\psi}_q(y) (1+2y^2)dy
\int_0^{L_y}\hat{\psi}_p(x) x^p (1+x^2)dx\\
&amp;= \int_0^{L_y} y^q (1+2y^2)dy
\int_0^{L_y}x^p (1+x^2)dx\\
&amp;= (\frac{1}{q+1} L_y^{q+1} + \frac{2}{q+3}L_y^{q+3})
(\frac{1}{p+1} L_x^{p+1} + \frac{2}{q+3}L_x^{p+3})\end{split}\]</div>
<p>Choosing <span class="math">\(L_x=L_y=2\)</span>, we have</p>
<div class="math">
\[\begin{split}A =
\left[\begin{array}{cccc}
4 &amp; 4 &amp; 4 &amp; 4\\
4 &amp; \frac{16}{3} &amp; 4 &amp; \frac{16}{3}\\
4 &amp; 4 &amp; \frac{16}{3} &amp; \frac{16}{3}\\
4 &amp; \frac{16}{3} &amp; \frac{16}{3} &amp; \frac{64}{9}
\end{array}\right],\quad
b = \left[\begin{array}{c}
\frac{308}{9}\\\frac{140}{3}\\44\\60\end{array}\right],
\quad c = \left[
\begin{array}{r}
-\frac{1}{9} \\
\frac{4}{3} \\
 - \frac{2}{3} \\
 8
\end{array}\right]
{\thinspace .}\end{split}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-ubilinear"><em>Approximation of a 2D quadratic function (left) by a 2D bilinear function (right) using the Galerkin or least squares method</em></a> illustrates the result.</p>
<div class="figure" id="fem-approx-fe-2d-fig-ubilinear">
<img alt="_images/approx2D_bilinear1.png" src="_images/approx2D_bilinear1.png" style="width: 800px;" />
<p class="caption"><em>Approximation of a 2D quadratic function (left) by a 2D bilinear function (right) using the Galerkin or least squares method</em></p>
</div>
</div>
<div class="section" id="implementation-3">
<span id="fem-approx-2d-global-code"></span><h2>Implementation  (3)<a class="headerlink" href="#implementation-3" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="docutils literal"><span class="pre">least_squares</span></tt> function from
the section <a class="reference internal" href="#fem-approx-global-orth"><em>Orthogonal basis functions</em></a> and/or the
file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx1D.py">approx1D.py</a>
can with very small modifications solve 2D approximation problems.
First, let <tt class="docutils literal"><span class="pre">Omega</span></tt> now be a list of the intervals in <span class="math">\(x\)</span> and <span class="math">\(y\)</span> direction.
For example, <span class="math">\(\Omega = [0,L_x]\times [0,L_y]\)</span> can be represented
by <tt class="docutils literal"><span class="pre">Omega</span> <span class="pre">=</span> <span class="pre">[[0,</span> <span class="pre">L_x],</span> <span class="pre">[0,</span> <span class="pre">L_y]]</span></tt>.</p>
<p>Second, the symbolic integration must be extended to 2D:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span>
                 <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span>
                 <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>provided <tt class="docutils literal"><span class="pre">integrand</span></tt> is an expression involving the <tt class="docutils literal"><span class="pre">sympy</span></tt> symbols <tt class="docutils literal"><span class="pre">x</span></tt>
and <tt class="docutils literal"><span class="pre">y</span></tt>.
The 2D version of numerical integration becomes</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
    <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span>
                       <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span>
                       <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
<p>The right-hand side integrals are modified in a similar way.</p>
<p>Third, we must construct a list of 2D basis functions. Here are two
examples based on tensor products of 1D &#8220;Taylor-style&#8221; polynomials <span class="math">\(x^i\)</span>
and 1D sine functions <span class="math">\(\sin((i+1)\pi x)\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Nx</span><span class="p">,</span> <span class="n">Ny</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="o">**</span><span class="n">i</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="n">j</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ny</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">sines</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Nx</span><span class="p">,</span> <span class="n">Ny</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ny</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>The complete code appears in
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx2D.py">approx2D.py</a>.</p>
<p>The previous hand calculation where a quadratic <span class="math">\(f\)</span> was approximated by
a bilinear function can be computed symbolically by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">approx2D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span> <span class="o">=</span> <span class="n">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Omega</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">8*x*y - 2*x/3 + 4*y/3 - 1/9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">2*x**2*y**2 + x**2 + 2*y**2 + 1</span>
</pre></div>
</div>
<p>We may continue with adding higher powers to the basis:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span> <span class="o">=</span> <span class="n">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">2*x**2*y**2 + x**2 + 2*y**2 + 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span><span class="o">-</span><span class="n">f</span>
<span class="go">0</span>
</pre></div>
</div>
<p>For <span class="math">\(N_x\geq 2\)</span> and <span class="math">\(N_y\geq 2\)</span> we recover the exact function <span class="math">\(f\)</span>, as
expected, since in that case <span class="math">\(f\in V\)</span> (see
the section <a class="reference internal" href="#fem-approx-global-exact"><em>Perfect approximation</em></a>).</p>
</div>
<div class="section" id="extension-to-3d">
<span id="fem-approx-3d-global"></span><h2>Extension to 3D<a class="headerlink" href="#extension-to-3d" title="Permalink to this headline">¶</a></h2>
<p>Extension to 3D is in principle straightforward once the 2D extension
is understood. The only major difference is that we need the
repeated outer tensor product,</p>
<div class="math">
\[V = V_x\otimes V_y\otimes V_z{\thinspace .}\]</div>
<p>In general, given vectors (first-order tensors)
<span class="math">\(a^{(q)} = (a^{(q)}_0,\ldots,a^{(q)}_{N_q}\)</span>, <span class="math">\(q=0,\ldots,m\)</span>,
the tensor product <span class="math">\(p=a^{(0)}\otimes\cdots\otimes a^{m}\)</span> has
elements</p>
<div class="math">
\[p_{i_0,i_1,\ldots,i_m} = a^{(0)}_{i_1}a^{(1)}_{i_1}\cdots a^{(m)}_{i_m}{\thinspace .}\]</div>
<p>The basis functions in 3D are then</p>
<div class="math">
\[{\psi}_{p,q,r}(x,y,z) = \hat{\psi}_p(x)\hat{\psi}_q(y)\hat{\psi}_r(z),\]</div>
<p>with <span class="math">\(p\in{I_x}\)</span>, <span class="math">\(q\in{I_y}\)</span>, <span class="math">\(r\in{I_z}\)</span>. The expansion of <span class="math">\(u\)</span> becomes</p>
<div class="math">
\[u(x,y,z) = \sum_{p\in{I_x}}\sum_{q\in{I_y}}\sum_{r\in{I_z}} c_{p,q,r}
{\psi}_{p,q,r}(x,y,z){\thinspace .}\]</div>
<p>A single index can be introduced also here, e.g., <span class="math">\(i=N_xN_yr + q_Nx + p\)</span>,
<span class="math">\(u=\sum_i c_i{\psi}_i(x,y,z)\)</span>.</p>
<div class="admonition-use-of-tensor-product-spaces admonition">
<p class="first admonition-title">Use of tensor product spaces</p>
<p class="last">Constructing a multi-dimensional space and basis from tensor products
of 1D spaces is a standard technique when working with global basis
functions. In the world of finite elements, constructing basis functions
by tensor products is much used on quadrilateral and hexahedra cell
shapes, but not on triangles and tetrahedra. Also, the global
finite element basis functions are almost exclusively denoted by a single
index and not by the natural tuple of indices that arises from
tensor products.</p>
</div>
</div>
</div>
<div class="section" id="finite-elements-in-2d-and-3d">
<h1>Finite elements in 2D and 3D<a class="headerlink" href="#finite-elements-in-2d-and-3d" title="Permalink to this headline">¶</a></h1>
<p>Finite element approximation is particularly powerful in 2D and 3D because
the method can handle a geometrically complex domain <span class="math">\(\Omega\)</span> with ease.
The principal idea is, as in 1D, to divide the domain into cells
and use polynomials for approximating a function over a cell.
Two popular cell shapes are triangles and the quadrilaterals.
Figures <a class="reference internal" href="#fem-approx-fe-2d-fig-rectp1"><em>Examples on 2D P1 elements</em></a>, <a class="reference internal" href="#fem-approx-fe-2d-fig-circp1"><em>Examples on 2D P1 elements in a deformed geometry</em></a>,
and <a class="reference internal" href="#fem-approx-fe-2d-fig-rectq1"><em>Examples on 2D Q1 elements</em></a> provide examples. P1 elements
means linear functions (<span class="math">\(a_0 + a_1x + a_2y\)</span>) over triangles, while Q1 elements
have bilinear functions (<span class="math">\(a_0 + a_1x + a_2y + a_3xy\)</span>) over rectangular cells.
Higher-order elements can easily be defined.</p>
<div class="figure" id="fem-approx-fe-2d-fig-rectp1">
<img alt="_images/mesh2D_rect_P11.png" src="_images/mesh2D_rect_P11.png" style="width: 800px;" />
<p class="caption"><em>Examples on 2D P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-circp1">
<img alt="_images/mesh2D_quarter_circle1.png" src="_images/mesh2D_quarter_circle1.png" style="width: 400px;" />
<p class="caption"><em>Examples on 2D P1 elements in a deformed geometry</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-rectq1">
<img alt="_images/mesh2D_rect_Q11.png" src="_images/mesh2D_rect_Q11.png" style="width: 400px;" />
<p class="caption"><em>Examples on 2D Q1 elements</em></p>
</div>
<div class="section" id="basis-functions-over-triangles-in-the-physical-domain">
<h2>Basis functions over triangles in the physical domain<a class="headerlink" href="#basis-functions-over-triangles-in-the-physical-domain" title="Permalink to this headline">¶</a></h2>
<p>Cells with triangular shape will be in main focus here.  With the P1
triangular element, <span class="math">\(u\)</span> is a linear function over each cell, as
depicted in Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-femfunc"><em>Example on piecewise linear 2D functions defined on triangles</em></a>, with
discontinuous derivatives at the cell boundaries.</p>
<div class="figure" id="fem-approx-fe-2d-fig-femfunc">
<img alt="_images/demo2D_4x3r1.png" src="_images/demo2D_4x3r1.png" style="width: 400px;" />
<p class="caption"><em>Example on piecewise linear 2D functions defined on triangles</em></p>
</div>
<p>We give the vertices of the cells global and local numbers as in 1D.
The degrees of freedom in the P1 element are the function values at
a set of nodes, which are the three vertices.
The basis function <span class="math">\({\varphi}_i(x,y)\)</span> is then 1 at the vertex with global vertex
number <span class="math">\(i\)</span> and zero at all other vertices.
On an element, the three degrees of freedom uniquely determine
the linear basis functions in that element, as usual.
The global
<span class="math">\({\varphi}_i(x,y)\)</span> function is then a combination of the linear functions
(planar surfaces)
over all the neighboring cells
that have vertex number <span class="math">\(i\)</span> in common. Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-basphi"><em>Example on a piecewise linear 2D basis function over a patch of triangles</em></a>
tries to illustrate the shape of such a &#8220;pyramid&#8221;-like function.</p>
<div class="figure" id="fem-approx-fe-2d-fig-basphi">
<img alt="_images/demo2D_basisfunc1.png" src="_images/demo2D_basisfunc1.png" style="width: 400px;" />
<p class="caption"><em>Example on a piecewise linear 2D basis function over a patch of triangles</em></p>
</div>
<div class="section" id="element-matrices-and-vectors">
<h3>Element matrices and vectors<a class="headerlink" href="#element-matrices-and-vectors" title="Permalink to this headline">¶</a></h3>
<p>As in 1D, we split the integral over <span class="math">\(\Omega\)</span> into a sum of integrals
over cells. Also as in 1D, <span class="math">\({\varphi}_i\)</span> overlaps <span class="math">\({\varphi}_j\)</span>
(i.e., <span class="math">\({\varphi}_i{\varphi}_j\neq 0\)</span>) if and only if
<span class="math">\(i\)</span> and <span class="math">\(j\)</span> are vertices in the same cell. Therefore, the integral
of <span class="math">\({\varphi}_i{\varphi}_j\)</span> over an element is nonzero only when <span class="math">\(i\)</span> and <span class="math">\(j\)</span>
run over the vertex numbers in the element. These nonzero contributions
to the coefficient matrix are, as in 1D, collected in an element matrix.
The size of the element matrix becomes <span class="math">\(3\times 3\)</span> since there are
three degrees of freedom
that <span class="math">\(i\)</span> and <span class="math">\(j\)</span> run over. Again, as in 1D, we number the
local vertices in a cell, starting at 0, and add the entries in
the element matrix into the global system matrix, exactly as in 1D.
All details and code appear below.</p>
</div>
</div>
<div class="section" id="basis-functions-over-triangles-in-the-reference-cell">
<h2>Basis functions over triangles in the reference cell<a class="headerlink" href="#basis-functions-over-triangles-in-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<p>As in 1D, we can define the basis functions and the degrees of freedom
in a reference cell and then use a mapping from the reference coordinate
system to the physical coordinate system.
We also have a mapping of local degrees of freedom numbers to global degrees
of freedom numbers.</p>
<p>The reference cell in an <span class="math">\((X,Y)\)</span> coordinate system has vertices
<span class="math">\((0,0)\)</span>, <span class="math">\((1,0)\)</span>, and <span class="math">\((0,1)\)</span>, corresponding to local vertex numbers
0, 1, and 2, respectively. The P1 element has linear functions
<span class="math">\({\tilde{\varphi}}_r(X,Y)\)</span> as basis functions, <span class="math">\(r=0,1,2\)</span>.
Since a linear function <span class="math">\({\tilde{\varphi}}_r(X,Y)\)</span> in 2D is on
the form <span class="math">\(C_{r,0} + C_{r,1}X + C_{r,2}Y\)</span>, and hence has three
parameters <span class="math">\(C_{r,0}\)</span>, <span class="math">\(C_{r,1}\)</span>, and <span class="math">\(C_{r,2}\)</span>, we need three
degrees of freedom. These are in general taken as the function values at a
set of nodes. For the P1 element the set of nodes is the three vertices.
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p12d"><em>2D P1 element</em></a> displays the geometry of the
element and the location of the nodes.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p12d">
<img alt="_images/P1_2d1.png" src="_images/P1_2d1.png" style="width: 100px;" />
<p class="caption"><em>2D P1 element</em></p>
</div>
<p>Requiring <span class="math">\({\tilde{\varphi}}_r=1\)</span> at node number <span class="math">\(r\)</span> and
<span class="math">\({\tilde{\varphi}}_r=0\)</span> at the two other nodes, gives three linear equations to
determine <span class="math">\(C_{r,0}\)</span>, <span class="math">\(C_{r,1}\)</span>, and <span class="math">\(C_{r,2}\)</span>. The result is</p>
<div class="math">
\[{\tilde{\varphi}}_0(X,Y) = 1 - X - Y,\]</div>
<div class="math">
\[{\tilde{\varphi}}_1(X,Y) = X,\]</div>
<div class="math">
\[{\tilde{\varphi}}_2(X,Y) = Y\]</div>
<p>Higher-order approximations are obtained by increasing the polynomial order,
adding additional nodes, and letting the degrees of freedom be
function values at the nodes. Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p22d"><em>2D P2 element</em></a>
shows the location of the six nodes in the P2 element.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p22d">
<img alt="_images/P2_2d1.png" src="_images/P2_2d1.png" style="width: 100px;" />
<p class="caption"><em>2D P2 element</em></p>
</div>
<p>A polynomial of degree <span class="math">\(p\)</span> in <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> has <span class="math">\(n_p=(p+1)(p+2)/2\)</span> terms
and hence needs <span class="math">\(n_p\)</span> nodes. The values at the nodes constitute <span class="math">\(n_p\)</span>
degrees of freedom. The location of the nodes for
<span class="math">\({\tilde{\varphi}}_r\)</span> up to degree 6 is displayed in Figure
<a class="reference internal" href="#fem-approx-fe-2d-fig-p162d"><em>2D P1, P2, P3, P4, P5, and P6 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p162d">
<img alt="_images/P1-6_2d1.png" src="_images/P1-6_2d1.png" style="width: 400px;" />
<p class="caption"><em>2D P1, P2, P3, P4, P5, and P6 elements</em></p>
</div>
<p>The generalization to 3D is straightforward: the reference element is a
<a class="reference external" href="http://en.wikipedia.org/wiki/Tetrahedron">tetrahedron</a>
with vertices <span class="math">\((0,0,0)\)</span>, <span class="math">\((1,0,0)\)</span>, <span class="math">\((0,1,0)\)</span>, and <span class="math">\((0,0,1)\)</span>
in a <span class="math">\(X,Y,Z\)</span> reference coordinate system. The P1 element has its degrees
of freedom as four nodes, which are the four vertices, see Figure
<a class="reference internal" href="#fem-approx-fe-2d-fig-p1-123d"><em>P1 elements in 1D, 2D, and 3D</em></a>. The P2 element adds additional
nodes along the edges of the cell, yielding a total of 10 nodes and
degrees of freedom, see
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p2-123d"><em>P2 elements in 1D, 2D, and 3D</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p1-123d">
<img alt="_images/P1-1d2d3d1.png" src="_images/P1-1d2d3d1.png" style="width: 400px;" />
<p class="caption"><em>P1 elements in 1D, 2D, and 3D</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-p2-123d">
<img alt="_images/P2-1d2d3d1.png" src="_images/P2-1d2d3d1.png" style="width: 400px;" />
<p class="caption"><em>P2 elements in 1D, 2D, and 3D</em></p>
</div>
<span class="target" id="index-58"></span><span class="target" id="index-59"></span><span class="target" id="index-60"></span><p id="index-61">The interval in 1D, the triangle in 2D, the tetrahedron in 3D, and
its generalizations to higher space dimensions are known
as <em>simplex</em> cells (the geometry) or <em>simplex</em> elements (the geometry,
basis functions, degrees of freedom, etc.). The plural forms
<a class="reference external" href="http://en.wikipedia.org/wiki/Simplex">simplices</a> and
simplexes are
also a much used shorter terms when referring to this type of cells or elements.
The side of a simplex is called a <em>face</em>, while the tetrahedron also
has <em>edges</em>.</p>
<p><strong>Acknowledgment.</strong>
Figures <a class="reference internal" href="#fem-approx-fe-2d-fig-p12d"><em>2D P1 element</em></a> to <a class="reference internal" href="#fem-approx-fe-2d-fig-p2-123d"><em>P2 elements in 1D, 2D, and 3D</em></a>
are created by Anders Logg and taken from the <a class="reference external" href="https://launchpad.net/fenics-book">FEniCS book</a>: <em>Automated Solution of Differential Equations by the Finite Element Method</em>, edited by A. Logg, K.-A. Mardal, and G. N. Wells, published
by <a class="reference external" href="http://goo.gl/lbyVMH">Springer</a>, 2012.</p>
</div>
<div class="section" id="affine-mapping-of-the-reference-cell">
<h2>Affine mapping of the reference cell<a class="headerlink" href="#affine-mapping-of-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\({\tilde{\varphi}}_r^{(1)}\)</span> denote the basis functions associated
with the P1 element in 1D, 2D, or 3D, and let <span class="math">\(\boldsymbol{x}_{q(e,r)}\)</span> be
the physical coordinates of local vertex number <span class="math">\(r\)</span> in cell <span class="math">\(e\)</span>.
Furthermore,
let <span class="math">\(\boldsymbol{X}\)</span> be a point in the reference coordinate system corresponding
to the point <span class="math">\(\boldsymbol{x}\)</span> in the physical coordinate system.
The affine mapping of any <span class="math">\(\boldsymbol{X}\)</span> onto <span class="math">\(\boldsymbol{x}\)</span> is
then defined by</p>
<div class="math" id="equation-fem:approx:fe:affine:map">
<span id="index-62"></span><span class="eqno">(43)</span>\[     \boldsymbol{x} = \sum_{r} {\tilde{\varphi}}_r^{(1)}(\boldsymbol{X})\boldsymbol{x}_{q(e,r)},\]</div>
<p>where <span class="math">\(r\)</span> runs over the local vertex numbers in the cell.
The affine mapping essentially stretches, translates, and rotates
the triangle. Straight or planar faces of the reference cell are
therefore mapped onto
straight or planar faces in the physical coordinate system. The mapping can
be used for both P1 and higher-order elements, but note that the
mapping itself always applies the P1 basis functions.</p>
<div class="figure" id="fem-approx-fe-map-fig-2dp1">
<img alt="_images/ElmT3n2D_map1.png" src="_images/ElmT3n2D_map1.png" style="width: 400px;" />
<p class="caption"><em>Affine mapping of a P1 element</em></p>
</div>
</div>
<div class="section" id="isoparametric-mapping-of-the-reference-cell">
<h2>Isoparametric mapping of the reference cell<a class="headerlink" href="#isoparametric-mapping-of-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-63"></span><p id="index-64">Instead of using the P1 basis functions in the mapping
<a href="#equation-fem:approx:fe:affine:map">(43)</a>,
we may use the basis functions of the actual Pd element:</p>
<div class="math" id="equation-fem:approx:fe:isop:map">
<span class="eqno">(44)</span>\[     \boldsymbol{x} = \sum_{r} {\tilde{\varphi}}_r(\boldsymbol{X})\boldsymbol{x}_{q(e,r)},\]</div>
<p>where <span class="math">\(r\)</span> runs over all nodes, i.e., all points associated with the
degrees of freedom. This is called an <em>isoparametric mapping</em>.
For P1 elements it is identical to the affine mapping
<a href="#equation-fem:approx:fe:affine:map">(43)</a>, but for higher-order elements
the mapping of the straight or planar faces of the reference cell will
result in a <em>curved</em> face in the physical coordinate system.
For example, when we use the basis functions of the triangular P2 element
in 2D in <a href="#equation-fem:approx:fe:isop:map">(44)</a>, the straight faces of the
reference triangle are mapped onto curved faces of parabolic shape in
the physical coordinate system, see Figure <a class="reference internal" href="#fem-approx-fe-map-fig-2dp2"><em>Isoparametric mapping of a P2 element</em></a>.</p>
<div class="figure" id="fem-approx-fe-map-fig-2dp2">
<img alt="_images/ElmT6n2D_map1.png" src="_images/ElmT6n2D_map1.png" style="width: 400px;" />
<p class="caption"><em>Isoparametric mapping of a P2 element</em></p>
</div>
<p>From <a href="#equation-fem:approx:fe:affine:map">(43)</a> or
<a href="#equation-fem:approx:fe:isop:map">(44)</a> it is easy to realize that the
vertices are correctly mapped. Consider a vertex with local number <span class="math">\(s\)</span>.
Then <span class="math">\({\tilde{\varphi}}_s=1\)</span> at this vertex and zero at the others.
This means that only one term in the sum is nonzero and <span class="math">\(\boldsymbol{x}=\boldsymbol{x}_{q(e,s)}\)</span>,
which is the coordinate of this vertex in the global coordinate system.</p>
</div>
<div class="section" id="computing-integrals">
<h2>Computing integrals<a class="headerlink" href="#computing-integrals" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\tilde\Omega^r\)</span> denote the reference cell and <span class="math">\(\Omega^{(e)}\)</span>
the cell in the physical coordinate system. The transformation of
the integral from the physical to the reference coordinate system reads</p>
<div class="math">
\[\int_{\Omega^{(e)}}{\varphi}_i (\boldsymbol{x}) {\varphi}_j (\boldsymbol{x}) {\, \mathrm{d}x} =
\int_{\tilde\Omega^r} {\tilde{\varphi}}_i (\boldsymbol{X}) {\tilde{\varphi}}_j (\boldsymbol{X})
\det J\, {\, \mathrm{d}X},\]</div>
<div class="math">
\[\int_{\Omega^{(e)}}{\varphi}_i (\boldsymbol{x}) f(\boldsymbol{x}) {\, \mathrm{d}x} =
\int_{\tilde\Omega^r} {\tilde{\varphi}}_i (\boldsymbol{X}) f(\boldsymbol{x}(\boldsymbol{X})) \det J\, {\, \mathrm{d}X},\]</div>
<p>where <span class="math">\({\, \mathrm{d}x}\)</span> means the infinitesimal area element <span class="math">\(dx dy\)</span> in 2D and
<span class="math">\(dx dy dz\)</span> in 3D, with a similar
definition of <span class="math">\({\, \mathrm{d}X}\)</span>. The quantity <span class="math">\(\det J\)</span> is the determinant of the
Jacobian of the mapping <span class="math">\(\boldsymbol{x}(\boldsymbol{X})\)</span>. In 2D,</p>
<div class="math" id="equation-fem:approx:fe:2D:mapping:J:detJ">
<span class="eqno">(45)</span>\[\begin{split}     J = \left[\begin{array}{cc}
     \frac{\partial x}{\partial X} &amp; \frac{\partial x}{\partial Y}\\
     \frac{\partial y}{\partial X} &amp; \frac{\partial y}{\partial Y}
     \end{array}\right], \quad
     \det J = \frac{\partial x}{\partial X}\frac{\partial y}{\partial Y}
     - \frac{\partial x}{\partial Y}\frac{\partial y}{\partial X}
     {\thinspace .}\end{split}\]</div>
<p>With the affine mapping
<a href="#equation-fem:approx:fe:affine:map">(43)</a>, <span class="math">\(\det J=2\Delta\)</span>, where <span class="math">\(\Delta\)</span> is
the area or volume of the cell in the physical coordinate system.</p>
<p><strong>Remark.</strong>
Observe that finite elements in 2D and 3D builds on the same
<em>ideas</em> and <em>concepts</em> as in 1D, but there is simply much
more to compute because the
specific mathematical formulas in 2D and 3D are more complicated
and the book keeping with dof maps also gets more complicated.
The manual work is tedious, lengthy, and error-prone
so automation by the computer is a must.</p>
</div>
</div>
<div class="section" id="exercises-1">
<h1>Exercises  (1)<a class="headerlink" href="#exercises-1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="exercise-1-linear-algebra-refresher-i">
<span id="fem-approx-exer-linalg1"></span><h2>Exercise 1: Linear algebra refresher I<a class="headerlink" href="#exercise-1-linear-algebra-refresher-i" title="Permalink to this headline">¶</a></h2>
<p>Look up the topic of <em>vector space</em> in your favorite linear algebra
book or search for the term at Wikipedia.
Prove that vectors in the plane <span class="math">\((a,b)\)</span> form a vector space
by showing that all the axioms of a vector space
are satisfied. Similarly,
prove that all linear functions of the form <span class="math">\(ax+b\)</span> constitute a vector space,
<span class="math">\(a,b\in\mathbb{R}\)</span>.</p>
<p>On the contrary,
show that all quadratic functions of the form <span class="math">\(1 + ax^2 + bx\)</span> <em>do not</em>
constitute a vector space.
Filename: <tt class="docutils literal"><span class="pre">linalg1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-2-linear-algebra-refresher-ii">
<span id="fem-approx-exer-linalg2"></span><h2>Exercise 2: Linear algebra refresher II<a class="headerlink" href="#exercise-2-linear-algebra-refresher-ii" title="Permalink to this headline">¶</a></h2>
<p>As an extension of <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a>, check out
the topic of <em>inner product spaces</em>. Suggest a possible inner product
for the space of all linear functions of the form <span class="math">\(ax+b\)</span>, <span class="math">\(a,b\in\mathbb{R}\)</span>.
Show that this inner product satisfies the
general requirements of an inner product in a vector space.
Filename: <tt class="docutils literal"><span class="pre">linalg2.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-3-approximate-a-three-dimensional-vector-in-a-plane">
<span id="fem-approx-exer-vec-3dby2d"></span><h2>Exercise 3: Approximate a three-dimensional vector in a plane<a class="headerlink" href="#exercise-3-approximate-a-three-dimensional-vector-in-a-plane" title="Permalink to this headline">¶</a></h2>
<p>Given <span class="math">\(\boldsymbol{f} = (1,1,1)\)</span> in <span class="math">\(\mathbb{R}^3\)</span>, find the best approximation vector
<span class="math">\(\boldsymbol{u}\)</span> in the plane spanned by the unit vectors <span class="math">\((1,0)\)</span> and <span class="math">\((0,1)\)</span>.
Repeat the calculations using the vectors <span class="math">\((2,1)\)</span> and <span class="math">\((1,2)\)</span>.
Filename: <tt class="docutils literal"><span class="pre">vec111_approx.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-4-approximate-the-exponential-function-by-power-functions">
<span id="fem-approx-exer-exp-powers"></span><h2>Exercise 4: Approximate the exponential function by power functions<a class="headerlink" href="#exercise-4-approximate-the-exponential-function-by-power-functions" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(V\)</span> be a function space with basis functions <span class="math">\(x^i\)</span>,
<span class="math">\(i=0,1,\ldots,N\)</span>.  Find the best approximation to <span class="math">\(f(x)=\exp(-x)\)</span> on
<span class="math">\(\Omega =[0,4]\)</span> among all functions in <span class="math">\(V\)</span> for <span class="math">\(N=2,4,6\)</span>. Illustrate
the three approximations in three separate plots.  Add the
corresponding Taylor polynomial approximation of degree <span class="math">\(N\)</span> in each
plot.
Filename: <tt class="docutils literal"><span class="pre">exp_powers.py</span></tt>.</p>
</div>
<div class="section" id="exercise-5-approximate-the-sine-function-by-power-functions">
<span id="fem-approx-exer-sin-powers"></span><h2>Exercise 5: Approximate the sine function by power functions<a class="headerlink" href="#exercise-5-approximate-the-sine-function-by-power-functions" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(V\)</span> be a function space with basis functions
<span class="math">\(x^{2i+1}\)</span>, <span class="math">\(i=0,1,\ldots,N\)</span>.
Find the best approximation to <span class="math">\(f(x)=\sin(x)\)</span> among all functions in <span class="math">\(V\)</span>,
using <span class="math">\(N=8\)</span> for a domain that includes more and more half-periods of
the sine function: <span class="math">\(\Omega = [0, k\pi/2]\)</span>, <span class="math">\(k=2,3,\ldots,12\)</span>.
How does a Taylor series of <span class="math">\(\sin(x)\)</span> around <span class="math">\(x\)</span> up to degree 9
behave for the largest domain?</p>
<p><strong>Hint.</strong>
One can make a loop over <span class="math">\(k\)</span> and call the functions <tt class="docutils literal"><span class="pre">least_squares</span></tt> and
<tt class="docutils literal"><span class="pre">comparison_plot</span></tt> from the <tt class="docutils literal"><span class="pre">approx1D</span></tt> module.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">sin_powers.py</span></tt>.</p>
</div>
<div class="section" id="exercise-6-approximate-a-steep-function-by-sines">
<span id="fem-approx-exer-tanh-sine1"></span><h2>Exercise 6: Approximate a steep function by sines<a class="headerlink" href="#exercise-6-approximate-a-steep-function-by-sines" title="Permalink to this headline">¶</a></h2>
<p>Find the best approximation of <span class="math">\(f(x) = \tanh (s(x-\pi))\)</span> on
<span class="math">\([0, 2\pi]\)</span> in the space <span class="math">\(V\)</span> with basis
<span class="math">\({\psi}_i(x) = \sin((2i+1)x)\)</span>, <span class="math">\(i\in{I} = \{0,\ldots,N\}\)</span>.
Make a movie showing how <span class="math">\(u=\sum_{j\in{I}}c_j{\psi}_j(x)\)</span>
approximates <span class="math">\(f(x)\)</span> as <span class="math">\(N\)</span> grows. Choose <span class="math">\(s\)</span> such that <span class="math">\(f\)</span> is
steep (<span class="math">\(s=20\)</span> may be appropriate).</p>
<p><strong>Hint.</strong>
One may naively call the <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> and <tt class="docutils literal"><span class="pre">comparison_plot</span></tt>
from the <tt class="docutils literal"><span class="pre">approx1D</span></tt> module in a loop and extend the basis with
one new element in each pass. This approach
implies a lot of recomputations.
A more efficient strategy is to let <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt>
compute with only one basis function at a time and accumulate
the corresponding <tt class="docutils literal"><span class="pre">u</span></tt> in the total solution.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">tanh_sines_approx1.py</span></tt>.</p>
</div>
<div class="section" id="exercise-7-animate-the-approximation-of-a-steep-function-by-sines">
<span id="fem-approx-exer-tanh-sine2"></span><h2>Exercise 7: Animate the approximation of a steep function by sines<a class="headerlink" href="#exercise-7-animate-the-approximation-of-a-steep-function-by-sines" title="Permalink to this headline">¶</a></h2>
<p>Make a movie where the steepness (<span class="math">\(s\)</span>) of the <span class="math">\(\tanh\)</span> function in
<a class="reference internal" href="#fem-approx-exer-tanh-sine1"><em>Exercise 6: Approximate a steep function by sines</em></a> grows in &#8220;time&#8221;,
and for each value of the steepness, the movie shows how the
approximation improves with increasing <span class="math">\(N\)</span>.
Filename: <tt class="docutils literal"><span class="pre">tanh_sines_approx2.py</span></tt>.</p>
</div>
<div class="section" id="exercise-8-fourier-series-as-a-least-squares-approximation">
<span id="fem-approx-exer-fourier"></span><h2>Exercise 8: Fourier series as a least squares approximation<a class="headerlink" href="#exercise-8-fourier-series-as-a-least-squares-approximation" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span> on an interval <span class="math">\([0,L]\)</span>, look up the formula
for the coefficients <span class="math">\(a_j\)</span> and <span class="math">\(b_j\)</span> in the Fourier series of <span class="math">\(f\)</span>:</p>
<div class="math">
\[f(x) = a_0 + \sum_{j=1}^\infty a_j\cos \left(j\frac{\pi x}{L}\right)
+ \sum_{j=1}^\infty b_j\sin \left(j\frac{\pi x}{L}\right){\thinspace .}\]</div>
<p>Let an infinite-dimensional vector space <span class="math">\(V\)</span> have the basis functions
<span class="math">\(\cos j\frac{\pi x}{L}\)</span> for <span class="math">\(j=0,1,\dots,\infty\)</span> and
<span class="math">\(\sin j\frac{\pi x}{L}\)</span> for <span class="math">\(j=1,\dots,\infty\)</span>.  Show that the least squares
approximation method from the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> leads to a
linear system whose solution coincides with the standard formulas for
the coefficients in a Fourier series of <span class="math">\(f(x)\)</span> (see also
the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>). You may choose</p>
<div class="math">
\[{\psi}_{2i} = \cos\left( i\frac{\pi}{L}x\right),\quad
{\psi}_{2i+1} = \sin\left( i\frac{\pi}{L}x\right),\]</div>
<p>for <span class="math">\(i=0,1,\ldots,N\rightarrow\infty\)</span>.</p>
<p>Choose <span class="math">\(f(x) = \tanh(s(x-\frac{1}{2}))\)</span> on <span class="math">\(\Omega=[0,1]\)</span>, which is
a smooth function, but with considerable steepness around <span class="math">\(x=1/2\)</span>
as <span class="math">\(s\)</span> grows in size.
Calculate the coefficients in the Fourier expansion by
solving the linear system, arising from the least squares or Galerkin
methods, by hand. Plot
some truncated versions of the series together with <span class="math">\(f(x)\)</span> to show how
the series expansion converges for <span class="math">\(s=10\)</span> and <span class="math">\(s=100\)</span>.
Filename: <tt class="docutils literal"><span class="pre">Fourier_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-9-approximate-a-steep-function-by-lagrange-polynomials">
<span id="fem-approx-exer-tanh"></span><h2>Exercise 9: Approximate a steep function by Lagrange polynomials<a class="headerlink" href="#exercise-9-approximate-a-steep-function-by-lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p>Use interpolation/collocation with uniformly distributed
points and Chebychev nodes to approximate</p>
<div class="math">
\[f(x) = -\tanh(s(x-\frac{1}{2})),\quad x\in [0,1],\]</div>
<p>by Lagrange polynomials for <span class="math">\(s=10\)</span> and <span class="math">\(s=100\)</span>, and <span class="math">\(N=3,6,9,11\)</span>.
Make separate plots of the approximation for each combination of
<span class="math">\(s\)</span>, point type (Chebyshev or uniform), and <span class="math">\(N\)</span>.
Filename: <tt class="docutils literal"><span class="pre">tanh_Lagrange.py</span></tt>.</p>
</div>
<div class="section" id="exercise-10-define-nodes-and-elements">
<span id="fem-approx-fe-exer-mesh1"></span><h2>Exercise 10: Define nodes and elements<a class="headerlink" href="#exercise-10-define-nodes-and-elements" title="Permalink to this headline">¶</a></h2>
<p>Consider a domain <span class="math">\(\Omega =[0,2]\)</span> divided into the three elements
<span class="math">\([0,1]\)</span>, <span class="math">\([1,1.2]\)</span>, and <span class="math">\([1.2,2]\)</span>, with two nodes in each element
(P1 elements).
Set up the list of coordinates and nodes (<tt class="docutils literal"><span class="pre">nodes</span></tt>) and the
numbers of the nodes that belong to each element (<tt class="docutils literal"><span class="pre">elements</span></tt>) in
two cases: 1) nodes and elements numbered from left to right, and 2)
nodes and elements numbered from right to left.</p>
<p>Thereafter, subdivide the element <span class="math">\([1.2,2]\)</span> into two new equal-sized elements.
Add the new node and the two new elements to the data structures created above,
and try to minimize the modifications.
Filename: <tt class="docutils literal"><span class="pre">fe_numberings1.py.</span></tt>.</p>
</div>
<div class="section" id="exercise-11-define-vertices-cells-and-dof-maps">
<span id="fem-approx-fe-exer-mesh2"></span><h2>Exercise 11: Define vertices, cells, and dof maps<a class="headerlink" href="#exercise-11-define-vertices-cells-and-dof-maps" title="Permalink to this headline">¶</a></h2>
<p>Repeat <a class="reference internal" href="#fem-approx-fe-exer-mesh1"><em>Exercise 10: Define nodes and elements</em></a>, but define the
data structures <tt class="docutils literal"><span class="pre">vertices</span></tt>, <tt class="docutils literal"><span class="pre">cells</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt> instead of
<tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt>.
Filename: <tt class="docutils literal"><span class="pre">fe_numberings2.py</span></tt>.</p>
</div>
<div class="section" id="exercise-12-construct-matrix-sparsity-patterns">
<span id="fem-approx-fe-exer-defmesh-sparsity"></span><h2>Exercise 12: Construct matrix sparsity patterns<a class="headerlink" href="#exercise-12-construct-matrix-sparsity-patterns" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="#fem-approx-fe-exer-mesh1"><em>Exercise 10: Define nodes and elements</em></a> describes a element mesh
with a total of five elements, but with two different element and
node orderings. For each of the two orderings,
make a <span class="math">\(5\times 5\)</span> matrix and fill in the entries that will be nonzero.</p>
<p><strong>Hint.</strong>
A matrix entry <span class="math">\((i,j)\)</span> is nonzero if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in the
same element.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">fe_sparsity_pattern.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-13-perform-symbolic-finite-element-computations">
<span id="fem-approx-fe-exer-asinwt-symbolic"></span><h2>Exercise 13: Perform symbolic finite element computations<a class="headerlink" href="#exercise-13-perform-symbolic-finite-element-computations" title="Permalink to this headline">¶</a></h2>
<p>Perform hand calculations to find formulas for the coefficient matrix
and right-hand side
when approximating <span class="math">\(f(x) = \sin (x)\)</span> on
<span class="math">\(\Omega=[0, \pi]\)</span> by two P1 elements of size <span class="math">\(\pi/2\)</span>.
Solve the system and compare <span class="math">\(u(\pi/2)\)</span> with
the exact value 1.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">sin_approx_P1.py</span></tt>.</p>
</div>
<div class="section" id="exercise-14-approximate-a-steep-function-by-p1-and-p2-elements">
<span id="id3"></span><h2>Exercise 14: Approximate a steep function by P1 and P2 elements<a class="headerlink" href="#exercise-14-approximate-a-steep-function-by-p1-and-p2-elements" title="Permalink to this headline">¶</a></h2>
<p>Given</p>
<div class="math">
\[f(x) = \tanh(s(x-\frac{1}{2}))\]</div>
<p>use the Galerkin or least squares method with finite elements to find
an approximate function <span class="math">\(u(x)\)</span>. Choose <span class="math">\(s=40\)</span> and try
<span class="math">\(N_e=4,8,16\)</span> P1 elements and
<span class="math">\(N_e=2,4,8\)</span> P2 elements.
Integrate <span class="math">\(f{\varphi}_i\)</span> numerically.
Filename: <tt class="docutils literal"><span class="pre">tanh_fe_P1P2_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-15-approximate-a-steep-function-by-p3-and-p4-elements">
<span id="fem-approx-exer-tanh2"></span><h2>Exercise 15: Approximate a steep function by P3 and P4 elements<a class="headerlink" href="#exercise-15-approximate-a-steep-function-by-p3-and-p4-elements" title="Permalink to this headline">¶</a></h2>
<p>Solve <em class="xref std std-ref">fem:approx:exer:tanh</em> using <span class="math">\(N_e=1,2,4\)</span> P3 and P4
elements. How will a collocation/interpolation method work in
this case with the same number of nodes?
Filename: <tt class="docutils literal"><span class="pre">tanh_fe_P3P4_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-16-investigate-the-approximation-error-in-finite-elements">
<span id="fem-approx-fe-exer-asinwt-interpol-error"></span><h2>Exercise 16: Investigate the approximation error in finite elements<a class="headerlink" href="#exercise-16-investigate-the-approximation-error-in-finite-elements" title="Permalink to this headline">¶</a></h2>
<p>The theory <a href="#equation-fem:approx:fe:error:theorem">(39)</a> from
the section <em class="xref std std-ref">fem:approx:fe:error</em> predicts that the
error in the Pd approximation of a function
should behave as <span class="math">\(h^{d+1}\)</span>. Use experiments to verify this
asymptotic behavior (i.e., for small enough <span class="math">\(h\)</span>).
Choose two examples: <span class="math">\(f(x)=Ae^{-\omega x}\)</span> on <span class="math">\([0,3/\omega]\)</span>
and <span class="math">\(f(x) = A\sin (\omega x)\)</span> on <span class="math">\(\Omega=[0, 2\pi/\omega]\)</span> for
constants <span class="math">\(A\)</span> and <span class="math">\(\omega\)</span>. What happens if you try
<span class="math">\(f(x)=\sqrt{x}\)</span> on <span class="math">\([0,1]\)</span>?</p>
<p><strong>Hint.</strong>
Run a series of experiments: <span class="math">\((h_i,E_)\)</span>, <span class="math">\(i=0,\ldots,m\)</span>, where <span class="math">\(E_i\)</span>
is the <span class="math">\(L^2\)</span> norm of the error corresponding to element length <span class="math">\(h_i\)</span>.
Assume an error model <span class="math">\(E=Ch^r\)</span> and compute <span class="math">\(r\)</span> from two successive
experiments:</p>
<div class="math">
\[r_i = \ln (E_{i+1}/E_i)/\ln (h_{i+1}/h_i),\quad i=0,\ldots,m-1{\thinspace .}\]</div>
<p>Hopefully, the sequence <span class="math">\(r_0,\ldots,r_{m-1}\)</span> converges to the true
<span class="math">\(r\)</span>, and <span class="math">\(r_{m-1}\)</span> can be taken as an approximation to <span class="math">\(r\)</span>.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">Asinwt_interpolation_error.py</span></tt>.</p>
</div>
<div class="section" id="exercise-17-approximate-a-step-function-by-finite-elements">
<span id="fem-approx-fe-exer-heaviside"></span><h2>Exercise 17: Approximate a step function by finite elements<a class="headerlink" href="#exercise-17-approximate-a-step-function-by-finite-elements" title="Permalink to this headline">¶</a></h2>
<p>Approximate the step function</p>
<div class="math">
\[\begin{split}f(x) = \left\lbrace\begin{array}{ll}
1 &amp; x &lt; {1/2},\\
2 &amp; x \geq {1/2}
\end{array}\right.\end{split}\]</div>
<p>by 2, 4, and 8 P1 and P2 elements. Compare
approximations visually.</p>
<p><strong>Hint.</strong>
This <span class="math">\(f\)</span> can also be expressed in terms of the Heaviside function <span class="math">\(H(x)\)</span>:
<span class="math">\(f(x) = H(x-{1/2})\)</span>.
Therefore, <span class="math">\(f\)</span> can be defined by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Heaviside</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span>  <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>making the <tt class="docutils literal"><span class="pre">approximate</span></tt> function in the
<tt class="docutils literal"><span class="pre">fe_approx1D.py</span></tt> module an obvious candidate to solve the
problem. However, <tt class="docutils literal"><span class="pre">sympy</span></tt> does not handle symbolic integration
with this particular integrand, and the <tt class="docutils literal"><span class="pre">approximate</span></tt> function faces a problem
when converting <tt class="docutils literal"><span class="pre">f</span></tt> to a Python function (for plotting) since
<tt class="docutils literal"><span class="pre">Heaviside</span></tt> is not an available function in <tt class="docutils literal"><span class="pre">numpy</span></tt>. It is better to make
special-purpose code for this case or perform all
calculations by hand.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">Heaviside_approx_P1P2.py.</span></tt>.</p>
</div>
<div class="section" id="exercise-18-2d-approximation-with-orthogonal-functions">
<span id="fem-approx-fe-exer-2dsines-symbolic"></span><h2>Exercise 18: 2D approximation with orthogonal functions<a class="headerlink" href="#exercise-18-2d-approximation-with-orthogonal-functions" title="Permalink to this headline">¶</a></h2>
<p>Assume we have basis functions <span class="math">\({\varphi}_i(x,y)\)</span> in 2D that are
orthogonal
such that <span class="math">\(({\varphi}_i,{\varphi}_j)=0\)</span> when <span class="math">\(i\neq j\)</span>.
The function <tt class="docutils literal"><span class="pre">least_squares</span></tt> in the
file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx2D.py">approx2D.py</a> will then spend much time on computing off-diagonal terms
in the coefficient matrix that we know are zero.
To speed up the computations, make a
version <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> that utilizes the orthogonality among the
basis functions. Apply the function to approximate</p>
<div class="math">
\[f(x,y) = x(1-x)y(1-y)e^{-x-y}\]</div>
<p>on <span class="math">\(\Omega = [0,1]\times [0,1]\)</span> via basis functions</p>
<div class="math">
\[{\varphi}_i(x,y) = \sin (p\pi x)\sin(q\pi y),\quad i=q N_x + p
{\thinspace .}\]</div>
<p><strong>Hint.</strong>
Get ideas from the function <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> in
the section <a class="reference internal" href="#fem-approx-global-orth"><em>Orthogonal basis functions</em></a> and
file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx1D.py">approx1D.py</a>.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">approx2D_lsorth_sin.py</span></tt>.</p>
</div>
<div class="section" id="exercise-19-use-the-trapezoidal-rule-and-p1-elements">
<span id="fem-approx-fe-exer-1d-trapez"></span><h2>Exercise 19: Use the Trapezoidal rule and P1 elements<a class="headerlink" href="#exercise-19-use-the-trapezoidal-rule-and-p1-elements" title="Permalink to this headline">¶</a></h2>
<p>Consider approximation of some <span class="math">\(f(x)\)</span> on an interval <span class="math">\(\Omega\)</span> using
the least squares or Galerkin methods with P1 elements. Derive
the element matrix and vector using the
Trapezoidal rule <a href="#equation-fem:approx:fe:numint1:trapez">(40)</a> for calculating
integrals on the reference element. Assemble the contributions, assuming
a uniform cell partitioning, and show that the resulting linear system
has the form <span class="math">\(c_i=f(x_{i})\)</span> for <span class="math">\(i\in{I}\)</span>.
Filename: <tt class="docutils literal"><span class="pre">fe_P1_trapez.pdf</span></tt>.</p>
</div>
<div class="section" id="problem-20-compare-p1-elements-and-interpolation">
<span id="fem-approx-fe-exer-1d-p1-vs-interp"></span><h2>Problem 20: Compare P1 elements and interpolation<a class="headerlink" href="#problem-20-compare-p1-elements-and-interpolation" title="Permalink to this headline">¶</a></h2>
<p>We shall approximate the function</p>
<div class="math">
\[f(x) = 1 + \epsilon\sin (2\pi nx),\quad x\in \Omega = [0,1],\]</div>
<p>where <span class="math">\(n\in\mathbb{Z}\)</span> and <span class="math">\(\epsilon \geq 0\)</span>.</p>
<p><strong>a)</strong>
Sketch <span class="math">\(f(x)\)</span> and find the wave length of the function.</p>
<p><strong>b)</strong>
We want to use <span class="math">\(N_P\)</span> elements per wave length. Show that the number
of elements is then <span class="math">\(nN_P\)</span>.</p>
<p><strong>c)</strong>
The critical quantity for accuracy is the number of elements per
wave length, not the element size in itself. It therefore suffices
to study an <span class="math">\(f\)</span> with just one wave length in <span class="math">\(\Omega = [0,1]\)</span>.
Set <span class="math">\(\epsilon = 0.5\)</span>.</p>
<p>Run the least squares or projection/Galerkin method for
<span class="math">\(N_P=2,4,8,16,32\)</span>. Compute the error <span class="math">\(E=||u-f||_{L^2}\)</span>.</p>
<p><strong>Hint.</strong>
Use the <tt class="docutils literal"><span class="pre">fe_approx1D_numint</span></tt> module to compute <span class="math">\(u\)</span> and use
the technique from the section <a class="reference internal" href="#fem-approx-fe-element-impl-error"><em>Computing the error of the approximation</em></a> to
compute the norm of the error.</p>
<p><strong>d)</strong>
Repeat the set of experiments in the above point, but
use interpolation/collocation based on the node points to
compute <span class="math">\(u(x)\)</span> (recall that <span class="math">\(c_i\)</span> is now simply <span class="math">\(f(x_{i})\)</span>).
Compute the error <span class="math">\(E=||u-f||_{L^2}\)</span>.
Which method seems to be most accurate?</p>
<p>Filename: <tt class="docutils literal"><span class="pre">P1_vs_interp.py</span></tt>.</p>
</div>
<div class="section" id="exercise-21-implement-3d-computations-with-global-basis-functions">
<span id="fem-approx-fe-exer-3d-approx3d"></span><h2>Exercise 21: Implement 3D computations with global basis functions<a class="headerlink" href="#exercise-21-implement-3d-computations-with-global-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>Extend the <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/approx2D.py">approx2D.py</a> code to 3D
applying ideas from the section <a class="reference internal" href="#fem-approx-3d-global"><em>Extension to 3D</em></a>.
Use a 3D generalization of the test problem in the section <a class="reference internal" href="#fem-approx-2d-global-code"><em>Implementation  (3)</em></a> to test the implementation.
Filename: <tt class="docutils literal"><span class="pre">approx3D.py</span></tt>.</p>
</div>
<div class="section" id="exercise-22-use-simpson-s-rule-and-p2-elements">
<span id="fem-approx-fe-exer-1d-simpson"></span><h2>Exercise 22: Use Simpson&#8217;s rule and P2 elements<a class="headerlink" href="#exercise-22-use-simpson-s-rule-and-p2-elements" title="Permalink to this headline">¶</a></h2>
<p>Redo <a class="reference internal" href="#fem-approx-fe-exer-1d-trapez"><em>Exercise 19: Use the Trapezoidal rule and P1 elements</em></a>, but use P2
elements and Simpson&#8217;s rule based on sampling the integrands at
the nodes in the reference cell.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">fe_P2_simpson.pdf</span></tt>.</p>
</div>
</div>
<div class="section" id="basic-principles-for-approximating-differential-equations">
<span id="fem-deq-1d-principles"></span><h1>Basic principles for approximating differential equations<a class="headerlink" href="#basic-principles-for-approximating-differential-equations" title="Permalink to this headline">¶</a></h1>
<p>The finite element method is a very flexible approach for solving partial
differential equations. Its two most attractive features are the ease
of handling domains of complex shape in two and three dimensions and
the ease of constructing higher-order discretization methods. The
finite element method is usually applied for discretization in space,
and therefore spatial problems will be our focus in the coming sections.
Extensions to time-dependent problems may, for instance, use finite difference
approximations in time.</p>
<p>Before studying how finite element methods are used to tackle differential
equation, we first look at how global basis functions and the
least squares, Galerkin, and collocation principles can be used to solve
differential equations.</p>
<div class="section" id="differential-equation-models">
<span id="fem-deq-1d-models"></span><h2>Differential equation models<a class="headerlink" href="#differential-equation-models" title="Permalink to this headline">¶</a></h2>
<p>Let us consider an abstract differential equation for a function <span class="math">\(u(x)\)</span> of
one variable, written as</p>
<div class="math">
\[\mathcal{L}(u) = 0,\quad x\in\Omega{\thinspace .}\]</div>
<p>Here are a few examples on possible choices of <span class="math">\(\mathcal{L}(u)\)</span>, of
increasing complexity:</p>
<div class="math" id="equation-fem:deq:1D:L1">
<span class="eqno">(46)</span>\[     \mathcal{L}(u) = \frac{d^2u}{dx^2} - f(x),\]</div>
<div class="math" id="equation-fem:deq:1D:L2">
<span class="eqno">(47)</span>\[     \mathcal{L}(u) = \frac{d}{dx}\left({\alpha}(x)\frac{du}{dx}\right) + f(x),\]</div>
<div class="math" id="equation-fem:deq:1D:L3">
<span class="eqno">(48)</span>\[     \mathcal{L}(u) = \frac{d}{dx}\left({\alpha}(u)\frac{du}{dx}\right) - au + f(x),\]</div>
<div class="math" id="equation-fem:deq:1D:L4">
<span class="eqno">(49)</span>\[     \mathcal{L}(u) = \frac{d}{dx}\left({\alpha}(u)\frac{du}{dx}\right) + f(u,x)\]\[     {\thinspace .}\]</div>
<p>Both <span class="math">\({\alpha}(x)\)</span> and <span class="math">\(f(x)\)</span> are considered as specified functions,
while <span class="math">\(a\)</span> is a prescribed parameter.  Differential equations
corresponding to <a href="#equation-fem:deq:1D:L1">(46)</a>-<a href="#equation-fem:deq:1D:L2">(47)</a> arise in
diffusion phenomena, such as steady transport of heat in solids and
flow of viscous fluids between flat plates. The form
<a href="#equation-fem:deq:1D:L3">(48)</a> arises when transient diffusion or wave
phenomenon are discretized in time by finite differences. The equation
<a href="#equation-fem:deq:1D:L4">(49)</a> appear in chemical models when diffusion of a
substance is combined with chemical reactions. Also in biology,
<a href="#equation-fem:deq:1D:L4">(49)</a> plays an important role, both for spreading of
species and in models involving generation and
propagation of electrical signals.</p>
<p>Let <span class="math">\(\Omega =[0,L]\)</span> be the domain in one space dimension.
In addition to the differential equation, <span class="math">\(u\)</span> must fulfill
boundary conditions at the boundaries of the domain, <span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span>.
When <span class="math">\(\mathcal{L}\)</span> contains up to second-order derivatives, as in the
examples above, <span class="math">\(m=1\)</span>, we need one boundary condition at each of
the (two) boundary points, here abstractly specified as</p>
<div class="math">
\[\mathcal{B}_0(u)=0,\ x=0,\quad \mathcal{B}_1(u)=0,\ x=L\]</div>
<p>There are three common choices of boundary conditions:</p>
<div class="math">
\[\mathcal{B}_i(u) = u - g,\quad \hbox{Dirichlet condition}\]</div>
<div class="math">
\[\mathcal{B}_i(u) = -{\alpha} \frac{du}{dx} - g,\quad \hbox{Neumann condition}\]</div>
<div class="math">
\[\mathcal{B}_i(u) = -{\alpha} \frac{du}{dx} - h(u-g),\quad \hbox{Robin condition}\]</div>
<p>Here, <span class="math">\(g\)</span> and <span class="math">\(a\)</span> are specified quantities.</p>
<p>From now on we shall use <span class="math">\({u_{\small\mbox{e}}}(x)\)</span> as symbol for the <em>exact</em> solution,
fulfilling</p>
<div class="math">
\[\mathcal{L}({u_{\small\mbox{e}}})=0,\quad x\in\Omega,\]</div>
<p>while <span class="math">\(u(x)\)</span> is our notation for an <em>approximate</em> solution of the differential
equation.</p>
<div class="admonition-remark-on-notation admonition">
<p class="first admonition-title">Remark on notation</p>
<p class="last">In the literature about the finite element method,
is common to use <span class="math">\(u\)</span> as the exact solution and <span class="math">\(u_h\)</span> as the
approximate solution, where <span class="math">\(h\)</span> is a discretization parameter. However,
the vast part of the present text is about the approximate solutions,
and having a subscript <span class="math">\(h\)</span> attached all the time
is cumbersome. Of equal importance is the close correspondence between
implementation and mathematics that we strive to achieve in this text:
when it is natural to use <tt class="docutils literal"><span class="pre">u</span></tt> and not <tt class="docutils literal"><span class="pre">u_h</span></tt> in
code, we let the mathematical notation be dictated by the code&#8217;s
preferred notation. After all, it is the powerful computer implementations
of the finite element method that justifies studying the mathematical
formulation and aspects of the method.</p>
</div>
</div>
<div class="section" id="simple-model-problems">
<span id="fem-deq-1d-models-simple"></span><h2>Simple model problems<a class="headerlink" href="#simple-model-problems" title="Permalink to this headline">¶</a></h2>
<p>A common model problem used much in the forthcoming examples is</p>
<div class="math" id="equation-fem:deq:1D:model1">
<span class="eqno">(50)</span>\[     -u''(x) = f(x),\quad x\in\Omega=[0,L],\quad u(0)=0,\ u(L)=D
     {\thinspace .}\]</div>
<p>A closely related problem with a different boundary condition at
<span class="math">\(x=0\)</span> reads</p>
<div class="math" id="equation-fem:deq:1D:model2">
<span class="eqno">(51)</span>\[     -u''(x) = f(x),\quad x\in\Omega=[0,L],\quad u'(0)=C,\ u(L)=D{\thinspace .}\]</div>
<p>A third variant has a variable coefficient,</p>
<div class="math" id="equation-fem:deq:1D:model3">
<span class="eqno">(52)</span>\[     -({\alpha}(x)u'(x))' = f(x),\quad x\in\Omega=[0,L],\quad u'(0)=C,\ u(L)=D{\thinspace .}\]</div>
<p>We can easily solve these using <tt class="docutils literal"><span class="pre">sympy</span></tt>. For <a href="#equation-fem:deq:1D:model1">(50)</a>
we can write the function</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">model1</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Solve -u&#39;&#39; = f(x), u(0)=0, u(L)=D.&quot;&quot;&quot;</span>
    <span class="n">u_x</span> <span class="o">=</span> <span class="o">-</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">c_0</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">u_x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">c_1</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="mi">0</span><span class="p">,</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">L</span><span class="p">)</span><span class="o">-</span><span class="n">D</span><span class="p">],</span> <span class="p">[</span><span class="n">c_0</span><span class="p">,</span> <span class="n">c_1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">c_0</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">c_0</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">c_1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>Calling <tt class="docutils literal"><span class="pre">model1(2,</span> <span class="pre">L,</span> <span class="pre">D)</span></tt> results in the solution</p>
<div class="math" id="equation-fem:deq:1D:model1:sol">
<span class="eqno">(53)</span>\[     u(x) = \frac{1}{L}x \left(D + L^{2} - L x\right)\]</div>
<p>Model <em class="xref std std-ref">fem:deq:1D:model2</em>) can be solved by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">model2</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Solve -u&#39;&#39; = f(x), u&#39;(0)=C, u(L)=D.&quot;&quot;&quot;</span>
    <span class="n">u_x</span> <span class="o">=</span> <span class="o">-</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">c_0</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">u_x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">c_1</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">sm</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">C</span><span class="p">,</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">L</span><span class="p">)</span><span class="o">-</span><span class="n">D</span><span class="p">],</span> <span class="p">[</span><span class="n">c_0</span><span class="p">,</span> <span class="n">c_1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">c_0</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">c_0</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">c_1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>to yield</p>
<div class="math" id="equation-fem:deq:1D:model2:sol">
<span class="eqno">(54)</span>\[     u(x) = - x^{2} + C x - C L + D + L^{2},\]</div>
<p>if <span class="math">\(f(x)=2\)</span>. Model <em class="xref std std-ref">fem:deq:1D:model3</em>) requires a bit more involved
code,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">model3</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Solve -(a*u&#39;)&#39; = f(x), u(0)=C, u(L)=D.&quot;&quot;&quot;</span>
    <span class="n">au_x</span> <span class="o">=</span> <span class="o">-</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">c_0</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">au_x</span><span class="o">/</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">c_1</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">C</span><span class="p">,</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">L</span><span class="p">)</span><span class="o">-</span><span class="n">D</span><span class="p">],</span> <span class="p">[</span><span class="n">c_0</span><span class="p">,</span> <span class="n">c_1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">c_0</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">c_0</span><span class="p">])</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">c_1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>With <span class="math">\(f(x)=0\)</span> and <span class="math">\({\alpha}(x)=1+x^2\)</span> we get</p>
<div class="math">
\[u(x) =
\frac{C \operatorname{atan}{\left (L \right )} - C \operatorname{atan}{\left (x \right )} + D \operatorname{atan}{\left (x \right )}}{\operatorname{atan}{\left (L \right )}}\]</div>
</div>
<div class="section" id="forming-the-residual">
<span id="fem-deq-1d-residual-min"></span><h2>Forming the residual<a class="headerlink" href="#forming-the-residual" title="Permalink to this headline">¶</a></h2>
<p>The fundamental idea is to seek an approximate solution
<span class="math">\(u\)</span> in some space <span class="math">\(V\)</span>,</p>
<div class="math">
\[V = \hbox{span}\{ {\psi}_0(x),\ldots,{\psi}_N(x)\},\]</div>
<p>which means that <span class="math">\(u\)</span> can always be expressed as a linear combination
of the basis functions <span class="math">\(\left\{ {{\varphi}}_i \right\}_{i\in{I}}\)</span>, with <span class="math">\({I}\)</span> as
the index set <span class="math">\(\{0,\ldots,N\}\)</span>:</p>
<div class="math">
\[u(x) = \sum_{j\in{I}} c_j{\psi}_j(x){\thinspace .}\]</div>
<p>The coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> are unknowns to be computed.</p>
<p>(Later, in the section <a class="reference internal" href="#fem-deq-1d-essbc"><em>Boundary conditions: specified nonzero value</em></a>, we will see that if we specify boundary values of <span class="math">\(u\)</span> different
from zero, we must look for an approximate solution
<span class="math">\(u(x) = B(x) + \sum_{j} c_j{\psi}_j(x)\)</span>,
where <span class="math">\(\sum_{j}c_j{\psi}_j\in V\)</span> and <span class="math">\(B(x)\)</span> is some function for
incorporating the right boundary values. Because of <span class="math">\(B(x)\)</span>, <span class="math">\(u\)</span> will not
necessarily lie in <span class="math">\(V\)</span>. This modification does not imply any difficulties.)</p>
<p>We need principles for deriving <span class="math">\(N+1\)</span> equations to determine the
<span class="math">\(N+1\)</span> unknowns <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>.
When approximating a given function <span class="math">\(f\)</span> by <span class="math">\(u=\sum_jc_j{\varphi}_j\)</span>,
a key idea is to minimize the square norm of the
approximation error <span class="math">\(e=u-f\)</span> or (equvalently) demand that <span class="math">\(e\)</span> is
orthogonal to <span class="math">\(V\)</span>. Working with <span class="math">\(e\)</span> is not so useful here since
the approximation error in our case is <span class="math">\(e={u_{\small\mbox{e}}} - u\)</span> and <span class="math">\({u_{\small\mbox{e}}}\)</span> is
unknown. The only general indicator we have on the quality of the approximate
solution is to what degree <span class="math">\(u\)</span> fulfills the differential equation.
Inserting <span class="math">\(u=\sum_j c_j {\psi}_j\)</span> into <span class="math">\(\mathcal{L}(u)\)</span> reveals that the
result is not zero, because <span class="math">\(u\)</span> is only likely to equal <span class="math">\({u_{\small\mbox{e}}}\)</span>.
The nonzero result,</p>
<div class="math" id="index-65">
\[R = \mathcal{L}(u) = \mathcal{L}(\sum_j c_j {\psi}_j),\]</div>
<p>is called the <em>residual</em> and measures the
error in fulfilling the governing equation.</p>
<p>Various principles for determining <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> try to minimize
<span class="math">\(R\)</span> in some sense. Note that <span class="math">\(R\)</span> varies with <span class="math">\(x\)</span> and
the <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> parameters. We may write this dependence
explicitly as</p>
<div class="math">
\[R = R(x; c_0, \ldots, c_N){\thinspace .}\]</div>
<p>Below, we present three principles for making <span class="math">\(R\)</span> small:
a least squares method, a projection or Galerkin method, and
a collocation or interpolation method.</p>
</div>
<div class="section" id="the-least-squares-method-4">
<h2>The least squares method  (4)<a class="headerlink" href="#the-least-squares-method-4" title="Permalink to this headline">¶</a></h2>
<p>The least-squares method aims to find <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> such that
the square norm of the residual</p>
<div class="math">
\[||R|| = (R, R) = \int_{\Omega} R^2 {\, \mathrm{d}x}\]</div>
<p>is minimized. By introducing
an inner product of two functions <span class="math">\(f\)</span> and <span class="math">\(g\)</span>
on <span class="math">\(\Omega\)</span> as</p>
<div class="math">
\[(f,g) = \int_{\Omega} f(x)g(x) {\, \mathrm{d}x},\]</div>
<p>the least-squares method can be defined as</p>
<div class="math">
\[\min_{c_0,\ldots,c_N} E = (R,R){\thinspace .}\]</div>
<p>Differentiating with respect to the free parameters <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>
gives the <span class="math">\(N+1\)</span> equations</p>
<div class="math" id="equation-fem:deq:1D:LS:eq1">
<span class="eqno">(55)</span>\[     \int_{\Omega} 2R\frac{\partial R}{\partial c_i} {\, \mathrm{d}x} = 0\quad
     \Leftrightarrow\quad (R,\frac{\partial R}{\partial c_i})=0,\quad
     i\in{I}{\thinspace .}\]</div>
</div>
<div class="section" id="the-galerkin-method-1">
<h2>The Galerkin method  (1)<a class="headerlink" href="#the-galerkin-method-1" title="Permalink to this headline">¶</a></h2>
<p>The least-squares
principle is equivalent to demanding the error to be orthogonal to
the space <span class="math">\(V\)</span> when approximating a function <span class="math">\(f\)</span> by <span class="math">\(u\in V\)</span>.
With a differential equation
we do not know the true error so we must instead require the residual <span class="math">\(R\)</span>
to be orthogonal to <span class="math">\(V\)</span>. This idea implies
seeking <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> such that</p>
<div class="math" id="equation-fem:deq:1D:Galerkin0">
<span class="eqno">(56)</span>\[     (R,v)=0,\quad \forall v\in V{\thinspace .}\]</div>
<p>This is the Galerkin method for differential equations.</p>
<p>This statement is equivalent to <span class="math">\(R\)</span> being orthogonal to the <span class="math">\(N+1\)</span>
basis functions only:</p>
<div class="math" id="equation-fem:deq:1D:Galerkin">
<span class="eqno">(57)</span>\[     (R,{\psi}_i)=0,\quad i\in{I},\]</div>
<p>resulting in <span class="math">\(N+1\)</span> equations for determining <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>.</p>
</div>
<div class="section" id="the-method-of-weighted-residuals">
<h2>The Method of Weighted Residuals<a class="headerlink" href="#the-method-of-weighted-residuals" title="Permalink to this headline">¶</a></h2>
<p>A generalization of the Galerkin method is to demand that <span class="math">\(R\)</span>
is orthogonal to some space <span class="math">\(W\)</span>, but not necessarily the same
space as <span class="math">\(V\)</span> where we seek the unknown function.
This generalization is naturally called the <em>method of weighted residuals</em>:</p>
<div class="math" id="equation-fem:deq:1D:WRM0">
<span class="eqno">(58)</span>\[     (R,v)=0,\quad \forall v\in W{\thinspace .}\]</div>
<p>If <span class="math">\(\{w_0,\ldots,w_N\}\)</span> is a basis for <span class="math">\(W\)</span>, we can equivalently
express the method of weighted residuals as</p>
<div class="math" id="equation-fem:deq:1D:WRM">
<span class="eqno">(59)</span>\[     (R,w_i)=0,\quad i\in{I}{\thinspace .}\]</div>
<p>The result is <span class="math">\(N+1\)</span> equations for <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>.</p>
<p>The least-squares method can also be viewed as a weighted residual
method with <span class="math">\(w_i = \partial R/\partial c_i\)</span>.</p>
<div class="admonition-variational-formulation-of-the-continuous-problem admonition" id="index-66">
<p class="first admonition-title">Variational formulation of the continuous problem</p>
<p class="last">Formulations like <a href="#equation-fem:deq:1D:WRM0">(58)</a> (or
<a href="#equation-fem:deq:1D:WRM">(59)</a>) and <a href="#equation-fem:deq:1D:Galerkin0">(56)</a>
(or <a href="#equation-fem:deq:1D:Galerkin">(57)</a>) are known as
<em>variational formulations</em>.
These equations are in this text primarily used for a numerical approximation
<span class="math">\(u\in V\)</span>, where <span class="math">\(V\)</span> is a <em>finite-dimensional</em> space with dimension
<span class="math">\(N+1\)</span>. However, we may also let <span class="math">\(V\)</span> be an <em>infinite-dimensional</em> space
containing the exact solution <span class="math">\({u_{\small\mbox{e}}}(x)\)</span> such that also <span class="math">\({u_{\small\mbox{e}}}\)</span>
fulfills the same variational formulation. The variational formulation is in
that case a mathematical way of stating the problem and acts as an
alternative to the usual formulation of a differential equation with
initial and/or boundary conditions.</p>
</div>
</div>
<div class="section" id="test-and-trial-functions">
<h2>Test and Trial Functions<a class="headerlink" href="#test-and-trial-functions" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-67"></span><span class="target" id="index-68"></span><span class="target" id="index-69"></span><p id="index-70">In the context of the Galerkin method and the method of weighted residuals it is
common to use the name <em>trial function</em> for the approximate <span class="math">\(u =
\sum_j c_j {\psi}_j\)</span>.</p>
<p>The space containing the trial function is known as the <em>trial space</em>.
The function <span class="math">\(v\)</span> entering the orthogonality requirement in
the Galerkin method and the method of weighted residuals is called
<em>test function</em>, and so are the <span class="math">\({\psi}_i\)</span> or <span class="math">\(w_i\)</span> functions that are
used as weights in the inner products with the residual.  The space
where the test functions comes from is naturally called the
<em>test space</em>.</p>
<p>We see that in the method of weighted residuals the test and trial spaces
are different and so are the test and trial functions.
In the Galerkin method the test and trial spaces are the same (so far).</p>
<div class="admonition-remark admonition">
<p class="first admonition-title">Remark</p>
<p class="last">It may be subject to debate whether
it is only the form of <a href="#equation-fem:deq:1D:WRM0">(58)</a> or <a href="#equation-fem:deq:1D:Galerkin0">(56)</a>
after integration by parts, as explained in the section <a class="reference internal" href="#fem-deq-1d-varform"><em>Integration by parts</em></a>,
that qualifies for the term variational formulation. The result after
integration by parts is what is obtained after taking the <em>first
variation</em> of an optimization problem, see the section <a class="reference internal" href="#fem-deq-1d-optimization"><em>Variational problems and optimization of functionals</em></a>. However, here we use variational formulation as a common term for
formulations which, in contrast to the differential equation <span class="math">\(R=0\)</span>,
instead demand that an average of <span class="math">\(R\)</span> is zero: <span class="math">\((R,v)=0\)</span> for all <span class="math">\(v\)</span> in some space.</p>
</div>
</div>
<div class="section" id="the-collocation-method-1">
<h2>The collocation method  (1)<a class="headerlink" href="#the-collocation-method-1" title="Permalink to this headline">¶</a></h2>
<p>The idea of the collocation method is to demand that <span class="math">\(R\)</span> vanishes
at <span class="math">\(N+1\)</span> selected points <span class="math">\(x_{0},\ldots,x_{N}\)</span> in <span class="math">\(\Omega\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:collocation">
<span class="eqno">(60)</span>\[     R(x_{i}; c_0,\ldots,c_N)=0,\quad i\in{I}{\thinspace .}\]</div>
<p>The collocation method can also be viewed as a method of weighted residuals
with Dirac delta functions as weighting functions.
Let <span class="math">\(\delta (x-x_{i})\)</span> be the Dirac delta function centered around
<span class="math">\(x=x_{i}\)</span> with the properties that <span class="math">\(\delta (x-x_{i})=0\)</span> for <span class="math">\(x\neq x_{i}\)</span>
and</p>
<div class="math" id="equation-fem:deq:1D:Dirac">
<span class="eqno">(61)</span>\[     \int_{\Omega} f(x)\delta (x-x_{i}) {\, \mathrm{d}x} =
     f(x_{i}),\quad x_{i}\in\Omega{\thinspace .}\]</div>
<p>Intuitively, we may think of <span class="math">\(\delta (x-x_{i})\)</span> as a very peak-shaped
function around <span class="math">\(x=x_{i}\)</span> with integral 1, roughly visualized
in Figure <a class="reference internal" href="#fem-deq-1d-fig-dirac"><em>Approximation of delta functions by narrow Gaussian functions</em></a>.
Because of <a href="#equation-fem:deq:1D:Dirac">(61)</a>, we can let <span class="math">\(w_i=\delta(x-x_{i})\)</span>
be weighting functions in the method of weighted residuals,
and <a href="#equation-fem:deq:1D:WRM">(59)</a> becomes equivalent to
<a href="#equation-fem:deq:1D:collocation">(60)</a>.</p>
<div class="figure" id="fem-deq-1d-fig-dirac">
<img alt="_images/delta_func_weight1.png" src="_images/delta_func_weight1.png" style="width: 400px;" />
<p class="caption"><em>Approximation of delta functions by narrow Gaussian functions</em></p>
</div>
<div class="section" id="the-subdomain-collocation-method">
<h3>The subdomain collocation method<a class="headerlink" href="#the-subdomain-collocation-method" title="Permalink to this headline">¶</a></h3>
<p>The idea of this approach is to demand the integral of <span class="math">\(R\)</span> to vanish
over <span class="math">\(N+1\)</span> subdomains <span class="math">\(\Omega_i\)</span> of <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[\int_{\Omega_i} R\, {\, \mathrm{d}x}=0,\quad i\in{I}{\thinspace .}\]</div>
<p>This statement can also be expressed as a weighted residual method</p>
<div class="math">
\[\int_{\Omega} Rw_i\, {\, \mathrm{d}x}=0,\quad i\in{I},\]</div>
<p>where <span class="math">\(w_i=1\)</span> for <span class="math">\(x\in\Omega_i\)</span> and <span class="math">\(w_i=0\)</span> otherwise.</p>
</div>
</div>
<div class="section" id="examples-on-using-the-principles">
<span id="fem-deq-1d-ex-sines"></span><h2>Examples on using the principles<a class="headerlink" href="#examples-on-using-the-principles" title="Permalink to this headline">¶</a></h2>
<p>Let us now apply global basis functions to illustrate the principles
for minimizing <span class="math">\(R\)</span>.</p>
<div class="section" id="the-model-problem">
<h3>The model problem<a class="headerlink" href="#the-model-problem" title="Permalink to this headline">¶</a></h3>
<p>We consider the differential equation problem</p>
<div class="math" id="equation-fem:deq:1D:model1b">
<span class="eqno">(62)</span>\[     -u''(x) = f(x),\quad x\in\Omega=[0,L],\quad u(0)=0,\ u(L)=0
     {\thinspace .}\]</div>
</div>
<div class="section" id="basis-functions">
<h3>Basis functions<a class="headerlink" href="#basis-functions" title="Permalink to this headline">¶</a></h3>
<p>Our choice of basis functions <span class="math">\({\psi}_i\)</span>
for <span class="math">\(V\)</span> is</p>
<div class="math" id="equation-fem:deq:1D:ex:sines:psi">
<span class="eqno">(63)</span>\[     {\psi}_i(x) = {\sin\left((i+1)\pi\frac{x}{L}\right)},\quad i\in{I}{\thinspace .}\]</div>
<p>An important property of these functions is that <span class="math">\({\psi}_i(0)={\psi}_i(L)=0\)</span>,
which means that the boundary conditions on <span class="math">\(u\)</span> are fulfilled:</p>
<div class="math">
\[u(0) = \sum_jc_j{\psi}_j(0) = 0,\quad u(L) = \sum_jc_j{\psi}_j(L) =0
{\thinspace .}\]</div>
<p>Another nice property is that the chosen sine functions
are orthogonal on <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[\begin{split}\int\limits_0^L {\sin\left((i+1)\pi\frac{x}{L}\right)}{\sin\left((j+1)\pi\frac{x}{L}\right)}\, {\, \mathrm{d}x} = \left\lbrace
\begin{array}{ll} \frac{1}{2} L &amp; i=j  \\ 0, &amp; i\neq j
\end{array}\right.\end{split}\]</div>
<p>provided <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are integers.</p>
</div>
<div class="section" id="the-residual">
<h3>The residual<a class="headerlink" href="#the-residual" title="Permalink to this headline">¶</a></h3>
<p>We can readily calculate the following explicit expression for the
residual:</p>
<div class="math">
\[R(x;c_0, \ldots, c_N) = u''(x) + f(x),\nonumber\]</div>
<div class="math">
\[= \frac{d^2}{dx^2}\left(\sum_{j\in{I}} c_j{\psi}_j(x)\right)
+ f(x),\nonumber\]</div>
<div class="math" id="equation-fem:deq:1D:ex:sines:res">
<span class="eqno">(64)</span>\[     = \sum_{j\in{I}} c_j{\psi}_j''(x) + f(x){\thinspace .}\]</div>
</div>
<div class="section" id="the-least-squares-method-5">
<h3>The least squares method  (5)<a class="headerlink" href="#the-least-squares-method-5" title="Permalink to this headline">¶</a></h3>
<p>The equations <a href="#equation-fem:deq:1D:LS:eq1">(55)</a>
in the least squares method require an expression for
<span class="math">\(\partial R/\partial c_i\)</span>. We have</p>
<div class="math">
\[\frac{\partial R}{\partial c_i} =
\frac{\partial}{\partial c_i}
\left(\sum_{j\in{I}} c_j{\psi}_j''(x) + f(x)\right)
= \sum_{j\in{I}} \frac{\partial c_j}{\partial c_i}{\psi}_j''(x)
= {\psi}_i''(x){\thinspace .}\]</div>
<p>The governing equations for <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> are then</p>
<div class="math">
\[(\sum_j c_j {\psi}_j'' + f,{\psi}_i'')=0,\quad i\in{I},\]</div>
<p>which can be rearranged as</p>
<div class="math">
\[\sum_{j\in{I}}({\psi}_i'',{\psi}_j'')c_j = -(f,{\psi}_i''),\quad i\in{I}{\thinspace .}\]</div>
<p>This is nothing but a linear system</p>
<div class="math">
\[\sum_{j\in{I}}A_{i,j}c_j = b_i,\quad i\in{I},\]</div>
<p>with</p>
<div class="math">
\[A_{i,j} = ({\psi}_i'',{\psi}_j'')\nonumber\]</div>
<div class="math">
\[= \pi^4(i+1)^2(j+1)^2L^{-4}\int_0^L {\sin\left((i+1)\pi\frac{x}{L}\right)}{\sin\left((j+1)\pi\frac{x}{L}\right)}\, {\, \mathrm{d}x}\nonumber\]</div>
<div class="math">
\[= \left\lbrace
\begin{array}{ll} {1\over2}L^{-3}\pi^4(i+1)^4  i=j\]</div>
<div class="math">
\[0,  i\neq j
\end{array}\right.\]</div>
<div class="math">
\[b_i = -(f,{\psi}_i'') = (i+1)^2\pi^2L^{-2}\int_0^Lf(x){\sin\left((i+1)\pi\frac{x}{L}\right)}\, {\, \mathrm{d}x}\]</div>
<p>Since the coefficient matrix is diagonal we can easily solve for</p>
<div class="math" id="equation-fem:deq:1D:ex:sines:solution">
<span class="eqno">(65)</span>\[     c_i = \frac{2L}{\pi^2(i+1)^2}\int_0^Lf(x){\sin\left((i+1)\pi\frac{x}{L}\right)}\, {\, \mathrm{d}x}{\thinspace .}\]</div>
<p>With the special choice of <span class="math">\(f(x)=2\)</span> can be calculated in <tt class="docutils literal"><span class="pre">sympy</span></tt> by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s">&#39;i j&#39;</span><span class="p">,</span> <span class="n">integer</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s">&#39;x L&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="o">/</span><span class="p">(</span><span class="n">pi</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">c_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">sin</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="o">/</span><span class="n">L</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span>
<span class="n">c_i</span> <span class="o">=</span> <span class="n">simplify</span><span class="p">(</span><span class="n">c_i</span><span class="p">)</span>
<span class="k">print</span> <span class="n">c_i</span>
</pre></div>
</div>
<p>The answer becomes</p>
<div class="math">
\[c_i = 4 \frac{L^{2} \left(\left(-1\right)^{i} + 1\right)}{\pi^{3}
\left(i^{3} + 3 i^{2} + 3 i + 1\right)}\]</div>
<p>Now, <span class="math">\(1+(-1)^i=0\)</span> for <span class="math">\(i\)</span> odd, so only the coefficients with even index
are nonzero. Introducing <span class="math">\(i=2k\)</span> for <span class="math">\(k=0,\ldots,N/2\)</span> to count the
relevant indices, we get the solution</p>
<div class="math">
\[u(x) = \sum_{k=0}^{N/2} \frac{8L^2}{\pi^3(2k+1)^3}{\sin\left((2k+1)\pi\frac{x}{L}\right)}{\thinspace .}\]</div>
<p>The coefficients decay very fast: <span class="math">\(c_2 = c_0/27\)</span>, <span class="math">\(c_4=c_0/125\)</span>.
The solution will therefore be dominated by the first term,</p>
<div class="math">
\[u(x) \approx \frac{8L^2}{\pi^3}\sin\left(\pi\frac{x}{L}\right){\thinspace .}\]</div>
</div>
<div class="section" id="the-galerkin-method-2">
<h3>The Galerkin method  (2)<a class="headerlink" href="#the-galerkin-method-2" title="Permalink to this headline">¶</a></h3>
<p>The Galerkin principle <a href="#equation-fem:deq:1D:Galerkin0">(56)</a>
applied to <a href="#equation-fem:deq:1D:model1b">(62)</a> consists of inserting
our special residual <a href="#equation-fem:deq:1D:ex:sines:res">(64)</a> in
<a href="#equation-fem:deq:1D:Galerkin0">(56)</a></p>
<div class="math">
\[(u''+f,v)=0,\quad \forall v\in V,\]</div>
<p>or</p>
<div class="math">
\[(u'',v) = -(f,v),\quad\forall v\in V{\thinspace .}\]</div>
<p>This is the variational formulation, based on the Galerkin principle,
of our differential equation.
The <span class="math">\(\forall v\in V\)</span> requirement is equivalent to
demanding the equation <span class="math">\((u'',v) = -(f,v)\)</span> to be fulfilled for all
basis functions <span class="math">\(v={\psi}_i\)</span>, <span class="math">\(i\in{I}\)</span>, see
<a href="#equation-fem:deq:1D:Galerkin0">(56)</a> and <a href="#equation-fem:deq:1D:Galerkin">(57)</a>.
We therefore have</p>
<div class="math">
\[(\sum_{j\in{I}} c_j{\psi}_j'', {\psi}_i)=-(f,{\psi}_i),\quad i\in{I}{\thinspace .}\]</div>
<p>This equation can be rearranged to a form that explicitly shows
that we get a linear system for the unknowns <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span>:</p>
<div class="math">
\[\sum_{j\in{I}} ({\psi}_i,{\psi}_j'')c_j = (f, {\psi}_i),\quad i\in{I}{\thinspace .}\]</div>
<p>For the particular choice of the basis functions <a href="#equation-fem:deq:1D:ex:sines:psi">(63)</a>
we get in fact the same linear system
as in the least squares method
because <span class="math">\({\psi}''= -(i+1)^2\pi^2L^{-2}{\psi}\)</span>.</p>
</div>
<div class="section" id="the-collocation-method-2">
<h3>The collocation method  (2)<a class="headerlink" href="#the-collocation-method-2" title="Permalink to this headline">¶</a></h3>
<p>For the collocation method <a href="#equation-fem:deq:1D:collocation">(60)</a> we need to
decide upon a set of <span class="math">\(N+1\)</span> collocation points in <span class="math">\(\Omega\)</span>. A simple
choice is to use uniformly spaced points: <span class="math">\(x_{i}=i\Delta x\)</span>, where
<span class="math">\(\Delta x = L/N\)</span> in our case (<span class="math">\(N\geq 1\)</span>). However, these points
lead to at least two rows in the matrix consisting of zeros
(since <span class="math">\({\psi}_i(x_{0})=0\)</span> and <span class="math">\({\psi}_i(x_{N})=0\)</span>), thereby making the matrix
singular and non-invertible. This forces us to choose some other
collocation points, e.g., random points or points uniformly distributed
in the interior of <span class="math">\(\Omega\)</span>.
Demanding the residual to vanish
at these points leads, in our model problem <a href="#equation-fem:deq:1D:model1b">(62)</a>, to
the equations</p>
<div class="math">
\[-\sum_{j\in{I}} c_j{\psi}_j''(x_{i}) = f(x_{i}),\quad i\in{I},\]</div>
<p>which is seen to be a linear system with entries</p>
<div class="math">
\[A_{i,j}=-{\psi}_j''(x_{i})=
(j+1)^2\pi^2L^{-2}\sin\left((j+1)\pi \frac{x_i}{L}\right),\]</div>
<p>in the coefficient matrix and entries
<span class="math">\(b_i=2\)</span> for the right-hand side (when <span class="math">\(f(x)=2\)</span>).</p>
<p>The special case of <span class="math">\(N=0\)</span>
can sometimes be of interest. A natural choice is then the midpoint
<span class="math">\(x_{0}=L/2\)</span> of the domain, resulting in
<span class="math">\(A_{0,0} = -{\psi}_0''(x_{0}) = \pi^2L^{-2}\)</span>, <span class="math">\(f(x_0)=2\)</span>,
and hence <span class="math">\(c_0=2L^2/\pi^2\)</span>.</p>
</div>
<div class="section" id="comparison">
<h3>Comparison<a class="headerlink" href="#comparison" title="Permalink to this headline">¶</a></h3>
<p>In the present model problem, with <span class="math">\(f(x)=2\)</span>, the exact solution is
<span class="math">\(u(x)=x(L-x)\)</span>, while for <span class="math">\(N=0\)</span> the Galerkin and least squares method
result in <span class="math">\(u(x)=8L^2\pi^{-3}\sin (\pi x/L)\)</span> and the
collocation method leads to <span class="math">\(u(x)=2L^2\pi^{-2}\sin (\pi x/L)\)</span>.
Since all methods fulfill the boundary conditions <span class="math">\(u(0)=u(L)=0\)</span>, we
expect the largest discrepancy to occur at the midpoint of the domain:
<span class="math">\(x=L/2\)</span>. The error at the midpoint becomes <span class="math">\(-0.008L^2\)</span> for the
Galerkin and least squares method, and <span class="math">\(0.047L^2\)</span> for the collocation
method.</p>
</div>
</div>
<div class="section" id="integration-by-parts">
<span id="fem-deq-1d-varform"></span><h2>Integration by parts<a class="headerlink" href="#integration-by-parts" title="Permalink to this headline">¶</a></h2>
<p id="index-71">A problem arises if we want to apply popular finite element functions
to solve our model problem <a href="#equation-fem:deq:1D:model1b">(62)</a>
by the standard least squares, Galerkin, or collocation methods: the piecewise
polynomials <span class="math">\({\psi}_i(x)\)</span> have discontinuous derivatives at the
cell boundaries which makes it problematic to compute
the second-order derivative.  This fact actually makes the least squares and
collocation methods less suitable for finite element approximation of
the unknown function. (By rewriting the equation <span class="math">\(-u''=f\)</span> as a
system of two first-order equations, <span class="math">\(u'=v\)</span> and <span class="math">\(-v'=f\)</span>, the
least squares method can be applied. Also, differentiating discontinuous
functions can actually be handled by distribution theory in
mathematics.)  The Galerkin method and the method of
weighted residuals can, however, be applied together with finite
element basis functions if we use <em>integration by parts</em>
as a means for transforming a second-order derivative to a first-order
one.</p>
<p>Consider the model problem <a href="#equation-fem:deq:1D:model1b">(62)</a> and its
Galerkin formulation</p>
<div class="math">
\[-(u'',v) = (f,v)\quad\forall v\in V{\thinspace .}\]</div>
<p>Using integration by parts in the Galerkin method,
we can move a derivative of <span class="math">\(u\)</span> onto <span class="math">\(v\)</span>:</p>
<div class="math">
\[\int_0^L u''(x)v(x) {\, \mathrm{d}x} = - \int_0^Lu'(x)v'(x){\, \mathrm{d}x}
+ [vu']_0^L\nonumber\]</div>
<div class="math" id="equation-fem:deq:1D:intbyparts">
<span class="eqno">(66)</span>\[     = - \int_0^Lu'(x)v'(x) {\, \mathrm{d}x}
     + u'(L)v(L) - u'(0)v(0){\thinspace .}\]</div>
<p>Usually, one integrates the problem at the stage where the <span class="math">\(u\)</span> and <span class="math">\(v\)</span>
functions enter the formulation.
Alternatively, but less common, we can integrate by parts in the expressions for
the matrix entries:</p>
<div class="math">
\[\int_0^L{\psi}_i(x){\psi}_j''(x) {\, \mathrm{d}x} =
- \int_0^L{\psi}_i'(x){\psi}_j'(x) dx
+ [{\psi}_i{\psi}_j']_0^L\nonumber\]</div>
<div class="math" id="equation-fem:deq:1D:intbyparts0">
<span class="eqno">(67)</span>\[     = - \int_0^L{\psi}_i'(x){\psi}_j'(x) {\, \mathrm{d}x}
     + {\psi}_i(L){\psi}_j'(L) - {\psi}_i(0){\psi}_j'(0){\thinspace .}\]</div>
<p>Integration by parts serves to reduce the order of the derivatives and
to make the coefficient matrix symmetric since
<span class="math">\(({\psi}_i',{\psi}_j') = ({\psi}_i',{\psi}_j')\)</span>.
The symmetry property depends
on the type of terms that enter the differential equation.
As will be seen later in the section <a class="reference internal" href="#fem-deq-1d-bc-nat"><em>Boundary conditions: specified derivative</em></a>,
integration by parts also provides a method for implementing
boundary conditions involving <span class="math">\(u'\)</span>.</p>
<p>With the choice <a href="#equation-fem:deq:1D:ex:sines:psi">(63)</a> of basis functions we see
that the &#8220;boundary terms&#8221; <span class="math">\({\psi}_i(L){\psi}_j'(L)\)</span> and <span class="math">\({\psi}_i(0){\psi}_j'(0)\)</span>
vanish since <span class="math">\({\psi}_i(0)={\psi}_i(L)=0\)</span>.</p>
<span class="target" id="index-72"></span><div class="section" id="weak-form">
<span id="index-73"></span><h3>Weak form<a class="headerlink" href="#weak-form" title="Permalink to this headline">¶</a></h3>
<p>Since the variational formulation after integration by parts make
weaker demands on the differentiability of <span class="math">\(u\)</span> and the basis
functions <span class="math">\({\psi}_i\)</span>,
the resulting integral formulation is referred to as a <em>weak form</em> of
the differential equation problem. The original variational formulation
with second-order derivatives, or the differential equation problem
with second-order derivative, is then the <em>strong form</em>, with
stronger requirements on the differentiability of the functions.</p>
<p>For differential equations with second-order derivatives, expressed as
variational formulations and solved by finite element methods, we will
always perform integration by parts to arrive at expressions involving
only first-order derivatives.</p>
</div>
</div>
<div class="section" id="boundary-function">
<span id="fem-deq-1d-essbc-bfunc"></span><h2>Boundary function<a class="headerlink" href="#boundary-function" title="Permalink to this headline">¶</a></h2>
<p>So far we have assumed zero Dirichlet boundary conditions, typically
<span class="math">\(u(0)=u(L)=0\)</span>, and we have demanded that <span class="math">\({\psi}_i(0)={\psi}_i(L)=0\)</span>
for <span class="math">\(i\in{I}\)</span>. What about a boundary condition like <span class="math">\(u(L)=D\neq0\)</span>?
This condition immediately faces a problem:
<span class="math">\(u = \sum_j c_j{\varphi}_j(L) = 0\)</span> since all <span class="math">\({\varphi}_i(L)=0\)</span>.</p>
<p>A boundary condition of the form <span class="math">\(u(L)=D\)</span> can be implemented by
demanding that all <span class="math">\({\psi}_i(L)=0\)</span>, but adding a
<em>boundary function</em> <span class="math">\(B(x)\)</span> with the right boundary value, <span class="math">\(B(L)=D\)</span>, to
the expansion for <span class="math">\(u\)</span>:</p>
<div class="math">
\[u(x) = B(x) + \sum_{j\in{I}} c_j{\psi}_j(x)
{\thinspace .}\]</div>
<p>This <span class="math">\(u\)</span> gets the right value at <span class="math">\(x=L\)</span>:</p>
<div class="math">
\[u(L) = B(L) + \sum_{j\in{I}} c_j{\psi}_j(L) = B(L) = D{\thinspace .}\]</div>
<p>The idea is that for any boundary where <span class="math">\(u\)</span> is known we demand <span class="math">\({\psi}_i\)</span> to
vanish and construct a function <span class="math">\(B(x)\)</span> to attain the boundary value of <span class="math">\(u\)</span>.
There are no restrictions how <span class="math">\(B(x)\)</span> varies with <span class="math">\(x\)</span> in the interior of the
domain, so this variation needs to be constructed in some way.</p>
<p>For example, with <span class="math">\(u(0)=0\)</span> and
<span class="math">\(u(L)=D\)</span>, we can choose <span class="math">\(B(x)=x D/L\)</span>, since this form ensures that
<span class="math">\(B(x)\)</span> fulfills the boundary conditions: <span class="math">\(B(0)=0\)</span> and <span class="math">\(B(L)=D\)</span>.
The unknown function is then sought on the form</p>
<div class="math" id="equation-fem:deq:1D:essBC:Bfunc:u1">
<span class="eqno">(68)</span>\[     u(x) = \frac{x}{L}D + \sum_{j\in{I}} c_j{\psi}_j(x),\]</div>
<p>with <span class="math">\({\psi}_i(0)={\psi}_i(L)=0\)</span>.</p>
<p>The <span class="math">\(B(x)\)</span> function can be chosen in many ways as long as its boundary
values are correct. For example, <span class="math">\(B(x)=D(x/L)^p\)</span> for any power <span class="math">\(p\)</span>
will work fine in the above example.</p>
<p>As another example, consider a domain <span class="math">\(\Omega = [a,b]\)</span>
where the boundary conditions are <span class="math">\(u(a)=U_a\)</span> and <span class="math">\(u(b)=U_b\)</span>.  A class
of possible <span class="math">\(B(x)\)</span> functions is</p>
<div class="math" id="equation-fem:deq:1D:essBC:Bfunc:gen  B(x)=U_a + \frac{U_b-U_a}{(b-a)^p}(x-a)^p,\quad p&gt;0 {\thinspace .}">
</div>
<p>Real applications will most likely use the simplest version, <span class="math">\(p=1\)</span>,
but here such a <span class="math">\(p\)</span> parameter was included to demonstrate the
ambiguity in the construction of <span class="math">\(B(x)\)</span>.</p>
<div class="admonition-summary admonition">
<p class="first admonition-title">Summary</p>
<p>The general procedure of incorporating Dirichlet boundary
conditions goes as follows.
Let <span class="math">\(\partial\Omega_E\)</span> be the part(s) of the boundary
<span class="math">\(\partial\Omega\)</span> of the domain <span class="math">\(\Omega\)</span> where <span class="math">\(u\)</span> is specified.
Set <span class="math">\({\psi}_i=0\)</span> at the points in <span class="math">\(\partial\Omega_E\)</span> and seek <span class="math">\(u\)</span>
as</p>
<div class="math" id="equation-fem:deq:1D:essBC:Bfunc:u2">
<span class="eqno">(70)</span>\[     u(x) = B(x) + \sum_{j\in{I}} c_j{\psi}_j(x),\]</div>
<p class="last">where <span class="math">\(B(x)\)</span> equals the boundary conditions on <span class="math">\(u\)</span> at <span class="math">\(\partial\Omega_E\)</span>.</p>
</div>
<p><strong>Remark.</strong>
With the <span class="math">\(B(x)\)</span> term, <span class="math">\(u\)</span> does not in general lie in <span class="math">\(V=\hbox{span}\,
\{{\psi}_0,\ldots,{\psi}_N\}\)</span> anymore. Moreover, when a prescribed value
of <span class="math">\(u\)</span> at the boundary, say <span class="math">\(u(a)=U_a\)</span> is different from zero, it does
not make sense to say that <span class="math">\(u\)</span> lies in a vector space, because
this space does not obey the requirements of addition and scalar multiplication.
For example,
<span class="math">\(2u\)</span> does not lie in the space since its boundary value is <span class="math">\(2U_a\)</span>,
which is incorrect. It only makes sense to split <span class="math">\(u\)</span> in two parts,
as done above, and have the unknown part <span class="math">\(\sum_j c_j {\psi}_j\)</span> in a
proper function space.</p>
</div>
<div class="section" id="abstract-notation-for-variational-formulations">
<span id="fem-deq-1d-varform-abstract"></span><h2>Abstract notation for variational formulations<a class="headerlink" href="#abstract-notation-for-variational-formulations" title="Permalink to this headline">¶</a></h2>
<p>We have seen that variational formulations end up with a formula involving
<span class="math">\(u\)</span> and <span class="math">\(v\)</span>, such as <span class="math">\((u',v')\)</span> and a formula involving <span class="math">\(v\)</span> and known
functions, such as <span class="math">\((f,v)\)</span>. A widely used notation is to introduce an abstract
variational statement written as <span class="math">\(a(u,v)=L(v)\)</span>,
where <span class="math">\(a(u,v)\)</span> is a so-called <em>bilinear form</em> involving all the terms
that contain both the test and trial
function, while <span class="math">\(L(v)\)</span> is a <em>linear form</em> containing all the terms without
the trial function. For example, the statement</p>
<div class="math">
\[\int_{\Omega} u' v' {\, \mathrm{d}x} =
\int_{\Omega} fv{\, \mathrm{d}x}\quad\hbox{or}\quad (u',v') = (f,v)
\quad\forall v\in V\]</div>
<p>can be written in abstract form: <em>find :math:`u` such that</em></p>
<div class="math">
\[a(u,v) = L(v)\quad \forall v\in V,\]</div>
<p>where we have the definitions</p>
<div class="math">
\[a(u,v) = (u',v'),\quad L(v) = (f,v){\thinspace .}\]</div>
<p>The term <em>linear</em> means that <span class="math">\(L(\alpha_1 v_1 + \alpha_2 v_2)
=\alpha_1 L(v_1) + \alpha_2 L(v_2)\)</span> for two test functions <span class="math">\(v_1\)</span> and <span class="math">\(v_2\)</span>, and
scalar parameters <span class="math">\(\alpha_1\)</span> and <span class="math">\(\alpha_2\)</span>. Similarly, the term <em>bilinear</em>
means that <span class="math">\(a(u,v)\)</span> is linear in both its arguments:</p>
<div class="math">
\[\begin{split}a(\alpha_1 u_1 + \alpha_2 u_2, v) &amp;= \alpha_1 a(u_1,v) + \alpha_2 a(u_2, v),
\\
a(u, \alpha_1 v_1 + \alpha_2 v_2) &amp;= \alpha_1 a(u,v_1) + \alpha_2 a(u, v_2)
{\thinspace .}\end{split}\]</div>
<p>In nonlinear problems these linearity properties do not hold in general
and the abstract notation is then <span class="math">\(F(u;v)=0\)</span>.</p>
<p>The matrix system associated with <span class="math">\(a(u,v)=L(v)\)</span> can also be written in
an abstract form by inserting <span class="math">\(v={\psi}_i\)</span> and <span class="math">\(u=\sum_j c_j{\psi}_j\)</span>
in <span class="math">\(a(u,v)=L(v)\)</span>. Using the linear properties, we get</p>
<div class="math">
\[\sum_{j\in{I}} a({\psi}_j,{\psi}_i) c_j = L({\psi}_i),\quad i\in{I},\]</div>
<p>which is a linear system</p>
<div class="math">
\[\sum_{j\in{I}}A_{i,j}c_j = b_i,\quad i\in{I},\]</div>
<p>where</p>
<div class="math">
\[A_{i,j} =a({\psi}_j,{\psi}_i), \quad b_i = L({\psi}_i){\thinspace .}\]</div>
<p>In many problems, <span class="math">\(a(u,v)\)</span> is symmetric such that
<span class="math">\(a({\psi}_j,{\psi}_i) = a({\psi}_i,{\psi}_j)\)</span>. In those cases the
coefficient matrix becomes symmetric, <span class="math">\(A_{i,j}=A_{j,i}\)</span>, a property
that can simplify solution algorithms for linear systems
and make them more stable in addition to saving memory and computations.</p>
<p>The abstract notation <span class="math">\(a(u,v)=L(v)\)</span> for linear differential equation problems
is much used in the literature and
in description of finite element software (in particular the
<a class="reference external" href="http://fenicsproject.org">FEniCS</a> documentation). We shall
frequently summarize variational forms using this notation.</p>
</div>
<div class="section" id="variational-problems-and-optimization-of-functionals">
<span id="fem-deq-1d-optimization"></span><h2>Variational problems and optimization of functionals<a class="headerlink" href="#variational-problems-and-optimization-of-functionals" title="Permalink to this headline">¶</a></h2>
<p>If <span class="math">\(a(u,v)=a(v,u)\)</span>, it can be shown that the variational statement</p>
<div class="math">
\[a(u,v)=L(v)\quad\forall v\in V,\]</div>
<p>is equivalent to minimizing the functional</p>
<div class="math">
\[F(v) = \frac{1}{2}a(v,v) - L(v)\]</div>
<p>over all functions <span class="math">\(v\in V\)</span>. That is,</p>
<div class="math">
\[F(u)\leq F(v)\quad \forall v\in V{\thinspace .}\]</div>
<p>Inserting a <span class="math">\(v=\sum_j c_j{\psi}_j\)</span> turns minimization of <span class="math">\(F(v)\)</span> into
minimization of a quadratic function</p>
<div class="math">
\[\bar F(c_0,\ldots,c_N) = \sum_{j\in{I}}\sum_{i\in{I}} a({\psi}_i,{\psi}_j)c_ic_j - \sum_{j\in{I}} L({\psi}_j)c_j\]</div>
<p>of <span class="math">\(N+1\)</span> parameters.</p>
<p>Minimization of <span class="math">\(\bar F\)</span> implies</p>
<div class="math">
\[\frac{\partial\bar F}{\partial c_i}=0,\quad i\in{I}{\thinspace .}\]</div>
<p>After some algebra one finds</p>
<div class="math">
\[\sum{j\in{I}} a({\psi}_i,{\psi}_j)c_j = L({\psi}_i),\quad i\in{I},\]</div>
<p>which is the same system as that arising from <span class="math">\(a(u,v)=L(v)\)</span>.</p>
<p>Many traditional applications of the finite element method, especially
in solid mechanics and structural analysis, start with formulating <span class="math">\(F(v)\)</span>
from physical principles, such as minimization of energy, and then
proceeds with deriving <span class="math">\(a(u,v)=L(v)\)</span>, which is the equation usually desired
in implementations.</p>
</div>
</div>
<div class="section" id="examples-on-variational-formulations">
<span id="fem-deq-1d-varform-ex"></span><h1>Examples on variational formulations<a class="headerlink" href="#examples-on-variational-formulations" title="Permalink to this headline">¶</a></h1>
<p>The following sections derive variational formulations for some
prototype differential equations in 1D, and demonstrate how we with
ease can handle variable coefficients, mixed Dirichlet and Neumann
boundary conditions, first-order derivatives, and nonlinearities.</p>
<div class="section" id="variable-coefficient">
<h2>Variable coefficient<a class="headerlink" href="#variable-coefficient" title="Permalink to this headline">¶</a></h2>
<p>Consider the problem</p>
<div class="math">
\[-\frac{d}{dx}\left( {\alpha}(x)\frac{du}{dx}\right) = f(x),\quad x\in\Omega =[0,L],\
u(0)=C,\ u(L)=D{\thinspace .}\]</div>
<p>There are two new features of this problem compared with
previous examples: a variable
coefficient <span class="math">\(a(x)\)</span> and nonzero Dirichlet conditions at both boundary points.</p>
<p>Let us first deal with the boundary conditions. We seek</p>
<div class="math">
\[u(x) = B(x) + \sum_{j\in{I}} c_j{\psi}_i(x),\]</div>
<p>with <span class="math">\({\psi}_i(0)={\psi}_i(L)=0\)</span> for <span class="math">\(i\in{I}\)</span>. The function <span class="math">\(B(x)\)</span>
must then fulfill <span class="math">\(B(0)=C\)</span> and <span class="math">\(B(L)=D\)</span>. How <span class="math">\(B\)</span> varies in between
<span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span> is not of importance. One possible choice is</p>
<div class="math">
\[B(x) = C + \frac{1}{L}(D-C)x,\]</div>
<p>which follows from <a href="#equation-fem:deq:1D:essBC:Bfunc:gen">(?)</a> with <span class="math">\(p=1\)</span>.</p>
<p>We seek <span class="math">\((u-B)\in V\)</span>. As usual,</p>
<div class="math">
\[V = \hbox{span}\{{\psi}_0,\ldots,{\psi}_N\},\]</div>
<p>but the two Dirichlet boundary conditions demand that</p>
<div class="math">
\[{\psi}_i(0)={\psi}_i(L)=0, \quad i\in{I}{\thinspace .}\]</div>
<p>Note that any <span class="math">\(v\in V\)</span> has the property <span class="math">\(v(0)=v(L)=0\)</span>.</p>
<p>The residual arises by inserting our <span class="math">\(u\)</span> in the differential equation:</p>
<div class="math">
\[R = -\frac{d}{dx}\left( {\alpha}\frac{du}{dx}\right) -f{\thinspace .}\]</div>
<p>Galerkin&#8217;s method is</p>
<div class="math">
\[(R, v) = 0,\quad \forall v\in V,\]</div>
<p>or written with explicit integrals,</p>
<div class="math">
\[\int_{\Omega} \left(\frac{d}{dx}\left( {\alpha}\frac{du}{dx}\right) -f\right)v {\, \mathrm{d}x} = 0,\quad \forall v\in V {\thinspace .}\]</div>
<p>We proceed with integration by parts to lower the derivative from
second to first order:</p>
<div class="math">
\[-\int_{\Omega} \frac{d}{dx}\left( {\alpha}(x)\frac{du}{dx}\right) v {\, \mathrm{d}x}
= \int_{\Omega} {\alpha}(x)\frac{du}{dx}\frac{dv}{dx}{\, \mathrm{d}x} -
\left[{\alpha}\frac{du}{dx}v\right]_0^L
{\thinspace .}\]</div>
<p>The boundary term vanishes since <span class="math">\(v(0)=v(L)=0\)</span>.
The variational formulation is then</p>
<div class="math">
\[\int_{\Omega} {\alpha}(x)\frac{du}{dx}\frac{dv}{dx}{\, \mathrm{d}x} = \int_{\Omega} f(x)v{\, \mathrm{d}x},\quad
\forall v\in V{\thinspace .}\]</div>
<p>The variational formulation can alternatively be written in a more
compact form:</p>
<div class="math">
\[({\alpha} u',v') = (f,v),\quad \forall v\in V
{\thinspace .}\]</div>
<p>The corresponding abstract notation reads</p>
<div class="math">
\[a(u,v)=L(v)\quad\forall v\in V,\]</div>
<p>with</p>
<div class="math">
\[a(u,v)= ({\alpha} u',v'),\quad L(v)=(f,v) {\thinspace .}\]</div>
<p>Note that the <span class="math">\(a\)</span> in the notation <span class="math">\(a(\cdot,\cdot)\)</span> is not to be mixed with the
variable coefficient <span class="math">\(a(x)\)</span> in the differential equation.</p>
<p>We may insert <span class="math">\(u=B + \sum_jc_j{\psi}_j\)</span> and <span class="math">\(v={\psi}_i\)</span> to
derive the linear system:</p>
<div class="math">
\[({\alpha} B' + {\alpha} \sum_{j\in{I}} c_j {\psi}_j', {\psi}_i') =
(f,{\psi}_i), \quad i\in{I} {\thinspace .}\]</div>
<p>Isolating everything with the <span class="math">\(c_j\)</span> coefficients on the left-hand side
and all known terms on the right-hand side
gives</p>
<div class="math">
\[\sum_{j\in{I}} ({\alpha}{\psi}_j', {\psi}_i')c_j  =
(f,{\psi}_i) + (a(D-C)L^{-1}, {\psi}_i'), \quad i\in{I}
{\thinspace .}\]</div>
<p>This is nothing but a linear system <span class="math">\(\sum_j A_{i,j}c_j=b_i\)</span>
with</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= (a{\psi}_j', {\psi}_i') = \int_{\Omega} {\alpha}(x){\psi}_j'(x),
{\psi}_i'(x){\, \mathrm{d}x},\\
b_i &amp;= (f,{\psi}_i) + (a(D-C)L^{-1},{\psi}_i')=
\int_{\Omega} \left(f(x){\psi}_i(x) + {\alpha}(x)\frac{D-C}{L}{\psi}_i'(x)\right) {\, \mathrm{d}x}
{\thinspace .}\end{split}\]</div>
</div>
<div class="section" id="first-order-derivative-in-the-equation-and-boundary-condition">
<h2>First-order derivative in the equation and boundary condition<a class="headerlink" href="#first-order-derivative-in-the-equation-and-boundary-condition" title="Permalink to this headline">¶</a></h2>
<p>The next problem to formulate in variational form reads</p>
<div class="math">
\[-u''(x) + bu'(x) = f(x),\quad x\in\Omega =[0,L],\
u(0)=C,\ u'(L)=E{\thinspace .}\]</div>
<p>The new features are a first-order derivative <span class="math">\(u'\)</span> in the equation
and the boundary
condition involving the derivative: <span class="math">\(u'(L)=E\)</span>.
Since we have a Dirichlet condition at <span class="math">\(x=0\)</span>,
we force <span class="math">\({\psi}_i(0)=0\)</span> and use a boundary function</p>
<div class="math">
\[B(x)=C(L-x)/L,\]</div>
<p>to take care of the condition <span class="math">\(u(0)=C\)</span>. Because there is no Dirichlet
condition on <span class="math">\(x=L\)</span> we do not make any requirements to <span class="math">\({\psi}_i(L)\)</span>.
The expansion for <span class="math">\(u\)</span> becomes</p>
<div class="math">
\[u = \frac{C}{L}(L-x) + \sum_{j\in{I}} c_j {\psi}_i(x)
{\thinspace .}\]</div>
<p>The variational formulation arises from multiplying the equation by
a test function <span class="math">\(v\in V\)</span> and integrating over <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[(-u'' + bu' - f, v) = 0,\quad\forall v\in V\]</div>
<p>We apply integration by parts to the <span class="math">\(u''v\)</span> term only. Although we could
also integrate <span class="math">\(u' v\)</span> by parts, this is not common.
The result becomes</p>
<div class="math">
\[(u' + bu',v') = (f,v) + [u' v]_0^L, \quad\forall v\in V {\thinspace .}\]</div>
<p>Now, <span class="math">\(v(0)=0\)</span> so</p>
<div class="math">
\[[u' v]_0^L = u'(L)v(L) = E v(L),\]</div>
<p>because <span class="math">\(u'(L)=E\)</span>.
Integration by parts allows us to take care of the Neumann condition
in the boundary term.</p>
<span class="target" id="index-74"></span><div class="admonition-natural-and-essential-boundary-conditions admonition" id="index-75">
<p class="first admonition-title">Natural and essential boundary conditions</p>
<p class="last">Omitting a boundary term like <span class="math">\([u'v]_0^L\)</span>
implies that we actually impose the condition <span class="math">\(u'=0\)</span> unless there
is a Dirichlet condition (i.e., <span class="math">\(v=0\)</span>) at that point! This result has great
practical consequences, because it is easy to forget the boundary
term, and this mistake may implicitly
set a boundary condition! Since
homogeneous Neumann conditions can be incorporated
without doing anything, and non-homogeneous Neumann conditions can
just be inserted in the boundary term,
such conditions are known as <em>natural boundary conditions</em>.
Dirichlet conditions requires more essential steps in the mathematical
formulation, such as forcing all <span class="math">\({\varphi}_i=0\)</span> on the boundary
and constructing a <span class="math">\(B(x)\)</span>, and are
therefore known as <em>essential boundary conditions</em>.</p>
</div>
<p>The final variational form reads</p>
<div class="math">
\[(u',v') + (bu',v) = (f,v) + E v(L), \quad\forall v\in V {\thinspace .}\]</div>
<p>In the abstract notation we have</p>
<div class="math">
\[a(u,v)=L(v)\quad\forall v\in V,\]</div>
<p>with the particular formulas</p>
<div class="math">
\[a(u,v)=(u',v') + (bu',v),\quad L(v)= (f,v) + E v(L){\thinspace .}\]</div>
<p>The associated linear system is derived by inserting <span class="math">\(u=B+\sum_jc_j{\psi}_j\)</span>
and replacing <span class="math">\(v\)</span> by <span class="math">\({\psi}_i\)</span> for <span class="math">\(i\in{I}\)</span>. Some algebra results in</p>
<div class="math">
\[\sum_{j\in{I}} \underbrace{(({\psi}_j',{\psi}_i') + (b{\psi}_j',{\psi}_i))}_{A_{i,j}} c_j = \underbrace{(f,{\psi}_i) + (bCL^{-1},{\psi}_i') + E {\psi}_i(L)}_{b_i}
{\thinspace .}\]</div>
<p>Observe that in this problem, the coefficient matrix is not symmetric,
because of the term</p>
<div class="math">
\[(b{\psi}_j',{\psi}_i)=\int_{\Omega} b{\psi}_j'{\psi}_i {\, \mathrm{d}x}
 \neq \int_{\Omega} b {\psi}_i' {\psi}_j {\, \mathrm{d}x} = ({\psi}_i',b{\psi}_j)
{\thinspace .}\]</div>
</div>
<div class="section" id="nonlinear-coefficient">
<h2>Nonlinear coefficient<a class="headerlink" href="#nonlinear-coefficient" title="Permalink to this headline">¶</a></h2>
<p>Finally, we show that the techniques used above to derive variational
forms also apply to nonlinear differential equation
problems as well. Here is a model problem with
a nonlinear coefficient and right-hand side:</p>
<div class="math">
\[-({\alpha}(u)u')' = f(u),\quad x\in [0,L],\ u(0)=0,\ u'(L)=E
{\thinspace .}\]</div>
<p>Our space <span class="math">\(V\)</span> has basis <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{I}}\)</span>, and because of the
condition <span class="math">\(u(0)=0\)</span>, we must require <span class="math">\({\psi}_i(0)=0\)</span>, <span class="math">\(i\in{I}\)</span>.</p>
<p>Galerkin&#8217;s method is about inserting the approximate
<span class="math">\(u\)</span>, multiplying the differential equation by <span class="math">\(v\in V\)</span>, and integrate,</p>
<div class="math">
\[-\int_0^L \frac{d}{dx}\left({\alpha}(u)\frac{du}{dx}\right)v {\, \mathrm{d}x} =
\int_0^L f(u)v {\, \mathrm{d}x}\quad\forall v\in V
{\thinspace .}\]</div>
<p>The integration by parts does not differ from the case where we have
<span class="math">\({\alpha}(x)\)</span> instead of <span class="math">\({\alpha}(u)\)</span>:</p>
<div class="math">
\[\int_0^L {\alpha}(u)\frac{du}{dx}\frac{dv}{dx}{\, \mathrm{d}x} =
\int_0^L f(u)v{\, \mathrm{d}x} + [{\alpha}(u)vu']_0^L\quad\forall v\in V
{\thinspace .}\]</div>
<p>The term <span class="math">\({\alpha}(u(0))v(0)u'(0)=0\)</span> since <span class="math">\(v(0)\)</span>.
The other term, <span class="math">\({\alpha}(u(L))v(L)u'(L)\)</span>,
is used to impose the other boundary condition <span class="math">\(u'(L)=E\)</span>, resulting in</p>
<div class="math">
\[\int_0^L {\alpha}(u)\frac{du}{dx}\frac{dv}{dx}v{\, \mathrm{d}x} =
\int_0^L f(u)v{\, \mathrm{d}x} + {\alpha}(u(L))v(L)E\quad\forall v\in V,\]</div>
<p>or alternatively written more compactly as</p>
<div class="math">
\[({\alpha}(u)u', v') = (f(u),v) + {\alpha}(L)v(L)E\quad\forall v\in V
{\thinspace .}\]</div>
<p>Since the problem is nonlinear, we cannot identify a bilinear
form <span class="math">\(a(u,v)\)</span> and a linear form <span class="math">\(L(v)\)</span>.
An abstract notation is typically <em>find :math:`u` such that</em></p>
<div class="math">
\[F(u;v) = 0\quad\forall v\in V,\]</div>
<p>with</p>
<div class="math">
\[F(u;v) = (a(u)u', v') - (f(u),v) - a(L)v(L)E
{\thinspace .}\]</div>
<p>By inserting <span class="math">\(u=\sum_j c_j{\psi}_j\)</span> we get a <em>nonlinear system of
algebraic equations</em> for the unknowns <span class="math">\(c_i\)</span>, <span class="math">\(i\in{I}\)</span>. Such systems must
be solved by constructing a sequence of linear systems whose solutions
hopefully converge to the solution of the nonlinear system. Frequently applied
methods are Picard iteration and Newton&#8217;s method.</p>
</div>
<div class="section" id="computing-with-dirichlet-and-neumann-conditions">
<span id="fem-deq-1d-varform-ex-dn-case"></span><h2>Computing with Dirichlet and Neumann conditions<a class="headerlink" href="#computing-with-dirichlet-and-neumann-conditions" title="Permalink to this headline">¶</a></h2>
<p>Let us perform the necessary calculations to solve</p>
<div class="math">
\[-u''(x)=2,\quad x\in \Omega=[0,1],\quad u'(0)=C,\ u(1)=D,\]</div>
<p>using a global polynomial basis <span class="math">\({\psi}_i\sim x^i\)</span>.
The requirements on <span class="math">\({\psi}_i\)</span> is that <span class="math">\({\psi}_i(1)=0\)</span>, because <span class="math">\(u\)</span> is
specified at <span class="math">\(x=1\)</span>, so a proper set of polynomial basis functions can be</p>
<div class="math">
\[{\psi}_i(x)=(1-x)^{i+1}, \quad i\in{I}{\thinspace .}\]</div>
<p>A suitable <span class="math">\(B(x)\)</span> function
to handle the boundary condition <span class="math">\(u(1)=D\)</span> is <span class="math">\(B(x)=Dx\)</span>.
The variational formulation becomes</p>
<div class="math">
\[(u',v') = (2,v) - Cv(0)\quad\forall v\in V{\thinspace .}\]</div>
<p>The entries in the linear system are then</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= ({\psi}_j,{\psi}_i) = \int_{0}^1 {\psi}_i'(x){\psi}_j'(x){\, \mathrm{d}x}
= \int_0^1 (i+1)(j+1)(1-x)^{i+j}{\, \mathrm{d}x} = \frac{ij + i + j + 1}{i + j + 1},\\
b_i &amp;= (2,{\psi}_i) - (D,{\psi}_i') -C{\psi}_i(0)\\
&amp;= \int_0^1\left( 2{\psi}_i(x) - D{\psi}_i'(x)\right){\, \mathrm{d}x} -C{\psi}_i(0)\\
&amp;= \int_0^1 \left( 2(1-x)^{i+1} - D(i+1)(1-x)^i\right){\, \mathrm{d}x}  -C{\psi}_i(0)\\
&amp;= \frac{2 - (2+i)(D+C)}{i+2}
{\thinspace .}\end{split}\]</div>
<p>With <span class="math">\(N=1\)</span>
the global matrix system is</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}
1 &amp; 1\\
1 &amp; 4/3
\end{array}\right)
\left(\begin{array}{c}
c_0\\
c_1
\end{array}\right)
=
\left(\begin{array}{c}
-C+D+1\\
2/3 -C + D
\end{array}\right)\end{split}\]</div>
<p>The solution becomes <span class="math">\(c_0=-C+D+2\)</span> and <span class="math">\(c_1=-1\)</span>, resulting in</p>
<div class="math">
\[u(x) = 1 -x^2 + D + C(x-1),\]</div>
<p>The exact solution is found by.
integrating twice and applying the boundary conditions, either
by hand or using <tt class="docutils literal"><span class="pre">sympy</span></tt> as shown in the section <a class="reference internal" href="#fem-deq-1d-models-simple"><em>Simple model problems</em></a>.
It appears that the numerical solution coincides with the exact one.
This result is to be expected because if <span class="math">\(({u_{\small\mbox{e}}} - B)\in V\)</span>, <span class="math">\(u = {u_{\small\mbox{e}}}\)</span>,
as proved next.</p>
</div>
<div class="section" id="when-the-numerical-method-is-exact">
<h2>When the numerical method is exact<a class="headerlink" href="#when-the-numerical-method-is-exact" title="Permalink to this headline">¶</a></h2>
<p>We have some variational formulation: find <span class="math">\((u-B)\in V\)</span> such that
<span class="math">\(a(u,v)=L(u)\ \forall V\)</span>. The exact solution also fulfills
<span class="math">\(a({u_{\small\mbox{e}}},v)=L(v)\)</span>, but normally <span class="math">\(({u_{\small\mbox{e}}} -B)\)</span> lies in a much larger
(infinite-dimensional) space. Suppose, nevertheless, that
<span class="math">\({u_{\small\mbox{e}}} = B + E\)</span>, where <span class="math">\(E\in V\)</span>. That is, apart from Dirichlet conditions,
<span class="math">\({u_{\small\mbox{e}}}\)</span> lines in our finite-dimensional space <span class="math">\(V\)</span> we use to compute <span class="math">\(u\)</span>.
Writing also <span class="math">\(u\)</span> on the same form <span class="math">\(u=B+F\)</span>, we have</p>
<div class="math">
\[\begin{split}a(B+E,v) &amp;= L(v)\quad\forall v\in V,\\
a(B+F,v) &amp;= L(v)\quad\forall v\in V{\thinspace .}\end{split}\]</div>
<p>Subtracting the equations show that <span class="math">\(a(E-F,v)=0\)</span> for all <span class="math">\(v\in V\)</span>, and
therefore <span class="math">\(E-F=0\)</span> and <span class="math">\(u={u_{\small\mbox{e}}}\)</span>.</p>
<p>The case treated in the section <a class="reference internal" href="#fem-deq-1d-varform-ex-dn-case"><em>Computing with Dirichlet and Neumann conditions</em></a>
is of the type where <span class="math">\({u_{\small\mbox{e}}} - B\)</span> is a quadratic function that is 0
at <span class="math">\(x=1\)</span>, and therefore <span class="math">\(({u_{\small\mbox{e}}} -B)\in V\)</span>, and the method
finds the exact solution.</p>
</div>
</div>
<div class="section" id="computing-with-finite-elements">
<span id="fem-deq-1d-fem1"></span><h1>Computing with finite elements<a class="headerlink" href="#computing-with-finite-elements" title="Permalink to this headline">¶</a></h1>
<p>The purpose of this section is to demonstrate in detail how
the finite element method can the be applied to the model problem</p>
<div class="math">
\[-u''(x) = 2,\quad x\in (0,L),\ u(0)=u(L)=0,\]</div>
<p>with variational formulation</p>
<div class="math">
\[(u',v') = (2,v)\quad\forall v\in V{\thinspace .}\]</div>
<p>The variational formulation is derived in
the section <a class="reference internal" href="#fem-deq-1d-varform"><em>Integration by parts</em></a>.</p>
<div class="section" id="finite-element-mesh-and-basis-functions">
<h2>Finite element mesh and basis functions<a class="headerlink" href="#finite-element-mesh-and-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>We introduce a finite element mesh with <span class="math">\(N_e\)</span> cells, all
with length <span class="math">\(h\)</span>, and number
the cells from left to right.
global nodes. Choosing P1 elements, there are two
nodes per cell, and the coordinates of the nodes become</p>
<div class="math">
\[x_{i} = i h,\quad h=L/N_e,\quad i=0,\ldots,N_n=N_e+1,\]</div>
<p>provided we number the nodes from left to right.</p>
<p>Each of the nodes, <span class="math">\(i\)</span>, is associated a finite element basis function
<span class="math">\({\varphi}_i(x)\)</span>.  When approximating a given function <span class="math">\(f\)</span> by a finite
element function <span class="math">\(u\)</span>, we expand <span class="math">\(u\)</span> using finite element basis
functions associated with <em>all</em> nodes in the mesh, i.e., <span class="math">\(N=N_n\)</span>.
However, when solving differential equations we will often have
<span class="math">\(N&lt;N_n\)</span> because of Dirichlet boundary conditions. Why this is the case
will now be explained in detail.</p>
<p>In our case with homogeneous Dirichlet boundary conditions we do not
need any boundary function <span class="math">\(B(x)\)</span> and can work with the expansion</p>
<div class="math" id="equation-fem:deq:1D:fem1:ex:u">
<span class="eqno">(71)</span>\[     u(x) = \sum_{j\in{I}} c_j{\psi}_j(x){\thinspace .}\]</div>
<p>Because of the boundary conditions, we must demand
<span class="math">\({\psi}_i(0)={\psi}_i(L)=0\)</span>, <span class="math">\(i\in{I}\)</span>. When <span class="math">\({\psi}_i\)</span>,
<span class="math">\(i=0,\ldots,N\)</span>, is to be selected among the finite element basis
functions <span class="math">\({\varphi}_j\)</span>, <span class="math">\(i=0,\ldots,N_n\)</span>, we have to avoid using
<span class="math">\({\varphi}_j\)</span> functions that do not vanish at <span class="math">\(x_{0}=0\)</span> and
<span class="math">\(x_{N_n}=L\)</span>. However, all <span class="math">\({\varphi}_j\)</span> vanish at these two nodes for
<span class="math">\(j=1,\ldots,N_n\)</span>.  Only basis functions associated with the end nodes,
<span class="math">\({\varphi}_0\)</span> and <span class="math">\({\varphi}_{N_n}\)</span>, violate the boundary conditions of
our differential equation. Therefore, we select the basis functions
<span class="math">\({\varphi}_i\)</span> to be the set of finite element basis functions associated
with all the interior nodes in the mesh:</p>
<div class="math">
\[{\psi}_i={\varphi}_{i+1},\quad i=0,\ldots,N{\thinspace .}\]</div>
<p>Here, <span class="math">\(N=N_n-2\)</span>.</p>
<p>In the general case, the nodes are not necessarily numbered from left
to right, so we introduce a mapping from the node numbering, or more
precisely the degree of freedom numbering, to the numbering of
the unknowns in the final equation system. These unknowns take on
the numbers <span class="math">\(0,\ldots,N\)</span>. Unknown number <span class="math">\(j\)</span> in the linear system
corresponds to degree of freedom number <span class="math">\(\nu (j)\)</span>, <span class="math">\(j\in{I}\)</span>.
We can then write</p>
<div class="math">
\[{\psi}_i={\varphi}_{\nu(i)},\quad i=0,\ldots,N{\thinspace .}\]</div>
<p>With a regular numbering as in the present example,
<span class="math">\(\nu(j) = j+1\)</span>, <span class="math">\(j=1,\ldots,N=N_n-2\)</span>.</p>
</div>
<div class="section" id="computation-in-the-global-physical-domain">
<span id="fem-deq-1d-comp-global"></span><h2>Computation in the global physical domain<a class="headerlink" href="#computation-in-the-global-physical-domain" title="Permalink to this headline">¶</a></h2>
<p>We shall first perform a computation in the <span class="math">\(x\)</span>
coordinate system because the integrals can be easily computed
here by simple, visual,
geometric considerations. This is called a global approach
since we work in the <span class="math">\(x\)</span> coordinate system and compute integrals on
the global domain <span class="math">\([0,L]\)</span>.</p>
<p>The entries in the coefficient matrix and right-hand side are</p>
<div class="math">
\[A_{i,j}=\int_0^L{\psi}_i'(x){\psi}_j'(x) {\, \mathrm{d}x},\quad
b_i=\int_0^L2{\psi}_i(x) {\, \mathrm{d}x}, \quad i,j\in{I}{\thinspace .}\]</div>
<p>Expressed in terms of finite element basis functions <span class="math">\({\varphi}_i\)</span> we
get the alternative expressions</p>
<div class="math">
\[A_{i,j}=\int_0^L{\varphi}_{i+1}'(x){\varphi}_{j+1}'(x) {\, \mathrm{d}x},\quad
b_i=\int_0^L2{\varphi}_{i+1}(x) {\, \mathrm{d}x},\quad i,j\in{I}{\thinspace .}\]</div>
<p>For the following calculations the subscripts on the finite
element basis functions are more conveniently written as
<span class="math">\(i\)</span> and <span class="math">\(j\)</span> instead of <span class="math">\(i+1\)</span> and <span class="math">\(j+1\)</span>, so our notation becomes</p>
<div class="math">
\[A_{i-1,j-1}=\int_0^L{\varphi}_{i}'(x){\varphi}_{j}'(x) {\, \mathrm{d}x},\quad
b_{i-1}=\int_0^L2{\varphi}_{i}(x) {\, \mathrm{d}x},\]</div>
<p>where the <span class="math">\(i\)</span> and <span class="math">\(j\)</span> indices run as <span class="math">\(i,j=1,\ldots,N_n-1=N+1\)</span>.</p>
<p>The <span class="math">\({\varphi}_i(x)\)</span> function is a hat function with peak at <span class="math">\(x=x_{i}\)</span>
and a linear variation in <span class="math">\([x_{i-1},x_{i}]\)</span> and
<span class="math">\([x_{i},x_{i+1}]\)</span>.
The derivative is <span class="math">\(1/h\)</span> to the left of <span class="math">\(x_{i}\)</span> and <span class="math">\(-1/h\)</span> to
the right, or more formally,</p>
<div class="math" id="equation-fem:approx:fe:Dphi:1:formula2">
<span class="eqno">(72)</span>\[\begin{split}     {\varphi}_i'(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     h^{-1},
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     -h^{-1},
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}
     \end{array}
     \right.\end{split}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-dp1"><em>Illustration of the derivative of piecewise linear basis functions associated with nodes in cell 2</em></a> shows <span class="math">\({\varphi}_1'(x)\)</span> and <span class="math">\({\varphi}_2'(x)\)</span>.</p>
<div class="figure" id="fem-approx-fe-fig-dp1">
<img alt="_images/fe_mesh1D_dphi_2_31.png" src="_images/fe_mesh1D_dphi_2_31.png" style="width: 400px;" />
<p class="caption"><em>Illustration of the derivative of piecewise linear basis functions associated with nodes in cell 2</em></p>
</div>
<p>We realize that <span class="math">\({\varphi}_i'\)</span> and <span class="math">\({\varphi}_j'\)</span> has no overlap, and hence their
product vanishes, unless <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes belonging to the same
cell. The only nonzero contributions to the coefficient matrix are
therefore</p>
<div class="math">
\[\begin{split}A_{i-1,i-2} &amp;=\int_0^L{\varphi}_i'(x) {\varphi}_{i-1}'(x) {\, \mathrm{d}x},\\
A_{i-1,i-1}&amp;=\int_0^L{\varphi}_{i}'(x)^2 {\, \mathrm{d}x}, \\
A_{i-1,i}&amp;=\int_0^L{\varphi}_{i}'(x){\varphi}_{i+1}'(x) {\, \mathrm{d}x},\end{split}\]</div>
<p>for <span class="math">\(i=1,\ldots,N_n-1\)</span>, but for <span class="math">\(i=1\)</span>, <span class="math">\(A_{i-1,i-2}\)</span> is not defined,
and for <span class="math">\(i=N_n-1\)</span>, <span class="math">\(A_{i-1,i}\)</span> is not defined.</p>
<p>We see that <span class="math">\({\varphi}_{i-1}'(x)\)</span> and <span class="math">\({\varphi}_i'(x)\)</span> have overlap of one
cell <span class="math">\(\Omega^{(i-1)}=[x_{i-1},x_{i}]\)</span> and that their product
then is <span class="math">\(-1/h^{2}\)</span>. The integrand is constant and therefore
<span class="math">\(A_{i-1,i-2}=-h^{-2}h=-h^{-1}\)</span>.
A similar reasoning can be applied to
<span class="math">\(A_{i-1,i}\)</span>, which also becomes <span class="math">\(-h^{-1}\)</span>. The integral of
<span class="math">\({\varphi}_i'(x)^2\)</span> gets contributions from two cells,
<span class="math">\(\Omega^{(i-1)}=[x_{i-1},x_{i}]\)</span> and
<span class="math">\(\Omega^{(i)}=[x_{i},x_{i+1}]\)</span>, but <span class="math">\({\varphi}_i'(x)^2=h^{-2}\)</span> in
both cells, and the length of the integration interval is <span class="math">\(2h\)</span> so
we get
<span class="math">\(A_{i-1,i-1}=2h^{-1}\)</span>.</p>
<p>The right-hand side involves an integral of <span class="math">\(2{\varphi}_i(x)\)</span>,
<span class="math">\(i=1,\ldots,N_n-1\)</span>,
which is just the area under a hat function of height 1 and width
<span class="math">\(2h\)</span>, i.e., equal to <span class="math">\(h\)</span>. Hence, <span class="math">\(b_{i-1}=2h\)</span>.</p>
<p>To summarize the linear system, we switch from <span class="math">\(i\)</span> to <span class="math">\(i+1\)</span> such that
we can write</p>
<div class="math">
\[A_{i,i-1}=A_{i,i-1}=-h^{-1},\quad A_{i,i}=2h^{-1},\quad
b_i = 2h{\thinspace .}\]</div>
<p>The equation system to be solved only involves the unknowns
<span class="math">\(c_i\)</span> for <span class="math">\(i\in{I}\)</span>. With our numbering of unknowns and
nodes, we have that <span class="math">\(c_i\)</span> equals <span class="math">\(u(x_{i+1})\)</span>.
The complete matrix system that takes the following form:</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob">
<span class="eqno">(73)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     2 &amp; -1 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; -1 &amp; 2
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     2h \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     2h
     \end{array}
     \right)\end{split}\]</div>
</div>
<div class="section" id="comparison-with-a-finite-difference-discretization">
<h2>Comparison with a finite difference discretization<a class="headerlink" href="#comparison-with-a-finite-difference-discretization" title="Permalink to this headline">¶</a></h2>
<p>A typical row in the matrix system can be written as</p>
<div class="math" id="equation-fem:deq:1D:fem:ex1:c">
<span class="eqno">(74)</span>\[     -\frac{1}{h}c_{i-1} + \frac{2}{h}c_{i} - \frac{1}{h}c_{i+1} = 2h{\thinspace .}\]</div>
<p>Let us introduce the notation <span class="math">\(u_j\)</span> for the value of <span class="math">\(u\)</span> at node <span class="math">\(j\)</span>:
<span class="math">\(u_j=u(x_{j})\)</span>. The unknowns <span class="math">\(c_0,\ldots,c_N\)</span> are <span class="math">\(u_1,\ldots,u_{N_n}\)</span>.
Shifting <span class="math">\(i\)</span> with <span class="math">\(i+1\)</span> in <a href="#equation-fem:deq:1D:fem:ex1:c">(74)</a> and inserting
<span class="math">\(u_i = c_{i-1}\)</span>, we get</p>
<div class="math" id="equation-fem:deq:1D:fem:ex1">
<span class="eqno">(75)</span>\[     -\frac{1}{h}u_{i-1} + \frac{2}{h}u_{i} - \frac{1}{h}u_{i+1} = 2h,\]</div>
<p>A finite difference discretization of <span class="math">\(-u''(x)=2\)</span> by a centered,
second-order finite difference approximation <span class="math">\(u''(x_i)\approx [D_x D_x u]_i\)</span>
with <span class="math">\(\Delta x = h\)</span>
yields</p>
<div class="math">
\[-\frac{u_{i-1} - 2u_{i} + u_{i+1}}{h^2} = 2,\]</div>
<p>which is, in fact, equivalent to <a href="#equation-fem:deq:1D:fem:ex1">(75)</a> if
<a href="#equation-fem:deq:1D:fem:ex1">(75)</a> is divided by <span class="math">\(h\)</span>.
Therefore, the finite difference and the finite element method are
equivalent in this simple test problem.</p>
<p>Sometimes a finite element method generates the finite difference
equations on a uniform mesh, and sometimes the finite element method
generates equations that are different.  The differences are modest,
but may influence the numerical quality of the solution significantly,
especially in time-dependent problems.</p>
</div>
<div class="section" id="cellwise-computations-1">
<span id="fem-deq-1d-comp-elmwise"></span><h2>Cellwise computations  (1)<a class="headerlink" href="#cellwise-computations-1" title="Permalink to this headline">¶</a></h2>
<p>We now employ the cell by cell computational procedure where
an element matrix and vector are calculated for each cell and
assembled in the global linear system.</p>
<p>All integrals are mapped to the local reference coordinate system
<span class="math">\(X\in [-1,1]\)</span>.</p>
<p>In the present case, the matrix entries contain derivatives
with respect to <span class="math">\(x\)</span>,</p>
<div class="math">
\[A_{i-1,j-1}^{(e)}=\int_{\Omega^{(e)}} {\varphi}_i'(x){\varphi}_j'(x) {\, \mathrm{d}x}
= \int_{-1}^1 \frac{d}{dx}{\tilde{\varphi}}_r(X)\frac{d}{dx}{\tilde{\varphi}}_s(X)
\frac{h}{2} {\, \mathrm{d}X},\]</div>
<p>where the global degree of freedom <span class="math">\(i\)</span> is related to the local
degree of freedom <span class="math">\(r\)</span> through <span class="math">\(i=q(e,r)\)</span>. Similarly,
<span class="math">\(j=q(e,s)\)</span>. The local degrees of freedom run as <span class="math">\(r,s=0,1\)</span> for a P1
element.</p>
<div class="section" id="the-integral-for-the-element-matrix">
<h3>The integral for the element matrix<a class="headerlink" href="#the-integral-for-the-element-matrix" title="Permalink to this headline">¶</a></h3>
<p>There are simple formulas for the basis functions <span class="math">\({\tilde{\varphi}}_r(X)\)</span> as
functions of <span class="math">\(X\)</span>.
However, we now
need to find the derivative of <span class="math">\({\tilde{\varphi}}_r(X)\)</span> with respect to <span class="math">\(x\)</span>.
Given</p>
<div class="math">
\[{\tilde{\varphi}}_0(X)=\frac{1}{2}(1-X),\quad{\tilde{\varphi}}_1(X)=\frac{1}{2}(1+X),\]</div>
<p>we can easily compute <span class="math">\(d{\tilde{\varphi}}_r/ dX\)</span>:</p>
<div class="math">
\[\frac{d{\tilde{\varphi}}_0}{dX} = -\frac{1}{2},\quad  \frac{d{\tilde{\varphi}}_1}{dX} = \frac{1}{2}{\thinspace .}\]</div>
<p>From the chain rule,</p>
<div class="math">
\[\frac{d{\tilde{\varphi}}_r}{dx} = \frac{d{\tilde{\varphi}}_r}{dX}\frac{dX}{dx}
= \frac{2}{h}\frac{d{\tilde{\varphi}}_r}{dX}{\thinspace .}\]</div>
<p>The transformed integral is then</p>
<div class="math">
\[A_{i-1,j-1}^{(e)}=\int_{\Omega^{(e)}} {\varphi}_i'(x){\varphi}_j'(x) {\, \mathrm{d}x}
= \int_{-1}^1 \frac{2}{h}\frac{d{\tilde{\varphi}}_r}{dX}\frac{2}{h}\frac{d{\tilde{\varphi}}_s}{dX}
\frac{h}{2} {\, \mathrm{d}X}
{\thinspace .}\]</div>
</div>
<div class="section" id="the-integral-for-the-element-vector">
<h3>The integral for the element vector<a class="headerlink" href="#the-integral-for-the-element-vector" title="Permalink to this headline">¶</a></h3>
<p>The right-hand side is transformed according to</p>
<div class="math">
\[b_{i-1}^{(e)} = \int_{\Omega^{(e)}} 2{\varphi}_i(x) {\, \mathrm{d}x} =
\int_{-1}^12{\tilde{\varphi}}_r(X)\frac{h}{2} {\, \mathrm{d}X},\quad i=q(e,r),\ r=0,1
{\thinspace .}\]</div>
</div>
<div class="section" id="detailed-calculations-of-the-element-matrix-and-vector">
<h3>Detailed calculations of the element matrix and vector<a class="headerlink" href="#detailed-calculations-of-the-element-matrix-and-vector" title="Permalink to this headline">¶</a></h3>
<p>Specifically for P1 elements we arrive at the following calculations for
the element matrix entries:</p>
<div class="math">
\[\begin{split}\tilde A_{0,0}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(-\frac{1}{2}\right)
\frac{2}{h}\left(-\frac{1}{2}\right)\frac{2}{h} {\, \mathrm{d}X} = \frac{1}{h}\\
\tilde A_{0,1}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(-\frac{1}{2}\right)
\frac{2}{h}\left(\frac{1}{2}\right)\frac{2}{h} {\, \mathrm{d}X} = -\frac{1}{h}\\
\tilde A_{1,0}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(\frac{1}{2}\right)
\frac{2}{h}\left(-\frac{1}{2}\right)\frac{2}{h} {\, \mathrm{d}X} = -\frac{1}{h}\\
\tilde A_{1,1}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(\frac{1}{2}\right)
\frac{2}{h}\left(\frac{1}{2}\right)\frac{2}{h} {\, \mathrm{d}X} = \frac{1}{h}\end{split}\]</div>
<p>The element vector entries become</p>
<div class="math">
\[\begin{split}\tilde b_0^{(e)} &amp;= \int_{-1}^12\frac{1}{2}(1-X)\frac{h}{2} {\, \mathrm{d}X} = h\\
\tilde b_1^{(e)} &amp;= \int_{-1}^12\frac{1}{2}(1+X)\frac{h}{2} {\, \mathrm{d}X} = h{\thinspace .}\end{split}\]</div>
<p>Expressing these entries in matrix and vector notation, we have</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm">
<span class="eqno">(76)</span>\[\begin{split}     \tilde A^{(e)} =\frac{1}{h}\left(\begin{array}{rr}
     1 &amp; -1\\
     -1 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(e)} = h\left(\begin{array}{c}
     1\\
     1
     \end{array}\right){\thinspace .}\end{split}\]</div>
</div>
<div class="section" id="contributions-from-the-first-and-last-cell">
<h3>Contributions from the first and last cell<a class="headerlink" href="#contributions-from-the-first-and-last-cell" title="Permalink to this headline">¶</a></h3>
<p>The first and last cell involve only one unknown and one basis function
because of the Dirichlet boundary conditions at the first and last
node.
The element matrix therefore becomes a <span class="math">\(1\times 1\)</span> matrix and there
is only one entry in the element vector. On cell 0, only <span class="math">\({\psi}_0={\varphi}_1\)</span>
is involved, corresponding to integration with <span class="math">\({\tilde{\varphi}}_1\)</span>. On cell <span class="math">\(N_e\)</span>,
only <span class="math">\({\psi}_N={\varphi}_{N_n-1}\)</span> is involved, corresponding to
integration with <span class="math">\({\tilde{\varphi}}_0\)</span>.
We then get the special end-cell contributions</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:ends">
<span class="eqno">(77)</span>\[     \tilde A^{(e)} =\frac{1}{h}\left(\begin{array}{r}
     1
     \end{array}\right),\quad
     \tilde b^{(e)} = h\left(\begin{array}{c}
     1
     \end{array}\right),\]</div>
<p>for <span class="math">\(e=0\)</span> and <span class="math">\(e=N_e\)</span>. In these cells, we have only one degree of
freedom, not two as in the interior cells.</p>
</div>
<div class="section" id="assembly">
<h3>Assembly<a class="headerlink" href="#assembly" title="Permalink to this headline">¶</a></h3>
<p>The next step is to assemble the contributions from the various cells.
The assembly of an element matrix and vector into the global matrix
and right-hand side can be expressed as</p>
<div class="math">
\[A_{q(e,r),q(e,s)} = A_{q(e,r),q(e,s)} + \tilde A^{(e)}_{r,s},\quad
b_{q(e,r)} = b_{q(e,r)} + \tilde b^{(e)}_{r},\quad\]</div>
<p>for <span class="math">\(r\)</span> and <span class="math">\(s\)</span> running over all local degrees of freedom in cell <span class="math">\(e\)</span>.</p>
<p>To make the assembly algorithm more precise, it is convenient to set up
Python data structures and a code snippet for carrying out all details
of the algorithm.
For a mesh of four equal-sized P1 elements and <span class="math">\(L=2\)</span> we have</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">cells</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>The total number of degrees of freedom is 3, being the function
values at the internal 3 nodes where <span class="math">\(u\)</span> is unknown.
In cell 0 we have global degree of freedom 0, the next
cell has <span class="math">\(u\)</span> unknown at its two nodes, which become
global degrees of freedom 0 and 1, and so forth according to
the <tt class="docutils literal"><span class="pre">dof_map</span></tt> list. The mathematical <span class="math">\(q(e,r)\)</span> quantity is nothing
but the <tt class="docutils literal"><span class="pre">dof_map</span></tt> list.</p>
<p>Assume all element matrices are stored in a list <tt class="docutils literal"><span class="pre">Ae</span></tt> such that
<tt class="docutils literal"><span class="pre">Ae[e][i,j]</span></tt> is <span class="math">\(\tilde A_{i,j}^{(e)}\)</span>. A corresponding list
for the element vectors is named <tt class="docutils literal"><span class="pre">be</span></tt>, where <tt class="docutils literal"><span class="pre">be[e][r]</span></tt> is
<span class="math">\(\tilde b_r^{(e)}\)</span>.
A Python code snippet
illustrates all details of the assembly algorithm:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># A[i,j]: coefficient matrix, b[i]: right-hand side</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ae</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ae</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ae</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">,</span><span class="n">r</span><span class="p">],</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">,</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">Ae</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
        <span class="n">b</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">,</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">be</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
</pre></div>
</div>
<p>The general case with <tt class="docutils literal"><span class="pre">N_e</span></tt> P1 elements of length <tt class="docutils literal"><span class="pre">h</span></tt> has</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">N_n</span> <span class="o">=</span> <span class="n">N_e</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_n</span><span class="p">)]</span>
<span class="n">cells</span> <span class="o">=</span> <span class="p">[[</span><span class="n">e</span><span class="p">,</span> <span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_e</span><span class="p">)]</span>
<span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[[</span><span class="n">e</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">e</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[[</span><span class="n">N_n</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>Carrying out the assembly results in a linear system that is identical
to <a href="#equation-fem:deq:1D:ex1:Ab:glob">(73)</a>, which is not surprising since
the procedures is mathematically equivalent to the calculations
in the physical domain.</p>
<p>A fundamental problem with the matrix system we have assembled is that
the boundary conditions are not incorporated if <span class="math">\(u(0)\)</span> or <span class="math">\(u(L)\)</span>
are different from zero. The next sections deals with this issue.</p>
</div>
</div>
</div>
<div class="section" id="boundary-conditions-specified-nonzero-value">
<span id="fem-deq-1d-essbc"></span><h1>Boundary conditions: specified nonzero value<a class="headerlink" href="#boundary-conditions-specified-nonzero-value" title="Permalink to this headline">¶</a></h1>
<p>We have to take special actions to incorporate Dirichlet conditions,
such as <span class="math">\(u(L)=D\)</span>, into the computational procedures. The present
section outlines alternative, yet mathematically equivalent, methods.</p>
<div class="section" id="general-construction-of-a-boundary-function">
<span id="fem-deq-1d-fem-essbc-bfunc"></span><h2>General construction of a boundary function<a class="headerlink" href="#general-construction-of-a-boundary-function" title="Permalink to this headline">¶</a></h2>
<p>In the section <a class="reference internal" href="#fem-deq-1d-essbc-bfunc"><em>Boundary function</em></a> we introduce a boundary function <span class="math">\(B(x)\)</span>
to deal with nonzero Dirichlet boundary conditions for <span class="math">\(u\)</span>. The
construction of such a function is not always trivial, especially not
in multiple dimensions. However, a simple and general construction
idea exists when the
basis functions have the property</p>
<div class="math">
\[\begin{split}{\varphi}_i(x_{j}) = \left\lbrace\begin{array}{ll}
1, &amp; i=j,\\
0, &amp; i\neq j,
\end{array}\right.\end{split}\]</div>
<p>where <span class="math">\(x_{j}\)</span> is a boundary point. Examples on such
functions are the Lagrange interpolating polynomials and finite
element functions.</p>
<p>Suppose now that <span class="math">\(u\)</span> has Dirichlet boundary conditions at nodes
with numbers <span class="math">\(i\in{I_b}\)</span>. For example, <span class="math">\({I_b} = \{0,N_n\}\)</span> in a 1D
mesh with node numbering from left to right.
Let <span class="math">\(U_i\)</span> be the corresponding prescribed values of <span class="math">\(u(x_{i})\)</span>.
We can then, in general, use</p>
<div class="math">
\[B(x) = \sum_{j\in{I_b}} U_j{\varphi}_j(x){\thinspace .}\]</div>
<p>It is easy to verify that
<span class="math">\(B(x_{i})= \sum_{j\in{I_b}} U_j{\varphi}_j(x_{j})=U_i\)</span>.</p>
<p>The unknown function can then be written as</p>
<div class="math">
\[u(x) = \sum_{j\in{I_b}} U_j{\varphi}_j(x) + \sum{j\in{I}}c_j{\varphi}_{\nu(j)},\]</div>
<p>where <span class="math">\(\nu(j)\)</span> maps unknown number <span class="math">\(j\)</span> in the equation system to
node <span class="math">\(\nu(j)\)</span>.</p>
<p>Some examples will clarify the notation. With a regular
left-to-right numbering of nodes in a mesh with P1 elements,
and Dirichlet conditions at <span class="math">\(x=0\)</span>, we
have <span class="math">\(\nu(j)=j+1\)</span>, <span class="math">\(j=0,\ldots,N=N_n-1\)</span>.</p>
<div class="figure">
<img alt="_images/fe_mesh1D1.png" src="_images/fe_mesh1D1.png" style="width: 500px;" />
</div>
<p>Here is an irregular node numbering:</p>
<div class="figure">
<img alt="_images/fe_mesh1D_random_numbering1.png" src="_images/fe_mesh1D_random_numbering1.png" style="width: 500px;" />
</div>
<p>Say, we have Dirichlet conditions on the left-most and right-most
node, with numbers 3 and 1, respectively. Then
we can number the unknowns at the interior nodes from left
to right, giving <span class="math">\(\nu(0)=0\)</span>, <span class="math">\(\nu(1)=4\)</span>, <span class="math">\(\nu(2)=5\)</span>, <span class="math">\(\nu(3)=2\)</span>.
This gives</p>
<div class="math">
\[B(x) = U_3{\varphi}_3(x) + U_1{\varphi}_1(x),\]</div>
<p>and</p>
<div class="math">
\[u(x) = B(x) + \sum_{j=0}^3 c_j{\varphi}_{\nu(j)}
= U_3{\varphi}_3 + U_1{\varphi}_1 + c_0{\varphi}_0 + c_1{\varphi}_4
+ c_2{\varphi}_5 + c_3{\varphi}_2{\thinspace .}\]</div>
<p>Switching to the more standard case of left-to-right numbering and
boundary conditions <span class="math">\(u(0)=C\)</span>, <span class="math">\(u(L)=D\)</span>, we have <span class="math">\(N=N_n-2\)</span> and</p>
<div class="math">
\[\begin{split}u(x) &amp;= C{\varphi}_0 + D{\varphi}_{N_n} + \sum_{j\in{I}} c_j{\varphi}_{j+1}
&amp;= C{\varphi}_0 + D{\varphi}_{N_n} + c_0{\varphi}_1 + c_1{\varphi}_2 +\cdots
+ c_N{\varphi}_{N_n-1}{\thinspace .}\end{split}\]</div>
<p>The idea of constructing <span class="math">\(B\)</span> described here generalizes almost
trivially to 2D and 3D problems: <span class="math">\(B=\sum_{j\in{I_b}}U_j{\varphi}_j\)</span>,
where <span class="math">\({I_b}\)</span> is the index set containing the numbers of all the
nodes on the boundaries where Dirichlet values are prescribed.</p>
<div class="section" id="example-3">
<h3>Example  (3)<a class="headerlink" href="#example-3" title="Permalink to this headline">¶</a></h3>
<p>Let us see how our previous model problem <span class="math">\(-u''=2\)</span>, <span class="math">\(u(0)=0\)</span>, <span class="math">\(u(L)=D\)</span>,
is affected by a <span class="math">\(B(x)\)</span> to incorporate boundary values.
Inserting the expression</p>
<div class="math">
\[u(x) = B(x) + \sum_{j\in{I}}c_j{\psi}_j(x)\]</div>
<p>in <span class="math">\(-(u'',{\psi}_i)=(f,{\psi}_i)\)</span> and
integrating by parts results in a linear system with</p>
<div class="math">
\[A_{i,j} = \int_0^L {\psi}_i'(x){\psi}_j'(x) {\, \mathrm{d}x},\quad
b_i = \int_0^L (f(x) - B'(x)){\psi}_i(x) {\, \mathrm{d}x}{\thinspace .}\]</div>
<p>We choose <span class="math">\({\psi}_i={\varphi}_{i+1}\)</span> if the node numbering is from left
to right. Later we also need the assumption that the cells too
are numbered from left to right.
The boundary function becomes</p>
<div class="math">
\[B(x) = 0\cdot{\varphi}_0(x) + D{\varphi}_{N_n}(x) = D{\varphi}_{N_n}(x){\thinspace .}\]</div>
<p>The expansion for <span class="math">\(u(x)\)</span> is</p>
<div class="math">
\[u(x)  = B(x) + \sum_{j\in{I}} c_j{\varphi}_{j+1}(x){\thinspace .}\]</div>
<p>The limit <span class="math">\(N\)</span> of the index set <span class="math">\({I}\)</span> equals <span class="math">\(N_n-2\)</span>.</p>
<p>We can write the matrix and right-hand side entries as</p>
<div class="math">
\[A_{i-1,j-1} = \int_0^L {\varphi}_i'(x){\varphi}_j'(x) {\, \mathrm{d}x},\quad
b_{i-1} = \int_0^L (f(x) - D{\varphi}_{N_n}'(x)){\varphi}_i(x) {\, \mathrm{d}x},\]</div>
<p>for <span class="math">\(i,j = 1,\ldots,N+1=N_n-1\)</span>. Note that we have here used
<span class="math">\(B'=D{\varphi}_{N_n}'\)</span>.</p>
<p>Most of the terms in the linear system have already been computed
so we concentrate on the new contribution from the boundary function.
The integral <span class="math">\(D\int_0^L {\varphi}_{N_n}'(x)){\varphi}_i(x) {\, \mathrm{d}x}\)</span> can only get
a nonzero contribution from the last cell,
<span class="math">\(\Omega^{(N_e)}=[x_{N_n-1},x_{N_n}]\)</span>
since <span class="math">\({\varphi}_{N_n}(x)=0\)</span> on all other cells. Moreover,
<span class="math">\({\varphi}_{N_n}'(x){\varphi}_i(x) {\, \mathrm{d}x} \neq 0\)</span> only for <span class="math">\(i=N_n-1\)</span> and <span class="math">\(i=N_n\)</span>,
since <span class="math">\({\varphi}_{N_n}'\neq 0\)</span> only on the last cell.
From the explanations of the
calculations in the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> we find that</p>
<div class="math">
\[\int_0^L {\varphi}_{N_n}'(x){\varphi}_{N_n-1}(x) {\, \mathrm{d}x} =
\frac{1}{h}\cdot\frac{1}{h} = \frac{1}{2},\]</div>
<p>The extra boundary term because of <span class="math">\(B(x)\)</span> boils down to adding
<span class="math">\(-D/2\)</span> to <span class="math">\(b_{N}=b_{N_n-1}\)</span>.</p>
<p>As an equivalent alternative, we now turn to <em>cellwise computations</em>.
The element matrices and vectors are calculated as the section <a class="reference internal" href="#fem-deq-1d-comp-elmwise"><em>Cellwise computations  (1)</em></a>, so now we concentrate on the impact of
the new term involving <span class="math">\(B(x)\)</span>.
We observe that <span class="math">\(B(x)=D{\varphi}_{N_n}'=0\)</span> on all cells except the last
one. Here there is only one unknown since <span class="math">\(u(L)\)</span> is prescribed, so
the element vector has only one entry. The entry becomes</p>
<div class="math">
\[\tilde b_0^{(e)} = \int_{-1}^1 \left(f - D\frac{2}{h}\frac{{\tilde{\varphi}}_1}{dX}\right)
{\tilde{\varphi}}_0\frac{h}{2} {\, \mathrm{d}X}
= (\frac{h}{2}(2 - D\frac{2}{h}\frac{1}{2})
\int_{-1}^1 {\tilde{\varphi}}_0 {\, \mathrm{d}X} =  h - D/2,\]</div>
<p>for <span class="math">\(e=N_e=N_n-1\)</span>.
When assembling these contributions, we see that <span class="math">\(b_{N}\)</span> in the
right-hand side of the linear system gets an
extra term <span class="math">\(-D/2\)</span>, as in the computations in the physical domain.</p>
</div>
</div>
<div class="section" id="modification-of-the-linear-system">
<span id="fem-deq-1d-fem-essbc-bfunc-modsys"></span><h2>Modification of the linear system<a class="headerlink" href="#modification-of-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>From an implementational point of view, there is a convenient alternative
to adding the <span class="math">\(B(x)\)</span> function and using only the basis functions associated
with nodes where <span class="math">\(u\)</span> is truly unknown.
Instead of seeking</p>
<div class="math" id="equation-fem:deq:1D:fem:essBC:Bfunc:modsys:utrad">
<span class="eqno">(78)</span>\[     u(x) = \sum_{j\in{I_b}} U_j{\varphi}_j(x)
     + \sum_{j\in{I}}c_j{\varphi}_{\nu(j)}(x),\]</div>
<p>we use the sum over all degrees of freedom, including the known boundary
values:</p>
<div class="math" id="equation-fem:deq:1D:fem:essBC:Bfunc:modsys:uall">
<span class="eqno">(79)</span>\[     u(x) = \sum_{j\in{I}}c_j{\varphi}_j(x){\thinspace .}\]</div>
<p>Note that the collections of unknowns
<span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> in <a href="#equation-fem:deq:1D:fem:essBC:Bfunc:modsys:utrad">(78)</a>
and <a href="#equation-fem:deq:1D:fem:essBC:Bfunc:modsys:uall">(79)</a> are different:
in <a href="#equation-fem:deq:1D:fem:essBC:Bfunc:modsys:utrad">(78)</a> <span class="math">\(N\)</span> counts the
number of nodes where <span class="math">\(u\)</span> is not known, while
in <a href="#equation-fem:deq:1D:fem:essBC:Bfunc:modsys:utrad">(78)</a> <span class="math">\(N=N_n\)</span>.
The number of unknowns in <a href="#equation-fem:deq:1D:fem:essBC:Bfunc:modsys:utrad">(78)</a>
also follows the node numbering (but this is not necessary).</p>
<p>The idea is to compute the entries in the linear system as if no
Dirichlet values are prescribed. Afterwards, we modify the linear system
to ensure that the known <span class="math">\(c_j\)</span> values are incorporated.</p>
<div class="section" id="computations-in-the-physical-system">
<h3>Computations in the physical system<a class="headerlink" href="#computations-in-the-physical-system" title="Permalink to this headline">¶</a></h3>
<p>Let us redo the computations in the example in
the section <a class="reference internal" href="#fem-deq-1d-fem-essbc-bfunc"><em>General construction of a boundary function</em></a>. We solve <span class="math">\(-u''=2\)</span> with
<span class="math">\(u(0)=0\)</span> and <span class="math">\(u(L)=D\)</span>. The expressions for <span class="math">\(A_{i,j}\)</span> and <span class="math">\(b_i\)</span>
are the same, but the numbering is different as the numbering of
unknowns and nodes now coincide:</p>
<div class="math">
\[A_{i,j} = \int_0^L {\varphi}_i'(x){\varphi}_j'(x) {\, \mathrm{d}x},\quad
b_{i} = \int_0^L (f(x) - D{\varphi}_{N_n}'(x)){\varphi}_i(x) {\, \mathrm{d}x},\]</div>
<p>for <span class="math">\(i,j = 0,\ldots,N=N_n\)</span>.
The integrals involving basis functions
corresponding to interior mesh nodes, <span class="math">\(i,j=1,\ldots,N_n-1\)</span>, are
obviously the same as before. We concentrate on the contributions
from <span class="math">\({\varphi}_0\)</span> and <span class="math">\({\varphi}_{N_n}\)</span>:</p>
<div class="math">
\[\begin{split}A_{0,0} &amp;= \int_0^L ({\varphi}_0')^2{\, \mathrm{d}x} = \int_{0}^{x_{1}}
= ({\varphi}_0')^2{\, \mathrm{d}x} \frac{1}{h},
A_{0,1} &amp;= \int_0^L {\varphi}_0'{\varphi}_1'{\, \mathrm{d}x}
= \int_{0}^{x_{1}} {\varphi}_0'{\varphi}_1'{\, \mathrm{d}x} = -\frac{1}{h},
A_{N,N} &amp;= \int_0^L ({\varphi}_0')^2{\, \mathrm{d}x}
= \int_{x_{N_n-1}}^{x_{N_n}} ({\varphi}_0')^2{\, \mathrm{d}x} = \frac{1}{h},
A_{N,N-1} &amp;= \int_0^L ({\varphi}_0')^2{\, \mathrm{d}x}
=\int_{x_{N_n-1}}^{x_{N_n}} ({\varphi}_0')^2{\, \mathrm{d}x} = -\frac{1}{h}{\thinspace .}\end{split}\]</div>
<p>The new terms on the right-hand side are also those involving
<span class="math">\({\varphi}_0\)</span> and <span class="math">\({\varphi}_{N_n}\)</span>:</p>
<div class="math">
\[\begin{split}b_0 &amp;= \int_0^L 2{\varphi}_0(x) {\, \mathrm{d}x} = \int_0^{x_{1}} 2{\varphi}_0(x){\, \mathrm{d}x} = h,
b_N &amp;=  \int_0^L 2{\varphi}_{N_n}{\, \mathrm{d}x} =
\int_{x_{N_n-1}}^{x_{N_n}} 2{\varphi}_{N_n}{\, \mathrm{d}x} = h{\thinspace .}
\int_0^L 2{\varphi}_0(x) {\, \mathrm{d}x} = h,\\\end{split}\]</div>
<p>The complete matrix system, involving all degrees of freedom, takes the form</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob2">
<span class="eqno">(80)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; -1 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; -1 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     h \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h\\
     h
     \end{array}
     \right)\end{split}\]</div>
<p>Incorporation of Dirichlet values can now be done by replacing
the first and last equation by
<span class="math">\(c_0=0\)</span> and <span class="math">\(c_N=D\)</span>. This action changes the system to</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob3">
<span class="eqno">(81)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; 0 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 0 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     0 \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h\\
     D
     \end{array}
     \right)\end{split}\]</div>
</div>
</div>
<div class="section" id="symmetric-modification-of-the-linear-system">
<span id="fem-deq-1d-fem-essbc-bfunc-modsys-symm"></span><h2>Symmetric modification of the linear system<a class="headerlink" href="#symmetric-modification-of-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>The original matrix system <a href="#equation-fem:deq:1D:ex1:Ab:glob">(73)</a> is symmetric,
but the modifications in <a href="#equation-fem:deq:1D:ex1:Ab:glob3">(81)</a> destroy
the symmetry. Our described modification will in general destroy an
initial symmetry in the matrix system. This is not a particular
computational disadvantage for tridiagonal systems arising in 1D
problems, but may be more serious in 2D and 3D when the systems are
large and exploiting symmetry can be very important for the solution method.
Therefore, a modification that preserves symmetry is frequently applied.</p>
<p>Let <span class="math">\(c_k\)</span> be a coefficient corresponding to a known value <span class="math">\(U_k\)</span>.
We want to replace equation <span class="math">\(k\)</span> in the system by <span class="math">\(c_k=U_k\)</span>, i.e.,
insert zeroes in row number <span class="math">\(k\)</span> in the coefficient matrix,
set 1 on the diagonal, and replace <span class="math">\(b_k\)</span> by <span class="math">\(U_k\)</span>.
A symmetry-preserving modification consists in first
subtracting column number <span class="math">\(k\)</span> in the coefficient matrix, i.e., <span class="math">\(A_{i,k}\)</span>
for <span class="math">\(i\in{I}\)</span>, times the boundary value <span class="math">\(U_k\)</span>, from the
right-hand side: <span class="math">\(b_i \leftarrow b_i - A_{i,k}U_k\)</span>. Then we put
zeroes in row number <span class="math">\(k\)</span> <em>and</em> column number <span class="math">\(k\)</span> in the coefficient matrix,
and finally set <span class="math">\(b_k=U_k\)</span>. The steps in algorithmic form becomes</p>
<blockquote>
<div><ol class="arabic simple">
<li><span class="math">\(b_i \leftarrow b_i - A_{i,k}U_k\)</span> for <span class="math">\(i\in{I}\)</span></li>
<li><span class="math">\(A_{i,k} = A_{k,i} = 0\)</span> for <span class="math">\(i\in{I}\)</span></li>
<li><span class="math">\(A_{k,k}=1\)</span></li>
<li><span class="math">\(b_i = U_k\)</span></li>
</ol>
</div></blockquote>
<p>This modification goes as follows for the specific linear system
written out in <a href="#equation-fem:deq:1D:ex1:Ab:glob2">(80)</a> in
the section <a class="reference internal" href="#fem-deq-1d-fem-essbc-bfunc-modsys"><em>Modification of the linear system</em></a>. First we
subtract the first column in the coefficient matrix, times the boundary
value, from the right-hand side. Because <span class="math">\(c_0=0\)</span>, this subtraction
has no effect. Then we subtract the last column, times the boundary value <span class="math">\(D\)</span>,
from the right-hand side. This action results in <span class="math">\(b_{N-1}=2h+D/h\)</span> and
<span class="math">\(b_N=h-2D/h\)</span>. Thereafter, we place zeros in the first and last row and
column in the coefficient matrix and 1 on the two corresponding diagonal
entries. Finally, we set <span class="math">\(b_0=0\)</span> and <span class="math">\(b_N=D\)</span>. The result becomes</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob3:symm">
<span class="eqno">(82)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; 0 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     0 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; 0 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 0 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     0 \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h +D/h\\
     D
     \end{array}
     \right)\end{split}\]</div>
</div>
<div class="section" id="modification-of-the-element-matrix-and-vector">
<h2>Modification of the element matrix and vector<a class="headerlink" href="#modification-of-the-element-matrix-and-vector" title="Permalink to this headline">¶</a></h2>
<p>The modifications of the global linear system can alternatively
be done for the element matrix and vector. (The assembled
system will get the value <span class="math">\(n\)</span> on the main diagonal if <span class="math">\(n\)</span> elements contribute
to the same unknown, but the factor <span class="math">\(n\)</span> will also appear on the
right-hand side and hence cancel out.)</p>
<p>We have, in the present computational example, the element matrix and vector
<a href="#equation-fem:deq:1D:ex1:Ab:elm">(76)</a>. The modifications are needed in
cells where one of the degrees of freedom is known. Here, this means
the first and last cell. In the first cell, local degree of freedom number 0
is known and the modification becomes</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:0">
<span class="eqno">(83)</span>\[\begin{split}     \tilde A^{(0)} =
     A = \frac{1}{h}\left(\begin{array}{rr}
     1 &amp; 0\\
     -1 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(0)} = \left(\begin{array}{c}
     0\\
     h
     \end{array}\right){\thinspace .}\end{split}\]</div>
<p>In the last cell we set</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:N">
<span class="eqno">(84)</span>\[\begin{split}     \tilde A^{(N_e)} =
     A = \frac{1}{h}\left(\begin{array}{rr}
     1 &amp; -1\\
     0 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(N_e)} = \left(\begin{array}{c}
     h\\
     D
     \end{array}\right){\thinspace .}\end{split}\]</div>
<p>We can also perform the symmetric modification. This operation affects
only the last cell with a nonzero Dirichlet condition. The algorithm
is the same as for the global linear system, resulting in</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:N:symm">
<span class="eqno">(85)</span>\[\begin{split}     \tilde A^{(N-1)} =
     A = \frac{1}{h}\left(\begin{array}{rr}
     1 &amp; 0\\
     0 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(N-1)} = \left(\begin{array}{c}
     h + D/h\\
     D
     \end{array}\right){\thinspace .}\end{split}\]</div>
<p>The reader is encouraged to assemble the element matrices and vectors and
check that the result coincides with the system
<a href="#equation-fem:deq:1D:ex1:Ab:glob3:symm">(82)</a>.</p>
</div>
</div>
<div class="section" id="boundary-conditions-specified-derivative">
<span id="fem-deq-1d-bc-nat"></span><h1>Boundary conditions: specified derivative<a class="headerlink" href="#boundary-conditions-specified-derivative" title="Permalink to this headline">¶</a></h1>
<p>Suppose our model problem <span class="math">\(-u''(x)=f(x)\)</span> features
the boundary conditions <span class="math">\(u'(0)=C\)</span> and <span class="math">\(u(L)=D\)</span>.
As already indicated in the section <a class="reference internal" href="#fem-deq-1d-varform-ex"><em>Examples on variational formulations</em></a>,
the former condition can be incorporated through the boundary term
that arises from integration by parts. This details of this method will now be
illustrated in the context of finite element basis functions.</p>
<div class="section" id="the-variational-formulation">
<h2>The variational formulation<a class="headerlink" href="#the-variational-formulation" title="Permalink to this headline">¶</a></h2>
<p>Starting with the Galerkin method,</p>
<div class="math">
\[\int_0^L(u''(x)+f(x)){\psi}_i(x) {\, \mathrm{d}x} = 0,\quad i\in{I},\]</div>
<p>integrating <span class="math">\(u''{\psi}_i\)</span> by parts results in</p>
<div class="math">
\[\int_0^Lu'(x)'{\psi}_i'(x) {\, \mathrm{d}x} -(u'(L){\psi}_i(L) - u'(0){\psi}_i(0)) =
\int_0^L f(x){\psi}_i(x) {\, \mathrm{d}x}, \quad i\in{I}{\thinspace .}\]</div>
<p>The first boundary term, <span class="math">\(u'(L){\psi}_i(L)\)</span>,
vanishes because <span class="math">\(u(L)=D\)</span>. There are two arguments for
this result, explained in detail below.
The second boundary
term, <span class="math">\(u'(0){\psi}_i(0)\)</span>, can be used to implement the condition <span class="math">\(u'(0)=C\)</span>,
provided <span class="math">\({\psi}_i(0)\neq 0\)</span> for some <span class="math">\(i\)</span> (but with finite elements
we fortunately have <span class="math">\({\psi}_0(0)=1\)</span>).
The variational form of the differential equation then becomes</p>
<div class="math" id="equation-fem:deq:1D:BC:nat:varform  \int_0^Lu'(x){\varphi}_i'(x) {\, \mathrm{d}x} + C{\varphi}_i(0) = \int_0^L f(x){\varphi}_i(x) {\, \mathrm{d}x},\quad i\in{I}{\thinspace .}">
</div>
</div>
<div class="section" id="boundary-term-vanishes-because-of-the-test-functions">
<span id="fem-deq-1d-bc-nat-ultest"></span><h2>Boundary term vanishes because of the test functions<a class="headerlink" href="#boundary-term-vanishes-because-of-the-test-functions" title="Permalink to this headline">¶</a></h2>
<p>At points where <span class="math">\(u\)</span> is known we may require <span class="math">\({\psi}_i\)</span> to vanish.
Here, <span class="math">\(u(L)=D\)</span> and then <span class="math">\({\psi}_i(0)=0\)</span>, <span class="math">\(i\in{I}\)</span>. Obviously,
the boundary term <span class="math">\(u'(L){\psi}_i(L)\)</span> then vanishes.</p>
<p>The set of basis functions <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{I}}\)</span> contains in this
case all the finite element basis functions on the mesh, expect
the one that is 1 at <span class="math">\(x=L\)</span>. The basis function that is left out is
used in a boundary function <span class="math">\(B(x)\)</span> instead.
With a left-to-right numbering,
<span class="math">\({\psi}_i = {\varphi}_i\)</span>, <span class="math">\(i=0,\ldots,N_n-1\)</span>, and <span class="math">\(B(x)=D{\varphi}_{N_n}\)</span>:</p>
<div class="math">
\[u(x) = D{\varphi}_{N_n}(x) + \sum_{j=0}^{N=N_n-1} c_j{\varphi}_j(x){\thinspace .}\]</div>
<p>Inserting this expansion for <span class="math">\(u\)</span> in the variational form
<a href="#equation-fem:deq:1D:BC:nat:varform">(?)</a> leads to the linear system</p>
<div class="math" id="equation-fem:deq:1D:natBC">
<span class="eqno">(87)</span>\[     \sum_{j=0}^{N}\left(
     \int_0^L {\varphi}_i'(x){\varphi}_j'(x) {\, \mathrm{d}x} \right)c_j =
     \int_0^L\left(f(x){\varphi}_i(x) -D{\varphi}_{N_n}'(x){\varphi}_i(x)\right) {\, \mathrm{d}x}
      - C{\varphi}_i(0),\]</div>
<p>for <span class="math">\(i=0,\ldots,N=N_n-1\)</span>.</p>
</div>
<div class="section" id="boundary-term-vanishes-because-of-linear-system-modifications">
<span id="fem-deq-1d-bc-nat-ulmod"></span><h2>Boundary term vanishes because of linear system modifications<a class="headerlink" href="#boundary-term-vanishes-because-of-linear-system-modifications" title="Permalink to this headline">¶</a></h2>
<p>We may, as an alternative to the approach in the previous section, use
a basis <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\in{I}}\)</span> which contains all the finite element
functions on the mesh: <span class="math">\({\psi}_i={\varphi}_i\)</span>, <span class="math">\(i=0,\ldots,N_n=N\)</span>.  In
this case, <span class="math">\(u'(L){\psi}_i(L)=u'(L){\varphi}_i(L)\neq 0\)</span> for the <span class="math">\(i\)</span>
corresponding to the boundary node at <span class="math">\(x=L\)</span> (where <span class="math">\({\varphi}_i=1\)</span>).
The number of this node is <span class="math">\(i=N_n=N\)</span> if a left-to-right numbering of
nodes is utilized.</p>
<p>However, even though <span class="math">\(u'(L){\varphi}_N(L)\neq 0\)</span>, we do not need to
compute this term.  For <span class="math">\(i&lt;N\)</span> we realize that <span class="math">\({\varphi}_i(L)=0\)</span>.  The
only nonzero contribution to the right-hand side from the affects
<span class="math">\(b_N\)</span> (<span class="math">\(i=N\)</span>). Without a boundary function we must implement the
condition <span class="math">\(u(L)=D\)</span> by the equivalent statement <span class="math">\(c_N=D\)</span> and modify the
linear system accordingly. This modification will earse the last
row and replace <span class="math">\(b_N\)</span> by another value. Any attempt to compute
the boundary term <span class="math">\(u'(L){\varphi}_N(L)\)</span> and store it in <span class="math">\(b_N\)</span> will be
lost. Therefore, we can safely forget about boundary terms
corresponding to Dirichlet boundary conditions also when we use
the methods from the section <a class="reference internal" href="#fem-deq-1d-fem-essbc-bfunc-modsys"><em>Modification of the linear system</em></a>
or the section <a class="reference internal" href="#fem-deq-1d-fem-essbc-bfunc-modsys-symm"><em>Symmetric modification of the linear system</em></a>.</p>
<p>The expansion for <span class="math">\(u\)</span> reads</p>
<div class="math">
\[u(x) = \sum_{j\in{I}} c_j{\varphi}_j(x),
\quad B(x) = D{\varphi}_N(x),\]</div>
<p>with <span class="math">\(N=N_n\)</span>. Insertion in the variational form
<a href="#equation-fem:deq:1D:BC:nat:varform">(?)</a> leads to
the linear system</p>
<div class="math" id="equation-fem:deq:1D:natBC2">
<span class="eqno">(88)</span>\[     \sum_{j\in{I}}\left(
     \int_0^L {\varphi}_i'(x){\varphi}_j'(x) {\, \mathrm{d}x} \right)c_j =
     \int_0^L\left(f(x){\varphi}_i(x)\right) {\, \mathrm{d}x}
      - C{\varphi}_i(0),\quad i\in{I}
     {\thinspace .}\]</div>
<p>After having computed the system, we replace the last row by
<span class="math">\(c_N=D\)</span>, either straightforwardly as in
Section ref:ref:<cite>fem:deq:1D:fem:essBC:Bfunc:modsys</cite> or in a symmetric
fashion as in Section ref:ref:<cite>fem:deq:1D:fem:essBC:Bfunc:modsys:symm</cite>.
These modifications can also be performed in the element matrix and
vector for the right-most cell.</p>
</div>
<div class="section" id="direct-computation-of-the-global-linear-system">
<span id="fem-deq-1d-bc-nat-aub"></span><h2>Direct computation of the global linear system<a class="headerlink" href="#direct-computation-of-the-global-linear-system" title="Permalink to this headline">¶</a></h2>
<p>We now turn to actual computations with P1 finite elements.
The focus is on how the linear system and
the element matrices and vectors are modified by the
condition <span class="math">\(u'(0)=C\)</span>.</p>
<p>Consider first the approach where Dirichlet conditions are incorporated
by a <span class="math">\(B(x)\)</span> function and the known degree of freedom
<span class="math">\(C_{N_n}\)</span> is left out from the linear system
(see the section <a class="reference internal" href="#fem-deq-1d-bc-nat-ultest"><em>Boundary term vanishes because of the test functions</em></a>).
The relevant formula for the linear
system is given by <a href="#equation-fem:deq:1D:natBC">(87)</a>.
There are three differences compared to the extensively
computed case where <span class="math">\(u(0)=0\)</span> in the sections <a class="reference internal" href="#fem-deq-1d-comp-global"><em>Computation in the global physical domain</em></a> and <a class="reference internal" href="#fem-deq-1d-comp-elmwise"><em>Cellwise computations  (1)</em></a>.
First, because we do not have a Dirichlet
condition at the left boundary, we need to extend the linear system
<a href="#equation-fem:deq:1D:ex1:Ab:glob">(73)</a> with an equation associated with the node
<span class="math">\(x_{0}=0\)</span>.
According to the section <a class="reference internal" href="#fem-deq-1d-fem-essbc-bfunc-modsys"><em>Modification of the linear system</em></a>, this
extension consists of including <span class="math">\(A_{0,0}=1/h\)</span>, <span class="math">\(A_{0,1}=-1/h\)</span>, and <span class="math">\(b_0=h\)</span>.
For <span class="math">\(i&gt;0\)</span> we have <span class="math">\(A_{i,i}=2/h\)</span>, <span class="math">\(A_{i-1,i}=A_{i,i+1}=-1/h\)</span>.
Second, we need to include
the extra term
<span class="math">\(-C{\varphi}_i(0)\)</span> on the right-hand side. Since all <span class="math">\({\varphi}_i(0)=0\)</span>
for <span class="math">\(i=1,\ldots,N\)</span>, this term reduces to <span class="math">\(-C{\varphi}_0(0)=-C\)</span> and
affects only the first equation (<span class="math">\(i=0\)</span>). We simply add <span class="math">\(-C\)</span> to <span class="math">\(b_0\)</span>
such that <span class="math">\(b_0=h - C\)</span>.
Third, the boundary term <span class="math">\(-\int_0^L D{\varphi}_{N_n}(x){\varphi}_i{\, \mathrm{d}x}\)</span>
must be computed. Since <span class="math">\(i=0,\ldots,N=N_n-1\)</span>, this integral can only
get a nonzero contribution with <span class="math">\(i=N_n-1\)</span> over the last cell.
The result becomes <span class="math">\(-Dh/6\)</span>.
The resulting linear system can be summarized in the form</p>
<div class="math" id="equation-fem:deq:1D:BC:nat:Aub:system">
<span class="eqno">(89)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; -1 &amp; 0 &amp;\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; -1 &amp; 2
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     h - C \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     2h - Dh/6
     \end{array}
     \right){\thinspace .}\end{split}\]</div>
<p>Next we consider the technique where we modify the linear system to
incorporate Dirichlet conditions
(see the section <a class="reference internal" href="#fem-deq-1d-bc-nat-ulmod"><em>Boundary term vanishes because of linear system modifications</em></a>). Now <span class="math">\(N=N_n\)</span>.
The two differences from the
case above is that the <span class="math">\(-\int_0^LD{\varphi}_{N_n}{\varphi}_i{\, \mathrm{d}x}\)</span> term is
left out of the right-hand side and an extra last row associated
with the node <span class="math">\(x_{N_n}=L\)</span> where the Dirichlet condition applies
is appended to the system.
This last row is anyway replaced by the condition <span class="math">\(C_N=D\)</span> or this
condition can be incorporated in a symmetric fashion. Using the simplest,
former approach gives</p>
<div class="math" id="equation-fem:deq:1D:BC:nat:Aub:system:mod">
<span class="eqno">(90)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; -1 &amp; 0 &amp;\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; -1 &amp; 2  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 0 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     h - C \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h \\
     D
     \end{array}
     \right){\thinspace .}\end{split}\]</div>
</div>
<div class="section" id="cellwise-computations-2">
<h2>Cellwise computations  (2)<a class="headerlink" href="#cellwise-computations-2" title="Permalink to this headline">¶</a></h2>
<p>Now we compute with one element at a time, working in the reference
coordinate system <span class="math">\(X\in [-1,1]\)</span>.
We need to see how the
<span class="math">\(u'(0)=C\)</span> condition affects the element matrix and vector.
The extra term <span class="math">\(-C{\varphi}_i(0)\)</span> in the variational formulation
only affects the element vector in the first cell.
On the reference cell, <span class="math">\(-C{\varphi}_i(0)\)</span> is transformed to
<span class="math">\(-C{\tilde{\varphi}}_r(-1)\)</span>, where <span class="math">\(r\)</span> counts local degrees of freedom.
We have <span class="math">\({\tilde{\varphi}}_0(-1)=1\)</span> and <span class="math">\({\tilde{\varphi}}_1(-1)=0\)</span> so
we are left with the contribution
<span class="math">\(-C{\tilde{\varphi}}_0(-1)=-C\)</span> to <span class="math">\(\tilde b^{(0)}_0\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:nat">
<span class="eqno">(91)</span>\[\begin{split}     \tilde A^{(0)} =
     A = \frac{1}{h}\left(\begin{array}{rr}
     1 &amp; 1\\
     -1 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(0)} = \left(\begin{array}{c}
     h - C\\
     h
     \end{array}\right){\thinspace .}\end{split}\]</div>
<p>No other element matrices or vectors are affected by the <span class="math">\(-C{\varphi}_i(0)\)</span>
boundary term.</p>
<p>There are two alternative ways of incorporating the Dirichlet condition.
Following the section <a class="reference internal" href="#fem-deq-1d-bc-nat-ultest"><em>Boundary term vanishes because of the test functions</em></a>, we get
a <span class="math">\(1\times 1\)</span> element matrix in the last cell and
an element vector with an extra term containing <span class="math">\(D\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:ends">
<span class="eqno">(92)</span>\[     \tilde A^{(e)} =\frac{1}{h}\left(\begin{array}{r}
     1
     \end{array}\right),\quad
     \tilde b^{(e)} = h\left(\begin{array}{c}
     1 - D/6
     \end{array}\right),\]</div>
<p>Alternatively, we include the degree of freedom at the node with
<span class="math">\(u\)</span> specified. The element matrix and vector must then be modified
to constrain the <span class="math">\(\tilde c_1 = c_N\)</span> value at local node <span class="math">\(r=1\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:nat:mod">
<span class="eqno">(93)</span>\[\begin{split}     \tilde A^{(N_e)} =
     A = \frac{1}{h}\left(\begin{array}{rr}
     1 &amp; 1\\
     0 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(N_e)} = \left(\begin{array}{c}
     h\\
     D
     \end{array}\right){\thinspace .}\end{split}\]</div>
</div>
</div>
<div class="section" id="implementation-4">
<span id="fem-deq-1d-code-global"></span><h1>Implementation  (4)<a class="headerlink" href="#implementation-4" title="Permalink to this headline">¶</a></h1>
<p>It is tempting to create a
program with symbolic calculations to perform all the steps in the
computational machinery,
both for automating the work and for documenting the complete algorithms.
As we have seen, there are quite many details involved with
finite element computations and incorporation of boundary conditions.
An implementation will also act as a structured summary of all these details.</p>
<div class="section" id="global-basis-functions">
<h2>Global basis functions<a class="headerlink" href="#global-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>We first consider implementations when <span class="math">\({\psi}_i\)</span> are global functions
are hence different from zero on most of <span class="math">\(\Omega =[0,L]\)</span> so all integrals
need integration over the entire domain. Since the expressions for
the entries in the linear system depend on the differential equation
problem being solved, the user must supply the necessary formulas via
Python functions. The implementations here attempt to perform symbolic
calculations, but fall back on numerical computations if the symbolic
ones fail.</p>
<p>The user must prepare a function
<tt class="docutils literal"><span class="pre">integrand_lhs(psi,</span> <span class="pre">i,</span> <span class="pre">j)</span></tt> for returning the integrand of the
integral that contributes to matrix entry <span class="math">\((i,j)\)</span>.
The <tt class="docutils literal"><span class="pre">psi</span></tt> variable is a Python dictionary holding the basis
functions and their derivatives in symbolic form. More precisely,
<tt class="docutils literal"><span class="pre">psi[q]</span></tt> is a list of</p>
<div class="math">
\[\{\frac{d^q{\psi}_0}{dx^q},\ldots,\frac{d^q{\psi}_N}{dx^q}\}
{\thinspace .}\]</div>
<p>Similarly, <tt class="docutils literal"><span class="pre">integrand_rhs(psi,</span> <span class="pre">i)</span></tt> returns the integrand
for entry number <span class="math">\(i\)</span> in the right-hand side vector.</p>
<p>Since we also have contributions to the right-hand side vector,
and potentially also the
matrix, from boundary terms without any integral, we introduce two
additional functions, <tt class="docutils literal"><span class="pre">boundary_lhs(psi,</span> <span class="pre">i,</span> <span class="pre">j)</span></tt> and
<tt class="docutils literal"><span class="pre">boundary_rhs(psi,</span> <span class="pre">i)</span></tt> for returning terms in the variational
formulation that are not to be integrated over the domain <span class="math">\(\Omega\)</span>.
Examples shown later will explain in more detail how these
user-supplied function may look like.</p>
<p>The linear system can be computed and solved symbolically by
the following function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="n">integrand_lhs</span><span class="p">,</span> <span class="n">integrand_rhs</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
          <span class="n">boundary_lhs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">boundary_rhs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_lhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="n">boundary_lhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_lhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>   <span class="c"># assume symmetry</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_rhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">boundary_rhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_rhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>Not surprisingly, symbolic solution of differential
equations, discretized by a Galerkin or least squares method
with global basis functions,
is of limited interest beyond the simplest problems, because
symbolic integration might be very time consuming or impossible, not
only in <tt class="docutils literal"><span class="pre">sympy</span></tt> but also in
<a class="reference external" href="http://wolframalpha.com">WolframAlpha</a>
(which applies the perhaps most powerful symbolic integration
software available today: Mathematica). Numerical integration
as an option is therefore desirable.</p>
<p>The extended <tt class="docutils literal"><span class="pre">solve</span></tt> function below tries to combine symbolic and
numerical integration.  The latter can be enforced by the user, or it
can be invoked after a non-successful symbolic integration (being
detected by an <tt class="docutils literal"><span class="pre">Integral</span></tt> object as the result of the integration
in <tt class="docutils literal"><span class="pre">sympy</span></tt>).</p>
<p>Note that for a
numerical integration, symbolic expressions must be converted to
Python functions (using <tt class="docutils literal"><span class="pre">lambdify</span></tt>), and the expressions cannot contain
other symbols than <tt class="docutils literal"><span class="pre">x</span></tt>. The real <tt class="docutils literal"><span class="pre">solve</span></tt> routine in the
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/varform1D.py">varform1D.py</a>
file has error checking and meaningful error messages in such cases.
The <tt class="docutils literal"><span class="pre">solve</span></tt> code below is a condensed version of the real one, with
the purpose of showing how to automate the Galerkin or least squares
method for solving differential equations in 1D with global basis functions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="n">integrand_lhs</span><span class="p">,</span> <span class="n">integrand_rhs</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
          <span class="n">boundary_lhs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">boundary_rhs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_lhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                    <span class="n">symbolic</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c"># force num.int. hereafter</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span><span class="p">:</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="k">if</span> <span class="n">boundary_lhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_lhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_rhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="n">symbolic</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span><span class="p">:</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="k">if</span> <span class="n">boundary_rhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_rhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
</div>
<div class="section" id="example-constant-right-hand-side">
<h2>Example: constant right-hand side<a class="headerlink" href="#example-constant-right-hand-side" title="Permalink to this headline">¶</a></h2>
<p>To demonstrate the code above, we address</p>
<div class="math">
\[-u''(x)=b,\quad x\in\Omega=[0,1],\quad u(0)=1,\ u(1)=0,\]</div>
<p>with <span class="math">\(b\)</span> as a (symbolic) constant. A possible basis for the space <span class="math">\(V\)</span>
is <span class="math">\({\psi}_i(x) = x^{i+1}(1-x)\)</span>, <span class="math">\(i\in{I}\)</span>. Note that
<span class="math">\({\psi}_i(0)={\psi}_i(1)=0\)</span> as required by the Dirichlet conditions.
We need a <span class="math">\(B(x)\)</span> function to take care of the known boundary
values of <span class="math">\(u\)</span>. Any function <span class="math">\(B(x)=1-x^p\)</span>, <span class="math">\(p\in\mathbb{R}\)</span>, is a candidate,
and one arbitrary choice from this family
is <span class="math">\(B(x)=1-x^3\)</span>. The unknown function is then written as
a sum of a known (<span class="math">\(B\)</span>) and an unknown (<span class="math">\(\bar u\)</span>) function:</p>
<div class="math">
\[u(x) = B(x) + \bar u (x),\quad \bar u(x) = \sum_{j\in{I}} c_j{\psi}_j(x){\thinspace .}\]</div>
<p>Let us use the Galerkin method to derive the variational formulation.
Multiplying the differential
equation by <span class="math">\(v\)</span> and integrate by parts yield</p>
<div class="math">
\[\int_0^1 u'v' {\, \mathrm{d}x} = \int_0^1 fv {\, \mathrm{d}x}\quad\forall v\in V,\]</div>
<p>and with <span class="math">\(u=B + \bar u\)</span>,</p>
<div class="math">
\[\int_0^1 \bar u'v' {\, \mathrm{d}x} = \int_0^1 (f-B')v {\, \mathrm{d}x}\quad\forall v\in V{\thinspace .}\]</div>
<p>Inserting <span class="math">\(\bar u = \sum_{j}c_j{\psi}_j\)</span>, we get the linear system</p>
<div class="math">
\[\sum_{j\in{I}}\left(\int_0^1{\psi}_i'{\psi}_j' {\, \mathrm{d}x}\right)c_j = \int_0^1(f-B'){\psi}_i {\, \mathrm{d}x},
\quad i\in{I}{\thinspace .}\]</div>
<p>The application can be coded as follows in <tt class="docutils literal"><span class="pre">sympy</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;x b&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">b</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span>
<span class="n">dBdx</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c"># Compute basis functions and their derivatives</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]}</span>
<span class="n">psi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">psi_i</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">psi_i</span> <span class="ow">in</span> <span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

<span class="k">def</span> <span class="nf">integrand_lhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">integrand_rhs</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">dBdx</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">u_bar</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">integrand_lhs</span><span class="p">,</span> <span class="n">integrand_rhs</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
              <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">B</span> <span class="o">+</span> <span class="n">u_bar</span>
<span class="k">print</span> <span class="s">&#39;solution u:&#39;</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
</pre></div>
</div>
<p>The printout of <tt class="docutils literal"><span class="pre">u</span></tt> reads <tt class="docutils literal"><span class="pre">-b*x**2/2</span> <span class="pre">+</span> <span class="pre">b*x/2</span> <span class="pre">-</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">1</span></tt>.
Note that expanding <tt class="docutils literal"><span class="pre">u</span></tt> and then simplifying is in the present case
desirable to get a compact, final expression with <tt class="docutils literal"><span class="pre">sympy</span></tt>.
A non-expanded <tt class="docutils literal"><span class="pre">u</span></tt> might be preferable in other cases - this depends on
the problem in question.</p>
<p>The exact solution <span class="math">\({u_{\small\mbox{e}}}(x)\)</span> can be derived by the following
<tt class="docutils literal"><span class="pre">sympy</span></tt> code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Solve -u&#39;&#39;=f by integrating f twice</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">f2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="c"># Add integration constants</span>
<span class="n">C1</span><span class="p">,</span> <span class="n">C2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;C1 C2&#39;</span><span class="p">)</span>
<span class="n">u_e</span> <span class="o">=</span> <span class="o">-</span><span class="n">f2</span> <span class="o">+</span> <span class="n">C1</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">C2</span>
<span class="c"># Find C1 and C2 from the boundary conditions u(0)=0, u(1)=1</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">u_e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">u_e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">])</span>
<span class="c"># Form the exact solution</span>
<span class="n">u_e</span> <span class="o">=</span> <span class="o">-</span><span class="n">f2</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="n">C1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="n">C2</span><span class="p">]</span>
<span class="k">print</span> <span class="s">&#39;analytical solution:&#39;</span><span class="p">,</span> <span class="n">u_e</span>
<span class="k">print</span> <span class="s">&#39;error:&#39;</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_e</span><span class="p">)</span>
</pre></div>
</div>
<p>The last line prints <tt class="docutils literal"><span class="pre">0</span></tt>, which is not surprising when
<span class="math">\({u_{\small\mbox{e}}}(x)\)</span> is a parabola and our approximate <span class="math">\(u\)</span> contains polynomials up to
degree 4. It suffices to have <span class="math">\(N=1\)</span>, i.e., polynomials of degree
2, to recover the exact solution.</p>
<p>We can play around with the code and test that with <span class="math">\(f\sim x^p\)</span>,
the solution is a polynomial of degree <span class="math">\(p+2\)</span>, and <span class="math">\(N=p+1\)</span> guarantees
that the approximate solution is exact.</p>
<p>Although the symbolic code is capable of integrating many choices of <span class="math">\(f(x)\)</span>,
the symbolic expressions for <span class="math">\(u\)</span> quickly become lengthy and non-informative,
so numerical integration in the code, and hence numerical answers,
have the greatest application potential.</p>
</div>
<div class="section" id="finite-elements">
<h2>Finite elements<a class="headerlink" href="#finite-elements" title="Permalink to this headline">¶</a></h2>
<p>Implementation of the finite element algorithms for differential
equations follows closely the algorithm for approximation of functions.
The new additional ingredients are</p>
<ol class="arabic simple">
<li>other types of integrands (as implied by the variational formulation)</li>
<li>additional boundary terms in the variational formulation for
Neumann boundary conditions</li>
<li>modification of element matrices and vectors due to Dirichlet
boundary conditions</li>
</ol>
<p>Point 1 and 2 can be taken care of by letting the user supply
functions defining the integrands and boundary terms on the
left- and right-hand side of the equation system:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">integrand_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">boundary_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">integrand_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">boundary_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <tt class="docutils literal"><span class="pre">phi</span></tt> is a dictionary where <tt class="docutils literal"><span class="pre">phi[q]</span></tt> holds a list of
the derivatives of order <tt class="docutils literal"><span class="pre">q</span></tt> of the basis functions at the
an evaluation point; <tt class="docutils literal"><span class="pre">r</span></tt> and <tt class="docutils literal"><span class="pre">s</span></tt> are indices for the corresponding
entries in the element matrix and vector, and <tt class="docutils literal"><span class="pre">x</span></tt> is the global
coordinate value corresponding to the current evaluation point.</p>
<p>Given a mesh represented by <tt class="docutils literal"><span class="pre">vertices</span></tt>, <tt class="docutils literal"><span class="pre">cells</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt> as
explained before, we can write a pseudo Python code to list all
the steps in the computational algorithm for finite element solution
of a differential equation.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="o">&lt;</span><span class="n">Declare</span> <span class="k">global</span> <span class="n">matrix</span> <span class="ow">and</span> <span class="n">rhs</span><span class="p">:</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="o">&gt;</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cells</span><span class="p">)):</span>

    <span class="c"># Compute element matrix and vector</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">])</span>  <span class="c"># no of dofs in this element</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span> <span class="o">-</span> <span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
    <span class="o">&lt;</span><span class="n">Declare</span> <span class="n">element</span> <span class="n">matrix</span> <span class="ow">and</span> <span class="n">vector</span><span class="p">:</span> <span class="n">A_e</span><span class="p">,</span> <span class="n">b_e</span><span class="o">&gt;</span>

    <span class="c"># Integrate over the reference cell</span>
    <span class="n">points</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">numerical</span> <span class="n">integration</span> <span class="n">rule</span><span class="o">&gt;</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="n">phi</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">basis</span> <span class="n">functions</span> <span class="ow">and</span> <span class="n">derivatives</span> <span class="n">at</span> <span class="n">X</span><span class="o">&gt;</span>
        <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">x</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">affine</span> <span class="n">mapping</span> <span class="kn">from</span> <span class="nn">X</span><span class="o">&gt;</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span> <span class="o">+=</span> <span class="n">integrand_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">detJ</span><span class="o">*</span><span class="n">w</span>
            <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">+=</span> <span class="n">integrand_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">detJ</span><span class="o">*</span><span class="n">w</span>

    <span class="c"># Add boundary terms</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span> <span class="o">+=</span> <span class="n">boundary_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">detJ</span><span class="o">*</span><span class="n">w</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">+=</span> <span class="n">boundary_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">detJ</span><span class="o">*</span><span class="n">w</span>

    <span class="c"># Incorporate essential boundary conditions</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">global_dof</span> <span class="o">=</span> <span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">global_dof</span> <span class="ow">in</span> <span class="n">essbc_dofs</span><span class="p">:</span>
            <span class="c"># dof r is subject to an essential condition</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">essbc_docs</span><span class="p">[</span><span class="n">global_dof</span><span class="p">]</span>
            <span class="c"># Symmetric modification</span>
            <span class="n">b_e</span> <span class="o">-=</span> <span class="n">value</span><span class="o">*</span><span class="n">A_e</span><span class="p">[:,</span><span class="n">r</span><span class="p">]</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">A_e</span><span class="p">[:,</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="c"># Assemble</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span> <span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
        <span class="n">b</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>

<span class="o">&lt;</span><span class="n">solve</span> <span class="n">linear</span> <span class="n">system</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="variational-formulations-in-2d-and-3d">
<span id="fem-deq-2d-varform"></span><h1>Variational formulations in 2D and 3D<a class="headerlink" href="#variational-formulations-in-2d-and-3d" title="Permalink to this headline">¶</a></h1>
<p>The major difference between deriving variational formulations in 2D and 3D
compared to 1D is the rule for integrating by parts.
A typical second-order term in a PDE may be written in dimension-independent
notation as</p>
<div class="math">
\[\nabla^2 u \quad\hbox{or}\quad \nabla\cdot\left( a(\boldsymbol{x})\nabla u\right)
{\thinspace .}\]</div>
<p>The explicit forms in a 2D problem become</p>
<div class="math">
\[\nabla^2 u = \nabla\cdot\nabla u =
\frac{\partial^2 u}{\partial x^2} +
\frac{\partial^2 u}{\partial y^2},\]</div>
<p>and</p>
<div class="math">
\[\nabla\cdot\left( a(\boldsymbol{x})\nabla u\right) =
\frac{\partial}{\partial x}\left( a(x,y)\frac{\partial u}{\partial x}\right) +
\frac{\partial}{\partial y}\left( a(x,y)\frac{\partial u}{\partial y}\right)
{\thinspace .}\]</div>
<p>The general rule for integrating by parts is often referred to as
<a class="reference external" href="http://en.wikipedia.org/wiki/Green's_identities">Green&#8217;s first identity</a>:</p>
<div class="math" id="equation-fem:deq:2D:int:by:parts">
<span class="eqno">(94)</span>\[     -\int_{\Omega} \nabla\cdot (a(\boldsymbol{x})\nabla u) v{\, \mathrm{d}x} =
     \int_{\Omega} a(\boldsymbol{x})\nabla u\cdot\nabla v {\, \mathrm{d}x} -
     \int_{\partial\Omega} a\frac{\partial u}{\partial n} v {\, \mathrm{d}s},\]</div>
<p>where <span class="math">\(\partial\Omega\)</span> is the boundary of <span class="math">\(\Omega\)</span> and
<span class="math">\(\partial u/\partial n = \boldsymbol{n}\cdot\nabla u\)</span> is the derivative
of <span class="math">\(u\)</span> in the outward normal direction, <span class="math">\(\boldsymbol{n}\)</span> being an outward
unit normal to <span class="math">\(\partial\Omega\)</span>. The integrals <span class="math">\(\int_\Omega (){\, \mathrm{d}x}\)</span> are
area integrals in 2D and volume integrals in 3D, while
<span class="math">\(\int_{\partial\Omega} (){\, \mathrm{d}s}\)</span> is a line integral in 2D and a surface
integral in 3D.</p>
<p>Note that <a href="#equation-fem:deq:2D:int:by:parts">(94)</a> obviously applies to a constant
<span class="math">\(a\)</span>, which is what we have if the PDE has a Laplace term <span class="math">\(a\nabla^2 u\)</span>.</p>
<p>Let us divide the boundary into two parts:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(\partial\Omega_N\)</span>, where we have Neumann conditions
<span class="math">\(-a\frac{\partial u}{\partial n} = g\)</span>, and</li>
<li><span class="math">\(\partial\Omega_D\)</span>, where we have Dirichlet conditions
<span class="math">\(u = u_0\)</span>.</li>
</ul>
</div></blockquote>
<p>The test functions <span class="math">\(v\)</span> are required to vanish on <span class="math">\(\partial\Omega_D\)</span>.</p>
<p><strong>Example.</strong>
Here is a quite general linear PDE arising in many problems:</p>
<div class="math">
\[\boldsymbol{v}\cdot\nabla u + \alpha u = \nabla\cdot\left( a\nabla u\right) + f,
\quad\boldsymbol{x}\in\Omega,\]</div>
<div class="math">
\[u = u_0,\quad\boldsymbol{x}\in\partial\Omega_D,\]</div>
<div class="math">
\[-a\frac{\partial u}{\partial n} = g,\quad\boldsymbol{x}\in\partial\Omega_N
{\thinspace .}\]</div>
<p>The vector field <span class="math">\(\boldsymbol{v}\)</span> and the scalar functions <span class="math">\(a\)</span>, <span class="math">\(\alpha\)</span>, <span class="math">\(f\)</span>, <span class="math">\(u_0\)</span>, and
<span class="math">\(g\)</span> may vary with the spatial coordinate <span class="math">\(\boldsymbol{x}\)</span> and must be known.</p>
<p>Such a second-order PDE needs exactly one boundary condition at each
point of the boundary, so <span class="math">\(\partial\Omega_N\cup\partial\Omega_D\)</span>
must be the complete boundary <span class="math">\(\partial\Omega\)</span>.</p>
<p>The unknown function can be expanded as</p>
<div class="math">
\[u = u_0 + \sum_{j\in{I}} c_j{\psi}_j {\thinspace .}\]</div>
<p>The variational formula is obtained from Galerkin&#8217;s method, which
technically implies multiplying the PDE by a test
function <span class="math">\(v\)</span> and integrating over <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[\int_{\Omega} (\boldsymbol{v}\cdot\nabla u + \alpha u)v{\, \mathrm{d}x} =
\int_{\Omega} \nabla\cdot\left( a\nabla u\right){\, \mathrm{d}x} + \int_{\Omega}fv {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>The second-order term is integrated by parts, according to</p>
<div class="math">
\[\int_{\Omega} \nabla\cdot\left( a\nabla u\right)v {\, \mathrm{d}x} =
-\int_{\Omega} a\nabla u\cdot\nabla v{\, \mathrm{d}x}
+ \int_{\partial\Omega} a\frac{\partial u}{\partial n} v{\, \mathrm{d}s}
{\thinspace .}\]</div>
<p>The variational form now reads</p>
<div class="math">
\[\int_{\Omega} (\boldsymbol{v}\cdot\nabla u + \alpha u)v{\, \mathrm{d}x} =
-\int_{\Omega} a\nabla u\cdot\nabla v{\, \mathrm{d}x}
+ \int_{\partial\Omega} a\frac{\partial u}{\partial n} v{\, \mathrm{d}s}
+ \int_{\Omega} fv {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>The boundary term can be developed further by noticing that <span class="math">\(v\neq 0\)</span>
only on <span class="math">\(\partial\Omega_N\)</span>,</p>
<div class="math">
\[\int_{\partial\Omega} a\frac{\partial u}{\partial n} v{\, \mathrm{d}s}
= \int_{\partial\Omega_N} a\frac{\partial u}{\partial n} v{\, \mathrm{d}s},\]</div>
<p>and that on <span class="math">\(\partial\Omega_N\)</span>, we have the condition
<span class="math">\(a\frac{\partial u}{\partial n}=-g\)</span>, so the term becomes</p>
<div class="math">
\[-\int_{\partial\Omega_N} gv{\, \mathrm{d}s}{\thinspace .}\]</div>
<p>The variational form is then</p>
<div class="math">
\[\int_{\Omega} (\boldsymbol{v}\cdot\nabla u + \alpha u)v{\, \mathrm{d}x} =
-\int_{\Omega} a\nabla u\cdot\nabla v {\, \mathrm{d}x}
- \int_{\partial\Omega} g v{\, \mathrm{d}s}
+ \int_{\Omega} fv {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>Instead of using the integral signs we may use the inner product
notation <span class="math">\((\cdot,\cdot)\)</span>:</p>
<div class="math">
\[(\boldsymbol{v}\cdot\nabla u, v) + (\alpha u,v) =
- (a\nabla u,\nabla v) - (g,v)_{N} + (f,v)
{\thinspace .}\]</div>
<p>The subscript <span class="math">\(N\)</span> in <span class="math">\((g,v)_{N}\)</span> is a notation for a line or surface
integral over <span class="math">\(\partial\Omega_N\)</span>.</p>
<p>Inserting the <span class="math">\(u\)</span> expansion results in</p>
<div class="math">
\[\begin{split}\sum_{j\in{I}} ((\boldsymbol{v}\cdot\nabla {\psi}_j, {\psi}_i) &amp;+ (\alpha {\psi}_j ,{\psi}_i) + (a\nabla {\psi}_j,\nabla {\psi}_i))c_j = \\
&amp; (g,{\psi}_i)_{N} + (f,{\psi}_i) -
(\boldsymbol{v}\cdot\nabla u_0, {\psi}_i) + (\alpha u_0 ,{\psi}_i) +
(a\nabla u_0,\nabla {\psi}_i)
{\thinspace .}\end{split}\]</div>
<p>This is a linear system with matrix entries</p>
<div class="math">
\[A_{i,j} = (\boldsymbol{v}\cdot\nabla {\psi}_j, {\psi}_i) + (\alpha {\psi}_j ,{\psi}_i) + (a\nabla {\psi}_j,\nabla {\psi}_i)\]</div>
<p>and right-hand side entries</p>
<div class="math">
\[b_i = (g,{\psi}_i)_{N} + (f,{\psi}_i) -
(\boldsymbol{v}\cdot\nabla u_0, {\psi}_i) + (\alpha u_0 ,{\psi}_i) +
(a\nabla u_0,\nabla {\psi}_i),\]</div>
<p>for <span class="math">\(i,j\in{I}\)</span>.</p>
<p>In the finite element method, we usually express <span class="math">\(u_0\)</span> in terms of
basis functions and restrict <span class="math">\(i\)</span> and <span class="math">\(j\)</span> to run over the degrees of
freedom that are not prescribed as Dirichlet conditions.
However, we can also keep all the <span class="math">\(c_j\)</span>, <span class="math">\(j\in{I}\)</span>, as unknowns
drop the <span class="math">\(u_0\)</span> in the expansion for <span class="math">\(u\)</span>, and incorporate all the
known <span class="math">\(c_j\)</span> values in the linear system. This has been explained
in detail in the 1D case.</p>
<div class="section" id="transformation-to-a-reference-cell-in-2d-and-3d">
<h2>Transformation to a reference cell in 2D and 3D<a class="headerlink" href="#transformation-to-a-reference-cell-in-2d-and-3d" title="Permalink to this headline">¶</a></h2>
<p>We consider an integral of the type</p>
<div class="math">
\[\int_{{\Omega}^{(e)}} a(\boldsymbol{x})\nabla{\varphi}_i\cdot\nabla{\varphi}_j{\, \mathrm{d}x}\]</div>
<p>in the physical domain.
Suppose we want to calculate this integral over a reference cell,
denoted by <span class="math">\(\tilde\Omega^r\)</span>, in a coordinate system with coordinates
<span class="math">\(\boldsymbol{X} = (X_0, X_1)\)</span> (2D) or <span class="math">\(\boldsymbol{X} = (X_0, X_1, X_2)\)</span> (3D).
The mapping between a point <span class="math">\(\boldsymbol{X}\)</span> in the reference coordinate system  and
the corresponding point <span class="math">\(\boldsymbol{x}\)</span> in the physical coordinate system is
given by a vector relation <span class="math">\(\boldsymbol{x}(\boldsymbol{X})\)</span>.
The corresponding Jacobian, <span class="math">\(J\)</span>, of this mapping has entries</p>
<div class="math">
\[J_{i,j}=\frac{\partial x_j}{\partial X_i}{\thinspace .}\]</div>
<p>The change of variables requires <span class="math">\({\, \mathrm{d}x}\)</span> to be replaced by <span class="math">\(\det J{\, \mathrm{d}X}\)</span>.
The derivatives in the <span class="math">\(\nabla\)</span> operator in the variational form are
with respect to <span class="math">\(\boldsymbol{x}\)</span>, which we may denote by <span class="math">\(\nabla_{\boldsymbol{x}}\)</span>.
The <span class="math">\({\varphi}_i(\boldsymbol{x})\)</span> functions in the integral
are replaced by local basis functions <span class="math">\({\tilde{\varphi}}_r(\boldsymbol{X})\)</span> so
the integral features <span class="math">\(\nabla_{\boldsymbol{x}}{\tilde{\varphi}}_r(\boldsymbol{X})\)</span>. We readily have
<span class="math">\(\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r(\boldsymbol{X})\)</span> from formulas for the basis functions, but
the desired quantity <span class="math">\(\nabla_{\boldsymbol{x}}{\tilde{\varphi}}_r(\boldsymbol{X})\)</span> requires some efforts
to compute. All the details are now given.</p>
<p>Let <span class="math">\(i=q(e,r)\)</span> and consider two space dimensions. By the chain rule,</p>
<div class="math">
\[\frac{\partial {\tilde{\varphi}}_r}{\partial X} =
\frac{\partial {\varphi}_i}{\partial X} =
\frac{\partial {\varphi}_i}{\partial x}\frac{\partial x}{\partial X} +
\frac{\partial {\varphi}_i}{\partial y}\frac{\partial y}{\partial X},\]</div>
<p>and</p>
<div class="math">
\[\frac{\partial {\tilde{\varphi}}_r}{\partial Y} =
\frac{\partial {\varphi}_i}{\partial Y} =
\frac{\partial {\varphi}_i}{\partial x}\frac{\partial x}{\partial Y} +
\frac{\partial {\varphi}_i}{\partial y}\frac{\partial y}{\partial Y}
{\thinspace .}\]</div>
<p>We can write this as a vector equation</p>
<div class="math">
\[\begin{split}\left[\begin{array}{c}
\frac{\partial {\tilde{\varphi}}_r}{\partial X}\\
\frac{\partial {\tilde{\varphi}}_r}{\partial Y}
\end{array}\right]
=
\left[\begin{array}{cc}
\frac{\partial x}{\partial X} &amp; \frac{\partial y}{\partial X}\\
\frac{\partial x}{\partial Y} &amp; \frac{\partial y}{\partial Y}
\end{array}\right]
\left[\begin{array}{c}
\frac{\partial {\varphi}_i}{\partial x}\\
\frac{\partial {\varphi}_i}{\partial y}
\end{array}\right]\end{split}\]</div>
<p>Identifying</p>
<div class="math">
\[\begin{split}\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r = \left[\begin{array}{c}
\frac{\partial {\tilde{\varphi}}_r}{\partial X}\\
\frac{\partial {\tilde{\varphi}}_r}{\partial Y}
\end{array}\right],
\quad
J =
\left[\begin{array}{cc}
\frac{\partial x}{\partial X} &amp; \frac{\partial y}{\partial X}\\
\frac{\partial x}{\partial Y} &amp; \frac{\partial y}{\partial Y}
\end{array}\right],
\quad
\nabla_{\boldsymbol{x}}{\varphi}_r =
\left[\begin{array}{c}
\frac{\partial {\varphi}_i}{\partial x}\\
\frac{\partial {\varphi}_i}{\partial y}
\end{array}\right],\end{split}\]</div>
<p>we have the relation</p>
<div class="math">
\[\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r = J\cdot\nabla_{\boldsymbol{x}}{\varphi}_i,\]</div>
<p>which we can solve with respect to <span class="math">\(\nabla_{\boldsymbol{x}}{\varphi}_i\)</span>:</p>
<div class="math">
\[\nabla_{\boldsymbol{x}}{\varphi}_i = J^{-1}\cdot\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r{\thinspace .}\]</div>
<p>This means that we have the following transformation of the
integral in the physical domain to its counterpart over the reference cell:</p>
<div class="math">
\[\int_{\Omega}^{(e)} a(\boldsymbol{x})\nabla_{\boldsymbol{x}}{\varphi}_i\cdot\nabla_{\boldsymbol{x}}{\varphi}_j{\, \mathrm{d}x}
\int_{\tilde\Omega^r} a(\boldsymbol{x}(\boldsymbol{X}))(J^{-1}\cdot\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r)\cdot
(J^{-1}\cdot\nabla{\tilde{\varphi}}_s)\det J{\, \mathrm{d}X}\]</div>
</div>
<div class="section" id="numerical-integration-2">
<h2>Numerical integration  (2)<a class="headerlink" href="#numerical-integration-2" title="Permalink to this headline">¶</a></h2>
<p>Integrals are normally computed by numerical integration rules.
For multi-dimensional cells, various families of rules exist.
All of them are similar to what is shown in 1D:
<span class="math">\(\int f {\, \mathrm{d}x}\approx \sum_jw_if(\boldsymbol{x}_j)\)</span>, where <span class="math">\(w_j\)</span> are weights and
<span class="math">\(\boldsymbol{x}_j\)</span> are corresponding points.</p>
</div>
<div class="section" id="convenient-formulas-for-p1-elements-in-2d">
<h2>Convenient formulas for P1 elements in 2D<a class="headerlink" href="#convenient-formulas-for-p1-elements-in-2d" title="Permalink to this headline">¶</a></h2>
<p>We shall now provide some formulas for piecewise linear <span class="math">\({\varphi}_i\)</span> functions
and their integrals <em>in the physical coordinate system</em>.
These formulas make it convenient to compute with P1 elements without
the need to work in the reference coordinate system and deal with mappings
and Jacobians.
A lot of computational and algorithmic details are hidden by this approach.</p>
<p>Let <span class="math">\(\Omega^{(e)}\)</span> be cell number <span class="math">\(e\)</span>, and let the three vertices
have global vertex numbers <span class="math">\(I\)</span>, <span class="math">\(J\)</span>, and <span class="math">\(K\)</span>.
The corresponding coordinates are
<span class="math">\((x_{I},y_{I})\)</span>, <span class="math">\((x_{J},y_{J})\)</span>, and <span class="math">\((x_{K},y_{K})\)</span>.
The basis function <span class="math">\({\varphi}_I\)</span> over <span class="math">\(\Omega^{(e)}\)</span> have the explicit
formula</p>
<div class="math" id="equation-fem:approx:fe:2D:phi:I">
<span class="eqno">(95)</span>\[     {\varphi}_I (x,y) = \frac{1}{2}\Delta \left( \alpha_I + \beta_Ix
     + \gamma_Iy\right),\]</div>
<p>where</p>
<div class="math" id="equation-fem:approx:fe:2D:phi:alpha:I">
<span class="eqno">(96)</span>\[     \alpha_I = x_{J}y_{K} - x_{K}y_{J},\]</div>
<div class="math" id="equation-fem:approx:fe:2D:phi:beta:I">
<span class="eqno">(97)</span>\[     \beta_I = y_{J} - y_{K},\]</div>
<div class="math" id="equation-fem:approx:fe:2D:phi:gamma:I">
<span class="eqno">(98)</span>\[     \gamma_I = x_{K} - x_{J},\]</div>
<div class="math">
\[2\Delta = \det\left(\begin{array}{rrr}
1  x_{I}  y_{I}\]</div>
<div class="math">
\[1  x_{J}  y_{J}\]</div>
<div class="math" id="equation-fem:approx:fe:2D:phi:Delta">
<span class="eqno">(99)</span>\[     1  x_{K}  y_{K} \end{array}\right)
     {\thinspace .}\]</div>
<p>The quantity <span class="math">\(\Delta\)</span> is the area of the cell.</p>
<p>The following formula is often convenient when computing element matrices
and vectors:</p>
<div class="math" id="equation-fem:approx:fe:2D:phi:integral">
<span class="eqno">(100)</span>\[     \int_{\Omega^{(e)}} {\varphi}_I^{p}{\varphi}_J^{q}{\varphi}_K^{r} dx dy =
     {p!q!r!\over (p+q+r+2)!}2\Delta\]\[     {\thinspace .}\]</div>
<p>(Note that the <span class="math">\(q\)</span> in this formula is not to be mixed with the <span class="math">\(q(e,r)\)</span>
mapping of degrees of freedom.)</p>
<p>As an example, the element matrix entry
<span class="math">\(\int_{\Omega^{(e)}} {\varphi}_I{\varphi}_J{\, \mathrm{d}x}\)</span>
can be computed by setting
<span class="math">\(p=q=1\)</span> and <span class="math">\(r=0\)</span>, when <span class="math">\(I\neq J\)</span>, yielding <span class="math">\(\Delta/12\)</span>, and
<span class="math">\(p=2\)</span> and <span class="math">\(q=r=0\)</span>, when <span class="math">\(I=J\)</span>, resulting in <span class="math">\(\Delta/6\)</span>.
We collect these numbers in a local element matrix:</p>
<div class="math">
\[\begin{split}\frac{\Delta}{12}
\left[\begin{array}{ccc}
2 &amp; 1 &amp; 1\\
1 &amp; 2 &amp; 1\\
1 &amp; 1 &amp; 2
\end{array}\right]\end{split}\]</div>
<p>The common element matrix entry <span class="math">\(\int_{\Omega^{(e)}} \nabla{\varphi}_I\cdot\nabla{\varphi}_J{\, \mathrm{d}x}\)</span>, arising from a Laplace term <span class="math">\(\nabla^2u\)</span>, can also easily be
computed by the formulas above. We have</p>
<div class="math">
\[\nabla{\varphi}_I\cdot\nabla{\varphi}_J =
\frac{\Delta^2}{4}(\beta_I\beta_J + \gamma_I\gamma_J) = \hbox{const},\]</div>
<p>so that the element matrix entry becomes
<span class="math">\(\frac{1}{4}\Delta^3(\beta_I\beta_J + \gamma_I\gamma_J)\)</span>.</p>
<p>From an implementational point of view, one will work with local vertex
numbers <span class="math">\(r=0,1,2\)</span>, parameterize the coefficients in the basis
functions by <span class="math">\(r\)</span>, and look up vertex coordinates through <span class="math">\(q(e,r)\)</span>.</p>
</div>
</div>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><ul>
<li><p class="first">When approximating <span class="math">\(f\)</span> by <span class="math">\(u = \sum_j c_j{\varphi}_j\)</span>, the least squares
method and the Galerkin/projection method give the same result.
The interpolation/collocation method is simpler and yields different
(mostly inferior) results.</p>
</li>
<li><p class="first">Fourier series expansion can be viewed as a least squares or Galerkin
approximation procedure with sine and cosine functions.</p>
</li>
<li><p class="first">Basis functions should optimally be orthogonal or almost orthogonal,
because this gives little round-off errors when solving the linear
system, and the coefficient matrix becomes diagonal or sparse.</p>
</li>
<li><p class="first">Finite element basis functions are <em>piecewise</em> polynomials, normally
with discontinuous derivatives at the cell boundaries. The basis
functions overlap very little, leading to stable numerics and sparse
matrices.</p>
</li>
<li><p class="first">To use the finite element method for differential equations, we use
the Galerkin method or the method of weighted residuals
to arrive at a variational form. Technically, the differential equation
is multiplied by a test function and integrated over the domain.
Second-order derivatives are integrated by parts to allow for typical finite
element basis functions that have discontinuous derivatives.</p>
</li>
<li><p class="first">The least squares method is not much used for finite element solution
of differential equations of second order, because
it then involves second-order derivatives which cause trouble for
basis functions with discontinuous derivatives.</p>
</li>
<li><p class="first">We have worked with two common finite element terminologies and
associated data structures
(both are much used, especially the first one, while the other is more
general):</p>
<blockquote>
<div><ol class="arabic simple">
<li><em>elements</em>, <em>nodes</em>, and <em>mapping between local and global
node numbers</em></li>
<li>an extended element concept consisting of <em>cell</em>, <em>vertices</em>,
<em>degrees of freedom</em>, <em>local basis functions</em>,
<em>geometry mapping</em>, and <em>mapping between
local and global degrees of freedom</em></li>
</ol>
</div></blockquote>
</li>
<li><p class="first">The meaning of the word &#8220;element&#8221; is multi-fold: the geometry of a finite
element (also known as a cell), the geometry and its basis functions,
or all information listed under point 2 above.</p>
</li>
<li><p class="first">One normally computes integrals in the finite element method element
by element (cell by cell), either in a local reference coordinate
system or directly in the physical domain.</p>
</li>
<li><p class="first">The advantage of working in the reference coordinate system is that
the mathematical expressions for the basis functions depend on the
element type only, not the geometry of that element in the physical
domain.  The disadvantage is that a mapping must be used, and
derivatives must be transformed from reference to physical
coordinates.</p>
</li>
<li><p class="first">Element contributions to the global linear system are collected in
an element matrix and vector, which must be assembled into the
global system using the degree of freedom mapping (<tt class="docutils literal"><span class="pre">dof_map</span></tt>) or
the node numbering mapping (<tt class="docutils literal"><span class="pre">elements</span></tt>), depending on which terminology
that is used.</p>
</li>
<li><p class="first">Dirichlet conditions, involving prescribed values of <span class="math">\(u\)</span> at the
boundary, are implemented either via a boundary function that take
on the right Dirichlet values, while the basis functions vanish at
such boundaries. In the finite element method, one has a general
expression for the boundary function, but one can also incorporate
Dirichlet conditions in the element matrix and vector or in the
global matrix system.</p>
</li>
<li><p class="first">Neumann conditions, involving prescribed values of the derivative
(or flux) of <span class="math">\(u\)</span>, are incorporated in boundary terms arising from
integrating terms with second-order derivatives by part.
Forgetting to account for the boundary terms implies the
condition <span class="math">\(\partial u/\partial n=0\)</span> at parts of the boundary where
no Dirichlet condition is set.</p>
</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="time-dependent-problems">
<h1>Time-dependent problems<a class="headerlink" href="#time-dependent-problems" title="Permalink to this headline">¶</a></h1>
<p>The finite element method is normally used for discretization in
space. There are two alternative strategies for performing
a discretization in the time:</p>
<blockquote>
<div><ul class="simple">
<li>use finite differences for time derivatives to arrive at
a recursive set of spatial problems that can be discretized by
the finite element method, or</li>
<li>discretize in space by finite elements first, and then solve
the resulting system of ordinary differential equations (ODEs) by
some standard method for ODEs.</li>
</ul>
</div></blockquote>
<p>We shall exemplify these strategies using a simple diffusion problem</p>
<div class="math" id="equation-fem:deq:diffu:eq">
<span class="eqno">(101)</span>\[     \frac{\partial u}{\partial t} = \alpha\nabla^2 u + f(\boldsymbol{x}, t),\quad \boldsymbol{x}\in\Omega, t\in (0,T],\]</div>
<div class="math" id="equation-fem:deq:diffu:ic">
<span class="eqno">(102)</span>\[     u(\boldsymbol{x}, 0)  = I(\boldsymbol{x}),\quad \boldsymbol{x}\in\Omega,\]</div>
<div class="math" id="equation-fem:deq:diffu:bcN">
<span class="eqno">(103)</span>\[     \frac{\partial u}{\partial n} = 0,\quad\boldsymbol{x}\in\partial\Omega,\ t\in (0,T]\]\[     {\thinspace .}\]</div>
<p>Here, <span class="math">\(u(\boldsymbol{x},t)\)</span> is the unknown function, <span class="math">\(\alpha\)</span> is a constant, and
<span class="math">\(f(\boldsymbol{x},t)\)</span> and <span class="math">\(I(x)\)</span> are given functions. We have assigned the particular
boundary condition <a href="#equation-fem:deq:diffu:bcN">(103)</a> to minimize
the details on handling boundary conditions in the finite element method.</p>
<div class="section" id="discretization-in-time-by-a-forward-euler-scheme">
<h2>Discretization in time by a Forward Euler scheme<a class="headerlink" href="#discretization-in-time-by-a-forward-euler-scheme" title="Permalink to this headline">¶</a></h2>
<div class="section" id="time-discretization-1">
<h3>Time discretization  (1)<a class="headerlink" href="#time-discretization-1" title="Permalink to this headline">¶</a></h3>
<p>We can apply a finite difference method in time to <a href="#equation-fem:deq:diffu:eq">(101)</a>.
First we need a mesh in time, here taken as uniform with
mesh points <span class="math">\(t_n = n\Delta t\)</span>, <span class="math">\(n=0,1,\ldots,N_t\)</span>.
A Forward Euler scheme consists of sampling <a href="#equation-fem:deq:diffu:eq">(101)</a>
at <span class="math">\(t_n\)</span> and approximating the time derivative by a forward
difference <span class="math">\([D_t^+ u]^n\approx
(u^{n+1}-u^n)/\Delta t\)</span>. This approximation turns <a href="#equation-fem:deq:diffu:eq">(101)</a>
into a differential equation that is discrete in time, but still
continuous in space.
With a finite difference operator notation we can write the
time-discrete problem as</p>
<div class="math">
\[[D_t^+ u = \alpha\nabla^2 u + f(\boldsymbol{x}, t)]^n,\]</div>
<p>for <span class="math">\(n=1,2,\ldots,N_t-1\)</span>. Writing this equation out in detail and
isolating the unknown <span class="math">\(u^{n+1}\)</span> on the left-hand side, demonstrates that
the time-discrete problem is a recursive set of problems that are
continuous in space:</p>
<div class="math" id="equation-fem:deq:diffu:FE:eq:unp1">
<span class="eqno">(104)</span>\[     u^{n+1} = u^n + \Delta t \left( \alpha\nabla^2 u^n + f(\boldsymbol{x}, t_n)\right)\]\[     {\thinspace .}\]</div>
<p>Given <span class="math">\(u^0=I\)</span>, we can use <a href="#equation-fem:deq:diffu:FE:eq:unp1">(104)</a> to compute
<span class="math">\(u^1,u^2,\dots,u^{N_t}\)</span>.</p>
<p>For absolute clarity in the various stages of the discretizations, we
introduce <span class="math">\({u_{\small\mbox{e}}}(\boldsymbol{x},t)\)</span> as the exact solution of the space-and time-continuous
partial differential equation <a href="#equation-fem:deq:diffu:eq">(101)</a> and
<span class="math">\({u_{\small\mbox{e}}}^n(\boldsymbol{x})\)</span> as the time-discrete approximation, arising from the finite
difference method in time <a href="#equation-fem:deq:diffu:FE:eq:unp1">(104)</a>.
More precisely, <span class="math">\({u_{\small\mbox{e}}}\)</span> fulfills and <span class="math">\({u_{\small\mbox{e}}}^n\)</span> we have</p>
<div class="math" id="equation-fem:deq:diffu:eq:uex">
<span class="eqno">(105)</span>\[     \frac{\partial {u_{\small\mbox{e}}}}{\partial t} = \alpha\nabla^2 {u_{\small\mbox{e}}} + f(\boldsymbol{x}, t)
     ,\]</div>
<p>while <span class="math">\({u_{\small\mbox{e}}}\)</span> with superscript is the solution of the time-discrete equations</p>
<div class="math" id="equation-fem:deq:diffu:FE:eq:uex:n">
<span class="eqno">(106)</span>\[     {u_{\small\mbox{e}}}^{n+1} = {u_{\small\mbox{e}}}^n + \Delta t \left( \alpha\nabla^2 {u_{\small\mbox{e}}}^n + f(\boldsymbol{x}, t_n)\right)\]\[     {\thinspace .}\]</div>
</div>
<div class="section" id="space-discretization">
<h3>Space discretization<a class="headerlink" href="#space-discretization" title="Permalink to this headline">¶</a></h3>
<p>We now introduce a finite element approximation to <span class="math">\({u_{\small\mbox{e}}}^n\)</span> and <span class="math">\({u_{\small\mbox{e}}}^{n+1}\)</span>
in <a href="#equation-fem:deq:diffu:FE:eq:uex:n">(106)</a>, where the coefficients depend on the
time level:</p>
<div class="math" id="equation-fem:deq:diffu:femapprox:n">
<span class="eqno">(107)</span>\[     {u_{\small\mbox{e}}}^n \approx u^n = \sum_{j=0}^{N_s} c_j^{n}{\varphi}_j(\boldsymbol{x}),\]</div>
<div class="math" id="equation-fem:deq:diffu:femapprox:np1">
<span class="eqno">(108)</span>\[     {u_{\small\mbox{e}}}^{n+1} \approx u^{n+1} = \sum_{j=0}^{N_s} c_j^{n+1}{\varphi}_j(\boldsymbol{x})\]\[     {\thinspace .}\]</div>
<p>Note that we have introduced <span class="math">\(N_s\)</span> as the number of degrees of freedom
in the spatial (s) domain. The number of time points is denoted by <span class="math">\(N\)</span>.
Also note that we use <span class="math">\(u^n\)</span> as the numerical solution we want
to compute in a program, while <span class="math">\({u_{\small\mbox{e}}}\)</span> and <span class="math">\({u_{\small\mbox{e}}}^n\)</span> are used when
we occasionally
need to refer to the exact solution and the time-discrete solution,
respectively.</p>
</div>
<div class="section" id="variational-forms-1">
<h3>Variational forms  (1)<a class="headerlink" href="#variational-forms-1" title="Permalink to this headline">¶</a></h3>
<p>A weighted residual method with weighting functions <span class="math">\(w_i\)</span> can
now be formulated. We insert <a href="#equation-fem:deq:diffu:femapprox:n">(107)</a> and
<a href="#equation-fem:deq:diffu:femapprox:np1">(108)</a> in
<a href="#equation-fem:deq:diffu:FE:eq:uex:n">(106)</a> to obtain the residual</p>
<div class="math">
\[R = u^{n+1} - u^n - \Delta t \left( \alpha\nabla^2 u^n + f(\boldsymbol{x}, t_n)\right)
{\thinspace .}\]</div>
<p>The weighted residual principle,</p>
<div class="math">
\[\int_\Omega Rw_i{\, \mathrm{d}x} = 0,\quad i=0,\ldots,N_s,\]</div>
<p>results in</p>
<div class="math">
\[\int_\Omega
\left\lbrack
u^{n+1} - u^n - \Delta t \left( \alpha\nabla^2 u^n + f(\boldsymbol{x}, t_n)\right)
\right\rbrack w_i {\, \mathrm{d}x} =0,\]</div>
<p>for <span class="math">\(i=0,\ldots,N_s\)</span>.</p>
<p>The Galerkin method corresponds to choosing <span class="math">\(w_i={\psi}_i\)</span>.
Isolating the unknown <span class="math">\(u^{n+1}\)</span> on the left-hand side gives</p>
<div class="math">
\[\int_{\Omega} u^{n+1}{\psi}_i{\, \mathrm{d}x} = \int_{\Omega}
\left\lbrack u^n - \Delta t \left( \alpha\nabla^2 u^n + f(\boldsymbol{x}, t_n)\right)
\right\rbrack{\psi}_i{\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>As usual in spatial finite element problems involving second-order
derivatives, we apply integration by parts on the term <span class="math">\(\nabla^2 u^n{\psi}_i\)</span>:</p>
<div class="math">
\[\int_{\Omega}\alpha\nabla^2 u^n{\psi}_i {\, \mathrm{d}x} =
-\int_{\Omega}\alpha\nabla u^n\cdot\nabla{\psi}_i{\, \mathrm{d}x} +
\int_{\partial\Omega}\alpha\frac{\partial u^n}{\partial n}{\psi} {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>The last term vanishes because we have the Neumann condition
<span class="math">\(\partial u^n/\partial n=0\)</span> for all <span class="math">\(n\)</span>. Our discrete problem in
space and time then reads</p>
<div class="math" id="equation-fem:deq:diffu:FE:vf:u:np1">
<span class="eqno">(109)</span>\[     \int_{\Omega} u^{n+1}{\psi}_i{\, \mathrm{d}x} =
     \int_{\Omega} u^n{\psi}_i{\, \mathrm{d}x} -
     \Delta t \int_{\Omega}\alpha\nabla u^n\cdot\nabla{\psi}_i{\, \mathrm{d}x} +
     \Delta t\int_{\Omega}f^n{\psi}_i{\, \mathrm{d}x}
     {\thinspace .}\]</div>
<p>This is the variational formulation of our recursive set of spatial
problems.</p>
<p>In a program it is only necessary to store <span class="math">\(u^{n+1}\)</span> and <span class="math">\(u^n\)</span> at the
same time. We therefore drop the <span class="math">\(n\)</span> index in programs and work with
two functions: <tt class="docutils literal"><span class="pre">u</span></tt> for <span class="math">\(u^{n+1}\)</span>, the new unknown, and <tt class="docutils literal"><span class="pre">u_1</span></tt> for
<span class="math">\(u^n\)</span>, the solution at the previous time level. This is also
convenient in the mathematics to maximize the correspondence with the
code. From now on <span class="math">\(u_1\)</span> means the discrete unknown at the previous
time level, <span class="math">\(u^{n}\)</span>, and <span class="math">\(u\)</span> represents the
discrete unknown at the new time level, <span class="math">\(u^{n+1}\)</span>.</p>
<div class="math" id="equation-fem:deq:diffu:FE:vf:u">
<span class="eqno">(110)</span>\[     \int_{\Omega} u{\psi}_i{\, \mathrm{d}x} =
     \int_{\Omega} u_1{\psi}_i{\, \mathrm{d}x} -
     \Delta t \int_{\Omega}\alpha\nabla u_1\cdot\nabla{\psi}_i{\, \mathrm{d}x} +
     \Delta t\int_{\Omega}f^n{\psi}_i{\, \mathrm{d}x}
     {\thinspace .}\]</div>
<p>This variational form can alternatively be expressed by the inner
product notation:</p>
<div class="math" id="equation-fem:deq:diffu:FE:vf:u:short">
<span class="eqno">(111)</span>\[     (u, {\psi}_i) = (u_1,{\psi}_i) -
     \Delta t (\alpha\nabla u_1,\nabla{\psi}_i) +
     (f^n,{\psi}_i)
     {\thinspace .}\]</div>
</div>
<div class="section" id="linear-systems-1">
<h3>Linear systems  (1)<a class="headerlink" href="#linear-systems-1" title="Permalink to this headline">¶</a></h3>
<p>To derive the equations for the new unknown coefficients <span class="math">\(c_j^{n+1}\)</span>,
now just called <span class="math">\(c_j\)</span>, we insert</p>
<div class="math">
\[u = \sum_{j=0}^{N_s}c_j{\psi}_j(\boldsymbol{x}),\quad
u_1 = \sum_{j=0}^{N_s} c_{1,j}{\psi}(\boldsymbol{x})\]</div>
<p>in <a href="#equation-fem:deq:diffu:FE:vf:u">(110)</a> or <a href="#equation-fem:deq:diffu:FE:vf:u:short">(111)</a>,
and order the terms as matrix-vector products:</p>
<div class="math">
\[\sum_{j=0}^{N_s} ({\psi}_i,{\psi}_j) c_j =
\sum_{j=0}^{N_s} ({\psi}_i,{\psi}_j) c_{1,j}
-\Delta t\alpha \sum_{j=0}^{N_s} (\nabla{\psi}_i,\nabla{\psi}_j) c_{1,j}
+ (f^n,{\psi}_i),\quad i=0,\ldots,N_s
{\thinspace .}\]</div>
<p>This is a linear system <span class="math">\(\sum_j A_{i,j} = b_i\)</span> with</p>
<div class="math">
\[A_{i,j} = ({\psi}_i,{\psi}_j)\]</div>
<p>and</p>
<div class="math">
\[b_i = \sum_{j=0}^{N_s} ({\psi}_i,{\psi}_j) c_{1,j}
-\Delta t\alpha \sum_{j=0}^{N_s} (\nabla{\psi}_i,\nabla{\psi}_j) c_{1,j}
+ (f^n,{\psi}_i){\thinspace .}\]</div>
<p>It is instructive and convenient for implementations to write the linear
system on the form</p>
<div class="math">
\[Mc = Mc_1 - \alpha\Delta t Kc_1 + f,\]</div>
<p>where</p>
<div class="math">
\[\begin{split}f &amp;= ((f(\boldsymbol{x},t_n),{\psi}_i), \ldots, (f(\boldsymbol{x},t_n),{\psi}_{N_s})),\\
c &amp;=(c_0,\ldots,c_{N_s}),\\
c_1 &amp;= (c_{1,j},\ldots,c_{1,N_s}),\end{split}\]</div>
<p>and <span class="math">\(M\)</span> and <span class="math">\(K\)</span> are matrices,</p>
<span class="target" id="index-76"></span><div class="math" id="index-77">
\[M_{i,j} = ({\psi}_i,{\psi}_j),\quad
K_{i,j} =(\nabla{\psi}_i,\nabla{\psi}_j)
{\thinspace .}\]</div>
<p>We realize that <span class="math">\(M\)</span> is the matrix arising from a term with the
zero-th derivative of <span class="math">\(u\)</span>, and called the mass matrix, while <span class="math">\(K\)</span> is
the matrix arising from a Laplace term <span class="math">\(\nabla^2 u\)</span>. The <span class="math">\(K\)</span> matrix
is often known as the <em>stiffness matrix</em>. (The terms mass and stiffness
stem from the early days of finite elements when applications to
vibrating structures dominated. The mass matrix arises from the
mass times acceleration term in Newton&#8217;s second law, while the stiffness
matrix arises from the elastic forces in that law. The mass and stiffness
matrix appearing in a diffusion have slightly different mathematical
formulas.)</p>
<p><strong>Remark.</strong>
The mathematical symbol <span class="math">\(f\)</span> has two meanings, either the
function <span class="math">\(f(\boldsymbol{x},t)\)</span> in the PDE or the <span class="math">\(f\)</span> vector in the linear system
to be solved at each time level. The symbol <span class="math">\(u\)</span> also has different
meanings, basically the unknown in the PDE or the finite element
function representing the unknown at a time level. The actual
meaning should be evident from the context.</p>
</div>
<div class="section" id="computational-algorithm">
<h3>Computational algorithm<a class="headerlink" href="#computational-algorithm" title="Permalink to this headline">¶</a></h3>
<p>We observe that <span class="math">\(M\)</span> and <span class="math">\(K\)</span> can be precomputed so that we can avoid
assembly of the matrix system at every time level. Instead, some
matrix-vector multiplications will produce the linear system to be solved.
The computational algorithm has the following steps:</p>
<ol class="arabic simple">
<li>Compute <span class="math">\(M\)</span> and <span class="math">\(K\)</span>.</li>
<li>Initialize <span class="math">\(u^0\)</span> by</li>
</ol>
<blockquote>
<div><ol class="arabic simple">
<li>interpolation: <span class="math">\(c_{1,j} = I(\boldsymbol{x}_j)\)</span>, where <span class="math">\(\boldsymbol{x}_j\)</span> is node number <span class="math">\(j\)</span>, or</li>
<li>projection: solve
<span class="math">\(\sum_j M_{i,j}c_{1,j} = (I,{\psi}_i)\)</span>, <span class="math">\(i=0,\ldots,N_s\)</span>.</li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="3">
<li>For <span class="math">\(n=1,2,\ldots,N_t\)</span>:</li>
</ol>
<blockquote>
<div><ol class="arabic simple">
<li>compute <span class="math">\(b = Mc_1 - \alpha\Delta t Kc_1 + f\)</span></li>
<li>solve <span class="math">\(Mc = b\)</span></li>
<li>set <span class="math">\(c_1 = c\)</span></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="comparison-with-the-finite-difference-method">
<h3>Comparison with the finite difference method<a class="headerlink" href="#comparison-with-the-finite-difference-method" title="Permalink to this headline">¶</a></h3>
<p>We can compute the <span class="math">\(M\)</span> and <span class="math">\(K\)</span> matrices using P1 elements.
From the section <a class="reference internal" href="#fem-deq-1d-comp-global"><em>Computation in the global physical domain</em></a> or
<a class="reference internal" href="#fem-deq-1d-comp-elmwise"><em>Cellwise computations  (1)</em></a> we have that the <span class="math">\(K\)</span> matrix is the same as we get
from the finite difference method: <span class="math">\(h[D_xD_x u]^n_i\)</span>, while
from the section <a class="reference internal" href="#fem-approx-fe-fd-feproj"><em>Finite difference interpretation of a finite element approximation</em></a> we know that <span class="math">\(M\)</span> can be
interpreted as the finite difference approximation:
<span class="math">\([u - \frac{1}{6}h^2D_xD_x u]^n_i\)</span>. The equation system <span class="math">\(Mc=b\)</span> in
the algorithm is therefore equivalent to the finite difference scheme</p>
<div class="math" id="equation-fem:deq:diffu:FE:fdinterp">
<span class="eqno">(112)</span>\[     [D_t^+(u - \frac{1}{6}h^2D_xD_x u) = \alpha D_xD_x u + f]^n_i\]\[     {\thinspace .}\]</div>
</div>
<div class="section" id="lumping-the-mass-matrix">
<h3>Lumping the mass matrix<a class="headerlink" href="#lumping-the-mass-matrix" title="Permalink to this headline">¶</a></h3>
<p>By applying Trapezoidal integration or summing the rows in <span class="math">\(M\)</span> and placing
the sum on the main diagonal, one can turn <span class="math">\(M\)</span> into a diagonal
matrix with <span class="math">\((h/2,h,\ldots,h,h/2)\)</span> on the diagonal. Then there are
no needs to solve a linear system at each time level, and the finite
element scheme becomes identical to a standard finite difference method</p>
<div class="math" id="equation-fem:deq:diffu:FE:fdinterp:lumped">
<span class="eqno">(113)</span>\[     [D_t^+ u = \alpha D_xD_x u + f]^n_i\]\[     {\thinspace .}\]</div>
</div>
</div>
<div class="section" id="discretization-in-time-by-a-backward-euler-scheme">
<h2>Discretization in time by a Backward Euler scheme<a class="headerlink" href="#discretization-in-time-by-a-backward-euler-scheme" title="Permalink to this headline">¶</a></h2>
<div class="section" id="time-discretization-2">
<h3>Time discretization  (2)<a class="headerlink" href="#time-discretization-2" title="Permalink to this headline">¶</a></h3>
<p>The Backward Euler scheme in time applied to our diffusion problem
can be expressed as follows using the finite difference operator notation:</p>
<div class="math">
\[[D_t^- u = \alpha\nabla^2 u + f(\boldsymbol{x}, t)]^n
{\thinspace .}\]</div>
<p>Written out, and collecting the unknown <span class="math">\(u^n\)</span> on the left-hand side,
the time-discrete differential equation becomes</p>
<div class="math" id="equation-fem:deq:diffu:BE:eq:un">
<span class="eqno">(114)</span>\[     u^{n} - \Delta t \left( \alpha\nabla^2 u^n + f(\boldsymbol{x}, t_{n})\right) = u^{n-1}\]\[     {\thinspace .}\]</div>
<p>Equation <a href="#equation-fem:deq:diffu:BE:eq:un">(114)</a> can compute
<span class="math">\(u^1,u^2,\dots,u^{N_t}\)</span>, if we have a start <span class="math">\(u^0=I\)</span> from the initial condition.</p>
</div>
<div class="section" id="variational-forms-2">
<h3>Variational forms  (2)<a class="headerlink" href="#variational-forms-2" title="Permalink to this headline">¶</a></h3>
<p>The Galerkin method applied to <a href="#equation-fem:deq:diffu:BE:eq:un">(114)</a> and
integrating by parts, as in the Forward Euler case, results
in the variational form</p>
<div class="math" id="equation-fem:deq:diffu:BE:vf:u:n">
<span class="eqno">(115)</span>\[     \int_{\Omega} \left( u^{n}{\psi}_i
     + \Delta t \alpha\nabla u^n\cdot\nabla{\psi}_i\right){\, \mathrm{d}x}
     = \int_{\Omega} u^{n-1}{\psi}_i{\, \mathrm{d}x} -
     \Delta t\int_{\Omega}f^n{\psi}_i{\, \mathrm{d}x}\]\[     {\thinspace .}\]</div>
<p>Expressed with <span class="math">\(u\)</span> as <span class="math">\(u^n\)</span> and <span class="math">\(u_1\)</span> as <span class="math">\(u^{n-1}\)</span>, this becomes</p>
<div class="math" id="equation-fem:deq:diffu:BE:vf:u">
<span class="eqno">(116)</span>\[     \int_{\Omega} \left( u{\psi}_i
     + \Delta t \alpha\nabla u\cdot\nabla{\psi}_i\right){\, \mathrm{d}x}
     = \int_{\Omega} u_1{\psi}_i{\, \mathrm{d}x} +
     \Delta t\int_{\Omega}f^n{\psi}_i{\, \mathrm{d}x},\]</div>
<p>or</p>
<div class="math" id="equation-fem:deq:diffu:BE:vf:u:short">
<span class="eqno">(117)</span>\[     (u,{\psi}_i)
     + \Delta t \alpha(\nabla u,\nabla{\psi}_i)
     = (u_1{\psi}_i) +
     \Delta t (f^n,{\psi}_i)\]\[     {\thinspace .}\]</div>
</div>
<div class="section" id="linear-systems-2">
<h3>Linear systems  (2)<a class="headerlink" href="#linear-systems-2" title="Permalink to this headline">¶</a></h3>
<p>Inserting <span class="math">\(u=\sum_j c_j{\psi}_i\)</span> and <span class="math">\(u_1=\sum_j c_{1,j}{\psi}_i\)</span>,
we arrive after some algebra at the following linear system to be
solved at each time level:</p>
<div class="math">
\[(M + \Delta t \alpha K)c = Mc_1 + f,\]</div>
<p>where <span class="math">\(M\)</span>, <span class="math">\(K\)</span>, and <span class="math">\(f\)</span> are as in the Forward Euler case.
This time we really have to solve a linear system at each time level.
The system corresponds to solving the finite difference problem</p>
<div class="math" id="equation-fem:deq:diffu:BE:fdinterp">
<span class="eqno">(118)</span>\[     [D_t^-(u - \frac{1}{6}h^2D_xD_x u) = \alpha D_xD_x u + f]^n_i\]\[     {\thinspace .}\]</div>
<p>The mass matrix <span class="math">\(M\)</span> can be lumped, and then the linear system corresponds
to a plain Backward Euler finite difference method for the diffusion equation:</p>
<div class="math" id="equation-fem:deq:diffu:BE:fdinterp:lumped">
<span class="eqno">(119)</span>\[     [D_t^- u = \alpha D_xD_x u + f]^n_i\]\[     {\thinspace .}\]</div>
</div>
</div>
<div class="section" id="analysis-of-the-discrete-equations">
<h2>Analysis of the discrete equations<a class="headerlink" href="#analysis-of-the-discrete-equations" title="Permalink to this headline">¶</a></h2>
<p>Let us see how a typical numerical wave component</p>
<div class="math" id="equation-fem:deq:diffu:analysis:uni">
<span class="eqno">(120)</span>\[     u^n_q = A^n e^{ikq\Delta x} = A^ne^{ikx},\]</div>
<p>is treated by the schemes. With the results</p>
<div class="math">
\[\begin{split}[D_t^+ A^n e^{ikq\Delta x}]^n &amp;= A^n e^{ikq\Delta x}\frac{A-1}{\Delta t},\\
[D_t^- A^n e^{ikq\Delta x}]^n &amp;= A^n e^{ikq\Delta x}\frac{1-A^{-1}}{\Delta t},\\
[D_t A^n e^{ikq\Delta x}]^{n+\frac{1}{2}} &amp;= A^{n+\frac{1}{2}} e^{ikq\Delta x}\frac{A^{\frac{1}{2}}-A^{-\frac{1}{2}}}{\Delta t} = A^ne^{ikq\Delta x}\frac{A-1}{\Delta t},\\
[D_xD_x A^ne^{ikq\Delta x}]_q &amp;= -A^n \frac{4}{\Delta x^2}\sin^2\left(\frac{k\Delta x}{2}\right),\end{split}\]</div>
<p>we can start inserting <a href="#equation-fem:deq:diffu:analysis:uni">(120)</a> in the
Forward Euler scheme with P1 elements in space and <span class="math">\(f=0\)</span>,</p>
<div class="math" id="equation-fem:deq:diffu:FE:fdinterp2">
<span class="eqno">(121)</span>\[     [D_t^+(u - \frac{1}{6}h^2D_xD_x u) = \alpha D_xD_x u]^n_q\]\[     {\thinspace .}\]</div>
<p>We have</p>
<div class="math">
\[[D_t^+D_xD_x Ae^{ikx}]^n_q = [D_t^+A]^n [D_xD_x e^{ikx}]_q
= -A^ne^{ikp\Delta x}
\frac{A-1}{\Delta t}\frac{4}{\Delta x^2}\sin^2 (\frac{k\Delta x}{2})
{\thinspace .}\]</div>
<p>The term <span class="math">\([D_t^+A^ne^{ikx} - \frac{1}{6}\Delta x^2 D_t^+D_xD_x Ae^{ikx}]^n_q\)</span>
then reduces to</p>
<div class="math">
\[\frac{A-1}{\Delta t} + \frac{1}{6}\Delta x^2 \frac{A-1}{\Delta t}
\frac{4}{\Delta x^2}\sin^2 (\frac{k\Delta x}{2}),\]</div>
<p>or</p>
<div class="math">
\[\frac{A-1}{\Delta t} \left(1 + \frac{2}{3}\sin^2 (k\Delta x/2)\right)
{\thinspace .}\]</div>
<p>The complete scheme becomes</p>
<div class="math">
\[(A-1) \left(1 + \frac{2}{3}\sin^2 (k\Delta x/2)\right)
= -4C\sin^2 (k\Delta x/2),\]</div>
<p>which we then solve for <span class="math">\(A\)</span>,</p>
<div class="math">
\[A = 1 - 4C\frac{\sin^2 (k\Delta x/2)}{1 + \frac{2}{3}\sin^2 (k\Delta x/2)}
{\thinspace .}\]</div>
<p>How does this <span class="math">\(A\)</span> change the stability criterion compared to the
Forward Euler finite difference scheme and centered differences in
space? The stability criterion is <span class="math">\(-1&lt;A\)</span>, meaning</p>
<div class="math">
\[4C\frac{\sin^2 (p/2}{1 + \frac{2}{3}\sin^2 (p/2)} \leq 2,\]</div>
<p>with <span class="math">\(p=k\Delta x\)</span>. The factor <span class="math">\(\sin^2 (p/2)/(1 + \frac{2}{3}\sin^2 (p/2))\)</span>
can be plotted for <span class="math">\(p\in [0,\pi ]\)</span>, and the maximum value goes to 3/5
as <span class="math">\(p\rightarrow \pi\)</span>. The worst case for stability therefore occurs for
the shortest waves, and the stability criterion becomes</p>
<div class="math">
\[C\leq \frac{5}{6}\quad\Rightarrow\quad \Delta t\leq \frac{5\Delta x^2}{6\alpha},\]</div>
<p>which is a factor 5/3 better than for the standard Forward Euler
finite difference method for the diffusion equation.
Lumping the mass matrix will, however, recover the finite difference
method and imply <span class="math">\(C\leq 1/2\)</span> for stability.</p>
<p>For the Backward Euler scheme</p>
<div class="math" id="equation-fem:deq:diffu:BE:fdinterp2">
<span class="eqno">(122)</span>\[     [D_t^-(u - \frac{1}{6}h^2D_xD_x u) = \alpha D_xD_x u]^n_i\]\[     {\thinspace .}\]</div>
<p>we get</p>
<div class="math">
\[(1-A^{-1}) \left(1 + \frac{2}{3}\sin^2 (k\Delta x/2)\right)
= -4C\sin^2 (k\Delta x/2),\]</div>
<p>and hence</p>
<div class="math">
\[A = \left( 1 + 4C\frac{\sin^2 (k\Delta x/2)}{(1 + \frac{2}{3}\sin^2 (k\Delta x/2))}\right)^{-1}
{\thinspace .}\]</div>
<p><strong>Remaining tasks</strong>:</p>
<blockquote>
<div><ul class="simple">
<li>Plot <span class="math">\(A\)</span> vs <span class="math">\({A_{\small\mbox{e}}}\)</span> for finite elements and finite differences
for each of the time schemes.</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="systems-of-differential-equations">
<span id="fem-sys"></span><h1>Systems of differential equations<a class="headerlink" href="#systems-of-differential-equations" title="Permalink to this headline">¶</a></h1>
<p>Many mathematical models involve <span class="math">\(m+1\)</span> unknown functions
governed by a system of <span class="math">\(m+1\)</span> differential equations. In abstract form
we may denote the unknowns by <span class="math">\(u^{(0)},\ldots,
u^{(m)}\)</span> and write the governing equations as</p>
<div class="math">
\[\begin{split}\mathcal{L}_0(u^{(0)},\ldots,u^{(m)}) &amp;= 0,\\
&amp;\vdots\\
\mathcal{L}_{m}(u^{(0)},\ldots,u^{(m)}) &amp;= 0,\end{split}\]</div>
<p>where <span class="math">\(\mathcal{L}_i\)</span> is some differential operator defining differential
equation number <span class="math">\(i\)</span>.</p>
<div class="section" id="variational-forms-3">
<span id="fem-sys-vform"></span><h2>Variational forms  (3)<a class="headerlink" href="#variational-forms-3" title="Permalink to this headline">¶</a></h2>
<p>There are basically two ways of formulating a variational form
for a system of differential equations. The first method treats
each equation independently as a scalar equation, while the other
method views the total system as a vector equation with a vector function
as unknown.</p>
<p>Let us start with the one equation at a time approach.
We multiply equation number <span class="math">\(i\)</span> by
some test function <span class="math">\(v^{(i)}\in V^{(i)}\)</span> and integrate over the domain:</p>
<div class="math" id="equation-fem:sys:vform:1by1a">
<span class="eqno">(123)</span>\[     \int_\Omega \mathcal{L}^{(0)}(u^{(0)},\ldots,u^{(m)}) v^{(0)}{\, \mathrm{d}x} = 0,\]</div>
<div class="math">
\[\vdots\]</div>
<div class="math" id="equation-fem:sys:vform:1by1b">
<span class="eqno">(124)</span>\[     \int_\Omega \mathcal{L}^{(m)}(u^{(0)},\ldots,u^{(m)}) v^{(m)}{\, \mathrm{d}x} = 0\]\[     {\thinspace .}\]</div>
<p>Terms with second-order derivatives may be integrated by parts, with
Neumann conditions inserted in boundary integrals.
Let</p>
<div class="math">
\[V^{(i)} = \hbox{span}\{{\psi}_0^{(i)},\ldots,{\psi}_{N_i}^{(i)}\},\]</div>
<p>such that</p>
<div class="math">
\[u^{(i)} = B^{(i)}(\boldsymbol{x}) + \sum_{j=0}^{N_i} c_j^{(i)} {\psi}_j^{(i)}(\boldsymbol{x}),\]</div>
<p>where <span class="math">\(B^{(i)}\)</span> is a boundary function to handle nonzero Dirichlet conditions.
Observe that different unknowns live in different spaces with different
basis functions and numbers of degrees of freedom.</p>
<p>From the <span class="math">\(m\)</span> equations in the variational forms we can derive
<span class="math">\(m\)</span> coupled systems of algebraic equations for the
<span class="math">\(\Pi_{i=0}^{m} N_i\)</span> unknown coefficients <span class="math">\(c_j^{(i)}\)</span>, <span class="math">\(j=0,\ldots,N_i\)</span>,
<span class="math">\(i=0,\ldots,m\)</span>.</p>
<p>The alternative method for deriving a variational form for a system of
differential equations introduces a vector of unknown functions</p>
<div class="math">
\[\boldsymbol{u} = (u^{(0)},\ldots,u^{(m)}),\]</div>
<p>a vector of test functions</p>
<div class="math">
\[\boldsymbol{v} = (u^{(0)},\ldots,u^{(m)}),\]</div>
<p>with</p>
<div class="math">
\[\boldsymbol{u}, \boldsymbol{v} \in  \boldsymbol{V} = V^{(0)}\times \cdots \times V^{(m)}
{\thinspace .}\]</div>
<p>With nonzero Dirichlet conditions, we have a vector
<span class="math">\(\boldsymbol{B} = (B^{(0)},\ldots,B^{(m)})\)</span> with boundary functions and then
it is <span class="math">\(\boldsymbol{u} - \boldsymbol{B}\)</span> that lies in <span class="math">\(\boldsymbol{V}\)</span>, not <span class="math">\(\boldsymbol{u}\)</span> itself.</p>
<p>The governing system of differential equations is written</p>
<div class="math">
\[\boldsymbol{\mathcal{L}}(\boldsymbol{u} ) = 0,\]</div>
<p>where</p>
<div class="math">
\[\boldsymbol{\mathcal{L}}(\boldsymbol{u} ) = (\mathcal{L}^{(0)}(\boldsymbol{u}),\ldots, \mathcal{L}^{(m)}(\boldsymbol{u}))
{\thinspace .}\]</div>
<p>The variational form is derived by taking the inner product of
the vector of equations and the test function vector:</p>
<div class="math" id="equation-fem:sys:vform:inner">
<span class="eqno">(125)</span>\[     \int_\Omega \boldsymbol{\mathcal{L}}(\boldsymbol{u} )\cdot\boldsymbol{v} = 0\quad\forall\boldsymbol{v}\in\boldsymbol{V}{\thinspace .}\]</div>
<p>Observe that <a href="#equation-fem:sys:vform:inner">(125)</a> is one scalar equation. To derive
systems of algebraic equations for the unknown coefficients in the
expansions of the unknown functions, one chooses <span class="math">\(m\)</span> linearly
independent <span class="math">\(\boldsymbol{v}\)</span> vectors to generate <span class="math">\(m\)</span> independent variational forms
from <a href="#equation-fem:sys:vform:inner">(125)</a>.  The particular choice <span class="math">\(\boldsymbol{v} =
(v^{(0)},0,\ldots,0)\)</span> recovers <a href="#equation-fem:sys:vform:1by1a">(123)</a>, <span class="math">\(\boldsymbol{v} =
(0,\ldots,0,v^{(m)}\)</span> recovers <a href="#equation-fem:sys:vform:1by1b">(124)</a>, and <span class="math">\(\boldsymbol{v} =
(0,\ldots,0,v^{(i)},0,\ldots,0)\)</span> recovers the variational form number
<span class="math">\(i\)</span>, <span class="math">\(\int_\Omega \mathcal{L}^{(i)} v^{(i)}{\, \mathrm{d}x} =0\)</span>, in
<a href="#equation-fem:sys:vform:1by1a">(123)</a>-<a href="#equation-fem:sys:vform:1by1b">(124)</a>.</p>
</div>
<div class="section" id="a-worked-example">
<span id="fem-sys-ut-ex"></span><h2>A worked example<a class="headerlink" href="#a-worked-example" title="Permalink to this headline">¶</a></h2>
<p>We now consider a specific system of two partial differential equations
in two space dimensions:</p>
<div class="math" id="equation-fem:sys:wT:ex:weq">
<span class="eqno">(126)</span>\[     \mu \nabla^2 w = -\beta,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:Teq">
<span class="eqno">(127)</span>\[     \kappa\nabla^2 T = - \mu ||\nabla w||^2
     {\thinspace .}\]</div>
<p>The unknown functions <span class="math">\(w(x,y)\)</span> and <span class="math">\(T(x,y)\)</span> are defined in a domain <span class="math">\(\Omega\)</span>,
while <span class="math">\(\mu\)</span>, <span class="math">\(\beta\)</span>,
and <span class="math">\(\kappa\)</span> are given constants. The norm in
<a href="#equation-fem:sys:wT:ex:Teq">(127)</a> is the standard Eucledian norm:</p>
<div class="math">
\[||\nabla w||^2 = \nabla w\cdot\nabla w = w_x^2 + w_y^2
{\thinspace .}\]</div>
<p>The boundary conditions associated with
<a href="#equation-fem:sys:wT:ex:weq">(126)</a>-<a href="#equation-fem:sys:wT:ex:Teq">(127)</a> are <span class="math">\(w=0\)</span> on
<span class="math">\(\partial\Omega\)</span> and <span class="math">\(T=T_0\)</span> on <span class="math">\(\partial\Omega\)</span>.
Each of the equations <a href="#equation-fem:sys:wT:ex:weq">(126)</a> and <a href="#equation-fem:sys:wT:ex:Teq">(127)</a>
need one condition at each point on the boundary.</p>
<p>The system <a href="#equation-fem:sys:wT:ex:weq">(126)</a>-<a href="#equation-fem:sys:wT:ex:Teq">(127)</a> arises
from fluid flow in a straight pipe, with the <span class="math">\(z\)</span> axis in the direction
of the pipe. The domain <span class="math">\(\Omega\)</span> is a cross section of the pipe, <span class="math">\(w\)</span>
is the velocity in the <span class="math">\(z\)</span> direction, <span class="math">\(\mu\)</span>
is the viscosity of the fluid, <span class="math">\(\beta\)</span> is the pressure gradient along
the pipe, <span class="math">\(T\)</span> is the temperature,
and <span class="math">\(\kappa\)</span> is the heat conduction coefficient of the
fluid. The equation <a href="#equation-fem:sys:wT:ex:weq">(126)</a> comes from the Navier-Stokes
equations, and <a href="#equation-fem:sys:wT:ex:Teq">(127)</a> follows from the energy equation.
The term <span class="math">\(- \mu ||\nabla w||^2\)</span> models heating of the fluid
due to internal friction.</p>
<p>Observe that the system <a href="#equation-fem:sys:wT:ex:weq">(126)</a>-<a href="#equation-fem:sys:wT:ex:Teq">(127)</a> has
only a one-way coupling: <span class="math">\(T\)</span> depends on <span class="math">\(w\)</span>, but <span class="math">\(w\)</span> does not depend on
<span class="math">\(T\)</span>, because we can solve <a href="#equation-fem:sys:wT:ex:weq">(126)</a> with respect
to <span class="math">\(w\)</span> and then <a href="#equation-fem:sys:wT:ex:Teq">(127)</a> with respect to <span class="math">\(T\)</span>.
Some may argue that this is not a real system of PDEs, but just two scalar
PDEs. Nevertheless, the one-way coupling
is convenient when comparing different variational forms
and different implementations.</p>
</div>
<div class="section" id="identical-function-spaces-for-the-unknowns">
<h2>Identical function spaces for the unknowns<a class="headerlink" href="#identical-function-spaces-for-the-unknowns" title="Permalink to this headline">¶</a></h2>
<p>Let us first apply the same function space <span class="math">\(V\)</span> for <span class="math">\(w\)</span> and <span class="math">\(T\)</span>
(or more precisely, <span class="math">\(w\in V\)</span> and <span class="math">\(T-T_0 \in V\)</span>).
With</p>
<div class="math">
\[V = \hbox{span}\{{\psi}_0(x,y),\ldots,{\psi}_N(x,y)\},\]</div>
<p>we write</p>
<div class="math" id="equation-fem:sys:wT:ex:sum">
<span class="eqno">(128)</span>\[     w = \sum_{j=0}^N c^{(w)}_j {\psi}_j,\quad T = T_0 + \sum_{j=0}^N c^{(T)}_j
     {\psi}_j{\thinspace .}\]</div>
<p>Note that <span class="math">\(w\)</span> and <span class="math">\(T\)</span> in <a href="#equation-fem:sys:wT:ex:weq">(126)</a>-<a href="#equation-fem:sys:wT:ex:Teq">(127)</a>
denote the exact solution of the PDEs, while <span class="math">\(w\)</span> and <span class="math">\(T\)</span>
<a href="#equation-fem:sys:wT:ex:sum">(128)</a> are the discrete functions that approximate
the exact solution. It should be clear from the context whether a
symbol means the exact or approximate solution, but when we need both
at the same time, we use a subscript e to denote the exact solution.</p>
<div class="section" id="variational-form-of-each-individual-pde">
<h3>Variational form of each individual PDE<a class="headerlink" href="#variational-form-of-each-individual-pde" title="Permalink to this headline">¶</a></h3>
<p>Inserting the expansions <a href="#equation-fem:sys:wT:ex:sum">(128)</a>
in the governing PDEs, results in a residual in each equation,</p>
<div class="math" id="equation-fem:sys:wT:ex:weq:R">
<span class="eqno">(129)</span>\[     R_w = \mu \nabla^2 w + \beta,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:Teq:R">
<span class="eqno">(130)</span>\[     R_T = \kappa\nabla^2 T + \mu ||\nabla w||^2
     {\thinspace .}\]</div>
<p>A Galerkin method demands <span class="math">\(R_w\)</span> and <span class="math">\(R_T\)</span> do be orthogonal to <span class="math">\(V\)</span>:</p>
<div class="math">
\[\begin{split}\int_\Omega R_w v {\, \mathrm{d}x} &amp;=0\quad\forall v\in V,\\
\int_\Omega R_T v {\, \mathrm{d}x} &amp;=0\quad\forall v\in V
{\thinspace .}\end{split}\]</div>
<p>Because of the Dirichlet conditions, <span class="math">\(v=0\)</span> on <span class="math">\(\partial\Omega\)</span>.
We integrate the Laplace terms by parts and note that the boundary terms
vanish since <span class="math">\(v=0\)</span> on <span class="math">\(\partial\Omega\)</span>:</p>
<div class="math" id="equation-fem:sys:wT:ex:w:vf1">
<span class="eqno">(131)</span>\[     \int_\Omega \mu \nabla w\cdot\nabla v {\, \mathrm{d}x} = \int_\Omega \beta v{\, \mathrm{d}x}
     \quad\forall v\in V,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:T:vf1">
<span class="eqno">(132)</span>\[     \int_\Omega \kappa \nabla T\cdot\nabla v {\, \mathrm{d}x} = \int_\Omega \mu
     \nabla w\cdot\nabla w\, v{\, \mathrm{d}x} \quad\forall v\in V\]\[     {\thinspace .}\]</div>
</div>
<div class="section" id="compound-scalar-variational-form">
<h3>Compound scalar variational form<a class="headerlink" href="#compound-scalar-variational-form" title="Permalink to this headline">¶</a></h3>
<p>The alternative way of deriving the variational from is to
introduce a test vector function <span class="math">\(\boldsymbol{v}\in\boldsymbol{V} = V\times V\)</span> and take
the inner product of <span class="math">\(\boldsymbol{v}\)</span> and the residuals, integrated over the domain:</p>
<div class="math">
\[\int_{\Omega} (R_w, R_T)\cdot\boldsymbol{v} {\, \mathrm{d}x} = 0\quad\forall\boldsymbol{v}\in\boldsymbol{V}
{\thinspace .}\]</div>
<p>With <span class="math">\(\boldsymbol{v} = (v_0,v_1)\)</span> we get</p>
<div class="math">
\[\int_{\Omega} (R_w v_0 + R_T v_1) {\, \mathrm{d}x} = 0\quad\forall\boldsymbol{v}\in\boldsymbol{V}
{\thinspace .}\]</div>
<p>Integrating the Laplace terms by parts results in</p>
<div class="math" id="equation-fem:sys:wT:ex:wT:vf2">
<span class="eqno">(133)</span>\[     \int_\Omega (\mu\nabla w\cdot\nabla v_0 + \kappa\nabla T\cdot\nabla v_1){\, \mathrm{d}x}
     = \int_\Omega (\beta v_0 + \mu\nabla w\cdot\nabla w\, v_1){\, \mathrm{d}x},
     \quad\forall \boldsymbol{v}\in\boldsymbol{V}
     {\thinspace .}\]</div>
<p>Choosing <span class="math">\(v_0=v\)</span> and <span class="math">\(v_1=0\)</span> gives the variational form
<a href="#equation-fem:sys:wT:ex:w:vf1">(131)</a>, while <span class="math">\(v_0=0\)</span> and <span class="math">\(v_1=v\)</span> gives
<a href="#equation-fem:sys:wT:ex:T:vf1">(132)</a>.</p>
<p>With the inner product notation, <span class="math">\((p,q) = \int_\Omega pq{\, \mathrm{d}x}\)</span>, we
can alternatively write <a href="#equation-fem:sys:wT:ex:w:vf1">(131)</a> and
<a href="#equation-fem:sys:wT:ex:T:vf1">(132)</a> as</p>
<div class="math">
\[\begin{split} (\mu\nabla w,\nabla v) &amp;= (\beta, v)
\quad\forall v\in V,\\
(\kappa \nabla T,\nabla v) &amp;= (\mu\nabla w\cdot\nabla w, v)\quad\forall v\in V,\end{split}\]</div>
<p>or since <span class="math">\(\mu\)</span> and <span class="math">\(\kappa\)</span> are considered constant,</p>
<div class="math" id="equation-fem:sys:wT:ex:w:vf1i">
<span class="eqno">(134)</span>\[     \mu (\nabla w,\nabla v) = (\beta, v)
     \quad\forall v\in V,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:T:vf1i">
<span class="eqno">(135)</span>\[     \kappa(\nabla T,\nabla v) = \mu(\nabla w\cdot\nabla w, v)\quad\forall v\in V\]\[     {\thinspace .}\]</div>
</div>
<div class="section" id="decoupled-linear-systems">
<h3>Decoupled linear systems<a class="headerlink" href="#decoupled-linear-systems" title="Permalink to this headline">¶</a></h3>
<p>The linear systems governing the coefficients <span class="math">\(c_j^{(w)}\)</span> and
<span class="math">\(c_j^{(T)}\)</span>, <span class="math">\(j=0,\ldots,N\)</span>, are derived by inserting the
expansions <a href="#equation-fem:sys:wT:ex:sum">(128)</a> in <a href="#equation-fem:sys:wT:ex:w:vf1">(131)</a>
and <a href="#equation-fem:sys:wT:ex:T:vf1">(132)</a>, and choosing <span class="math">\(v={\psi}_i\)</span> for
<span class="math">\(i=0,\ldots,N\)</span>. The result becomes</p>
<div class="math" id="equation-fem:sys:wT:ex:linsys:w1">
<span class="eqno">(136)</span>\[     \sum_{j=0}^N A^{(w)}_{i,j} c^{(w)}_j = b_i^{(w)},\quad i=0,\ldots,N,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:linsys:T1">
<span class="eqno">(137)</span>\[     \sum_{j=0}^N A^{(T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N,\]</div>
<div class="math">
\[A^{(w)}_{i,j} = \mu(\nabla {\psi}_j,\nabla {\psi}_i),\]</div>
<div class="math">
\[b_i^{(w)} = (\beta, {\psi}_i),\]</div>
<div class="math">
\[A^{(T)}_{i,j} = \kappa(\nabla {\psi}_j,\nabla {\psi}_i),\]</div>
<div class="math">
\[b_i^{(T)} = \mu((\sum_j c^{(w)}_j\nabla{\psi}_j)\cdot (\sum_k
c^{(w)}_k\nabla{\psi}_k), {\psi}_i)
{\thinspace .}\]</div>
<p>It can also be instructive to write the linear systems using matrices
and vectors. Define <span class="math">\(K\)</span> as the matrix corresponding to the Laplace
operator <span class="math">\(\nabla^2\)</span>. That is, <span class="math">\(K_{i,j} = (\nabla {\psi}_j,\nabla {\psi}_i)\)</span>.
Let us introduce the vectors</p>
<div class="math">
\[\begin{split}b^{(w)} &amp;= (b_0^{(w)},\ldots,b_{N}^{(w)}),\\
b^{(T)} &amp;= (b_0^{(T)},\ldots,b_{N}^{(T)}),\\
c^{(w)} &amp;= (c_0^{(w)},\ldots,c_{N}^{(w)}),\\
c^{(T)} &amp;= (c_0^{(T)},\ldots,c_{N}^{(T)}){\thinspace .}\end{split}\]</div>
<p>The system <a href="#equation-fem:sys:wT:ex:linsys:w1">(136)</a>-<a href="#equation-fem:sys:wT:ex:linsys:T1">(137)</a>
can now be expressed in matrix-vector form as</p>
<div class="math">
\[\mu K c^{(w)} = b^{(w)},\]</div>
<div class="math">
\[\kappa K c^{(T)} = b^{(T)}{\thinspace .}\]</div>
<p>We can solve the first system for <span class="math">\(c^{(w)}\)</span>, and then
the right-hand side <span class="math">\(b^{(T)}\)</span> is known such that we can
solve the second system for <span class="math">\(c^{(T)}\)</span>.</p>
</div>
<div class="section" id="coupled-linear-systems">
<h3>Coupled linear systems<a class="headerlink" href="#coupled-linear-systems" title="Permalink to this headline">¶</a></h3>
<p>Despite the fact that <span class="math">\(w\)</span> can be computed first, without knowing <span class="math">\(T\)</span>,
we shall now pretend that <span class="math">\(w\)</span> and <span class="math">\(T\)</span> enter a two-way coupling such
that we need to derive the
algebraic equations as <em>one system</em> for all the unknowns
<span class="math">\(c_j^{(w)}\)</span> and <span class="math">\(c_j^{(T)}\)</span>, <span class="math">\(j=0,\ldots,N\)</span>. This system is
nonlinear in <span class="math">\(c_j^{(w)}\)</span> because of the <span class="math">\(\nabla w\cdot\nabla w\)</span> product.
To remove this nonlinearity, imagine that we introduce an iteration
method where we replace <span class="math">\(\nabla w\cdot\nabla w\)</span> by
<span class="math">\(\nabla w_{-}\cdot\nabla w\)</span>, <span class="math">\(w_{-}\)</span> being the <span class="math">\(w\)</span>
computed in the previous iteration. Then the term
<span class="math">\(\nabla w_{-}\cdot\nabla w\)</span> is linear in <span class="math">\(w\)</span> since <span class="math">\(w_{-}\)</span> is
known. The total linear system becomes</p>
<div class="math" id="equation-fem:sys:wT:ex:linsys:w2">
<span class="eqno">(138)</span>\[     \sum_{j=0}^N A^{(w,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^N A^{(w,T)}_{i,j} c^{(T)}_j
     = b_i^{(w)},\quad i=0,\ldots,N,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:linsys:T2">
<span class="eqno">(139)</span>\[     \sum_{j=0}^N A^{(T,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^N A^{(T,T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N,\]</div>
<div class="math">
\[A^{(w,w)}_{i,j} = \mu(\nabla {\psi}_j,{\psi}_i),\]</div>
<div class="math">
\[A^{(w,T)}_{i,j} = 0,\]</div>
<div class="math">
\[b_i^{(w)} = (\beta, {\psi}_i),\]</div>
<div class="math">
\[A^{(w,T)}_{i,j} = \mu((\nabla{\psi} w_{-})\cdot\nabla{\psi}_j), {\psi}_i),\]</div>
<div class="math">
\[A^{(T,T)}_{i,j} = \kappa(\nabla {\psi}_j,{\psi}_i),\]</div>
<div class="math">
\[b_i^{(T)} = 0
{\thinspace .}\]</div>
<p>This system can alternatively be written in matrix-vector form as</p>
<div class="math">
\[\mu K c^{(w)} = 0 b^{(w)},\]</div>
<div class="math">
\[L c^{(w)} + \kappa K c^{(T)}  =0,\]</div>
<p>with <span class="math">\(L\)</span> as the matrix from the <span class="math">\(\nabla w_{-}\cdot\nabla\)</span> operator:
<span class="math">\(L_{i,j} = A^{(w,T)}_{i,j}\)</span>.</p>
<p>The matrix-vector equations are often conveniently written in block form:</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}
\mu K &amp; 0\\
L &amp; \kappa K
\end{array}\right)
\left(\begin{array}{c}
c^{(w)}\\
c^{(T)}
\end{array}\right) =
\left(\begin{array}{c}
b^{(w)}\\
0
\end{array}\right),\end{split}\]</div>
<p>Note that in the general case where all unknowns enter all equations,
we have to solve the compound system
<a href="#equation-fem:sys:wT:ex:linsys:w2">(145)</a>-<a href="#equation-fem:sys:wT:ex:linsys:T2">(146)</a> since
then we cannot utilize the special property that
<a href="#equation-fem:sys:wT:ex:linsys:w1">(136)</a> does not involve <span class="math">\(T\)</span> and can be solved
first.</p>
<p>When the viscosity depends on the temperature, the
<span class="math">\(\mu\nabla^2w\)</span> term must be replaced by <span class="math">\(\nabla\cdot (\mu(T)\nabla w)\)</span>,
and then <span class="math">\(T\)</span> enters the equation for <span class="math">\(w\)</span>. Now we have a two-way coupling
since both equations contain <span class="math">\(w\)</span> and <span class="math">\(T\)</span> and therefore
must be solved simultaneously
Th equation <span class="math">\(\nabla\cdot (\mu(T)\nabla w)=-\beta\)</span> is nonlinear,
and if some iteration procedure is invoked, where we use a previously
computed <span class="math">\(T_{-}\)</span> in the viscosity (<span class="math">\(\mu(T_{-})\)</span>), the coefficient is known,
and the equation involves only one unknown, <span class="math">\(w\)</span>. In that case we are
back to the one-way coupled set of PDEs.</p>
<p>We may also formulate our PDE system as a vector equation. To this end,
we introduce the vector of unknowns <span class="math">\(\boldsymbol{u} = (u^{(0)},u^{(1)})\)</span>,
where <span class="math">\(u^{(0)}=w\)</span> and <span class="math">\(u^{(1)}=T\)</span>. We then have</p>
<div class="math">
\[\begin{split}\nabla^2 \boldsymbol{u} = \left(\begin{array}{cc}
-{\mu}^{-1}{\beta}\\
-{\kappa}^{-1}\mu \nabla u^{(0)}\cdot\nabla u^{(0)}
\end{array}\right){\thinspace .}\end{split}\]</div>
</div>
</div>
<div class="section" id="different-function-spaces-for-the-unknowns">
<h2>Different function spaces for the unknowns<a class="headerlink" href="#different-function-spaces-for-the-unknowns" title="Permalink to this headline">¶</a></h2>
<p id="index-78">It is easy to generalize the previous formulation to the case where
<span class="math">\(w\in V^{(w)}\)</span> and <span class="math">\(T\in V^{(T)}\)</span>, where <span class="math">\(V^{(w)}\)</span> and <span class="math">\(V^{(T)}\)</span>
can be different spaces with different numbers of degrees of freedom.
For example, we may use quadratic basis functions for <span class="math">\(w\)</span> and linear
for <span class="math">\(T\)</span>. Approximation of the unknowns by different finite element
spaces is known as <em>mixed finite element methods</em>.</p>
<p>We write</p>
<div class="math">
\[\begin{split}V^{(w)} &amp;= \hbox{span}\{{\psi}_0^{(w)},\ldots,{\psi}_{N_w}^{(w)}\},\\
V^{(T)} &amp;= \hbox{span}\{{\psi}_0^{(T)},\ldots,{\psi}_{N_T}^{(T)}\}
{\thinspace .}\end{split}\]</div>
<p>The next step is to
multiply <a href="#equation-fem:sys:wT:ex:weq">(126)</a> by a test function <span class="math">\(v^{(w)}\in V^{(w)}\)</span>
and <a href="#equation-fem:sys:wT:ex:Teq">(127)</a> by a <span class="math">\(v^{(T)}\in V^{(T)}\)</span>, integrate by
parts and arrive at</p>
<div class="math" id="equation-fem:sys:wT:ex:w:vf3">
<span class="eqno">(140)</span>\[     \int_\Omega \mu \nabla w\cdot\nabla v^{(w)} {\, \mathrm{d}x} = \int_\Omega \beta v^{(w)}{\, \mathrm{d}x}
     \quad\forall v^{(w)}\in V^{(w)},\]</div>
<div class="math" id="equation-fem:sys:wT:ex:T:vf3">
<span class="eqno">(141)</span>\[     \int_\Omega \kappa \nabla T\cdot\nabla v^{(T)} {\, \mathrm{d}x} = \int_\Omega \mu
     \nabla w\cdot\nabla w\, v^{(T)}{\, \mathrm{d}x} \quad\forall v^{(T)}\in V^{(T)}\]\[     {\thinspace .}\]</div>
<p>The compound scalar variational formulation applies a test vector function
<span class="math">\(\boldsymbol{v} = (v^{(w)}, v^{(T)})\)</span> and reads</p>
<div class="math" id="equation-fem:sys:wT:ex:wT:vf3">
<span class="eqno">(142)</span>\[     \int_\Omega (\mu\nabla w\cdot\nabla v^{(w)} +
     \kappa\nabla T\cdot\nabla v^{(T)}){\, \mathrm{d}x}
     = \int_\Omega (\beta v^{(w)} + \mu\nabla w\cdot\nabla w\, v^{(T)}){\, \mathrm{d}x},\]</div>
<p>valid <span class="math">\(\forall \boldsymbol{v}\in\boldsymbol{V} = V^{(w)}\times V^{(T)}\)</span>.</p>
<p>The associated linear system is similar to
<a href="#equation-fem:sys:wT:ex:linsys:w1">(136)</a>-<a href="#equation-fem:sys:wT:ex:linsys:T1">(137)</a>
or
<a href="#equation-fem:sys:wT:ex:linsys:w2">(145)</a>-<a href="#equation-fem:sys:wT:ex:linsys:T2">(146)</a>,
except that we need to distinguish between <span class="math">\({\psi}_i^{(w)}\)</span>
and <span class="math">\({\psi}_i^{(T)}\)</span>, and the range in the sums over <span class="math">\(j\)</span>
must match the number of degrees of freedom in the spaces <span class="math">\(V^{(w)}\)</span>
and <span class="math">\(V^{(T)}\)</span>. The formulas become</p>
<div class="math" id="equation-fem:sys:wT:ex:linsys:w1:mixed">
<span class="eqno">(143)</span>\[     \sum_{j=0}^{N_w} A^{(w)}_{i,j} c^{(w)}_j = b_i^{(w)},\quad i=0,\ldots,N_w,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:linsys:T1:mixed">
<span class="eqno">(144)</span>\[     \sum_{j=0}^{N_T} A^{(T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N_T,\]</div>
<div class="math">
\[A^{(w)}_{i,j} = \mu(\nabla {\psi}_j^{(w)},{\psi}_i^{(w)}),\]</div>
<div class="math">
\[b_i^{(w)} = (\beta, {\psi}_i^{(w)}),\]</div>
<div class="math">
\[A^{(T)}_{i,j} = \kappa(\nabla {\psi}_j^{(T)},{\psi}_i^{(T)}),\]</div>
<div class="math">
\[b_i^{(T)} = \mu(\nabla w_{-}, {\psi}_i^{(T)})
{\thinspace .}\]</div>
<p>In the case we formulate one compound linear system involving
both <span class="math">\(c^{(w)}_j\)</span>, <span class="math">\(j=0,\ldots,N_w\)</span>, and <span class="math">\(c^{(T)}_j\)</span>, <span class="math">\(j=0,\ldots,N_T\)</span>,
<a href="#equation-fem:sys:wT:ex:linsys:w2">(145)</a>-<a href="#equation-fem:sys:wT:ex:linsys:T2">(146)</a>
becomes</p>
<div class="math" id="equation-fem:sys:wT:ex:linsys:w2">
<span class="eqno">(145)</span>\[     \sum_{j=0}^{N_w} A^{(w,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^{N_T} A^{(w,T)}_{i,j} c^{(T)}_j
     = b_i^{(w)},\quad i=0,\ldots,N_w,\]</div>
<div class="math" id="equation-fem:sys:wT:ex:linsys:T2">
<span class="eqno">(146)</span>\[     \sum_{j=0}^{N_w} A^{(T,w)}_{i,j} c^{(w)}_j + \sum_{j=0}^{N_T} A^{(T,T)}_{i,j} c^{(T)}_j = b_i^{(T)},\quad i=0,\ldots,N_T,\]</div>
<div class="math">
\[A^{(w,w)}_{i,j} = \mu(\nabla {\psi}_j^{(w)},{\psi}_i^{(w)}),\]</div>
<div class="math">
\[A^{(w,T)}_{i,j} = 0,\]</div>
<div class="math">
\[b_i^{(w)} = (\beta, {\psi}_i^{(w)}),\]</div>
<div class="math">
\[A^{(w,T)}_{i,j} = \mu (\nabla w_{-}\cdot\nabla{\psi}_j^{(w)}), {\psi}_i^{(T)}),\]</div>
<div class="math">
\[A^{(T,T)}_{i,j} = \kappa(\nabla {\psi}_j^{(T)},{\psi}_i^{(T)}),\]</div>
<div class="math">
\[b_i^{(T)} = 0
{\thinspace .}\]</div>
<p>The corresponding block form</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}
\mu K^{(w)} &amp; 0\\
L &amp; \kappa K^{(T)}
\end{array}\right)
\left(\begin{array}{c}
c^{(w)}\\
c^{(T)}
\end{array}\right) =
\left(\begin{array}{c}
b^{(w)}\\
0
\end{array}\right),\end{split}\]</div>
<p>has square and rectangular block matrices: <span class="math">\(K^{(w)}\)</span> is <span class="math">\(N_w\times N_w\)</span>,
<span class="math">\(K^{(T)}\)</span> is <span class="math">\(N_T\times N_T\)</span>, while <span class="math">\(L\)</span> is <span class="math">\(N_T\times N_w\)</span>,</p>
</div>
<div class="section" id="computations-in-1d">
<h2>Computations in 1D<a class="headerlink" href="#computations-in-1d" title="Permalink to this headline">¶</a></h2>
<p>We can reduce the system <a href="#equation-fem:sys:wT:ex:weq">(126)</a>-<a href="#equation-fem:sys:wT:ex:Teq">(127)</a>
to one space dimension, which corresponds to flow in a channel between
two flat plates. Alternatively, one may consider flow in a circular
pipe, introduce cylindrical coordinates, and utilize the radial symmetry
to reduce the equations to a one-dimensional problem in the radial
coordinate. The former model becomes</p>
<div class="math" id="equation-fem:sys:wT:ex1D:weq">
<span class="eqno">(147)</span>\[     \mu w_{xx} = -\beta,\]</div>
<div class="math" id="equation-fem:sys:wT:ex1D:Teq">
<span class="eqno">(148)</span>\[     \kappa T_{xx} = - \mu w_x^2,\]</div>
<p>while the model in the radial coordinate <span class="math">\(r\)</span> reads</p>
<div class="math" id="equation-fem:sys:wT:ex1Dr:weq">
<span class="eqno">(149)</span>\[     \mu\frac{1}{r}\frac{d}{dr}\left( r\frac{dw}{dr}\right) = -\beta,\]</div>
<div class="math" id="equation-fem:sys:wT:ex1Dr:Teq">
<span class="eqno">(150)</span>\[     \kappa \frac{1}{r}\frac{d}{dr}\left( r\frac{dw}{dr}\right) = - \mu \left(
     \frac{dw}{dr}\right)^2
     {\thinspace .}\]</div>
<p>The domain for <a href="#equation-fem:sys:wT:ex1D:weq">(147)</a>-<a href="#equation-fem:sys:wT:ex1D:Teq">(148)</a>
is <span class="math">\(\Omega = [0,H]\)</span>, with boundary conditions <span class="math">\(w(0)=w(H)=0\)</span> and
<span class="math">\(T(0)=T(H)=T_0\)</span>. For
<a href="#equation-fem:sys:wT:ex1Dr:weq">(149)</a>-<a href="#equation-fem:sys:wT:ex1Dr:Teq">(150)</a> the domain
is <span class="math">\([0,R]\)</span> (<span class="math">\(R\)</span> being the radius of the pipe) and the boundary
conditions are <span class="math">\(du/dr = dT/dr =0\)</span> for <span class="math">\(r=0\)</span>, <span class="math">\(u(R)=0\)</span>, and <span class="math">\(T(R)=T_0\)</span>.</p>
<p><strong>Calculations to be continued...</strong></p>
</div>
<div class="section" id="another-example-in-1d">
<span id="fem-sys-up-1d"></span><h2>Another example in 1D<a class="headerlink" href="#another-example-in-1d" title="Permalink to this headline">¶</a></h2>
<div class="math" id="equation-fem:sys:up:1D:eq:mass">
<span class="eqno">(151)</span>\[     \frac{\partial w}{\partial x} = 0,\]</div>
<div class="math" id="equation-fem:sys:up:1D:eq:Darcy">
<span class="eqno">(152)</span>\[     w =-a\frac{partial u}{\partial x}\]\[     {\thinspace .}\]</div>
<p>Boundary conditions: <span class="math">\(u(0)=0\)</span>, <span class="math">\(u(L)=C\)</span>.</p>
<div class="math" id="equation-fem:sys:up:1D:eq:u">
<span class="eqno">(153)</span>\[     \frac{\partial}{\partial x}\left( a \frac{partial u}{\partial x}\right )= 0\]\[     {\thinspace .}\]</div>
<p>Mixed finite elements vs standard finite elements.</p>
<p><strong>Calculations to be continued...</strong></p>
</div>
</div>
<div class="section" id="exercises-2">
<h1>Exercises  (2)<a class="headerlink" href="#exercises-2" title="Permalink to this headline">¶</a></h1>
<div class="section" id="exercise-23-refactor-functions-into-a-more-general-class">
<span id="fem-deq-exer-bvp1d-class"></span><h2>Exercise 23: Refactor functions into a more general class<a class="headerlink" href="#exercise-23-refactor-functions-into-a-more-general-class" title="Permalink to this headline">¶</a></h2>
<p>the section <a class="reference internal" href="#fem-deq-1d-models-simple"><em>Simple model problems</em></a> displays three functions
for computing the analytical solution of some simple
model problems. There is quite some repetitive code, suggesting
that the functions can benefit from being refactored into a
class where the user can define the <span class="math">\(f(x)\)</span>, <span class="math">\(a(x)\)</span>, and the boundary
conditions in particular methods in subclasses. Demonstrate how
the new class can be used to solve the three particular
problems in the section <a class="reference internal" href="#fem-deq-1d-models-simple"><em>Simple model problems</em></a>.</p>
<p>In the method that computes the solution, check that the solution
found fulfills the differential equation and the boundary conditions.
Filename: <tt class="docutils literal"><span class="pre">uxx_f_sympy_class.py</span></tt>.</p>
</div>
<div class="section" id="exercise-24-compute-the-deflection-of-a-cable-with-sine-functions">
<span id="fem-deq-exer-tension-cable"></span><h2>Exercise 24: Compute the deflection of a cable with sine functions<a class="headerlink" href="#exercise-24-compute-the-deflection-of-a-cable-with-sine-functions" title="Permalink to this headline">¶</a></h2>
<p>A hanging cable of length <span class="math">\(L\)</span>
with significant tension has a downward deflection <span class="math">\(w(x)\)</span>
governed by</p>
<p>Solve</p>
<div class="math">
\[T w''(x) = \ell(x),\]</div>
<p>where <span class="math">\(T\)</span> is the tension in the cable
and <span class="math">\(\ell(x)\)</span> the load per unit length.
The cable is fixed at <span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span> so the boundary conditions become
<span class="math">\(T(0)=T(L)=0\)</span>. We assume a constant load <span class="math">\(\ell(x)=\hbox{const}\)</span>.</p>
<p>The solution is expected to be symmetric around <span class="math">\(x=L/2\)</span>. Formulating
the problem for <span class="math">\(x\in [0,L/2]\)</span> and then scaling it, results in
the scaled problem for the dimensionless vertical deflection <span class="math">\(u\)</span>:</p>
<div class="math">
\[u'' = 1,\quad x\in (0,1),\quad u(0)=0,\ u'(1)=0\thinspace\]</div>
<p>Introduce the function space spanned by <span class="math">\({\psi}_i=\sin ((i+1)\pi x/2)\)</span>,
<span class="math">\(i=1,\ldots,N\)</span>.
Use a Galerkin and a least squares method to find the coefficients
<span class="math">\(c_j\)</span> in <span class="math">\(u(x)=\sum_j c_j{\psi}_j\)</span>. Find how fast the coefficients
decrease in magnitude by looking at <span class="math">\(c_j/c_{j-1}\)</span>.
Find the error in the maximum deflection at <span class="math">\(x=1\)</span> when only one
basis function is used (<span class="math">\(N=0\)</span>).</p>
<p>What happens if we choose basis functions
<span class="math">\({\psi}_i=\sin ((i+1)\pi x)\)</span>?
Filename: <tt class="docutils literal"><span class="pre">cable_sin</span></tt>.</p>
</div>
<div class="section" id="exercise-25-check-integration-by-parts">
<span id="fem-deq-exer-intg-parts"></span><h2>Exercise 25: Check integration by parts<a class="headerlink" href="#exercise-25-check-integration-by-parts" title="Permalink to this headline">¶</a></h2>
<p>Consider the Galerkin method for the problem involving <span class="math">\(u\)</span>
in <a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 24: Compute the deflection of a cable with sine functions</em></a>.
Show that the formulas for <span class="math">\(c_j\)</span> are independent of whether we perform
integration by parts or not.
Filename: <tt class="docutils literal"><span class="pre">cable_integr_by_parts</span></tt>.</p>
</div>
<div class="section" id="exercise-26-compute-the-deflection-of-a-cable-with-2-p1-elements">
<span id="id9"></span><h2>Exercise 26: Compute the deflection of a cable with 2 P1 elements<a class="headerlink" href="#exercise-26-compute-the-deflection-of-a-cable-with-2-p1-elements" title="Permalink to this headline">¶</a></h2>
<p>Solve the problem for <span class="math">\(u\)</span> in <a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 24: Compute the deflection of a cable with sine functions</em></a>
using two P1 linear elements.
Filename: <tt class="docutils literal"><span class="pre">cable_2P1</span></tt>.</p>
</div>
<div class="section" id="exercise-27-compute-the-deflection-of-a-cable-with-1-p2-element">
<span id="id10"></span><h2>Exercise 27: Compute the deflection of a cable with 1 P2 element<a class="headerlink" href="#exercise-27-compute-the-deflection-of-a-cable-with-1-p2-element" title="Permalink to this headline">¶</a></h2>
<p>Solve the problem for <span class="math">\(u\)</span> in <a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 24: Compute the deflection of a cable with sine functions</em></a>
using one P2 element with quadratic basis functions.
Filename: <tt class="docutils literal"><span class="pre">cable_1P2</span></tt>.</p>
</div>
<div class="section" id="exercise-28-compute-the-deflection-of-a-cable-with-a-step-load">
<span id="id11"></span><h2>Exercise 28: Compute the deflection of a cable with a step load<a class="headerlink" href="#exercise-28-compute-the-deflection-of-a-cable-with-a-step-load" title="Permalink to this headline">¶</a></h2>
<p>We consider the deflection of a tension cable as described in
<a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 24: Compute the deflection of a cable with sine functions</em></a>. Now the load is</p>
<div class="math">
\[\begin{split}\ell (x) =\left\lbrace\begin{array}{ll}
\ell_1, &amp; x &lt;L/2,\\
\ell_2, &amp; x \geq L/2
\end{array}\right.\quad x\in [0,L]
{\thinspace .}\end{split}\]</div>
<p>This load is not symmetric
with respect to the midpoint <span class="math">\(x=L/2\)</span> so the solution loses its symmetry
and we must solve the scaled problem</p>
<div class="math">
\[\begin{split}u'' =\left\lbrace\begin{array}{ll}
1, &amp; x &lt;1/2,\\
0, &amp; x \geq 1/2
\end{array}\right.
\quad x\in (0,1),\quad u(0)=0,\ u(1)=0
{\thinspace .}\end{split}\]</div>
<p><strong>a)</strong>
Use <span class="math">\({\psi}_i = \sin((i+1)\pi x)\)</span>, <span class="math">\(i=0,\ldots,N\)</span> and the Galerkin method
without integration by parts. Derive a formula
for <span class="math">\(c_j\)</span> in the solution expansion <span class="math">\(u=\sum_j c_j{\psi}_j\)</span>.
Plot how fast the coefficients <span class="math">\(c_j\)</span> tend to zero (on a log scale).</p>
<p><strong>b)</strong>
Solve the problem with P1 finite elements.
Plot the solution for <span class="math">\(N_e=2,4,8\)</span> elements.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">cable_discont_load</span></tt>.</p>
</div>
<div class="section" id="exercise-29-show-equivalence-between-linear-systems">
<span id="fem-deq-exer-aub-essbc-equiv"></span><h2>Exercise 29: Show equivalence between linear systems<a class="headerlink" href="#exercise-29-show-equivalence-between-linear-systems" title="Permalink to this headline">¶</a></h2>
<p>Incorporation of Dirichlet conditions can either be done by
introducing an expansion <span class="math">\(u(x)=U_0{\varphi}_0 + U_N{\varphi}_N + \sum_{j=1}^{N-1}
c_j{\varphi}_j\)</span> and considering <span class="math">\(c_1,\dots,c_{N-1}\)</span> as unknowns, <em>or</em>
one can assemble the matrix system with <span class="math">\(u(x)=\sum_{j=0}^{N}
c_j{\varphi}_j\)</span> and afterwards replace the rows corresponding to known
<span class="math">\(c_j\)</span> values by the boundary conditions.
The purpose of this exercise is to show the equivalence of these two
approaches.</p>
<p>Consider the system <a href="#equation-fem:deq:1D:ex1:Ab:glob">(73)</a>
modified for the boundary value <span class="math">\(u(L)=D\)</span>, as explained in
the section <a class="reference internal" href="#fem-deq-1d-fem-essbc-bfunc"><em>General construction of a boundary function</em></a>, and the system
<a href="#equation-fem:deq:1D:ex1:Ab:glob3">(81)</a>, where all <span class="math">\(\left\{ {c}_i \right\}_{i\in{I}}\)</span> are
involved. Show that eliminating <span class="math">\(c_1\)</span> and <span class="math">\(c_N\)</span> from
<a href="#equation-fem:deq:1D:ex1:Ab:glob3">(81)</a> results in the other system
<a href="#equation-fem:deq:1D:ex1:Ab:glob">(73)</a>.</p>
</div>
<div class="section" id="exercise-30-compute-with-a-non-uniform-mesh">
<span id="fem-deq-exer-1d-mesh-nonuniform"></span><h2>Exercise 30: Compute with a non-uniform mesh<a class="headerlink" href="#exercise-30-compute-with-a-non-uniform-mesh" title="Permalink to this headline">¶</a></h2>
<p>Derive the linear system for the problem <span class="math">\(-u''=2\)</span> on <span class="math">\([0,1]\)</span>,
with <span class="math">\(u(0)=0\)</span> and <span class="math">\(u(1)=1\)</span>, using P1 elements and a <em>non-uniform</em>
mesh. The vertices have coordinates <span class="math">\(x_{0}=0 &lt; x_{1} &lt;\cdots &lt; x_{N}=1\)</span>,
and the length of cell number <span class="math">\(e\)</span> is <span class="math">\(h_e = x_{e+1} -x_{e}\)</span>.</p>
<p>It is of interest to compare the discrete equations for the finite element
method in a non-uniform mesh with the corresponding discrete equations
arising from a finite difference method. Repeat the reasoning for
the finite difference formula <span class="math">\(u''(x_i) \approx [D_x D_x u]_i\)</span> and
use it to find a natural discretization of <span class="math">\(u''(x_i)\)</span> on a non-uniform
mesh.
Filename: <tt class="docutils literal"><span class="pre">nonuniform_P1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-31-solve-a-1d-finite-element-problem-by-hand">
<span id="fem-deq-exer-1d-gen-problem1"></span><h2>Exercise 31: Solve a 1D finite element problem by hand<a class="headerlink" href="#exercise-31-solve-a-1d-finite-element-problem-by-hand" title="Permalink to this headline">¶</a></h2>
<p>The following scaled 1D problem is a very simple, yet relevant, model
for convective transport in fluids:</p>
<div class="math">
\[u' = \epsilon u'' ,\quad u(0)=0,\ u(1)=1,\ x\in [0,1]
{\thinspace .}\]</div>
<p><strong>a)</strong>
Find the analytical solution to this problem.
(Introduce <span class="math">\(w=u'\)</span>, solve the first-order differential equation for <span class="math">\(w(x)\)</span>,
and integrate once more.)</p>
<p><strong>b)</strong>
Derive the variational form of this problem.</p>
<p><strong>c)</strong>
Introduce a finite element mesh with uniform partitioning.
Use P1 elements and compute the element matrix and vector for
a general element.</p>
<p><strong>d)</strong>
Incorporate the boundary conditions and
assemble the element contributions.</p>
<p><strong>e)</strong>
Identify the resulting linear system as a finite difference discretization
of the differential equation using</p>
<div class="math">
\[[D_{2x}u = \epsilon D_xD_x u]_i {\thinspace .}\]</div>
<p><strong>f)</strong>
Compute the numerical solution and plot it together with the exact solution
for a mesh with 20 elements and
<span class="math">\(\epsilon=0.1, 0.01\)</span>.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">convdiff1D_P1</span></tt>.</p>
</div>
<div class="section" id="exercise-32-compare-finite-elements-and-differences-for-a-radially-symmetric-poisson-equation">
<span id="fem-deq-exer-1d-poisson-polar"></span><h2>Exercise 32: Compare finite elements and differences for a radially symmetric Poisson equation<a class="headerlink" href="#exercise-32-compare-finite-elements-and-differences-for-a-radially-symmetric-poisson-equation" title="Permalink to this headline">¶</a></h2>
<p>We consider the Poisson problem in a disk with radius <span class="math">\(R\)</span> with
Dirichlet conditions at the boundary.
Given that the solution is radially symmetric and hence dependent only on
the radial coordinate (<span class="math">\(r=\sqrt{x^2+y^2}\)</span>), we can reduce the problem
to a 1D Poisson equation</p>
<div class="math" id="equation-fem:deq:exer:1D:Poisson:polar:eq">
<span class="eqno">(154)</span>\[     -\frac{1}{r}\frac{d}{dr}\left( r\frac{du}{dr}\right) = f(r),\quad r\in (0,R),\
     u'(0)=0,\ u(R)=U_R
     {\thinspace .}\]</div>
<p><strong>a)</strong>
Derive a variational form of <a href="#equation-fem:deq:exer:1D:Poisson:polar:eq">(154)</a>
by integrating over the whole disk, or posed equivalently: use
a weighting function <span class="math">\(2\pi r v(r)\)</span> and integrate <span class="math">\(r\)</span> from <span class="math">\(0\)</span> to <span class="math">\(R\)</span>.</p>
<p><strong>b)</strong>
Use a uniform mesh partition with P1 elements and show what the
resulting set of equations becomes. Integrate the matrix entries
exact by hand, but use a Trapezoidal rule to integrate the <span class="math">\(f\)</span> term.</p>
<p><strong>c)</strong>
Explain that a natural
finite difference method applied to <a href="#equation-fem:deq:exer:1D:Poisson:polar:eq">(154)</a>
gives</p>
<div class="math">
\[\frac{1}{r_i}\frac{1}{h^2}\left( r_{i+\frac{1}{2}}(u_{i+1}-u_i) -
r_{i-\frac{1}{2}}(u_{i}-u_{i-1})\right) = f_i,\quad i=rh
{\thinspace .}\]</div>
<p>For <span class="math">\(i=0\)</span> the factor <span class="math">\(1/r_i\)</span> seemingly becomes problematic. One must always
have <span class="math">\(u'(0)=0\)</span>, because of the radial symmetry, which implies
<span class="math">\(u_{-1}=u_1\)</span>, if we allow introduction of a fictitious value <span class="math">\(u_{-1}\)</span>.
Using this <span class="math">\(u_{-1}\)</span> in the difference equation for <span class="math">\(i=0\)</span> gives</p>
<div class="math">
\[\frac{1}{r_0}\frac{1}{h^2}\left( r_{\frac{1}{2}}(u_{1}-u_0) -
r_{-\frac{1}{2}}(u_{0}-u_{1})\right) =
\frac{1}{r_0}\frac{1}{2h^2}\left( (r_0 + r_1)(u_{1}-u_0) -
(r_{-1} + r_0)(u_{0}-u_{1})\right) \approx
2(u_1-u_0),\]</div>
<p>if we use <span class="math">\(r_{-1}+r_1\approx 2r_0\)</span>.</p>
<p>Set up the complete set of equations for the finite difference method
and compare to the finite element method in case a Trapezoidal rule
is used to integrate the <span class="math">\(f\)</span> term in the latter method.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">radial_Poisson1D_P1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-33-compute-with-variable-coefficients-and-p1-elements-by-hand">
<span id="fem-deq-exer-1d-gen-problem2"></span><h2>Exercise 33: Compute with variable coefficients and P1 elements by hand<a class="headerlink" href="#exercise-33-compute-with-variable-coefficients-and-p1-elements-by-hand" title="Permalink to this headline">¶</a></h2>
<p>Consider the problem</p>
<div class="math" id="equation-fem:deq:1D:model4">
<span class="eqno">(155)</span>\[     -\frac{d}{dx}\left( a(x)\frac{du}{dx}\right) + \gamma u = f(x),
     \quad x\in\Omega=[0,L],\quad u(0)=\alpha,\ u'(L)=\beta{\thinspace .}\]</div>
<p>We choose <span class="math">\(a(x)=1+x^2\)</span>. Then</p>
<div class="math">
\[u(x) = \alpha + \beta(1+L^2)\tan^{-1}(x),\]</div>
<p>is an exact solution if <span class="math">\(f(x) = \gamma u\)</span>.</p>
<p>Derive a variational formulation and compute general expressions for the
element matrix and vector in an arbitrary element, using P1 elements
and a uniform partitioning of <span class="math">\([0,L]\)</span>. The right-hand side
integral is challenging and can be computed by a numerical integration
rule. The Trapezoidal rule <a href="#equation-fem:approx:fe:numint1:trapez">(40)</a>
gives particularly simple expressions.
Filename: <tt class="docutils literal"><span class="pre">atan1D_P1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-34-solve-a-2d-poisson-equation-using-polynomials-and-sines">
<span id="fem-deq-exer-2d-torsion-xy-sin"></span><h2>Exercise 34: Solve a 2D Poisson equation using polynomials and sines<a class="headerlink" href="#exercise-34-solve-a-2d-poisson-equation-using-polynomials-and-sines" title="Permalink to this headline">¶</a></h2>
<p>The classical problem of applying a torque to the ends of a rod
can be modeled by a Poisson equation defined in the cross section <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[-\nabla^2 u = 2,\quad (x,y)\in\Omega,\]</div>
<p>with <span class="math">\(u=0\)</span> on <span class="math">\(\partial\Omega\)</span>. Exactly the same problem arises for
the deflection of a membrane with shape <span class="math">\(\Omega\)</span> under a constant load.</p>
<p>For a circular cross section one can readily
find an analytical solution. For a rectangular cross section the analytical
approach ends up with a sine series. The idea in this exercise is to
use a single basis function to obtain an approximate answer.</p>
<p>We assume for simplicity that the cross section is the unit square:
<span class="math">\(\Omega = [0,1]\times [0,1]\)</span>.</p>
<p><strong>a)</strong>
We consider the basis
<span class="math">\({\psi}_{p,q}(x,y) = \sin((p+1)\pi x)\sin (q\pi y)\)</span>, <span class="math">\(p,q=0,\ldots,n\)</span>.
These basis functions fulfill the Dirichlet condition.
Use a Galerkin method and <span class="math">\(n=0\)</span>.</p>
<p><strong>b)</strong>
The basis function involving sine functions are orthogonal.
Use this property in the Galerkin method
to derive the coefficients <span class="math">\(c_{p,q}\)</span> in a
formula <span class="math">\(u=\sum_p\sum_q c_{p,q}{\psi}_{p,q}(x,y)\)</span>.</p>
<p><strong>c)</strong>
Another possible basis is
<span class="math">\({\psi}_i(x,y) = (x(1-x)y(1-y))^{i+1}\)</span>, <span class="math">\(i=0,\ldots,N\)</span>.
Use the Galerkin method to compute the solution for <span class="math">\(N=0\)</span>.
Which choice of a single basis function is best,
<span class="math">\(u\sim x(1-x)y(1-y)\)</span> or <span class="math">\(u\sim \sin(\pi x)\sin(\pi y)\)</span>?
In order to answer the question,
it is necessary to search the web or the literature for an accurate
estimate of the maximum <span class="math">\(u\)</span> value at <span class="math">\(x=y=1/2\)</span>.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">torsion_sin_xy.pdf</span></tt>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Introduction to finite element methods</a></li>
<li><a class="reference internal" href="#approximation-of-vectors">Approximation of vectors</a><ul>
<li><a class="reference internal" href="#approximation-of-planar-vectors">Approximation of planar vectors</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-1">The least squares method  (1)</a></li>
<li><a class="reference internal" href="#the-projection-method">The projection method</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-general-vectors">Approximation of general vectors</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-2">The least squares method  (2)</a></li>
<li><a class="reference internal" href="#the-galerkin-or-projection-method">The Galerkin or projection method</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-functions">Approximation of functions</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-3">The least squares method  (3)</a></li>
<li><a class="reference internal" href="#the-projection-or-galerkin-method">The projection (or Galerkin) method</a></li>
<li><a class="reference internal" href="#example-linear-approximation">Example: linear approximation</a></li>
<li><a class="reference internal" href="#implementation-of-the-least-squares-method">Implementation of the least squares method</a></li>
<li><a class="reference internal" href="#perfect-approximation">Perfect approximation</a></li>
<li><a class="reference internal" href="#ill-conditioning">Ill-conditioning</a></li>
<li><a class="reference internal" href="#fourier-series">Fourier series</a></li>
<li><a class="reference internal" href="#orthogonal-basis-functions">Orthogonal basis functions</a></li>
<li><a class="reference internal" href="#numerical-computations">Numerical computations</a></li>
<li><a class="reference internal" href="#the-interpolation-or-collocation-method">The interpolation (or collocation) method</a><ul>
<li><a class="reference internal" href="#example-1">Example  (1)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lagrange-polynomials">Lagrange polynomials</a><ul>
<li><a class="reference internal" href="#approximation-of-a-polynomial">Approximation of a polynomial</a></li>
<li><a class="reference internal" href="#successful-example">Successful example</a></li>
<li><a class="reference internal" href="#less-successful-example">Less successful example</a></li>
<li><a class="reference internal" href="#remedy-for-strong-oscillations">Remedy for strong oscillations</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#finite-element-basis-functions">Finite element basis functions</a><ul>
<li><a class="reference internal" href="#elements-and-nodes">Elements and nodes</a><ul>
<li><a class="reference internal" href="#example-2">Example  (2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-basis-functions">The basis functions</a><ul>
<li><a class="reference internal" href="#construction-principles">Construction principles</a></li>
<li><a class="reference internal" href="#properties-of">Properties of <span class="math">\({\varphi}_i\)</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-on-piecewise-quadratic-finite-element-functions">Example on piecewise quadratic finite element functions</a></li>
<li><a class="reference internal" href="#example-on-piecewise-linear-finite-element-functions">Example on piecewise linear finite element functions</a></li>
<li><a class="reference internal" href="#example-on-piecewise-cubic-finite-element-basis-functions">Example on piecewise cubic finite element basis functions</a></li>
<li><a class="reference internal" href="#calculating-the-linear-system">Calculating the linear system</a><ul>
<li><a class="reference internal" href="#calculating-a-specific-matrix-entry">Calculating a specific matrix entry</a></li>
<li><a class="reference internal" href="#calculating-a-general-row-in-the-matrix">Calculating a general row in the matrix</a></li>
</ul>
</li>
<li><a class="reference internal" href="#assembly-of-elementwise-computations">Assembly of elementwise computations</a></li>
<li><a class="reference internal" href="#mapping-to-a-reference-element">Mapping to a reference element</a></li>
<li><a class="reference internal" href="#example-integration-over-a-reference-element">Example: Integration over a reference element</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-1">Implementation  (1)</a><ul>
<li><a class="reference internal" href="#integration">Integration</a></li>
<li><a class="reference internal" href="#linear-system-assembly-and-solution">Linear system assembly and solution</a></li>
<li><a class="reference internal" href="#example-on-computing-symbolic-approximations">Example on computing symbolic approximations</a></li>
<li><a class="reference internal" href="#comparison-with-finite-elements-and-interpolation-collocation">Comparison with finite elements and interpolation/collocation</a></li>
<li><a class="reference internal" href="#example-on-computing-numerical-approximations">Example on computing numerical approximations</a></li>
<li><a class="reference internal" href="#the-structure-of-the-coefficient-matrix">The structure of the coefficient matrix</a></li>
<li><a class="reference internal" href="#applications">Applications</a></li>
<li><a class="reference internal" href="#sparse-matrix-storage-and-solution">Sparse matrix storage and solution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comparison-of-finite-element-and-finite-difference-approximation">Comparison of finite element and finite difference approximation</a><ul>
<li><a class="reference internal" href="#finite-difference-approximation-of-given-functions">Finite difference approximation of given functions</a></li>
<li><a class="reference internal" href="#finite-difference-interpretation-of-a-finite-element-approximation">Finite difference interpretation of a finite element approximation</a></li>
<li><a class="reference internal" href="#making-finite-elements-behave-as-finite-differences">Making finite elements behave as finite differences</a><ul>
<li><a class="reference internal" href="#computations-in-physical-space">Computations in physical space</a></li>
<li><a class="reference internal" href="#elementwise-computations">Elementwise computations</a></li>
<li><a class="reference internal" href="#terminology">Terminology</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#a-generalized-element-concept">A generalized element concept</a><ul>
<li><a class="reference internal" href="#cells-vertices-and-degrees-of-freedom">Cells, vertices, and degrees of freedom</a></li>
<li><a class="reference internal" href="#extended-finite-element-concept">Extended finite element concept</a></li>
<li><a class="reference internal" href="#implementation-2">Implementation  (2)</a></li>
<li><a class="reference internal" href="#computing-the-error-of-the-approximation">Computing the error of the approximation</a></li>
<li><a class="reference internal" href="#example-cubic-hermite-polynomials">Example: Cubic Hermite polynomials</a></li>
</ul>
</li>
<li><a class="reference internal" href="#numerical-integration-1">Numerical integration  (1)</a><ul>
<li><a class="reference internal" href="#newton-cotes-rules">Newton-Cotes rules</a></li>
<li><a class="reference internal" href="#gauss-legendre-rules-with-optimized-points">Gauss-Legendre rules with optimized points</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-functions-in-2d">Approximation of functions in 2D</a><ul>
<li><a class="reference internal" href="#d-basis-functions-as-tensor-products-of-1d-functions">2D basis functions as tensor products of 1D functions</a></li>
<li><a class="reference internal" href="#example-polynomial-basis-in-2d">Example: Polynomial basis in 2D</a></li>
<li><a class="reference internal" href="#implementation-3">Implementation  (3)</a></li>
<li><a class="reference internal" href="#extension-to-3d">Extension to 3D</a></li>
</ul>
</li>
<li><a class="reference internal" href="#finite-elements-in-2d-and-3d">Finite elements in 2D and 3D</a><ul>
<li><a class="reference internal" href="#basis-functions-over-triangles-in-the-physical-domain">Basis functions over triangles in the physical domain</a><ul>
<li><a class="reference internal" href="#element-matrices-and-vectors">Element matrices and vectors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#basis-functions-over-triangles-in-the-reference-cell">Basis functions over triangles in the reference cell</a></li>
<li><a class="reference internal" href="#affine-mapping-of-the-reference-cell">Affine mapping of the reference cell</a></li>
<li><a class="reference internal" href="#isoparametric-mapping-of-the-reference-cell">Isoparametric mapping of the reference cell</a></li>
<li><a class="reference internal" href="#computing-integrals">Computing integrals</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises-1">Exercises  (1)</a><ul>
<li><a class="reference internal" href="#exercise-1-linear-algebra-refresher-i">Exercise 1: Linear algebra refresher I</a></li>
<li><a class="reference internal" href="#exercise-2-linear-algebra-refresher-ii">Exercise 2: Linear algebra refresher II</a></li>
<li><a class="reference internal" href="#exercise-3-approximate-a-three-dimensional-vector-in-a-plane">Exercise 3: Approximate a three-dimensional vector in a plane</a></li>
<li><a class="reference internal" href="#exercise-4-approximate-the-exponential-function-by-power-functions">Exercise 4: Approximate the exponential function by power functions</a></li>
<li><a class="reference internal" href="#exercise-5-approximate-the-sine-function-by-power-functions">Exercise 5: Approximate the sine function by power functions</a></li>
<li><a class="reference internal" href="#exercise-6-approximate-a-steep-function-by-sines">Exercise 6: Approximate a steep function by sines</a></li>
<li><a class="reference internal" href="#exercise-7-animate-the-approximation-of-a-steep-function-by-sines">Exercise 7: Animate the approximation of a steep function by sines</a></li>
<li><a class="reference internal" href="#exercise-8-fourier-series-as-a-least-squares-approximation">Exercise 8: Fourier series as a least squares approximation</a></li>
<li><a class="reference internal" href="#exercise-9-approximate-a-steep-function-by-lagrange-polynomials">Exercise 9: Approximate a steep function by Lagrange polynomials</a></li>
<li><a class="reference internal" href="#exercise-10-define-nodes-and-elements">Exercise 10: Define nodes and elements</a></li>
<li><a class="reference internal" href="#exercise-11-define-vertices-cells-and-dof-maps">Exercise 11: Define vertices, cells, and dof maps</a></li>
<li><a class="reference internal" href="#exercise-12-construct-matrix-sparsity-patterns">Exercise 12: Construct matrix sparsity patterns</a></li>
<li><a class="reference internal" href="#exercise-13-perform-symbolic-finite-element-computations">Exercise 13: Perform symbolic finite element computations</a></li>
<li><a class="reference internal" href="#exercise-14-approximate-a-steep-function-by-p1-and-p2-elements">Exercise 14: Approximate a steep function by P1 and P2 elements</a></li>
<li><a class="reference internal" href="#exercise-15-approximate-a-steep-function-by-p3-and-p4-elements">Exercise 15: Approximate a steep function by P3 and P4 elements</a></li>
<li><a class="reference internal" href="#exercise-16-investigate-the-approximation-error-in-finite-elements">Exercise 16: Investigate the approximation error in finite elements</a></li>
<li><a class="reference internal" href="#exercise-17-approximate-a-step-function-by-finite-elements">Exercise 17: Approximate a step function by finite elements</a></li>
<li><a class="reference internal" href="#exercise-18-2d-approximation-with-orthogonal-functions">Exercise 18: 2D approximation with orthogonal functions</a></li>
<li><a class="reference internal" href="#exercise-19-use-the-trapezoidal-rule-and-p1-elements">Exercise 19: Use the Trapezoidal rule and P1 elements</a></li>
<li><a class="reference internal" href="#problem-20-compare-p1-elements-and-interpolation">Problem 20: Compare P1 elements and interpolation</a></li>
<li><a class="reference internal" href="#exercise-21-implement-3d-computations-with-global-basis-functions">Exercise 21: Implement 3D computations with global basis functions</a></li>
<li><a class="reference internal" href="#exercise-22-use-simpson-s-rule-and-p2-elements">Exercise 22: Use Simpson&#8217;s rule and P2 elements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#basic-principles-for-approximating-differential-equations">Basic principles for approximating differential equations</a><ul>
<li><a class="reference internal" href="#differential-equation-models">Differential equation models</a></li>
<li><a class="reference internal" href="#simple-model-problems">Simple model problems</a></li>
<li><a class="reference internal" href="#forming-the-residual">Forming the residual</a></li>
<li><a class="reference internal" href="#the-least-squares-method-4">The least squares method  (4)</a></li>
<li><a class="reference internal" href="#the-galerkin-method-1">The Galerkin method  (1)</a></li>
<li><a class="reference internal" href="#the-method-of-weighted-residuals">The Method of Weighted Residuals</a></li>
<li><a class="reference internal" href="#test-and-trial-functions">Test and Trial Functions</a></li>
<li><a class="reference internal" href="#the-collocation-method-1">The collocation method  (1)</a><ul>
<li><a class="reference internal" href="#the-subdomain-collocation-method">The subdomain collocation method</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-on-using-the-principles">Examples on using the principles</a><ul>
<li><a class="reference internal" href="#the-model-problem">The model problem</a></li>
<li><a class="reference internal" href="#basis-functions">Basis functions</a></li>
<li><a class="reference internal" href="#the-residual">The residual</a></li>
<li><a class="reference internal" href="#the-least-squares-method-5">The least squares method  (5)</a></li>
<li><a class="reference internal" href="#the-galerkin-method-2">The Galerkin method  (2)</a></li>
<li><a class="reference internal" href="#the-collocation-method-2">The collocation method  (2)</a></li>
<li><a class="reference internal" href="#comparison">Comparison</a></li>
</ul>
</li>
<li><a class="reference internal" href="#integration-by-parts">Integration by parts</a><ul>
<li><a class="reference internal" href="#weak-form">Weak form</a></li>
</ul>
</li>
<li><a class="reference internal" href="#boundary-function">Boundary function</a></li>
<li><a class="reference internal" href="#abstract-notation-for-variational-formulations">Abstract notation for variational formulations</a></li>
<li><a class="reference internal" href="#variational-problems-and-optimization-of-functionals">Variational problems and optimization of functionals</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-on-variational-formulations">Examples on variational formulations</a><ul>
<li><a class="reference internal" href="#variable-coefficient">Variable coefficient</a></li>
<li><a class="reference internal" href="#first-order-derivative-in-the-equation-and-boundary-condition">First-order derivative in the equation and boundary condition</a></li>
<li><a class="reference internal" href="#nonlinear-coefficient">Nonlinear coefficient</a></li>
<li><a class="reference internal" href="#computing-with-dirichlet-and-neumann-conditions">Computing with Dirichlet and Neumann conditions</a></li>
<li><a class="reference internal" href="#when-the-numerical-method-is-exact">When the numerical method is exact</a></li>
</ul>
</li>
<li><a class="reference internal" href="#computing-with-finite-elements">Computing with finite elements</a><ul>
<li><a class="reference internal" href="#finite-element-mesh-and-basis-functions">Finite element mesh and basis functions</a></li>
<li><a class="reference internal" href="#computation-in-the-global-physical-domain">Computation in the global physical domain</a></li>
<li><a class="reference internal" href="#comparison-with-a-finite-difference-discretization">Comparison with a finite difference discretization</a></li>
<li><a class="reference internal" href="#cellwise-computations-1">Cellwise computations  (1)</a><ul>
<li><a class="reference internal" href="#the-integral-for-the-element-matrix">The integral for the element matrix</a></li>
<li><a class="reference internal" href="#the-integral-for-the-element-vector">The integral for the element vector</a></li>
<li><a class="reference internal" href="#detailed-calculations-of-the-element-matrix-and-vector">Detailed calculations of the element matrix and vector</a></li>
<li><a class="reference internal" href="#contributions-from-the-first-and-last-cell">Contributions from the first and last cell</a></li>
<li><a class="reference internal" href="#assembly">Assembly</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#boundary-conditions-specified-nonzero-value">Boundary conditions: specified nonzero value</a><ul>
<li><a class="reference internal" href="#general-construction-of-a-boundary-function">General construction of a boundary function</a><ul>
<li><a class="reference internal" href="#example-3">Example  (3)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#modification-of-the-linear-system">Modification of the linear system</a><ul>
<li><a class="reference internal" href="#computations-in-the-physical-system">Computations in the physical system</a></li>
</ul>
</li>
<li><a class="reference internal" href="#symmetric-modification-of-the-linear-system">Symmetric modification of the linear system</a></li>
<li><a class="reference internal" href="#modification-of-the-element-matrix-and-vector">Modification of the element matrix and vector</a></li>
</ul>
</li>
<li><a class="reference internal" href="#boundary-conditions-specified-derivative">Boundary conditions: specified derivative</a><ul>
<li><a class="reference internal" href="#the-variational-formulation">The variational formulation</a></li>
<li><a class="reference internal" href="#boundary-term-vanishes-because-of-the-test-functions">Boundary term vanishes because of the test functions</a></li>
<li><a class="reference internal" href="#boundary-term-vanishes-because-of-linear-system-modifications">Boundary term vanishes because of linear system modifications</a></li>
<li><a class="reference internal" href="#direct-computation-of-the-global-linear-system">Direct computation of the global linear system</a></li>
<li><a class="reference internal" href="#cellwise-computations-2">Cellwise computations  (2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-4">Implementation  (4)</a><ul>
<li><a class="reference internal" href="#global-basis-functions">Global basis functions</a></li>
<li><a class="reference internal" href="#example-constant-right-hand-side">Example: constant right-hand side</a></li>
<li><a class="reference internal" href="#finite-elements">Finite elements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#variational-formulations-in-2d-and-3d">Variational formulations in 2D and 3D</a><ul>
<li><a class="reference internal" href="#transformation-to-a-reference-cell-in-2d-and-3d">Transformation to a reference cell in 2D and 3D</a></li>
<li><a class="reference internal" href="#numerical-integration-2">Numerical integration  (2)</a></li>
<li><a class="reference internal" href="#convenient-formulas-for-p1-elements-in-2d">Convenient formulas for P1 elements in 2D</a></li>
</ul>
</li>
<li><a class="reference internal" href="#summary">Summary</a></li>
<li><a class="reference internal" href="#time-dependent-problems">Time-dependent problems</a><ul>
<li><a class="reference internal" href="#discretization-in-time-by-a-forward-euler-scheme">Discretization in time by a Forward Euler scheme</a><ul>
<li><a class="reference internal" href="#time-discretization-1">Time discretization  (1)</a></li>
<li><a class="reference internal" href="#space-discretization">Space discretization</a></li>
<li><a class="reference internal" href="#variational-forms-1">Variational forms  (1)</a></li>
<li><a class="reference internal" href="#linear-systems-1">Linear systems  (1)</a></li>
<li><a class="reference internal" href="#computational-algorithm">Computational algorithm</a></li>
<li><a class="reference internal" href="#comparison-with-the-finite-difference-method">Comparison with the finite difference method</a></li>
<li><a class="reference internal" href="#lumping-the-mass-matrix">Lumping the mass matrix</a></li>
</ul>
</li>
<li><a class="reference internal" href="#discretization-in-time-by-a-backward-euler-scheme">Discretization in time by a Backward Euler scheme</a><ul>
<li><a class="reference internal" href="#time-discretization-2">Time discretization  (2)</a></li>
<li><a class="reference internal" href="#variational-forms-2">Variational forms  (2)</a></li>
<li><a class="reference internal" href="#linear-systems-2">Linear systems  (2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#analysis-of-the-discrete-equations">Analysis of the discrete equations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#systems-of-differential-equations">Systems of differential equations</a><ul>
<li><a class="reference internal" href="#variational-forms-3">Variational forms  (3)</a></li>
<li><a class="reference internal" href="#a-worked-example">A worked example</a></li>
<li><a class="reference internal" href="#identical-function-spaces-for-the-unknowns">Identical function spaces for the unknowns</a><ul>
<li><a class="reference internal" href="#variational-form-of-each-individual-pde">Variational form of each individual PDE</a></li>
<li><a class="reference internal" href="#compound-scalar-variational-form">Compound scalar variational form</a></li>
<li><a class="reference internal" href="#decoupled-linear-systems">Decoupled linear systems</a></li>
<li><a class="reference internal" href="#coupled-linear-systems">Coupled linear systems</a></li>
</ul>
</li>
<li><a class="reference internal" href="#different-function-spaces-for-the-unknowns">Different function spaces for the unknowns</a></li>
<li><a class="reference internal" href="#computations-in-1d">Computations in 1D</a></li>
<li><a class="reference internal" href="#another-example-in-1d">Another example in 1D</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises-2">Exercises  (2)</a><ul>
<li><a class="reference internal" href="#exercise-23-refactor-functions-into-a-more-general-class">Exercise 23: Refactor functions into a more general class</a></li>
<li><a class="reference internal" href="#exercise-24-compute-the-deflection-of-a-cable-with-sine-functions">Exercise 24: Compute the deflection of a cable with sine functions</a></li>
<li><a class="reference internal" href="#exercise-25-check-integration-by-parts">Exercise 25: Check integration by parts</a></li>
<li><a class="reference internal" href="#exercise-26-compute-the-deflection-of-a-cable-with-2-p1-elements">Exercise 26: Compute the deflection of a cable with 2 P1 elements</a></li>
<li><a class="reference internal" href="#exercise-27-compute-the-deflection-of-a-cable-with-1-p2-element">Exercise 27: Compute the deflection of a cable with 1 P2 element</a></li>
<li><a class="reference internal" href="#exercise-28-compute-the-deflection-of-a-cable-with-a-step-load">Exercise 28: Compute the deflection of a cable with a step load</a></li>
<li><a class="reference internal" href="#exercise-29-show-equivalence-between-linear-systems">Exercise 29: Show equivalence between linear systems</a></li>
<li><a class="reference internal" href="#exercise-30-compute-with-a-non-uniform-mesh">Exercise 30: Compute with a non-uniform mesh</a></li>
<li><a class="reference internal" href="#exercise-31-solve-a-1d-finite-element-problem-by-hand">Exercise 31: Solve a 1D finite element problem by hand</a></li>
<li><a class="reference internal" href="#exercise-32-compare-finite-elements-and-differences-for-a-radially-symmetric-poisson-equation">Exercise 32: Compare finite elements and differences for a radially symmetric Poisson equation</a></li>
<li><a class="reference internal" href="#exercise-33-compute-with-variable-coefficients-and-p1-elements-by-hand">Exercise 33: Compute with variable coefficients and P1 elements by hand</a></li>
<li><a class="reference internal" href="#exercise-34-solve-a-2d-poisson-equation-using-polynomials-and-sines">Exercise 34: Solve a 2D Poisson equation using polynomials and sines</a></li>
</ul>
</li>
</ul>

  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/main_fem.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li><a href="index.html">Introduction to finite element methods</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
  <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
  </div>
</div>

  </body>
</html>