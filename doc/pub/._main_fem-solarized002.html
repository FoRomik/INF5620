<!DOCTYPE html>
<!--
Automatically generated HTML file from Doconce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Doconce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Introduction to finite element methods">
<meta name="keywords" content="approximation of vectors in the plane,least squreas method vectors,Galerkin method vectors,projection vectors,approximation of general vectors,Galerkin method vectors,projection vectors,approximation of functions,Galerkin method functions,projection functions,approximation by sines,collocation method (approximation),approximation collocation,interpolation,approximation interpolation,Lagrange (interpolating) polynomial,Kronecker delta,Runge's phenomenon,Chebyshev nodes,finite element mesh,mesh finite elements,Kronecker delta,chapeau function,hat function,finite element basis function,linear elements,quadratic elements,P1 element,P2 element,element matrix,assembly,affine mapping,mapping of reference cells affine mapping,sparse matrices,mass matrix,mass lumping,lumped mass matrix,cell,vertex,degree of freedom,reference cell,finite element, definition,dof map,finite element expansion reference element,Hermite polynomials,numerical integration Midpoint rule,numerical integration Trapezoidal rule,numerical integration Simpson's rule,numerical integration Newton-Cotes formulas,Midpoint rule,Trapezoidal rule,Simpson's rule,Newton-Cotes rules,Gauss-Legendre quadrature,tensor product,simplex elements,simplices,faces,edges,affine mapping,isoparametric mapping,mapping of reference cells isoparametric mapping,residual,variational formulation,trial function,test function,trial space,test space,integration by parts,weak form,strong form,natural boundary condition,essential boundary condition,mass matrix,stiffness matrix,mass matrix,mass lumping,lumped mass matrix,mixed finite elements">



<style type="text/css">
    /* solarized style */
    body {
      margin:5;
      padding:0;
      border:0;	/* Remove the border around the viewport in old versions of IE */
      width:100%;
      background: #fdf6e3;
      min-width:600px;	/* Minimum width of layout - remove if not required */
      font-family: Verdana, Helvetica, Arial, sans-serif;
      font-size: 1.0em;
      line-height: 1.3em;
      color: #657b83;
    }
    a { color: #657b83; text-decoration:none; }
    a:hover { color: #b58900; background: #eee8d5; text-decoration:none; }
    h1, h2, h3 { margin:.8em 0 .2em 0; padding:0; line-height: 125%; }
    h2 { font-variant: small-caps; }
    pre {
      background: #fdf6e3;
      -webkit-box-shadow: inset 0 0 2px #000000;
      -moz-box-shadow: inset 0 0 2px #000000;
      box-shadow: inset 0 0 2px #000000;
      color: #586e75;
      margin-left: 0px;
      font-family: 'Droid Sans Mono', monospace;
      padding: 2px;
      -webkit-border-radius: 4px;
      -moz-border-radius: 4px;
      border-radius: 4px;
      -moz-background-clip: padding;
      -webkit-background-clip: padding-box;
      background-clip: padding-box;
    }
    tt { font-family: "Courier New", Courier; }
    hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    p { text-indent: 0px; }
    p.caption { width: 80%; font-style: normal; text-align: left; }
    hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    .alert-text-small   { font-size: 80%;  }
    .alert-text-large   { font-size: 130%; }
    .alert-text-normal  { font-size: 90%;  }
    .alert {
             padding:8px 35px 8px 14px; margin-bottom:18px;
             text-shadow:0 1px 0 rgba(255,255,255,0.5);
             border:1px solid #FFBF00;
             -webkit-border-radius: 4px; -moz-border-radius: 4px;
             border-radius: 4px
             color: #555;
             background-color: #fbeed5;
             background-position: 10px 5px;
             background-repeat: no-repeat;
             background-size: 38px;
             padding-left: 55px;
             width: 75%;
     }
     .alert-block {padding-top:14px; padding-bottom:14px}
     .alert-block > p, .alert-block > ul {margin-bottom:1em}
     .alert li {margin-top: 1em}
     .alert-block p+p {margin-top:5px}
     .alert-notice { background-image: url(https://raw.github.com/hplgit/doconce/master/bundled/html_images/small_yellow_notice.png); }
     .alert-summary  { background-image:url(https://raw.github.com/hplgit/doconce/master/bundled/html_images/small_yellow_summary.png); }
     .alert-warning { background-image: url(https://raw.github.com/hplgit/doconce/master/bundled/html_images/small_yellow_warning.png); }
     .alert-question {background-image:url(https://raw.github.com/hplgit/doconce/master/bundled/html_images/small_yellow_question.png); }

</style>

</head>

<!-- tocinfo
{'highest level': 1,
 'sections': [(' Approximation of vectors ',
               1,
               'fem:approx:vec',
               'fem:approx:vec'),
              (' Approximation of planar vectors ',
               2,
               'fem:approx:vec:plane',
               'fem:approx:vec:plane'),
              (' The least squares method ', 3, None, '___sec2'),
              (' The projection method ', 3, None, '___sec3'),
              (' Approximation of general vectors ',
               2,
               'fem:approx:vec:Np1dim',
               'fem:approx:vec:Np1dim'),
              (' The least squares method ', 3, None, '___sec5'),
              (' The Galerkin or projection method ', 3, None, '___sec6'),
              (' Approximation of functions ',
               1,
               'fem:approx:global',
               'fem:approx:global'),
              (' The least squares method ',
               2,
               'fem:approx:LS',
               'fem:approx:LS'),
              (' The projection (or Galerkin) method ', 2, None, '___sec9'),
              (' Example: linear approximation ',
               2,
               'fem:approx:global:linear',
               'fem:approx:global:linear'),
              (' Implementation of the least squares method ',
               2,
               'fem:approx:global:LS:code',
               'fem:approx:global:LS:code'),
              (' Perfect approximation ',
               2,
               'fem:approx:global:exact',
               'fem:approx:global:exact'),
              (' Ill-conditioning ',
               2,
               'fem:approx:global:illconditioning',
               'fem:approx:global:illconditioning'),
              (' Fourier series ',
               2,
               'fem:approx:global:Fourier',
               'fem:approx:global:Fourier'),
              (' Orthogonal basis functions ',
               2,
               'fem:approx:global:orth',
               'fem:approx:global:orth'),
              (' Numerical computations ', 2, None, '___sec16'),
              (' The interpolation (or collocation) method ',
               2,
               'fem:approx:global:interp',
               'fem:approx:global:interp'),
              (' Example ', 3, None, '___sec18'),
              (' Lagrange polynomials ',
               2,
               'fem:approx:global:Lagrange',
               'fem:approx:global:Lagrange'),
              (' Approximation of a polynomial ', 3, None, '___sec20'),
              (' Successful example ', 3, None, '___sec21'),
              (' Less successful example ', 3, None, '___sec22'),
              (' Remedy for strong oscillations ', 3, None, '___sec23'),
              (' Finite element basis functions ',
               1,
               'fem:approx:fe',
               'fem:approx:fe'),
              (' Elements and nodes ',
               2,
               'fem:approx:fe:def:elements:nodes',
               'fem:approx:fe:def:elements:nodes'),
              (' Example ', 3, None, '___sec26'),
              (' The basis functions ', 2, None, '___sec27'),
              (' Construction principles ', 3, None, '___sec28'),
              (' Properties of $\\basphi_i$ ', 3, None, '___sec29'),
              (' Example on piecewise quadratic finite element functions ',
               2,
               None,
               '___sec30'),
              (' Example on piecewise linear finite element functions ',
               2,
               None,
               '___sec31'),
              (' Example on piecewise cubic finite element basis functions ',
               2,
               None,
               '___sec32'),
              (' Calculating the linear system ',
               2,
               'fem:approx:global:linearsystem',
               'fem:approx:global:linearsystem'),
              (' Calculating a specific matrix entry ', 3, None, '___sec34'),
              (' Calculating a general row in the matrix ',
               3,
               None,
               '___sec35'),
              (' Assembly of elementwise computations ',
               2,
               'fem:approx:fe:elementwise',
               'fem:approx:fe:elementwise'),
              (' Mapping to a reference element ',
               2,
               'fem:approx:fe:mapping',
               'fem:approx:fe:mapping'),
              (' Example: Integration over a reference element ',
               2,
               'fem:approx:fe:intg:ref',
               'fem:approx:fe:intg:ref'),
              (' Implementation ',
               1,
               'fem:approx:fe:impl',
               'fem:approx:fe:impl'),
              (' Integration ',
               2,
               'fem:approx:fe:impl:intg',
               'fem:approx:fe:impl:intg'),
              (' Linear system assembly and solution ',
               2,
               'fem:approx:fe:impl:linsys',
               'fem:approx:fe:impl:linsys'),
              (' Example on computing symbolic approximations ',
               2,
               'fem:approx:fe:impl:ex1:symbolic',
               'fem:approx:fe:impl:ex1:symbolic'),
              (' Comparison with finite elements and interpolation/collocation ',
               2,
               'fem:approx:fe:impl:ex1:collocation',
               'fem:approx:fe:impl:ex1:collocation'),
              (' Example on computing numerical approximations ',
               2,
               'fem:approx:fe:impl:ex1:numeric',
               'fem:approx:fe:impl:ex1:numeric'),
              (' The structure of the coefficient matrix ',
               2,
               'fem:approx:fe:A:structure',
               'fem:approx:fe:A:structure'),
              (' Applications ',
               2,
               'fem:approx:fe:impl:ex2',
               'fem:approx:fe:impl:ex2'),
              (' Sparse matrix storage and solution ',
               2,
               'fem:approx:fe:impl:sparse',
               'fem:approx:fe:impl:sparse'),
              (' Comparison of finite element and finite difference approximation ',
               1,
               'fem:approx:fe:fd',
               'fem:approx:fe:fd'),
              (' Finite difference approximation of given functions ',
               2,
               'fem:approx:fe:fd:fdproj',
               'fem:approx:fe:fd:fdproj'),
              (' Finite difference interpretation of a finite element approximation ',
               2,
               'fem:approx:fe:fd:feproj',
               'fem:approx:fe:fd:feproj'),
              (' Making finite elements behave as finite differences ',
               2,
               None,
               '___sec51'),
              (' Computations in physical space ', 3, None, '___sec52'),
              (' Elementwise computations ', 3, None, '___sec53'),
              (' Terminology ', 3, None, '___sec54'),
              (' A generalized element concept ',
               1,
               'fem:approx:fe:element',
               'fem:approx:fe:element'),
              (' Cells, vertices, and degrees of freedom ',
               2,
               'fem:approx:fe:element:terminology',
               'fem:approx:fe:element:terminology'),
              (' Extended finite element concept ',
               2,
               'fem:approx:fe:element:def',
               'fem:approx:fe:element:def'),
              (' Implementation ',
               2,
               'fem:approx:fe:element:impl',
               'fem:approx:fe:element:impl'),
              (' Computing the error of the approximation ',
               2,
               'fem:approx:fe:element:impl:error',
               'fem:approx:fe:element:impl:error'),
              (' Example: Cubic Hermite polynomials ',
               2,
               'fem:approx:fe:element:impl:Hermite',
               'fem:approx:fe:element:impl:Hermite'),
              (' Numerical integration ', 1, None, '___sec61'),
              (' Newton-Cotes rules ',
               2,
               'fem:approx:fe:numint1',
               'fem:approx:fe:numint1'),
              (' Gauss-Legendre rules with optimized points ',
               2,
               None,
               '___sec63'),
              (' Approximation of functions in 2D ',
               1,
               'fem:approx:2D',
               'fem:approx:2D'),
              (' 2D basis functions as tensor products of 1D functions ',
               2,
               'fem:approx:2D:global',
               'fem:approx:2D:global'),
              (' Example: Polynomial basis in 2D ', 2, None, '___sec66'),
              (' Implementation ',
               2,
               'fem:approx:2D:global:code',
               'fem:approx:2D:global:code'),
              (' Extension to 3D ',
               2,
               'fem:approx:3D:global',
               'fem:approx:3D:global'),
              (' Finite elements in 2D and 3D ', 1, None, '___sec69'),
              (' Basis functions over triangles in the physical domain ',
               2,
               None,
               '___sec70'),
              (' Element matrices and vectors ', 3, None, '___sec71'),
              (' Basis functions over triangles in the reference cell ',
               2,
               None,
               '___sec72'),
              (' Affine mapping of the reference cell ', 2, None, '___sec73'),
              (' Isoparametric mapping of the reference cell ',
               2,
               None,
               '___sec74'),
              (' Computing integrals ', 2, None, '___sec75'),
              (' Exercises ', 1, None, '___sec76'),
              (' Exercise 1: Linear algebra refresher I ',
               2,
               'fem:approx:exer:linalg1',
               'fem:approx:exer:linalg1'),
              (' Exercise 2: Linear algebra refresher II ',
               2,
               'fem:approx:exer:linalg2',
               'fem:approx:exer:linalg2'),
              (' Exercise 3: Approximate a three-dimensional vector in a plane ',
               2,
               'fem:approx:exer:vec:3Dby2D',
               'fem:approx:exer:vec:3Dby2D'),
              (' Exercise 4: Approximate the exponential function by power functions ',
               2,
               'fem:approx:exer:exp:powers',
               'fem:approx:exer:exp:powers'),
              (' Exercise 5: Approximate the sine function by power functions ',
               2,
               'fem:approx:exer:sin:powers',
               'fem:approx:exer:sin:powers'),
              (' Exercise 6: Approximate a steep function by sines ',
               2,
               'fem:approx:exer:tanh:sine1',
               'fem:approx:exer:tanh:sine1'),
              (' Exercise 7: Animate the approximation of a steep function by sines ',
               2,
               'fem:approx:exer:tanh:sine2',
               'fem:approx:exer:tanh:sine2'),
              (' Exercise 8: Fourier series as a least squares approximation ',
               2,
               'fem:approx:exer:Fourier',
               'fem:approx:exer:Fourier'),
              (' Exercise 9: Approximate a steep function by Lagrange polynomials ',
               2,
               'fem:approx:exer:tanh',
               'fem:approx:exer:tanh'),
              (' Exercise 10: Define nodes and elements ',
               2,
               'fem:approx:fe:exer:mesh1',
               'fem:approx:fe:exer:mesh1'),
              (' Exercise 11: Define vertices, cells, and dof maps ',
               2,
               'fem:approx:fe:exer:mesh2',
               'fem:approx:fe:exer:mesh2'),
              (' Exercise 12: Construct matrix sparsity patterns ',
               2,
               'fem:approx:fe:exer:defmesh:sparsity',
               'fem:approx:fe:exer:defmesh:sparsity'),
              (' Exercise 13: Perform symbolic finite element computations ',
               2,
               'fem:approx:fe:exer:Asinwt:symbolic',
               'fem:approx:fe:exer:Asinwt:symbolic'),
              (' Exercise 14: Approximate a steep function by P1 and P2 elements ',
               2,
               'fem:approx:exer:tanh',
               'fem:approx:exer:tanh'),
              (' Exercise 15: Approximate a steep function by P3 and P4 elements ',
               2,
               'fem:approx:exer:tanh2',
               'fem:approx:exer:tanh2'),
              (' Exercise 16: Investigate the approximation error in finite elements ',
               2,
               'fem:approx:fe:exer:Asinwt:interpol:error',
               'fem:approx:fe:exer:Asinwt:interpol:error'),
              (' Exercise 17: Approximate a step function by finite elements ',
               2,
               'fem:approx:fe:exer:Heaviside',
               'fem:approx:fe:exer:Heaviside'),
              (' Exercise 18: 2D approximation with orthogonal functions ',
               2,
               'fem:approx:fe:exer:2Dsines:symbolic',
               'fem:approx:fe:exer:2Dsines:symbolic'),
              (' Exercise 19: Use the Trapezoidal rule and P1 elements ',
               2,
               'fem:approx:fe:exer:1D:trapez',
               'fem:approx:fe:exer:1D:trapez'),
              (' Problem 20: Compare P1 elements and interpolation ',
               2,
               'fem:approx:fe:exer:1D:P1:vs:interp',
               'fem:approx:fe:exer:1D:P1:vs:interp'),
              (' Exercise 21: Implement 3D computations with global basis functions ',
               2,
               'fem:approx:fe:exer:3D:approx3D',
               'fem:approx:fe:exer:3D:approx3D'),
              (" Exercise 22: Use Simpson's rule and P2 elements ",
               2,
               'fem:approx:fe:exer:1D:simpson',
               'fem:approx:fe:exer:1D:simpson'),
              (' Basic principles for approximating differential equations ',
               1,
               'fem:deq:1D:principles',
               'fem:deq:1D:principles'),
              (' Differential equation models ',
               2,
               'fem:deq:1D:models',
               'fem:deq:1D:models'),
              (' Simple model problems ',
               2,
               'fem:deq:1D:models:simple',
               'fem:deq:1D:models:simple'),
              (' Forming the residual ',
               2,
               'fem:deq:1D:residual:min',
               'fem:deq:1D:residual:min'),
              (' The least squares method ', 2, None, '___sec103'),
              (' The Galerkin method ', 2, None, '___sec104'),
              (' The Method of Weighted Residuals ', 2, None, '___sec105'),
              (' Test and Trial Functions ', 2, None, '___sec106'),
              (' The collocation method ', 2, None, '___sec107'),
              (' The subdomain collocation method ', 3, None, '___sec108'),
              (' Examples on using the principles ',
               2,
               'fem:deq:1D:ex:sines',
               'fem:deq:1D:ex:sines'),
              (' The model problem ', 3, None, '___sec110'),
              (' Basis functions ', 3, None, '___sec111'),
              (' The residual ', 3, None, '___sec112'),
              (' The least squares method ', 3, None, '___sec113'),
              (' The Galerkin method ', 3, None, '___sec114'),
              (' The collocation method ', 3, None, '___sec115'),
              (' Comparison ', 3, None, '___sec116'),
              (' Integration by parts ',
               2,
               'fem:deq:1D:varform',
               'fem:deq:1D:varform'),
              (' Weak form ', 3, None, '___sec118'),
              (' Boundary function ',
               2,
               'fem:deq:1D:essBC:Bfunc',
               'fem:deq:1D:essBC:Bfunc'),
              (' Abstract notation for variational formulations ',
               2,
               'fem:deq:1D:varform:abstract',
               'fem:deq:1D:varform:abstract'),
              (' Variational problems and optimization of functionals ',
               2,
               'fem:deq:1D:optimization',
               'fem:deq:1D:optimization'),
              (' Examples on variational formulations ',
               1,
               'fem:deq:1D:varform:ex',
               'fem:deq:1D:varform:ex'),
              (' Variable coefficient ', 2, None, '___sec123'),
              (' First-order derivative in the equation and boundary condition ',
               2,
               None,
               '___sec124'),
              (' Nonlinear coefficient ', 2, None, '___sec125'),
              (' Computing with Dirichlet and Neumann conditions ',
               2,
               'fem:deq:1D:varform:ex:DN:case',
               'fem:deq:1D:varform:ex:DN:case'),
              (' When the numerical method is exact ', 2, None, '___sec127'),
              (' Computing with finite elements ',
               1,
               'fem:deq:1D:fem1',
               'fem:deq:1D:fem1'),
              (' Finite element mesh and basis functions ',
               2,
               None,
               '___sec129'),
              (' Computation in the global physical domain ',
               2,
               'fem:deq:1D:comp:global',
               'fem:deq:1D:comp:global'),
              (' Comparison with a finite difference discretization ',
               2,
               None,
               '___sec131'),
              (' Cellwise computations ',
               2,
               'fem:deq:1D:comp:elmwise',
               'fem:deq:1D:comp:elmwise'),
              (' The integral for the element matrix ', 3, None, '___sec133'),
              (' The integral for the element vector ', 3, None, '___sec134'),
              (' Detailed calculations of the element matrix and vector ',
               3,
               None,
               '___sec135'),
              (' Contributions from the first and last cell ',
               3,
               None,
               '___sec136'),
              (' Assembly ', 3, None, '___sec137'),
              (' Boundary conditions: specified nonzero value ',
               1,
               'fem:deq:1D:essBC',
               'fem:deq:1D:essBC'),
              (' General construction of a boundary function ',
               2,
               'fem:deq:1D:fem:essBC:Bfunc',
               'fem:deq:1D:fem:essBC:Bfunc'),
              (' Example on computing with finite element-based a boundary function ',
               2,
               None,
               '___sec140'),
              (' Computations in physical coordinates ',
               3,
               None,
               '___sec141'),
              (' Cellwise computations on the reference element ',
               3,
               None,
               '___sec142'),
              (' Modification of the linear system ',
               2,
               'fem:deq:1D:fem:essBC:Bfunc:modsys',
               'fem:deq:1D:fem:essBC:Bfunc:modsys'),
              (' Computations in the physical system ', 3, None, '___sec144'),
              (' Symmetric modification of the linear system ',
               2,
               'fem:deq:1D:fem:essBC:Bfunc:modsys:symm',
               'fem:deq:1D:fem:essBC:Bfunc:modsys:symm'),
              (' Modification of the element matrix and vector ',
               2,
               None,
               '___sec146'),
              (' Boundary conditions: specified derivative ',
               1,
               'fem:deq:1D:BC:nat',
               'fem:deq:1D:BC:nat'),
              (' The variational formulation ', 2, None, '___sec148'),
              (' Boundary term vanishes because of the test functions ',
               2,
               'fem:deq:1D:BC:nat:uLtest',
               'fem:deq:1D:BC:nat:uLtest'),
              (' Boundary term vanishes because of linear system modifications ',
               2,
               'fem:deq:1D:BC:nat:uLmod',
               'fem:deq:1D:BC:nat:uLmod'),
              (' Direct computation of the global linear system ',
               2,
               'fem:deq:1D:BC:nat:Aub',
               'fem:deq:1D:BC:nat:Aub'),
              (' Cellwise computations ', 2, None, '___sec152'),
              (' Implementation ',
               1,
               'fem:deq:1D:code:global',
               'fem:deq:1D:code:global'),
              (' Global basis functions ', 2, None, '___sec154'),
              (' Example: constant right-hand side ', 2, None, '___sec155'),
              (' Finite elements ', 2, None, '___sec156'),
              (' Variational formulations in 2D and 3D ',
               1,
               'fem:deq:2D:varform',
               'fem:deq:2D:varform'),
              (' Transformation to a reference cell in 2D and 3D ',
               2,
               None,
               '___sec158'),
              (' Numerical integration ', 2, None, '___sec159'),
              (' Convenient formulas for P1 elements in 2D ',
               2,
               None,
               '___sec160'),
              (' Summary ', 1, None, '___sec161'),
              (' Time-dependent problems ',
               1,
               'fem:deq:timedep',
               'fem:deq:timedep'),
              (' Discretization in time by a Forward Euler scheme ',
               2,
               'fem:deq:diffu:FE',
               'fem:deq:diffu:FE'),
              (' Time discretization ', 3, None, '___sec164'),
              (' Space discretization ', 3, None, '___sec165'),
              (' Variational forms ', 2, None, '___sec166'),
              (' Simplified notation for the solution at recent time levels ',
               2,
               None,
               '___sec167'),
              (' Deriving the linear systems ', 2, None, '___sec168'),
              (' Computational algorithm ', 2, None, '___sec169'),
              (' Comparing P1 elements with the finite difference method ',
               2,
               'fem:deq:diffu:FE:fdvsP1fe',
               'fem:deq:diffu:FE:fdvsP1fe'),
              (' Lumping the mass matrix ', 3, None, '___sec171'),
              (' Discretization in time by a Backward Euler scheme ',
               2,
               'fem:deq:diffu:BE',
               'fem:deq:diffu:BE'),
              (' Time discretization ', 3, None, '___sec173'),
              (' Variational forms ', 3, None, '___sec174'),
              (' Linear systems ', 3, None, '___sec175'),
              (' Dirichlet boundary conditions ',
               2,
               'fem:deq:diffu:Dirichlet',
               'fem:deq:diffu:Dirichlet'),
              (' Boundary function ', 3, None, '___sec177'),
              (' Finite element basis functions ', 3, None, '___sec178'),
              (' Modification of the linear system ', 3, None, '___sec179'),
              (' Example: Oscillating Dirichlet boundary condition ',
               2,
               'fem:deq:diffu:Dirichlet:ex',
               'fem:deq:diffu:Dirichlet:ex'),
              (' Analysis of the discrete equations ',
               2,
               'fem:deq:diffu:anal',
               'fem:deq:diffu:anal'),
              (' Forward Euler discretization ', 3, None, '___sec182'),
              (' Backward Euler discretization ', 3, None, '___sec183'),
              (' Comparing amplification factors ', 3, None, '___sec184'),
              (' Systems of differential equations ',
               1,
               'fem:sys',
               'fem:sys'),
              (' Variational forms ', 2, 'fem:sys:vform', 'fem:sys:vform'),
              (' A worked example ', 2, 'fem:sys:uT:ex', 'fem:sys:uT:ex'),
              (' Identical function spaces for the unknowns ',
               2,
               None,
               '___sec188'),
              (' Variational form of each individual PDE ',
               3,
               None,
               '___sec189'),
              (' Compound scalar variational form ', 3, None, '___sec190'),
              (' Decoupled linear systems ', 3, None, '___sec191'),
              (' Coupled linear systems ', 3, None, '___sec192'),
              (' Different function spaces for the unknowns ',
               2,
               None,
               '___sec193'),
              (' Computations in 1D ', 2, None, '___sec194'),
              (' Exercises ', 1, None, '___sec195'),
              (' Exercise 23: Refactor functions into a more general class ',
               2,
               'fem:deq:exer:BVP1D:class',
               'fem:deq:exer:BVP1D:class'),
              (' Exercise 24: Compute the deflection of a cable with sine functions ',
               2,
               'fem:deq:exer:tension:cable',
               'fem:deq:exer:tension:cable'),
              (' Exercise 25: Check integration by parts ',
               2,
               'fem:deq:exer:intg:parts',
               'fem:deq:exer:intg:parts'),
              (' Exercise 26: Compute the deflection of a cable with 2 P1 elements ',
               2,
               'fem:deq:exer:intg:parts',
               'fem:deq:exer:intg:parts'),
              (' Exercise 27: Compute the deflection of a cable with 1 P2 element ',
               2,
               'fem:deq:exer:intg:parts',
               'fem:deq:exer:intg:parts'),
              (' Exercise 28: Compute the deflection of a cable with a step load ',
               2,
               'fem:deq:exer:intg:parts',
               'fem:deq:exer:intg:parts'),
              (' Exercise 29: Show equivalence between linear systems ',
               2,
               'fem:deq:exer:Aub:essbc:equiv',
               'fem:deq:exer:Aub:essbc:equiv'),
              (' Exercise 30: Compute with a non-uniform mesh ',
               2,
               'fem:deq:exer:1D:mesh:nonuniform',
               'fem:deq:exer:1D:mesh:nonuniform'),
              (' Problem 31: Solve a 1D finite element problem by hand ',
               2,
               'fem:deq:exer:1D:gen:problem1',
               'fem:deq:exer:1D:gen:problem1'),
              (' Exercise 32: Compare finite elements and differences for a radially symmetric Poisson equation ',
               2,
               'fem:deq:exer:1D:Poisson:polar',
               'fem:deq:exer:1D:Poisson:polar'),
              (' Exercise 33: Compute with variable coefficients and P1 elements by hand ',
               2,
               'fem:deq:exer:1D:gen:problem2',
               'fem:deq:exer:1D:gen:problem2'),
              (' Exercise 34: Solve a 2D Poisson equation using polynomials and sines ',
               2,
               'fem:deq:exer:2D:torsion:xy:sin',
               'fem:deq:exer:2D:torsion:xy:sin'),
              (' Exercise 35: Analyze a Crank-Nicolson scheme for the diffusion equation ',
               2,
               'fem:deq:exer:diffu:analysis:CN',
               'fem:deq:exer:diffu:analysis:CN')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- Fix slow MathJax rendering in IE8 -->
<meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7">


<!-- newcommands_keep.tex -->
$$
\newcommand{\uex}{{u_{\small\mbox{e}}}}
\newcommand{\uexd}[1]{{u_{\small\mbox{e}, #1}}}
\newcommand{\vex}{{v_{\small\mbox{e}}}}
\newcommand{\vexd}[1]{{v_{\small\mbox{e}, #1}}}
\newcommand{\Aex}{{A_{\small\mbox{e}}}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\halfi}{{1/2}}
\newcommand{\tp}{\thinspace .}

\newcommand{\Ddt}[1]{\frac{D #1}{dt}}
\newcommand{\E}[1]{\hbox{E}\lbrack #1 \rbrack}
\newcommand{\Var}[1]{\hbox{Var}\lbrack #1 \rbrack}
\newcommand{\Std}[1]{\hbox{Std}\lbrack #1 \rbrack}

\newcommand{\xpoint}{\boldsymbol{x}}
\newcommand{\normalvec}{\boldsymbol{n}}
\newcommand{\Oof}[1]{\mathcal{O}(#1)}

\newcommand{\x}{\boldsymbol{x}}
\newcommand{\X}{\boldsymbol{X}}
\renewcommand{\u}{\boldsymbol{u}}
\renewcommand{\v}{\boldsymbol{v}}
\newcommand{\w}{\boldsymbol{w}}
\newcommand{\V}{\boldsymbol{V}}
\newcommand{\e}{\boldsymbol{e}}
\newcommand{\f}{\boldsymbol{f}}
\newcommand{\F}{\boldsymbol{F}}
\newcommand{\stress}{\boldsymbol{\sigma}}
\newcommand{\strain}{\boldsymbol{\varepsilon}}
\newcommand{\stressc}{{\sigma}}
\newcommand{\strainc}{{\varepsilon}}
\newcommand{\I}{\boldsymbol{I}}
\newcommand{\T}{\boldsymbol{T}}

\newcommand{\dfc}{\alpha}  % diffusion coefficient
\newcommand{\ii}{\boldsymbol{i}}
\newcommand{\jj}{\boldsymbol{j}}
\newcommand{\kk}{\boldsymbol{k}}
\newcommand{\ir}{\boldsymbol{i}_r}
\newcommand{\ith}{\boldsymbol{i}_{\theta}}
\newcommand{\iz}{\boldsymbol{i}_z}

\newcommand{\Ix}{\mathcal{I}_x}
\newcommand{\Iy}{\mathcal{I}_y}
\newcommand{\Iz}{\mathcal{I}_z}
\newcommand{\It}{\mathcal{I}_t}
\newcommand{\If}{\mathcal{I}_s}     % for FEM
\newcommand{\Ifd}{{I_d}}  % for FEM
\newcommand{\Ifb}{{I_b}}  % for FEM
\newcommand{\setb}[1]{#1^0}    % set begin
\newcommand{\sete}[1]{#1^{-1}} % set end
\newcommand{\setl}[1]{#1^-}
\newcommand{\setr}[1]{#1^+}
\newcommand{\seti}[1]{#1^i}
\newcommand{\sequencei}[1]{\left\{ {#1}_i \right\}_{i\in\If}}

\newcommand{\basphi}{\varphi}
\newcommand{\baspsi}{\psi}
\newcommand{\refphi}{\tilde\basphi}
\newcommand{\psib}{\boldsymbol{\psi}}
\newcommand{\sinL}[1]{\sin\left((#1+1)\pi\frac{x}{L}\right)}
\newcommand{\xno}[1]{x_{#1}}
\newcommand{\Xno}[1]{X_{(#1)}}
\newcommand{\yno}[1]{y_{#1}}
\newcommand{\Yno}[1]{Y_{(#1)}}
\newcommand{\xdno}[1]{\boldsymbol{x}_{#1}}

\newcommand{\dX}{\, \mathrm{d}X}
\newcommand{\dx}{\, \mathrm{d}x}
\newcommand{\ds}{\, \mathrm{d}s}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Integerp}{\mathbb{N}}
\newcommand{\Integer}{\mathbb{Z}}
$$




    
<a name="part0002"></a>
<!-- begin top navigation -->
<a href="._main_fem-solarized001.html"><img src="http://hplgit.github.io/doconce/bundled/html_images/prev1.png" border=0 alt="previous"></a>

<a href="._main_fem-solarized003.html"><img src="http://hplgit.github.io/doconce/bundled/html_images/next1.png" border=0 alt="next"></a>
<!-- end top navigation -->

<p>
<!-- !split -->

<h2>Approximation of functions <a name="fem:approx:global"></a></h2>

<p>
Let \( V \) be a function space spanned by a set of <em>basis functions</em>
\( \baspsi_0,\ldots,\baspsi_N \),

<p>
$$
\begin{equation*} V = \hbox{span}\,\{\baspsi_0,\ldots,\baspsi_N\},\end{equation*}
$$

such that any function \( u\in V \) can be written as a linear
combination of the basis functions:

<p>
$$
\begin{equation}
u = \sum_{j\in\If} c_j\baspsi_j\tp
\tag{14}
\end{equation}
$$

The index set \( \If \) is defined as \( \If =\{0,\ldots,N\} \) and is used
both for compact notation and for flexibility in the numbering of
elements in sequences.

<p>
For now, in this introduction, we shall look at functions of a
single variable \( x \):
\( u=u(x) \), \( \baspsi_i=\baspsi_i(x) \), \( i\in\If \). Later, we will almost
trivially extend the mathematical details
to functions of two- or three-dimensional physical spaces.
The approximation <a href="#mjx-eqn-14">(14)</a> is typically used
to discretize a problem in space. Other methods, most notably
finite differences, are common for time discretization, although the
form <a href="#mjx-eqn-14">(14)</a> can be used in time as well.

<h3>The least squares method <a name="fem:approx:LS"></a></h3>

<p>
Given a function \( f(x) \), how can we determine its best approximation
\( u(x)\in V \)? A natural starting point is to apply the same reasoning
as we did for vectors in the section <a href="._main_fem-solarized001.html#fem:approx:vec:Np1dim">Approximation of general vectors</a>. That is,
we minimize the distance between \( u \) and \( f \). However, this requires
a norm for measuring distances, and a norm is most conveniently
defined through an
inner product. Viewing a function as a vector of infinitely
many point values, one for each value of \( x \), the inner product could
intuitively be defined as the usual summation of
pairwise components, with summation replaced by integration:

<p>
$$
\begin{equation*}
(f,g) = \int f(x)g(x)\, \dx
\tp
\end{equation*}
$$

To fix the integration domain, we let \( f(x) \) and \( \baspsi_i(x) \)
be defined for a domain \( \Omega\subset\Real \).
The inner product of two functions \( f(x) \) and \( g(x) \) is then

<p>
$$
\begin{equation}
(f,g) = \int_\Omega f(x)g(x)\, \dx
\tag{15}
\tp
\end{equation}
$$


<p>
The distance between \( f \) and any function \( u\in V \) is simply
\( f-u \), and the squared norm of this distance is

<p>
$$
\begin{equation}
E = (f(x)-\sum_{j\in\If} c_j\baspsi_j(x), f(x)-\sum_{j\in\If} c_j\baspsi_j(x))\tp
\tag{16}
\end{equation}
$$

Note the analogy with <a href="._main_fem-solarized001.html#mjx-eqn-10">(10)</a>: the given function
\( f \) plays the role of the given vector \( \f \), and the basis function
\( \baspsi_i \) plays the role of the basis vector \( \psib_i \).
We can rewrite <a href="#mjx-eqn-16">(16)</a>,
through similar steps as used for the result
<a href="._main_fem-solarized001.html#mjx-eqn-10">(10)</a>, leading to

<p>
$$
\begin{equation}
E(c_i, \ldots, c_N) = (f,f) -2\sum_{j\in\If} c_j(f,\baspsi_i)
+ \sum_{p\in\If}\sum_{q\in\If} c_pc_q(\baspsi_p,\baspsi_q)\tp  \end{equation}
$$

Minimizing this function of \( N+1 \) scalar variables
\( \sequencei{c} \), requires differentiation
with respect to \( c_i \), for all \( i\in\If \). The resulting
equations are very similar to those we had in the vector case,
and we hence end up with a
linear system of the form <a href="._main_fem-solarized001.html#mjx-eqn-11">(11)</a>, with
basically the same expressions:

<p>
$$
\begin{align}
A_{i,j} &= (\baspsi_i,\baspsi_j),
\tag{17}\\ 
b_i &= (f,\baspsi_i)\tp
\tag{18}
\end{align}
$$

<h3>The projection (or Galerkin) method  <a name="___sec9"></a></h3>

<p>
As in the section <a href="._main_fem-solarized001.html#fem:approx:vec:Np1dim">Approximation of general vectors</a>, the minimization of \( (e,e) \)
is equivalent to

<p>
$$
\begin{equation}
(e,v)=0,\quad\forall v\in V\tp
\tag{19}
\end{equation}
$$

This is known as a projection of a function \( f \) onto the subspace \( V \).
We may also call it a Galerkin method for approximating functions.
Using the same reasoning as
in
<a href="._main_fem-solarized001.html#mjx-eqn-12">(12)</a>-<a href="._main_fem-solarized001.html#mjx-eqn-13">(13)</a>,
it follows that <a href="#mjx-eqn-19">(19)</a> is equivalent to

<p>
$$
\begin{equation}
(e,\baspsi_i)=0,\quad i\in\If\tp
\tag{20}
\end{equation}
$$

Inserting \( e=f-u \) in this equation and ordering terms, as in the
multi-dimensional vector case, we end up with a linear
system with a coefficient matrix <a href="#mjx-eqn-17">(17)</a> and
right-hand side vector <a href="#mjx-eqn-18">(18)</a>.

<p>
Whether we work with vectors in the plane, general vectors, or
functions in function spaces, the least squares principle and
the projection or Galerkin method are equivalent.

<h3>Example: linear approximation <a name="fem:approx:global:linear"></a></h3>

<p>
Let us apply the theory in the previous section to a simple problem:
given a parabola \( f(x)=10(x-1)^2-1 \) for \( x\in\Omega=[1,2] \), find
the best approximation \( u(x) \) in the space of all linear functions:

<p>
$$
\begin{equation*} V = \hbox{span}\,\{1, x\}\tp  \end{equation*}
$$

With our notation, \( \baspsi_0(x)=1 \), \( \baspsi_1(x)=x \), and \( N=1 \).
We seek

<p>
$$
\begin{equation*} u=c_0\baspsi_0(x) + c_1\baspsi_1(x) = c_0 + c_1x,\end{equation*}
$$

where
\( c_0 \) and \( c_1 \) are found by solving a \( 2\times 2 \) the linear system.
The coefficient matrix has elements

<p>
$$
\begin{align}
A_{0,0} &= (\baspsi_0,\baspsi_0) = \int_1^21\cdot 1\, \dx = 1,\\ 
A_{0,1} &= (\baspsi_0,\baspsi_1) = \int_1^2 1\cdot x\, \dx = 3/2,\\ 
A_{1,0} &= A_{0,1} = 3/2,\\ 
A_{1,1} &= (\baspsi_1,\baspsi_1) = \int_1^2 x\cdot x\,\dx = 7/3\tp  \end{align}
$$

The corresponding right-hand side is

<p>
$$
\begin{align}
b_1 &= (f,\baspsi_0) = \int_1^2 (10(x-1)^2 - 1)\cdot 1 \, \dx = 7/3,\\ 
b_2 &= (f,\baspsi_1) = \int_1^2 (10(x-1)^2 - 1)\cdot x\, \dx = 13/3\tp  \end{align}
$$

Solving the linear system results in

<p>
$$
\begin{equation}
c_0 = -38/3,\quad c_1 = 10,
\end{equation}
$$

and consequently

<p>
$$
\begin{equation}
u(x) = 10x - \frac{38}{3}\tp  \end{equation}
$$

Figure <a href="#fem:approx:global:fig:parabola:linear">3</a> displays the
parabola and its best approximation in the space of all linear functions.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 3:  Best approximation of a parabola by a straight line.  <a name="fem:approx:global:fig:parabola:linear"></a> </p></center>
<p><img src="fig-fem/parabola_ls_linear.png" align="bottom" width=400></p>
</center>

<h3>Implementation of the least squares method <a name="fem:approx:global:LS:code"></a></h3>

<p>
The linear system can be computed either symbolically or
numerically (a numerical integration rule is needed in the latter case).
Here is a function for symbolic computation of the linear system,
where \( f(x) \) is given as a <code>sympy</code> expression <code>f</code> involving
the symbol <code>x</code>, <code>psi</code> is a list of expressions for \( \sequencei{\baspsi} \),
and <code>Omega</code> is a 2-tuple/list holding the limits of the domain \( \Omega \):

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">sympy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">sp</span>

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">least_squares</span>(f, psi, Omega):
    N = <span style="color: #658b00">len</span>(psi) - <span style="color: #B452CD">1</span>
    A = sp.zeros((N+<span style="color: #B452CD">1</span>, N+<span style="color: #B452CD">1</span>))
    b = sp.zeros((N+<span style="color: #B452CD">1</span>, <span style="color: #B452CD">1</span>))
    x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>):
        <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(i, N+<span style="color: #B452CD">1</span>):
            A[i,j] = sp.integrate(psi[i]*psi[j],
                                  (x, Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]))
            A[j,i] = A[i,j]
        b[i,<span style="color: #B452CD">0</span>] = sp.integrate(psi[i]*f, (x, Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]))
    c = A.LUsolve(b)
    u = <span style="color: #B452CD">0</span>
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #658b00">len</span>(psi)):
        u += c[i,<span style="color: #B452CD">0</span>]*psi[i]
    <span style="color: #8B008B; font-weight: bold">return</span> u, c
</pre></div>
<p>
Observe that we exploit the symmetry of the coefficient matrix:
only the upper triangular part is computed. Symbolic integration in
<code>sympy</code> is often time consuming, and (roughly) halving the
work has noticeable effect on the waiting time for the function to
finish execution.

<p>
Comparing the given \( f(x) \) and the approximate \( u(x) \) visually is
done by the following function, which with the aid of
<code>sympy</code>'s <code>lambdify</code> tool converts a <code>sympy</code>
expression to a Python function for numerical
computations:

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">comparison_plot</span>(f, u, Omega, filename=<span style="color: #CD5555">&#39;tmp.pdf&#39;</span>):
    x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
    f = sp.lambdify([x], f, modules=<span style="color: #CD5555">&quot;numpy&quot;</span>)
    u = sp.lambdify([x], u, modules=<span style="color: #CD5555">&quot;numpy&quot;</span>)
    resolution = <span style="color: #B452CD">401</span>  <span style="color: #228B22"># no of points in plot</span>
    xcoor  = linspace(Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>], resolution)
    exact  = f(xcoor)
    approx = u(xcoor)
    plot(xcoor, approx)
    hold(<span style="color: #CD5555">&#39;on&#39;</span>)
    plot(xcoor, exact)
    legend([<span style="color: #CD5555">&#39;approximation&#39;</span>, <span style="color: #CD5555">&#39;exact&#39;</span>])
    savefig(filename)
</pre></div>
<p>
The <code>modules='numpy'</code> argument to <code>lambdify</code> is important
if there are mathematical functions, such as <code>sin</code> or <code>exp</code>
in the symbolic expressions in <code>f</code> or <code>u</code>, and these
mathematical functions are to be used with vector arguments, like
<code>xcoor</code> above.

<p>
Both the <code>least_squares</code> and
<code>comparison_plot</code>
are found and coded in the file
<a href="http://tinyurl.com/jvzzcfn/fem/approx1D.py" target="_self"><tt>approx1D.py</tt></a>.
The forthcoming examples on their use appear in
<code>ex_approx1D.py</code>.

<h3>Perfect approximation <a name="fem:approx:global:exact"></a></h3>

<p>
Let us use the code above to recompute the problem from
the section <a href="#fem:approx:global:linear">Example: linear approximation</a> where we want to approximate
a parabola. What happens if we add an element \( x^2 \) to the basis and test what
the best approximation is if \( V \) is the space of all parabolic functions?
The answer is quickly found by running

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">&gt;&gt;&gt; <span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">approx1D</span> <span style="color: #8B008B; font-weight: bold">import</span> *
&gt;&gt;&gt; x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
&gt;&gt;&gt; f = <span style="color: #B452CD">10</span>*(x-<span style="color: #B452CD">1</span>)**<span style="color: #B452CD">2</span>-<span style="color: #B452CD">1</span>
&gt;&gt;&gt; u, c = least_squares(f=f, psi=[<span style="color: #B452CD">1</span>, x, x**<span style="color: #B452CD">2</span>], Omega=[<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>])
&gt;&gt;&gt; <span style="color: #8B008B; font-weight: bold">print</span> u
<span style="color: #B452CD">10</span>*x**<span style="color: #B452CD">2</span> - <span style="color: #B452CD">20</span>*x + <span style="color: #B452CD">9</span>
&gt;&gt;&gt; <span style="color: #8B008B; font-weight: bold">print</span> sp.expand(f)
<span style="color: #B452CD">10</span>*x**<span style="color: #B452CD">2</span> - <span style="color: #B452CD">20</span>*x + <span style="color: #B452CD">9</span>
</pre></div>
<p>
Now, what if we use \( \baspsi_i(x)=x^i \) for \( i=0,1,\ldots,N=40 \)?
The output from <code>least_squares</code> gives \( c_i=0 \) for \( i>2 \), which
means that the method finds the perfect approximation.

<p>
In fact, we have a general result that
if \( f\in V \), the least squares and projection/Galerkin methods compute
the exact solution \( u=f \).
The proof is straightforward: if \( f\in V \), \( f \) can be expanded in
terms of the basis functions, \( f=\sum_{j\in\If} d_j\baspsi_j \), for
some coefficients \( \sequencei{d} \),
and the right-hand side then has entries

<p>
$$
\begin{equation*} b_i = (f,\baspsi_i) = \sum_{j\in\If} d_j(\baspsi_j, \baspsi_i) = \sum_{j\in\If} d_jA_{i,j}
\tp  \end{equation*}
$$

The linear system \( \sum_jA_{i,j}c_j = b_i \), \( i\in\If \), is then

<p>
$$
\begin{equation*} \sum_{j\in\If} c_jA_{i,j} = \sum_{j\in\If}d_jA_{i,j},
\quad i\in\If,\end{equation*}
$$

which implies that \( c_i=d_i \) for \( i\in\If \).

<h3>Ill-conditioning <a name="fem:approx:global:illconditioning"></a></h3>

<p>
The computational example in the section <a href="#fem:approx:global:exact">Perfect approximation</a>
applies the <code>least_squares</code> function which invokes symbolic
methods to calculate and solve the linear system. The correct
solution \( c_0=9, c_1=-20, c_2=10, c_i=0 \) for \( i\geq 3 \) is perfectly
recovered.

<p>
Suppose we
convert the matrix and right-hand side to floating-point arrays
and then solve the system using finite-precision arithmetics, which
is what one will (almost) always do in real life. This time we
get astonishing results! Up to about \( N=7 \) we get a solution that
is reasonably close to the exact one. Increasing \( N \) shows that
seriously wrong coefficients are computed.
Below is a table showing the solution of the linear system arising from
approximating a parabola
by functions on the form \( u(x)=c_0 + c_1x + c_2x^2 + \cdots + c_{10}x^{10} \).
Analytically, we know that \( c_j=0 \) for \( j>2 \), but numerically we may get
\( c_j\neq 0 \) for \( j>2 \).

<p>
<table border="1">
<tr><td align="center"><b>        exact         </b></td> <td align="center"><b>  <code>sympy</code>  </b></td> <td align="center"><b> <code>numpy32</code> </b></td> <td align="center"><b> <code>numpy64</code> </b></td> </tr>
<tr><td align="right">   9                       </td> <td align="right">   9.62                    </td> <td align="right">   5.57                    </td> <td align="right">   8.98                    </td> </tr>
<tr><td align="right">   -20                     </td> <td align="right">   -23.39                  </td> <td align="right">   -7.65                   </td> <td align="right">   -19.93                  </td> </tr>
<tr><td align="right">   10                      </td> <td align="right">   17.74                   </td> <td align="right">   -4.50                   </td> <td align="right">   9.96                    </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   -9.19                   </td> <td align="right">   4.13                    </td> <td align="right">   -0.26                   </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   5.25                    </td> <td align="right">   2.99                    </td> <td align="right">   0.72                    </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   0.18                    </td> <td align="right">   -1.21                   </td> <td align="right">   -0.93                   </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   -2.48                   </td> <td align="right">   -0.41                   </td> <td align="right">   0.73                    </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   1.81                    </td> <td align="right">   -0.013                  </td> <td align="right">   -0.36                   </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   -0.66                   </td> <td align="right">   0.08                    </td> <td align="right">   0.11                    </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   0.12                    </td> <td align="right">   0.04                    </td> <td align="right">   -0.02                   </td> </tr>
<tr><td align="right">   0                       </td> <td align="right">   -0.001                  </td> <td align="right">   -0.02                   </td> <td align="right">   0.002                   </td> </tr>
</table>
<p>
The exact value of \( c_j \), \( j=0,1,\ldots,10 \), appears in the first
column while the other columns correspond to results obtained
by three different methods:

<p>

<ul>
  <li> Column 2: The matrix and vector are converted to
    the data structure  <code>sympy.mpmath.fp.matrix</code> and the
    <code>sympy.mpmath.fp.lu_solve</code> function is used to solve the system.</li>
  <li> Column 3: The matrix and vector are converted to
    <code>numpy</code> arrays with data type <code>numpy.float32</code>
    (single precision floating-point number) and solved by
    the <code>numpy.linalg.solve</code> function.</li>
  <li> Column 4: As column 3, but the data type is
    <code>numpy.float64</code> (double
    precision floating-point number).</li>
</ul>

We see from the numbers in the table that
double precision performs much better than single precision.
Nevertheless, when plotting all these solutions the curves cannot be
visually distinguished (!). This means that the approximations look
perfect, despite the partially very wrong values of the coefficients.

<p>
Increasing \( N \) to 12 makes the numerical solver in <code>numpy</code>
abort with the message: "matrix is numerically singular".
A matrix has to be non-singular to be invertible, which is a requirement
when solving a linear system. Already when the matrix is close to
singular, it is <em>ill-conditioned</em>, which here implies that
the numerical solution algorithms are sensitive to round-off
errors and may produce (very) inaccurate results.

<p>
The reason why the coefficient matrix is nearly singular and
ill-conditioned is that our basis functions \( \baspsi_i(x)=x^i \) are
nearly linearly dependent for large \( i \).  That is, \( x^i \) and \( x^{i+1} \)
are very close for \( i \) not very small. This phenomenon is
illustrated in Figure <a href="#fem:approx:global:fig:illconditioning">4</a>.
There are 15 lines in this figure, but only half of them are
visually distinguishable.
Almost linearly dependent basis functions give rise to an
ill-conditioned and almost singular matrix.  This fact can be
illustrated by computing the determinant, which is indeed very close
to zero (recall that a zero determinant implies a singular and
non-invertible matrix): \( 10^{-65} \) for \( N=10 \) and \( 10^{-92} \) for
\( N=12 \). Already for \( N=28 \) the numerical determinant computation
returns a plain zero.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 4:  The 15 first basis functions \( x^i \), \( i=0,\ldots,14 \). <a name="fem:approx:global:fig:illconditioning"></a> </p></center>
<p><img src="fig-fem/ill_conditioning.png" align="bottom" width=600></p>
</center>

<p>
On the other hand, the double precision <code>numpy</code> solver do run for
\( N=100 \), resulting in answers that are not significantly worse than
those in the table above, and large powers are
associated with small coefficients (e.g., \( c_j<10^{-2} \) for \( 10\leq
j\leq 20 \) and \( c<10^{-5} \) for \( j>20 \)). Even for \( N=100 \) the
approximation still lies on top of the exact curve in a plot (!).

<p>
The conclusion is that visual inspection of the quality of the approximation
may not uncover fundamental numerical problems with the computations.
However, numerical analysts have studied approximations and ill-conditioning
for decades, and it is well known that the basis \( \{1,x,x^2,x^3,\ldots,\} \)
is a bad basis. The best basis from a matrix conditioning point of view
is to have orthogonal functions such that \( (\psi_i,\psi_j)=0 \) for
\( i\neq j \). There are many known sets of orthogonal polynomials and
other functions.
The functions used in the finite element methods are almost orthogonal,
and this property helps to avoid problems with solving matrix systems.
Almost orthogonal is helpful, but not enough when it comes to
partial differential equations, and ill-conditioning
of the coefficient matrix is a theme when solving large-scale matrix
systems arising from finite element discretizations.

<h3>Fourier series <a name="fem:approx:global:Fourier"></a></h3>

<p>
A set of sine functions is widely used for approximating functions
(the sines are also orthogonal as explained more in the section <a href="#fem:approx:global:illconditioning">Ill-conditioning</a>).  Let us take

<p>
$$
\begin{equation*}
V = \hbox{span}\,\{ \sin \pi x, \sin 2\pi x,\ldots,\sin (N+1)\pi x\}
\tp  \end{equation*}
$$

That is,

<p>
$$
\begin{equation*} \baspsi_i(x) = \sin ((i+1)\pi x),\quad i\in\If\tp \end{equation*}
$$

An approximation to the \( f(x) \) function from
the section <a href="#fem:approx:global:linear">Example: linear approximation</a> can then be computed by the
<code>least_squares</code> function from the section <a href="#fem:approx:global:LS:code">Implementation of the least squares method</a>:

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">N = <span style="color: #B452CD">3</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">sympy</span> <span style="color: #8B008B; font-weight: bold">import</span> sin, pi
x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
psi = [sin(pi*(i+<span style="color: #B452CD">1</span>)*x) <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>)]
f = <span style="color: #B452CD">10</span>*(x-<span style="color: #B452CD">1</span>)**<span style="color: #B452CD">2</span> - <span style="color: #B452CD">1</span>
Omega = [<span style="color: #B452CD">0</span>, <span style="color: #B452CD">1</span>]
u, c = least_squares(f, psi, Omega)
comparison_plot(f, u, Omega)
</pre></div>
<p>
Figure <a href="#fem:approx:global:fig:parabola:sine1">5</a> (left) shows the oscillatory approximation
of \( \sum_{j=0}^Nc_j\sin ((j+1)\pi x) \) when \( N=3 \).
Changing \( N \) to 11 improves the approximation considerably, see
Figure <a href="#fem:approx:global:fig:parabola:sine1">5</a> (right).

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 5:  Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions.  <a name="fem:approx:global:fig:parabola:sine1"></a> </p></center>
<p><img src="fig-fem/parabola_ls_sines4_12.png" align="bottom" width=800></p>
</center>

<p>
There is an error \( f(0)-u(0)=9 \) at \( x=0 \) in Figure <a href="#fem:approx:global:fig:parabola:sine1">5</a> regardless of how large \( N \) is, because all \( \baspsi_i(0)=0 \) and hence
\( u(0)=0 \). We may help the approximation to be correct at \( x=0 \) by
seeking

<p>
$$
\begin{equation}
u(x) = f(0) + \sum_{j\in\If} c_j\baspsi_j(x)
\tp
\end{equation}
$$

However, this adjustment introduces a new problem at \( x=1 \) since
we now get an error \( f(1)-u(1)=f(1)-0=-1 \) at this point. A more
clever adjustment is to replace the \( f(0) \) term by a term that
is \( f(0) \) at \( x=0 \) and \( f(1) \) at \( x=1 \). A simple linear combination
\( f(0)(1-x) + xf(1) \) does the job:
$$
\begin{equation}
u(x) = f(0)(1-x) + xf(1) + \sum_{j\in\If} c_j\baspsi_j(x)
\tp
\end{equation}
$$

This adjustment of \( u \) alters the linear system slightly as we get an extra
term \( -(f(0)(1-x) + xf(1),\baspsi_i) \) on the right-hand side.
Figure <a href="#fem:approx:global:fig:parabola:sine2">6</a> shows the result
of this technique for
ensuring right boundary values: even 3 sines can now adjust the
\( f(0)(1-x) + xf(1) \) term such that \( u \) approximates the parabola really
well, at least visually.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 6:  Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term.  <a name="fem:approx:global:fig:parabola:sine2"></a> </p></center>
<p><img src="fig-fem/parabola_ls_sines4_12_wfterm.png" align="bottom" width=800></p>
</center>

<h3>Orthogonal basis functions <a name="fem:approx:global:orth"></a></h3>

<p>
The choice of sine functions \( \baspsi_i(x)=\sin ((i+1)\pi x) \) has a great
computational advantage: on \( \Omega=[0,1] \) these basis functions are
<em>orthogonal</em>, implying that \( A_{i,j}=0 \) if \( i\neq j \). This
result is realized by trying

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">integrate(sin(j*pi*x)*sin(k*pi*x), x, <span style="color: #B452CD">0</span>, <span style="color: #B452CD">1</span>)
</pre></div>
<p>
in <a href="http://wolframalpha.com" target="_self">WolframAlpha</a>
(avoid <code>i</code> in the integrand as this symbol means
the imaginary unit \( \sqrt{-1} \)).
Also by asking WolframAlpha
about \( \int_0^1\sin^2 (j\pi x) \dx \), we find it
to equal 1/2.
With a diagonal matrix we can easily solve for the coefficients
by hand:

<p>
$$
\begin{equation}
c_i = 2\int_0^1 f(x)\sin ((i+1)\pi x) \dx,\quad i\in\If,
\end{equation}
$$

which is nothing but the classical formula for the coefficients of
the Fourier sine series of \( f(x) \) on \( [0,1] \). In fact, when
\( V \) contains the basic functions used in a Fourier series expansion,
the approximation method derived in the section <a href="#fem:approx:global">Approximation of functions</a>
results in the classical Fourier series for \( f(x) \) (see <a href="._main_fem-solarized010.html#fem:approx:exer:Fourier">Exercise 8: Fourier series as a least squares approximation</a>
for details).

<p>
With orthogonal basis functions we can make the
<code>least_squares</code> function (much) more efficient since we know that
the matrix is diagonal and only the diagonal elements need to be computed:

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">least_squares_orth</span>(f, psi, Omega):
    N = <span style="color: #658b00">len</span>(psi) - <span style="color: #B452CD">1</span>
    A = [<span style="color: #B452CD">0</span>]*(N+<span style="color: #B452CD">1</span>)
    b = [<span style="color: #B452CD">0</span>]*(N+<span style="color: #B452CD">1</span>)
    x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>):
        A[i] = sp.integrate(psi[i]**<span style="color: #B452CD">2</span>, (x, Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]))
        b[i] = sp.integrate(psi[i]*f,  (x, Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]))
    c = [b[i]/A[i] <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #658b00">len</span>(b))]
    u = <span style="color: #B452CD">0</span>
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #658b00">len</span>(psi)):
        u += c[i]*psi[i]
    <span style="color: #8B008B; font-weight: bold">return</span> u, c
</pre></div>
<p>
This function is found in the file <code>approx1D.py</code>.

<h3>Numerical computations  <a name="___sec16"></a></h3>

<p>
Sometimes the basis functions \( \baspsi_i \) and/or the function \( f \)
have a nature that makes symbolic integration CPU-time
consuming or impossible.
Even though we implemented a fallback on numerical integration
of \( \int f\basphi_i dx \) considerable time might be required
by <code>sympy</code> in the attempt to integrate symbolically.
Therefore, it will be handy to have function for fast
<em>numerical</em> integration and <em>numerical</em> solution
of the linear system. Below is such a method. It requires
Python functions <code>f(x)</code> and <code>psi(x,i)</code> for \( f(x) \) and \( \baspsi_i(x) \)
as input. The output is a mesh function
with values <code>u</code> on the mesh with points in the array <code>x</code>.
Three numerical integration methods are offered:
<code>scipy.integrate.quad</code> (precision set to \( 10^{-8} \)),
<code>sympy.mpmath.quad</code> (high precision), and a Trapezoidal
rule based on the points in <code>x</code>.

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">least_squares_numerical</span>(f, psi, N, x,
                            integration_method=<span style="color: #CD5555">&#39;scipy&#39;</span>,
                            orthogonal_basis=<span style="color: #658b00">False</span>):
    <span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">scipy.integrate</span>
    A = np.zeros((N+<span style="color: #B452CD">1</span>, N+<span style="color: #B452CD">1</span>))
    b = np.zeros(N+<span style="color: #B452CD">1</span>)
    Omega = [x[<span style="color: #B452CD">0</span>], x[-<span style="color: #B452CD">1</span>]]
    dx = x[<span style="color: #B452CD">1</span>] - x[<span style="color: #B452CD">0</span>]

    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>):
        j_limit = i+<span style="color: #B452CD">1</span> <span style="color: #8B008B; font-weight: bold">if</span> orthogonal_basis <span style="color: #8B008B; font-weight: bold">else</span> N+<span style="color: #B452CD">1</span>
        <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(i, j_limit):
            <span style="color: #8B008B; font-weight: bold">print</span> <span style="color: #CD5555">&#39;(%d,%d)&#39;</span> % (i, j)
            <span style="color: #8B008B; font-weight: bold">if</span> integration_method == <span style="color: #CD5555">&#39;scipy&#39;</span>:
                A_ij = scipy.integrate.quad(
                    <span style="color: #8B008B; font-weight: bold">lambda</span> x: psi(x,i)*psi(x,j),
                    Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>], epsabs=<span style="color: #B452CD">1E-9</span>, epsrel=<span style="color: #B452CD">1E-9</span>)[<span style="color: #B452CD">0</span>]
            <span style="color: #8B008B; font-weight: bold">elif</span> integration_method == <span style="color: #CD5555">&#39;sympy&#39;</span>:
                A_ij = sp.mpmath.quad(
                    <span style="color: #8B008B; font-weight: bold">lambda</span> x: psi(x,i)*psi(x,j),
                    [Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]])
            <span style="color: #8B008B; font-weight: bold">else</span>:
                values = psi(x,i)*psi(x,j)
                A_ij = trapezoidal(values, dx)
            A[i,j] = A[j,i] = A_ij

        <span style="color: #8B008B; font-weight: bold">if</span> integration_method == <span style="color: #CD5555">&#39;scipy&#39;</span>:
            b_i = scipy.integrate.quad(
                <span style="color: #8B008B; font-weight: bold">lambda</span> x: f(x)*psi(x,i), Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>],
                epsabs=<span style="color: #B452CD">1E-9</span>, epsrel=<span style="color: #B452CD">1E-9</span>)[<span style="color: #B452CD">0</span>]
        <span style="color: #8B008B; font-weight: bold">elif</span> integration_method == <span style="color: #CD5555">&#39;sympy&#39;</span>:
            b_i = sp.mpmath.quad(
                <span style="color: #8B008B; font-weight: bold">lambda</span> x: f(x)*psi(x,i), [Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]])
        <span style="color: #8B008B; font-weight: bold">else</span>:
            values = f(x)*psi(x,i)
            b_i = trapezoidal(values, dx)
        b[i] = b_i

    c = b/np.diag(A) <span style="color: #8B008B; font-weight: bold">if</span> orthogonal_basis <span style="color: #8B008B; font-weight: bold">else</span> np.linalg.solve(A, b)
    u = <span style="color: #658b00">sum</span>(c[i]*psi(x, i) <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>))
    <span style="color: #8B008B; font-weight: bold">return</span> u, c

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">trapezoidal</span>(values, dx):
    <span style="color: #CD5555">&quot;&quot;&quot;Integrate values by the Trapezoidal rule (mesh size dx).&quot;&quot;&quot;</span>
    <span style="color: #8B008B; font-weight: bold">return</span> dx*(np.sum(values) - <span style="color: #B452CD">0.5</span>*values[<span style="color: #B452CD">0</span>] - <span style="color: #B452CD">0.5</span>*values[-<span style="color: #B452CD">1</span>])
</pre></div>
<p>
Here is an example on calling the function:

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">import</span> linspace, tanh, pi

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">psi</span>(x, i):
    <span style="color: #8B008B; font-weight: bold">return</span> sin((i+<span style="color: #B452CD">1</span>)*x)

x = linspace(<span style="color: #B452CD">0</span>, <span style="color: #B452CD">2</span>*pi, <span style="color: #B452CD">501</span>)
N = <span style="color: #B452CD">20</span>
u, c = least_squares_numerical(<span style="color: #8B008B; font-weight: bold">lambda</span> x: tanh(x-pi), psi, N, x,
                               orthogonal_basis=<span style="color: #658b00">True</span>)
</pre></div>

<h3>The interpolation (or collocation) method <a name="fem:approx:global:interp"></a></h3>

<p>
The principle of minimizing the distance between \( u \) and \( f \) is
an intuitive way of computing a best approximation \( u\in V \) to \( f \).
However, there are other approaches as well.
One is to demand that \( u(\xno{i}) = f(\xno{i}) \) at some selected points
\( \xno{i} \), \( i\in\If \):

<p>
$$
\begin{equation}
u(\xno{i}) = \sum_{j\in\If} c_j \baspsi_j(\xno{i}) = f(\xno{i}),
\quad i\in\If\tp \end{equation}
$$

This criterion also gives a linear system
with \( N+1 \) unknown coefficients \( \sequencei{c} \):

<p>
$$
\begin{equation}
\sum_{j\in\If} A_{i,j}c_j = b_i,\quad i\in\If,
\end{equation}
$$

with

<p>
$$
\begin{align}
A_{i,j} &= \baspsi_j(\xno{i}),\\ 
b_i &= f(\xno{i})\tp  \end{align}
$$

This time the coefficient matrix is not symmetric because
\( \baspsi_j(\xno{i})\neq \baspsi_i(\xno{j}) \) in general.
The method is often referred to as an <em>interpolation method</em>
since some point values of \( f \) are given (\( f(\xno{i}) \)) and we
fit a continuous function \( u \) that goes through the \( f(\xno{i}) \) points.
In this case the \( \xno{i} \) points are called <em>interpolation points</em>.
When the same approach is used to approximate differential equations,
one usually applies the name <em>collocation method</em> and
\( \xno{i} \) are known as <em>collocation points</em>.

<p>
Given \( f \)  as a <code>sympy</code> symbolic expression <code>f</code>, \( \sequencei{\baspsi} \)
as a list <code>psi</code>, and a set of points \( \sequencei{x} \)  as a list or array
<code>points</code>, the following Python function sets up and solves the matrix system
for the coefficients \( \sequencei{c} \):

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">interpolation</span>(f, psi, points):
    N = <span style="color: #658b00">len</span>(psi) - <span style="color: #B452CD">1</span>
    A = sp.zeros((N+<span style="color: #B452CD">1</span>, N+<span style="color: #B452CD">1</span>))
    b = sp.zeros((N+<span style="color: #B452CD">1</span>, <span style="color: #B452CD">1</span>))
    x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
    <span style="color: #228B22"># Turn psi and f into Python functions</span>
    psi = [sp.lambdify([x], psi[i]) <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>)]
    f = sp.lambdify([x], f)
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>):
        <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>):
            A[i,j] = psi[j](points[i])
        b[i,<span style="color: #B452CD">0</span>] = f(points[i])
    c = A.LUsolve(b)
    u = <span style="color: #B452CD">0</span>
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #658b00">len</span>(psi)):
        u += c[i,<span style="color: #B452CD">0</span>]*psi[i](x)
    <span style="color: #8B008B; font-weight: bold">return</span> u
</pre></div>
<p>
The <code>interpolation</code> function is a part of the <code>approx1D</code>
module.

<p>
We found it convenient in the above function to turn the expressions <code>f</code> and
<code>psi</code> into ordinary Python functions of <code>x</code>, which can be called with
<code>float</code> values in the list <code>points</code> when building the matrix and
the right-hand side. The alternative is to use the <code>subs</code> method
to substitute the <code>x</code> variable in an expression by an element from
the <code>points</code> list. The following session illustrates both approaches
in a simple setting:

<p>

<!-- code=text (from !bc ipy) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">&gt;&gt;&gt; from sympy import *
&gt;&gt;&gt; x = Symbol(&#39;x&#39;)
&gt;&gt;&gt; e = x**2              # symbolic expression involving x
&gt;&gt;&gt; p = 0.5               # a value of x
&gt;&gt;&gt; v = e.subs(x, p)      # evaluate e for x=p
&gt;&gt;&gt; v
0.250000000000000
&gt;&gt;&gt; type(v)
sympy.core.numbers.Float
&gt;&gt;&gt; e = lambdify([x], e)  # make Python function of e
&gt;&gt;&gt; type(e)
&gt;&gt;&gt; function
&gt;&gt;&gt; v = e(p)              # evaluate e(x) for x=p
&gt;&gt;&gt; v
0.25
&gt;&gt;&gt; type(v)
float
</pre></div>
<p>
A nice feature of the interpolation or collocation method is that it
avoids computing integrals. However, one has to decide on the location
of the \( \xno{i} \) points.  A simple, yet common choice, is to
distribute them uniformly throughout \( \Omega \).

<h4>Example  <a name="___sec18"></a></h4>

<p>
Let us illustrate the interpolation or collocation method by approximating
our parabola \( f(x)=10(x-1)^2-1 \) by a linear function on \( \Omega=[1,2] \),
using two collocation points \( x_0=1+1/3 \) and \( x_1=1+2/3 \):

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">f = <span style="color: #B452CD">10</span>*(x-<span style="color: #B452CD">1</span>)**<span style="color: #B452CD">2</span> - <span style="color: #B452CD">1</span>
psi = [<span style="color: #B452CD">1</span>, x]
Omega = [<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>]
points = [<span style="color: #B452CD">1</span> + sp.Rational(<span style="color: #B452CD">1</span>,<span style="color: #B452CD">3</span>), <span style="color: #B452CD">1</span> + sp.Rational(<span style="color: #B452CD">2</span>,<span style="color: #B452CD">3</span>)]
u = interpolation(f, psi, points)
comparison_plot(f, u, Omega)
</pre></div>
<p>
The resulting linear system becomes

<p>
$$
\begin{equation*}
\left(\begin{array}{ll}
1 & 4/3\\ 
1 & 5/3\\ 
\end{array}\right)
\left(\begin{array}{l}
c_0\\ 
c_1\\ 
\end{array}\right)
=
\left(\begin{array}{l}
1/9\\ 
31/9\\ 
\end{array}\right)
\end{equation*}
$$

with solution \( c_0=-119/9 \) and \( c_1=10 \).
Figure <a href="#fem:approx:global:linear:interp:fig1">7</a> (left) shows the resulting
approximation \( u=-119/9 + 10x \).
We can easily test other interpolation points, say \( x_0=1 \) and \( x_1=2 \).
This changes the line quite significantly, see
Figure <a href="#fem:approx:global:linear:interp:fig1">7</a> (right).

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 7:  Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right).  <a name="fem:approx:global:linear:interp:fig1"></a> </p></center>
<p><img src="fig-fem/parabola_inter.png" align="bottom" width=800></p>
</center>

<h3>Lagrange polynomials <a name="fem:approx:global:Lagrange"></a></h3>

<p>
In the section <a href="#fem:approx:global:Fourier">Fourier series</a> we explain the advantage with having
a diagonal matrix: formulas for the coefficients \( \sequencei{c} \) can
then be derived by hand. For an interpolation/collocation method a
diagonal matrix implies that
\( \baspsi_j(\xno{i}) = 0 \) if \( i\neq j \). One set of basis functions \( \baspsi_i(x) \)
with this property is the <em>Lagrange interpolating polynomials</em>,
or just <em>Lagrange polynomials</em>. (Although the functions are named
after Lagrange, they were first discovered by Waring in 1779,
rediscovered by Euler in 1783, and published by Lagrange in 1795.)
The Lagrange polynomials have the form

<p>
$$
\begin{equation}
\baspsi_i(x) =
\prod_{j=0,j\neq i}^N
\frac{x-\xno{j}}{\xno{i}-\xno{j}}
= \frac{x-x_0}{\xno{i}-x_0}\cdots\frac{x-\xno{i-1}}{\xno{i}-\xno{i-1}}\frac{x-\xno{i+1}}{\xno{i}-\xno{i+1}}
\cdots\frac{x-x_N}{\xno{i}-x_N},
\tag{21}
\end{equation}
$$

for \( i\in\If \).
We see from <a href="#mjx-eqn-21">(21)</a> that all the \( \baspsi_i \)
functions are polynomials of degree \( N \) which have the property

<p>
$$
\begin{equation}
\baspsi_i(x_s) = \delta_{is},\quad \delta_{is} =
\left\lbrace\begin{array}{ll}
1, & i=s,\\ 
0, & i\neq s,
\end{array}\right.
\tag{22}
\end{equation}
$$

when \( x_s \) is an interpolation/collocation point.
Here we have used the <em>Kronecker delta</em> symbol \( \delta_{is} \).
This property implies that \( A_{i,j}=0 \) for \( i\neq j \) and
\( A_{i,j}=1 \) when \( i=j \). The solution of the linear system is
them simply

<p>
$$
\begin{equation}
c_i = f(\xno{i}),\quad i\in\If,
\end{equation}
$$

and

<p>
$$
\begin{equation}
u(x) = \sum_{j\in\If} f(\xno{i})\baspsi_i(x)\tp  \end{equation}
$$


<p>
The following function computes the Lagrange interpolating polynomial
\( \baspsi_i(x) \), given the interpolation points \( \xno{0},\ldots,\xno{N} \) in
the list or array <code>points</code>:

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">Lagrange_polynomial</span>(x, i, points):
    p = <span style="color: #B452CD">1</span>
    <span style="color: #8B008B; font-weight: bold">for</span> k <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #658b00">len</span>(points)):
        <span style="color: #8B008B; font-weight: bold">if</span> k != i:
            p *= (x - points[k])/(points[i] - points[k])
    <span style="color: #8B008B; font-weight: bold">return</span> p
</pre></div>
<p>
The next function computes a complete basis using equidistant points throughout
\( \Omega \):

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">Lagrange_polynomials_01</span>(x, N):
    <span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #658b00">isinstance</span>(x, sp.Symbol):
        h = sp.Rational(<span style="color: #B452CD">1</span>, N-<span style="color: #B452CD">1</span>)
    <span style="color: #8B008B; font-weight: bold">else</span>:
        h = <span style="color: #B452CD">1.0</span>/(N-<span style="color: #B452CD">1</span>)
    points = [i*h <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N)]
    psi = [Lagrange_polynomial(x, i, points) <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N)]
    <span style="color: #8B008B; font-weight: bold">return</span> psi, points
</pre></div>
<p>
When <code>x</code> is an <code>sp.Symbol</code> object, we let the
spacing between
the interpolation points, <code>h</code>, be a <code>sympy</code> rational number
for nice end results in the formulas for \( \baspsi_i \).
The other case, when <code>x</code> is a plain Python <code>float</code>,
signifies numerical computing, and then we let <code>h</code> be a floating-point
number.
Observe that the <code>Lagrange_polynomial</code> function works equally well
in the symbolic and numerical case - just think of <code>x</code> being an
<code>sp.Symbol</code> object or a Python <code>float</code>.
A little interactive session illustrates the difference between symbolic
and numerical computing of the basis functions and points:

<p>

<!-- code=text (from !bc ipy) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">&gt;&gt;&gt; import sympy as sp
&gt;&gt;&gt; x = sp.Symbol(&#39;x&#39;)
&gt;&gt;&gt; psi, points = Lagrange_polynomials_01(x, N=3)
&gt;&gt;&gt; points
[0, 1/2, 1]
&gt;&gt;&gt; psi
[(1 - x)*(1 - 2*x), 2*x*(2 - 2*x), -x*(1 - 2*x)]

&gt;&gt;&gt; x = 0.5  # numerical computing
&gt;&gt;&gt; psi, points = Lagrange_polynomials_01(x, N=3)
&gt;&gt;&gt; points
[0.0, 0.5, 1.0]
&gt;&gt;&gt; psi
[-0.0, 1.0, 0.0]
</pre></div>
<p>
The Lagrange polynomials are very much used in finite element methods
because of their property <a href="#mjx-eqn-22">(22)</a>.

<h4>Approximation of a polynomial  <a name="___sec20"></a></h4>

<p>
The Galerkin or least squares method lead to an exact approximation
if \( f \) lies in the space spanned by the basis functions. It could be
interest to see how the interpolation method with Lagrange
polynomials as basis is able to approximate a polynomial, e.g.,
a parabola. Running

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">for</span> N <span style="color: #8B008B">in</span> <span style="color: #B452CD">2</span>, <span style="color: #B452CD">4</span>, <span style="color: #B452CD">5</span>, <span style="color: #B452CD">6</span>, <span style="color: #B452CD">8</span>, <span style="color: #B452CD">10</span>, <span style="color: #B452CD">12</span>:
    f = x**<span style="color: #B452CD">2</span>
    psi, points = Lagrange_polynomials_01(x, N)
    u = interpolation(f, psi, points)
</pre></div>
<p>
shows the result that up to <code>N=4</code> we achieve an exact approximation,
and then round-off errors start to grow, such that
<code>N=15</code> leads to a 15-degree polynomial for \( u \) where
the coefficients in front of \( x^r \) for \( r>2 \) are
of size \( 10^{-5} \) and smaller.

<h4>Successful example  <a name="___sec21"></a></h4>

<p>
Trying out the Lagrange polynomial basis for approximating
\( f(x)=\sin 2\pi x \) on \( \Omega =[0,1] \) with the least squares
and the interpolation techniques can be done by

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%">x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
f = sp.sin(<span style="color: #B452CD">2</span>*sp.pi*x)
psi, points = Lagrange_polynomials_01(x, N)
Omega=[<span style="color: #B452CD">0</span>, <span style="color: #B452CD">1</span>]
u = least_squares(f, psi, Omega)
comparison_plot(f, u, Omega)
u = interpolation(f, psi, points)
comparison_plot(f, u, Omega)
</pre></div>
<p>
Figure <a href="#fem:approx:global:Lagrange:fig:sine:ls:colloc">8</a> shows the results.
There is little difference between the least squares and the interpolation
technique. Increasing \( N \) gives visually better approximations.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 8:  Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3. <a name="fem:approx:global:Lagrange:fig:sine:ls:colloc"></a> </p></center>
<p><img src="fig-fem/Lagrange_ls_interp_sin_4.png" align="bottom" width=800></p>
</center>

<h4>Less successful example  <a name="___sec22"></a></h4>

<p>
The next example concerns interpolating \( f(x)=|1-2x| \) on
\( \Omega =[0,1] \) using Lagrange polynomials. Figure <a href="#fem:approx:global:Lagrange:fig:abs:Lag:unif:7:14">9</a> shows a peculiar effect: the approximation starts to oscillate
more and more as \( N \) grows. This numerical artifact is not surprising
when looking at the individual Lagrange polynomials. Figure <a href="#fem:approx:global:Lagrange:fig:abs:Lag:unif:osc">10</a> shows two such polynomials, \( \psi_2(x) \) and
\( \psi_7(x) \), both of degree 11 and computed from uniformly spaced
points \( \xno{x_i}=i/11 \), \( i=0,\ldots,11 \), marked with circles.
We clearly see the property of Lagrange polynomials:
\( \psi_2(\xno{i})=0 \) and \( \psi_7(\xno{i})=0 \) for all \( i \),
except \( \psi_2(\xno{2})=1 \) and \( \psi_7(\xno{7})=1 \).
The most striking feature, however, is the significant oscillation
near the boundary. The reason is easy to understand:
since we force the functions to zero at so many points,
a polynomial of high degree is forced to oscillate between
the points.
The phenomenon is named <em>Runge's phenomenon</em> and you can read
a more detailed explanation on <a href="http://en.wikipedia.org/wiki/Runge%27s_phenomenon" target="_self">Wikipedia</a>.

<h4>Remedy for strong oscillations  <a name="___sec23"></a></h4>

<p>
The oscillations can be reduced by a more clever choice of
interpolation points, called the <em>Chebyshev nodes</em>:

<p>
$$
\begin{equation}
\xno{i} = \half (a+b) + \half(b-a)\cos\left( \frac{2i+1}{2(N+1)}pi\right),\quad i=0\ldots,N,
\end{equation}
$$

on the interval \( \Omega = [a,b] \).
Here is a flexible version of the <code>Lagrange_polynomials_01</code> function above,
valid for any interval \( \Omega =[a,b] \) and with the possibility to generate
both uniformly distributed points and Chebyshev nodes:

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">Lagrange_polynomials</span>(x, N, Omega, point_distribution=<span style="color: #CD5555">&#39;uniform&#39;</span>):
    <span style="color: #8B008B; font-weight: bold">if</span> point_distribution == <span style="color: #CD5555">&#39;uniform&#39;</span>:
        <span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #658b00">isinstance</span>(x, sp.Symbol):
            h = sp.Rational(Omega[<span style="color: #B452CD">1</span>] - Omega[<span style="color: #B452CD">0</span>], N)
        <span style="color: #8B008B; font-weight: bold">else</span>:
            h = (Omega[<span style="color: #B452CD">1</span>] - Omega[<span style="color: #B452CD">0</span>])/<span style="color: #658b00">float</span>(N)
        points = [Omega[<span style="color: #B452CD">0</span>] + i*h <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>)]
    <span style="color: #8B008B; font-weight: bold">elif</span> point_distribution == <span style="color: #CD5555">&#39;Chebyshev&#39;</span>:
        points = Chebyshev_nodes(Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>], N)
    psi = [Lagrange_polynomial(x, i, points) <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>)]
    <span style="color: #8B008B; font-weight: bold">return</span> psi, points

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">Chebyshev_nodes</span>(a, b, N):
    <span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">math</span> <span style="color: #8B008B; font-weight: bold">import</span> cos, pi
    <span style="color: #8B008B; font-weight: bold">return</span> [<span style="color: #B452CD">0.5</span>*(a+b) + <span style="color: #B452CD">0.5</span>*(b-a)*cos(<span style="color: #658b00">float</span>(<span style="color: #B452CD">2</span>*i+<span style="color: #B452CD">1</span>)/(<span style="color: #B452CD">2</span>*N+<span style="color: #B452CD">1</span>))*pi) \ 
            <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>)]
</pre></div>
<p>
All the functions computing Lagrange polynomials listed
above are found in the module file <code>Lagrange.py</code>.
Figure <a href="#fem:approx:global:Lagrange:fig:abs:Lag:Cheb:7:14">11</a> shows the improvement of
using Chebyshev nodes (compared with Figure <a href="#fem:approx:global:Lagrange:fig:abs:Lag:unif:7:14">9</a>). The reason is that the corresponding Lagrange
polynomials have much smaller oscillations as seen in
Figure <a href="#fem:approx:global:Lagrange:fig:abs:Lag:Cheb:osc">12</a>
(compare with Figure <a href="#fem:approx:global:Lagrange:fig:abs:Lag:unif:osc">10</a>).

<p>
Another cure for undesired oscillation of higher-degree interpolating
polynomials is to use lower-degree Lagrange
polynomials on many small patches of the domain, which is the idea
pursued in the finite element method. For instance, linear Lagrange
polynomials on \( [0,1/2] \) and \( [1/2,1] \) would yield a perfect
approximation to \( f(x)=|1-2x| \) on \( \Omega = [0,1] \)
since \( f \) is piecewise linear.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 9:  Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right).  <a name="fem:approx:global:Lagrange:fig:abs:Lag:unif:7:14"></a> </p></center>
<p><img src="fig-fem/Lagrange_interp_abs_8_15.png" align="bottom" width=800></p>
</center>

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 10:  Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles).  <a name="fem:approx:global:Lagrange:fig:abs:Lag:unif:osc"></a> </p></center>
<p><img src="fig-fem/Lagrange_basis_12.png" align="bottom" width=400></p>
</center>

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 11:  Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right).  <a name="fem:approx:global:Lagrange:fig:abs:Lag:Cheb:7:14"></a> </p></center>
<p><img src="fig-fem/Lagrange_interp_abs_Cheb_8_15.png" align="bottom" width=800></p>
</center>

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 12:  Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles).  <a name="fem:approx:global:Lagrange:fig:abs:Lag:Cheb:osc"></a> </p></center>
<p><img src="fig-fem/Lagrange_basis_12.png" align="bottom" width=400></p>
</center>

<p>
How does the least squares or projection methods work with Lagrange
polynomials?
Unfortunately, <code>sympy</code> has problems integrating the \( f(x)=|1-2x| \)
function times a polynomial. Other choices of \( f(x) \) can also
make the symbolic integration fail. Therefore, we should extend
the <code>least_squares</code> function such that it falls back on
numerical integration if the symbolic integration is unsuccessful.
In the latter case, the returned value from <code>sympy</code>'s
<code>integrate</code> function is an object of type <code>Integral</code>.
We can test on this type and utilize the <code>mpmath</code> module in
<code>sympy</code> to perform numerical integration of high precision.
Here is the code:<a name="fem:Integral:fallback"></a>

<p>

<!-- code=python (from !bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">least_squares</span>(f, psi, Omega):
    N = <span style="color: #658b00">len</span>(psi) - <span style="color: #B452CD">1</span>
    A = sp.zeros((N+<span style="color: #B452CD">1</span>, N+<span style="color: #B452CD">1</span>))
    b = sp.zeros((N+<span style="color: #B452CD">1</span>, <span style="color: #B452CD">1</span>))
    x = sp.Symbol(<span style="color: #CD5555">&#39;x&#39;</span>)
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(N+<span style="color: #B452CD">1</span>):
        <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(i, N+<span style="color: #B452CD">1</span>):
            integrand = psi[i]*psi[j]
            I = sp.integrate(integrand, (x, Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]))
            <span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #658b00">isinstance</span>(I, sp.Integral):
                <span style="color: #228B22"># Could not integrate symbolically, fallback</span>
                <span style="color: #228B22"># on numerical integration with mpmath.quad</span>
                integrand = sp.lambdify([x], integrand)
                I = sp.mpmath.quad(integrand, [Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]])
            A[i,j] = A[j,i] = I
        integrand = psi[i]*f
        I = sp.integrate(integrand, (x, Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]))
        <span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #658b00">isinstance</span>(I, sp.Integral):
            integrand = sp.lambdify([x], integrand)
            I = sp.mpmath.quad(integrand, [Omega[<span style="color: #B452CD">0</span>], Omega[<span style="color: #B452CD">1</span>]])
        b[i,<span style="color: #B452CD">0</span>] = I
    c = A.LUsolve(b)
    u = <span style="color: #B452CD">0</span>
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #658b00">len</span>(psi)):
        u += c[i,<span style="color: #B452CD">0</span>]*psi[i]
    <span style="color: #8B008B; font-weight: bold">return</span> u
</pre></div>
<p>
<!-- Convergence of Lagrange polynomials. -->

<p>
<p>
<!-- begin bottom navigation -->
<a href="._main_fem-solarized001.html"><img src="http://hplgit.github.io/doconce/bundled/html_images/prev1.png" border=0 alt="previous"></a>

<a href="._main_fem-solarized003.html"><img src="http://hplgit.github.io/doconce/bundled/html_images/next1.png" border=0 alt="next"></a>
<!-- end bottom navigation -->

<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

