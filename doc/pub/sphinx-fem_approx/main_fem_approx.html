

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Approximation of functions with finite elements</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Approximation of functions with finite elements" href="index.html" /> 
  
   <style type=text/css>
     div.admonition {
       background-color: whiteSmoke;
       border: 1px solid #bababa;
     }
   </style>
  </head>

  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li><a href="index.html">Approximation of functions with finite elements</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="approximation-of-functions-with-finite-elements">
<h1>Approximation of functions with finite elements<a class="headerlink" href="#approximation-of-functions-with-finite-elements" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Hans Petter Langtangen</td>
</tr>
<tr class="field-even field"><th class="field-name">Date:</th><td class="field-body">Oct 16, 2013</td>
</tr>
</tbody>
</table>
<p><strong>PRELIMINARY VERSION</strong></p>
<p>The finite element method is a powerful tool for solving differential
equations. The method can easily deal with complex geometries and
higher-order approximations of the solution.
Figure <a class="reference internal" href="#fem-motivation-fig-dolfin"><em>Domain for flow around a dolphin</em></a> shows
a two-dimensional domain with a non-trivial geometry. The idea is to
divide the domain into triangles (elements) and seek a polynomial approximations
to the unknown functions on each triangle. The method glues these
piecewise approximations together to find a global solution.
Linear and quadratic polynomials over the triangles are particularly
popular.</p>
<div class="figure" id="fem-motivation-fig-dolfin">
<img alt="_images/dolfin_mesh1.png" src="_images/dolfin_mesh1.png" style="width: 400px;" />
<p class="caption"><em>Domain for flow around a dolphin</em></p>
</div>
<p>Many successful numerical methods for differential equations,
including the finite element method,
aim at approximating the unknown function by a sum</p>
<div class="math" id="equation-fem:u">
<span class="eqno">(1)</span>\[      u(x) = \sum_{i=0}^N c_i{\psi}_i(x),\]</div>
<p>where <span class="math">\({\psi}_i(x)\)</span> are prescribed functions and <span class="math">\(c_0,\ldots,c_N\)</span>
are unknown coefficients to be determined.
Solution methods for differential equations
utilizing <a href="#equation-fem:u">(1)</a> must
have a <em>principle</em> for constructing <span class="math">\(N+1\)</span> equations to
determine <span class="math">\(c_0,\ldots,c_N\)</span>. Then there is a <em>machinery</em> regarding
the actual constructions of the equations for <span class="math">\(c_0,\ldots,c_N\)</span>, in a
particular problem. Finally, there is a <em>solve</em> phase for computing
the solution <span class="math">\(c_0,\ldots,c_N\)</span> of the <span class="math">\(N+1\)</span> equations.</p>
<p>Especially in the finite element method, the machinery for constructing
the discrete equations to be implemented on a computer is quite
comprehensive, with many mathematical and implementational
details entering the scene at the
same time. From an ease-of-learning perspective it can therefore be
wise to introduce the computational machinery for a trivial equation:
<span class="math">\(u=f\)</span>. Solving this equation with <span class="math">\(f\)</span> given and <span class="math">\(u\)</span> on the form
<a href="#equation-fem:u">(1)</a> means that we seek an approximation
<span class="math">\(u\)</span> to <span class="math">\(f\)</span>.
This approximation problem has the advantage of introducing most of the
finite element toolbox, but with postponing demanding topics related to
differential equations (e.g., integration by parts, boundary conditions,
and coordinate mappings).
This is the reason why we shall first become familiar
with finite element <em>approximation</em> before addressing
finite element methods for differential equations.</p>
<p>First, we refresh some linear algebra concepts about approximating
vectors in vector spaces. Second, we extend these concepts to
approximating functions in function spaces, using the same
principles and the same notation.
We present examples on approximating functions by  global basis functions with
support throughout the entire domain.
Third, we introduce the finite element type of local basis functions
and explain the computational algorithms for working with such functions.
Three types of approximation principles are covered: 1) the least squares
method, 2) the <span class="math">\(L_2\)</span> projection or Galerkin method,
and 3) interpolation or collocation.</p>
</div>
<div class="section" id="approximation-of-vectors">
<span id="fem-approx-vec"></span><h1>Approximation of vectors<a class="headerlink" href="#approximation-of-vectors" title="Permalink to this headline">¶</a></h1>
<p>We shall start with introducing two fundamental methods for
determining the coefficients <span class="math">\(c_i\)</span> in <a href="#equation-fem:u">(1)</a> and illustrate
the methods on approximation of vectors, because vectors in vector
spaces give a more intuitive understanding than starting directly
with approximation of functions in function spaces.
The extension from vectors to functions will be trivial as soon as
the fundamental ideas are understood.</p>
<p>The first method of approximation is called the <em>least squares method</em>
and consists in finding <span class="math">\(c_i\)</span> such that the difference <span class="math">\(u-f\)</span>, measured
in some norm, is minimized. That is, we aim at finding the best
approximation <span class="math">\(u\)</span> to <span class="math">\(f\)</span> (in some norm). The second method is not
as intuitive: we find <span class="math">\(u\)</span> such that the error <span class="math">\(u-f\)</span> is orthogonal to
the space where we seek <span class="math">\(u\)</span>. This is known as <em>projection</em>, or
we may also call it a <em>Galerkin method</em>.
When approximating vectors and functions, the two methods are
equivalent, but this is no longer the case when applying the
principles to differential equations.</p>
<div class="section" id="approximation-of-planar-vectors">
<span id="fem-approx-vec-plane"></span><h2>Approximation of planar vectors<a class="headerlink" href="#approximation-of-planar-vectors" title="Permalink to this headline">¶</a></h2>
<p id="index-0">Suppose we have given a vector <span class="math">\(\boldsymbol{f} = (3,5)\)</span> in the <span class="math">\(xy\)</span> plane
and that we want to approximate this vector by a vector aligned
in the direction of the vector <span class="math">\((a,b)\)</span>. Figure <a class="reference internal" href="#fem-approx-vec-plane-fig"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></a>
depicts the situation.</p>
<div class="figure" id="fem-approx-vec-plane-fig">
<img alt="_images/vecapprox_plane1.png" src="_images/vecapprox_plane1.png" style="width: 400px;" />
<p class="caption"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></p>
</div>
<p>We introduce the vector space <span class="math">\(V\)</span>
spanned by the vector <span class="math">\(\boldsymbol{\psi}_0=(a,b)\)</span>:</p>
<div class="math">
\[V = \mbox{span}\,\{ \boldsymbol{\psi}_0\}{\thinspace .}\]</div>
<p>We say that <span class="math">\(\boldsymbol{\psi}_0\)</span> is a basis vector in the space <span class="math">\(V\)</span>.
Our aim is to find the vector <span class="math">\(\boldsymbol{u} = c_0\boldsymbol{\psi}_0\in V\)</span> which best approximates
the given vector <span class="math">\(\boldsymbol{f} = (3,5)\)</span>. A reasonable criterion for a best
approximation could be to minimize the length of the difference between
the approximate <span class="math">\(\boldsymbol{u}\)</span> and the given <span class="math">\(\boldsymbol{f}\)</span>. The difference, or error
<span class="math">\(\boldsymbol{e} = \boldsymbol{f} -\boldsymbol{u}\)</span>, has its length given by the <em>norm</em></p>
<div class="math">
\[||\boldsymbol{e}|| = (\boldsymbol{e},\boldsymbol{e})^{\frac{1}{2}},\]</div>
<p>where <span class="math">\((\boldsymbol{e},\boldsymbol{e})\)</span> is the <em>inner product</em> of <span class="math">\(\boldsymbol{e}\)</span> and itself. The inner
product, also called <em>scalar product</em> or <em>dot product</em>, of two vectors
<span class="math">\(\boldsymbol{u}=(u_0,u_1)\)</span> and <span class="math">\(\boldsymbol{v} =(v_0,v_1)\)</span> is defined as</p>
<div class="math">
\[(\boldsymbol{u}, \boldsymbol{v}) = u_0v_0 + u_1v_1{\thinspace .}\]</div>
<p><em>Remark 1.</em> We should point out that we use the notation
<span class="math">\((\cdot,\cdot)\)</span> for two different things: <span class="math">\((a,b)\)</span> for scalar
quantities <span class="math">\(a\)</span> and <span class="math">\(b\)</span> means the vector starting in the origin and
ending in the point <span class="math">\((a,b)\)</span>, while <span class="math">\((\boldsymbol{u},\boldsymbol{v})\)</span> with vectors <span class="math">\(\boldsymbol{u}\)</span> and
<span class="math">\(\boldsymbol{v}\)</span> means the inner product of these vectors.  Since vectors are here
written in boldface font there should be no confusion.  We may add
that the norm associated with this inner product is the usual
Eucledian length of a vector.</p>
<p><em>Remark 2.</em> It might be wise to refresh some basic linear algebra by consulting a
textbook.  <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a> and
<a class="reference internal" href="#fem-approx-exer-linalg2"><em>Exercise 2: Linear algebra refresher II</em></a> suggest specific tasks to regain
familiarity with fundamental operations on inner product vector
spaces.</p>
<div class="section" id="the-least-squares-method-1">
<span id="index-1"></span><h3>The least squares method  (1)<a class="headerlink" href="#the-least-squares-method-1" title="Permalink to this headline">¶</a></h3>
<p>We now want to find <span class="math">\(c_0\)</span> such that it minimizes <span class="math">\(||\boldsymbol{e}||\)</span>. The algebra
is simplified if we minimize the square of the norm, <span class="math">\(||\boldsymbol{e}||^2 = (\boldsymbol{e}, \boldsymbol{e})\)</span>,
instead of the norm itself.
Define the function</p>
<div class="math">
\[E(c_0) = (\boldsymbol{e},\boldsymbol{e}) = (\boldsymbol{f} - c_0\boldsymbol{\psi}_0, \boldsymbol{f} - c_0\boldsymbol{\psi}_0)
{\thinspace .}\]</div>
<p>We can rewrite the expressions of the right-hand side in a more
convenient form for further work:</p>
<div class="math" id="equation-fem:vec:E">
<span class="eqno">(2)</span>\[     E(c_0) = (\boldsymbol{f},\boldsymbol{f}) - 2c_0(\boldsymbol{f},\boldsymbol{\psi}_0) + c_0^2(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0){\thinspace .}\]</div>
<p>The rewrite results from using the following fundamental rules for inner
product spaces:</p>
<div class="math" id="equation-fem:vec:rule:scalarmult">
<span class="eqno">(3)</span>\[     (\alpha\boldsymbol{u},\boldsymbol{v})=\alpha(\boldsymbol{u},\boldsymbol{v}),\quad \alpha\in\mathbb{R},\]</div>
<div class="math" id="equation-fem:vec:rule:sum">
<span class="eqno">(4)</span>\[     (\boldsymbol{u} +\boldsymbol{v},\boldsymbol{w}) = (\boldsymbol{u},\boldsymbol{w}) + (\boldsymbol{v}, \boldsymbol{w}),\]</div>
<div class="math" id="equation-fem:vec:rule:symmetry">
<span class="eqno">(5)</span>\[     (\boldsymbol{u}, \boldsymbol{v}) = (\boldsymbol{v}, \boldsymbol{u}){\thinspace .}\]</div>
<p>Minimizing <span class="math">\(E(c_0)\)</span> implies finding <span class="math">\(c_0\)</span> such that</p>
<div class="math">
\[\frac{\partial E}{\partial c_0} = 0{\thinspace .}\]</div>
<p>Differentiating <a href="#equation-fem:vec:E">(2)</a> with respect to <span class="math">\(c_0\)</span> gives</p>
<div class="math" id="equation-fem:vec:dEdc0:v1">
<span class="eqno">(6)</span>\[     \frac{\partial E}{\partial c_0} = -2(\boldsymbol{f},\boldsymbol{\psi}_0) + 2c_0 (\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)
     {\thinspace .}\]</div>
<p>Setting the above expression equal to zero and solving for <span class="math">\(c_0\)</span> gives</p>
<div class="math" id="equation-fem:vec:c0">
<span class="eqno">(7)</span>\[     c_0 = \frac{(\boldsymbol{f},\boldsymbol{\psi}_0)}{(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)},\]</div>
<p>which in the present case with <span class="math">\(\boldsymbol{\psi}_0=(a,b)\)</span> results in</p>
<div class="math">
\[c_0 = \frac{3a + 5b}{a^2 + b^2}{\thinspace .}\]</div>
<p>For later, it is worth mentioning that setting
the key equation <a href="#equation-fem:vec:dEdc0:v1">(6)</a> to zero can be rewritten
as</p>
<div class="math">
\[(\boldsymbol{f}-c0\boldsymbol{\psi}_0,\boldsymbol{\psi}_0) = 0,\]</div>
<p>or</p>
<div class="math" id="equation-fem:vec:dEdc0:Galerkin">
<span class="eqno">(8)</span>\[     (\boldsymbol{e}, \boldsymbol{\psi}_0) = 0
     {\thinspace .}\]</div>
<span class="target" id="index-2"></span></div>
<div class="section" id="the-projection-method">
<span id="index-3"></span><h3>The projection method<a class="headerlink" href="#the-projection-method" title="Permalink to this headline">¶</a></h3>
<p>We shall now show that minimizing <span class="math">\(||\boldsymbol{e}||^2\)</span> implies that <span class="math">\(\boldsymbol{e}\)</span> is
orthogonal to <em>any</em> vector <span class="math">\(\boldsymbol{v}\)</span> in the space <span class="math">\(V\)</span>. This result is
visually quite clear from Figure <a class="reference internal" href="#fem-approx-vec-plane-fig"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></a> (think of
other vectors along the line <span class="math">\((a,b)\)</span>: all of them will lead to
a larger distance between the approximation and <span class="math">\(\boldsymbol{f}\)</span>).
To see this result mathematically, we
express any <span class="math">\(\boldsymbol{v}\in V\)</span> as <span class="math">\(\boldsymbol{v}=s\boldsymbol{\psi}_0\)</span> for any scalar parameter <span class="math">\(s\)</span>,
recall that two vectors are orthogonal when their inner product vanishes,
and calculate the inner product</p>
<div class="math">
\[\begin{split}(\boldsymbol{e}, s\boldsymbol{\psi}_0) &amp;= (\boldsymbol{f} - c_0\boldsymbol{\psi}_0, s\boldsymbol{\psi}_0)\\
&amp;= (\boldsymbol{f},s\boldsymbol{\psi}_0) - (c_0\boldsymbol{\psi}_0, s\boldsymbol{\psi}_0)\\
&amp;= s(\boldsymbol{f},\boldsymbol{\psi}_0) - sc_0(\boldsymbol{\psi}_0, \boldsymbol{\psi}_0)\\
&amp;= s(\boldsymbol{f},\boldsymbol{\psi}_0) - s\frac{(\boldsymbol{f},\boldsymbol{\psi}_0)}{(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)}(\boldsymbol{\psi}_0,\boldsymbol{\psi}_0)\\
&amp;= s\left( (\boldsymbol{f},\boldsymbol{\psi}_0) - (\boldsymbol{f},\boldsymbol{\psi}_0)\right)\\
&amp;=0{\thinspace .}\end{split}\]</div>
<p>Therefore, instead of minimizing the square of the norm, we could
demand that <span class="math">\(\boldsymbol{e}\)</span> is orthogonal to any vector in <span class="math">\(V\)</span>.
This method is known as <em>projection</em>, because it is the same as
projecting the vector onto the subspace.
(The approach can also be referred to as a Galerkin method as
explained at the end of the section <em class="xref std std-ref">approximation!of general vectors</em>.)</p>
<p>Mathematically the projection method is stated
by the equation</p>
<div class="math" id="equation-fem:vec:Galerkin1">
<span class="eqno">(9)</span>\[     (\boldsymbol{e}, \boldsymbol{v}) = 0,\quad\forall\boldsymbol{v}\in V{\thinspace .}\]</div>
<p>An arbitrary <span class="math">\(\boldsymbol{v}\in V\)</span> can be expressed as
<span class="math">\(s\boldsymbol{\psi}_0\)</span>, <span class="math">\(s\in\mathbb{R}\)</span>, and therefore
<a href="#equation-fem:vec:Galerkin1">(9)</a> implies</p>
<div class="math">
\[(\boldsymbol{e},s\boldsymbol{\psi}_0) = s(\boldsymbol{e}, \boldsymbol{\psi}_0) = 0,\]</div>
<p>which means that the error must be orthogonal to the basis vector in
the space <span class="math">\(V\)</span>:</p>
<div class="math">
\[(\boldsymbol{e}, \boldsymbol{\psi}_0)=0\quad\hbox{or}\quad
(\boldsymbol{f} - c_0\boldsymbol{\psi}_0, \boldsymbol{\psi}_0)=0
{\thinspace .}\]</div>
<p>The latter equation gives <a href="#equation-fem:vec:c0">(7)</a> and it
also arose from least squares computations in
<a href="#equation-fem:vec:dEdc0:Galerkin">(8)</a>.</p>
</div>
</div>
<div class="section" id="approximation-of-general-vectors">
<span id="fem-approx-vec-np1dim"></span><h2>Approximation of general vectors<a class="headerlink" href="#approximation-of-general-vectors" title="Permalink to this headline">¶</a></h2>
<p id="index-4">Let us generalize the vector approximation from the previous section
to vectors in spaces with arbitrary dimension. Given some vector <span class="math">\(\boldsymbol{f}\)</span>,
we want to find the best approximation to this vector in
the space</p>
<div class="math">
\[V = \hbox{span}\,\{\boldsymbol{\psi}_0,\ldots,\boldsymbol{\psi}_N\}
{\thinspace .}\]</div>
<p>We assume that the <em>basis vectors</em> <span class="math">\(\boldsymbol{\psi}_0,\ldots,\boldsymbol{\psi}_N\)</span> are
linearly independent so that none of them are redundant and
the space has dimension <span class="math">\(N+1\)</span>.
Any vector <span class="math">\(\boldsymbol{u}\in V\)</span> can be written as a linear combination
of the basis vectors,</p>
<div class="math">
\[\boldsymbol{u} = \sum_{j=0}^N c_j\boldsymbol{\psi}_j,\]</div>
<p>where <span class="math">\(c_j\in\mathbb{R}\)</span> are scalar coefficients to be determined.</p>
<div class="section" id="the-least-squares-method-2">
<h3>The least squares method  (2)<a class="headerlink" href="#the-least-squares-method-2" title="Permalink to this headline">¶</a></h3>
<p>Now we want to find <span class="math">\(c_0,\ldots,c_N\)</span>, such that <span class="math">\(\boldsymbol{u}\)</span> is the best
approximation to <span class="math">\(\boldsymbol{f}\)</span> in the sense that the distance (error)
<span class="math">\(\boldsymbol{e} = \boldsymbol{f} - \boldsymbol{u}\)</span> is minimized. Again, we define
the squared distance as a function of the free parameters
<span class="math">\(c_0,\ldots,c_N\)</span>,</p>
<div class="math">
\[E(c_0,\ldots,c_N) = (\boldsymbol{e},\boldsymbol{e}) = (\boldsymbol{f} -\sum_jc_j\boldsymbol{\psi}_j,\boldsymbol{f} -\sum_jc_j\boldsymbol{\psi}_j)
\nonumber\]</div>
<div class="math" id="equation-fem:vec:genE">
<span class="eqno">(10)</span>\[     = (\boldsymbol{f},\boldsymbol{f}) - 2\sum_{j=0}^N c_j(\boldsymbol{f},\boldsymbol{\psi}_j) +
     \sum_{p=0}^N\sum_{q=0}^N c_pc_q(\boldsymbol{\psi}_p,\boldsymbol{\psi}_q){\thinspace .}\]</div>
<p>Minimizing this <span class="math">\(E\)</span> with respect to the independent variables
<span class="math">\(c_0,\ldots,c_N\)</span> is obtained by requiring</p>
<div class="math">
\[\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N
{\thinspace .}\]</div>
<p>The second term in <a href="#equation-fem:vec:genE">(10)</a> is differentiated as follows:</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{j=0}^N c_j(\boldsymbol{f},\boldsymbol{\psi}_j) = (\boldsymbol{f},\boldsymbol{\psi}_i),\]</div>
<p>since the expression to be differentiated is a sum and only one term,
<span class="math">\(c_i(\boldsymbol{f},\boldsymbol{\psi}_i)\)</span>,
contains <span class="math">\(c_i\)</span> and this term is linear in <span class="math">\(c_i\)</span>.
To understand this differentiation in detail, write out the sum specifically for,
e.g, <span class="math">\(N=3\)</span> and <span class="math">\(i=1\)</span>.</p>
<p>The last term in <a href="#equation-fem:vec:genE">(10)</a>
is more tedious to differentiate. We start with</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
c_pc_q =
\left\lbrace\begin{array}{ll}
0,  \hbox{ if } p\neq i\hbox{ and } q\neq i,\]</div>
<div class="math">
\[c_q,  \hbox{ if } p=i\hbox{ and } q\neq i,\]</div>
<div class="math">
\[c_p,  \hbox{ if } p\neq i\hbox{ and } q=i,\]</div>
<div class="math">
\[2c_i,  \hbox{ if } p=q= i,\]</div>
<div class="math">
\[\end{array}\right.\]</div>
<p>Then</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\boldsymbol{\psi}_p,\boldsymbol{\psi}_q)
= \sum_{p=0, p\neq i}^N c_p(\boldsymbol{\psi}_p,\boldsymbol{\psi}_i)
+ \sum_{q=0, q\neq i}^N c_q(\boldsymbol{\psi}_q,\boldsymbol{\psi}_i)
+2c_i(\boldsymbol{\psi}_i,\boldsymbol{\psi}_i){\thinspace .}\]</div>
<p>The last term can be included in the other two sums, resulting in</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\boldsymbol{\psi}_p,\boldsymbol{\psi}_q)
= 2\sum_{j=0}^N c_i(\boldsymbol{\psi}_j,\boldsymbol{\psi}_i){\thinspace .}\]</div>
<p>It then follows that setting</p>
<div class="math">
\[\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N,\]</div>
<p>leads to a linear system
for <span class="math">\(c_0,\ldots,c_N\)</span>:</p>
<div class="math" id="equation-fem:approx:vec:Np1dim:eqsys">
<span class="eqno">(11)</span>\[     \sum_{j=0}^N A_{i,j} c_j = b_i, \quad i=0,\ldots,N,\]</div>
<p>where</p>
<div class="math">
\[A_{i,j} = (\boldsymbol{\psi}_i,\boldsymbol{\psi}_j),\]</div>
<div class="math">
\[b_i = (\boldsymbol{\psi}_i, \boldsymbol{f}){\thinspace .}\]</div>
<p>We have changed the order of the two vectors in the inner
product according to <a href="#equation-fem:vec:rule:symmetry">(5)</a>:</p>
<div class="math">
\[A_{i,j} = (\boldsymbol{\psi}_j,\boldsymbol{\psi}_i) = (\boldsymbol{\psi}_i,\boldsymbol{\psi}_j),\]</div>
<p>simply because the sequence <span class="math">\(i\)</span>-$j$ looks more aesthetic.</p>
</div>
<div class="section" id="the-galerkin-or-projection-method">
<h3>The Galerkin or projection method<a class="headerlink" href="#the-galerkin-or-projection-method" title="Permalink to this headline">¶</a></h3>
<p>In analogy with the &#8220;one-dimensional&#8221; example in
the section <a class="reference internal" href="#fem-approx-vec-plane"><em>Approximation of planar vectors</em></a>, it holds also here in the general
case that minimizing the distance
(error) <span class="math">\(\boldsymbol{e}\)</span> is equivalent to demanding that <span class="math">\(\boldsymbol{e}\)</span> is orthogonal to
all <span class="math">\(\boldsymbol{v}\in V\)</span>:</p>
<span class="target" id="index-5"></span><div class="math" id="equation-fem:approx:vec:Np1dim:Galerkin">
<span id="index-6"></span><span class="eqno">(12)</span>\[     (\boldsymbol{e},\boldsymbol{v})=0,\quad \forall\boldsymbol{v}\in V{\thinspace .}\]</div>
<p>Since any <span class="math">\(\boldsymbol{v}\in V\)</span> can be written as <span class="math">\(\boldsymbol{v} =\sum_{i=0}^N c_i\boldsymbol{\psi}_i\)</span>,
the statement <a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a> is equivalent to
saying that</p>
<div class="math">
\[(\boldsymbol{e}, \sum_{i=0}^N c_i\boldsymbol{\psi}_i) = 0,\]</div>
<p>for any choice of coefficients <span class="math">\(c_0,\ldots,c_N\)</span>.
The latter equation can be rewritten as</p>
<div class="math">
\[\sum_{i=0}^N c_i (\boldsymbol{e},\boldsymbol{\psi}_i) =0{\thinspace .}\]</div>
<p>If this is to hold for arbitrary values of <span class="math">\(c_0,\ldots,c_N\)</span>
we must require that each term in the sum vanishes,</p>
<div class="math" id="equation-fem:approx:vec:Np1dim:Galerkin0">
<span class="eqno">(13)</span>\[     (\boldsymbol{e},\boldsymbol{\psi}_i)=0,\quad i=0,\ldots,N{\thinspace .}\]</div>
<p>These <span class="math">\(N+1\)</span> equations result in the same linear system as
<a href="#equation-fem:approx:vec:Np1dim:eqsys">(11)</a>:</p>
<div class="math">
\[(\boldsymbol{f} - \sum_{j=0}^N c_j\boldsymbol{\psi}_j, \boldsymbol{\psi}_i) = (\boldsymbol{f}, \boldsymbol{\psi}_i) - \sum_{j\inI}
(\boldsymbol{\psi}_i,\boldsymbol{\psi}_j)c_j = 0,\]</div>
<p>and hence</p>
<div class="math">
\[\sum_{j=0}^N (\boldsymbol{\psi}_i,\boldsymbol{\psi}_j)c_j = (\boldsymbol{f}, \boldsymbol{\psi}_i),\quad i=0,\ldots, N
{\thinspace .}\]</div>
<p>So, instead of differentiating the
<span class="math">\(E(c_0,\ldots,c_N)\)</span> function, we could simply use
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a> as the principle for
determining <span class="math">\(c_0,\ldots,c_N\)</span>, resulting in the <span class="math">\(N+1\)</span>
equations <a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(13)</a>.</p>
<p>The names <em>least squares method</em> or <em>least squares approximation</em>
are natural since the calculations consists of
minimizing <span class="math">\(||\boldsymbol{e}||^2\)</span>, and <span class="math">\(||\boldsymbol{e}||^2\)</span> is a sum of squares
of differences between the components in <span class="math">\(\boldsymbol{f}\)</span> and <span class="math">\(\boldsymbol{u}\)</span>.
We find <span class="math">\(\boldsymbol{u}\)</span> such that this sum of squares is minimized.</p>
<p>The principle <a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a>,
or the equivalent form <a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(13)</a>,
is known as <em>projection</em>. Almost the same mathematical idea
was used by the Russian mathematician <a class="reference external" href="http://en.wikipedia.org/wiki/Boris_Galerkin">Boris Galerkin</a> to solve
differential equations, resulting in what is widely known as
<em>Galerkin&#8217;s method</em>.</p>
</div>
</div>
</div>
<div class="section" id="approximation-of-functions">
<span id="fem-approx-global"></span><h1>Approximation of functions<a class="headerlink" href="#approximation-of-functions" title="Permalink to this headline">¶</a></h1>
<p id="index-7">Let <span class="math">\(V\)</span> be a function space spanned by a set of <em>basis functions</em>
<span class="math">\({\psi}_0,\ldots,{\psi}_N\)</span>,</p>
<div class="math">
\[V = \hbox{span}\,\{{\psi}_0,\ldots,{\psi}_N\},\]</div>
<p>such that any function <span class="math">\(u\in V\)</span> can be written as a linear
combination of the basis functions:</p>
<div class="math" id="equation-fem:approx:ufem">
<span class="eqno">(14)</span>\[     u = \sum_{j\inI} c_j{\psi}_j{\thinspace .}\]</div>
<p>The index set <span class="math">\(I\)</span> is defined as <span class="math">\(I =\{0,\ldots,N\}\)</span> and is used
both for compact notation and for flexibility in the numbering of
elements in sequences.</p>
<p>For now, in this introduction, we shall look at functions of a
single variable <span class="math">\(x\)</span>:
<span class="math">\(u=u(x)\)</span>, <span class="math">\({\psi}_i={\psi}_i(x)\)</span>, <span class="math">\(i\inI\)</span>. Later, we will almost
trivially extend the mathematical details
to functions of two- or three-dimensional physical spaces.
The approximation <a href="#equation-fem:approx:ufem">(14)</a> is typically used
to discretize a problem in space. Other methods, most notably
finite differences, are common for time discretization, although the
form <a href="#equation-fem:approx:ufem">(14)</a> can be used in time as well.</p>
<div class="section" id="the-least-squares-method-3">
<span id="fem-approx-ls"></span><h2>The least squares method  (3)<a class="headerlink" href="#the-least-squares-method-3" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span>, how can we determine its best approximation
<span class="math">\(u(x)\in V\)</span>? A natural starting point is to apply the same reasoning
as we did for vectors in the section <a class="reference internal" href="#fem-approx-vec-np1dim"><em>Approximation of general vectors</em></a>. That is,
we minimize the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span>. However, this requires
a norm for measuring distances, and a norm is most conveniently
defined through an
inner product. Viewing a function as a vector of infinitely
many point values, one for each value of <span class="math">\(x\)</span>, the inner product could
intuitively be defined as the usual summation of
pairwise components, with summation replaced by integration:</p>
<div class="math">
\[(f,g) = \int f(x)g(x)\, {\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>To fix the integration domain, we let <span class="math">\(f(x)\)</span> and <span class="math">\({\psi}_i(x)\)</span>
be defined for a domain <span class="math">\(\Omega\subset\mathbb{R}\)</span>.
The inner product of two functions <span class="math">\(f(x)\)</span> and <span class="math">\(g(x)\)</span> is then</p>
<div class="math" id="equation-fem:approx:LS:innerprod">
<span class="eqno">(15)</span>\[     (f,g) = \int_\Omega f(x)g(x)\, {\, \mathrm{d}x}\]\[     {\thinspace .}\]</div>
<p>The distance between <span class="math">\(f\)</span> and any function <span class="math">\(u\in V\)</span> is simply
<span class="math">\(f-u\)</span>, and the squared norm of this distance is</p>
<div class="math" id="equation-fem:approx:LS:E">
<span class="eqno">(16)</span>\[     E = (f(x)-\sum_{j\inI} c_j{\psi}_j(x), f(x)-\sum_{j\inI} c_j{\psi}_j(x)){\thinspace .}\]</div>
<p>Note the analogy with <a href="#equation-fem:vec:genE">(10)</a>: the given function
<span class="math">\(f\)</span> plays the role of the given vector <span class="math">\(\boldsymbol{f}\)</span>, and the basis function
<span class="math">\({\psi}_i\)</span> plays the role of the basis vector <span class="math">\(\boldsymbol{\psi}_i\)</span>.
We can rewrite <a href="#equation-fem:approx:LS:E">(16)</a>,
through similar steps as used for the result
<a href="#equation-fem:vec:genE">(10)</a>, leading to</p>
<div class="math">
\[E(c_i, \ldots, c_N) = (f,f) -2\sum_{j\inI} c_j(f,{\psi}_i)
+ \sum_{p\inI}\sum_{q\inI} c_pc_q({\psi}_p,{\psi}_q){\thinspace .}\]</div>
<p>Minimizing this function of <span class="math">\(N+1\)</span> scalar variables
<span class="math">\(\left\{ {c}_i \right\}_{i\inI}\)</span>, requires differentiation
with respect to <span class="math">\(c_i\)</span>, for all <span class="math">\(i\inI\)</span>. The resulting
equations are very similar to those we had in the vector case,
and we hence end up with a
linear system of the form <a href="#equation-fem:approx:vec:Np1dim:eqsys">(11)</a>, with
basically the same expressions:</p>
<div class="math" id="equation-fem:approx:Aij">
<span class="eqno">(17)</span>\[     A_{i,j} = ({\psi}_i,{\psi}_j),\]</div>
<div class="math" id="equation-fem:approx:bi">
<span class="eqno">(18)</span>\[     b_i = (f,{\psi}_i){\thinspace .}\]</div>
</div>
<div class="section" id="the-projection-or-galerkin-method">
<h2>The projection (or Galerkin) method<a class="headerlink" href="#the-projection-or-galerkin-method" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-8"></span><p id="index-9">As in the section <a class="reference internal" href="#fem-approx-vec-np1dim"><em>Approximation of general vectors</em></a>, the minimization of <span class="math">\((e,e)\)</span>
is equivalent to</p>
<div class="math" id="equation-fem:approx:Galerkin">
<span class="eqno">(19)</span>\[     (e,v)=0,\quad\forall v\in V{\thinspace .}\]</div>
<p>This is known as a projection of a function <span class="math">\(f\)</span> onto the subspace <span class="math">\(V\)</span>.
We may also call it a Galerkin method for approximating functions.
Using the same reasoning as
in
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(12)</a>-<a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(13)</a>,
it follows that <a href="#equation-fem:approx:Galerkin">(19)</a> is equivalent to</p>
<div class="math" id="equation-fem:approx:Galerkin0">
<span class="eqno">(20)</span>\[     (e,{\psi}_i)=0,\quad i\inI{\thinspace .}\]</div>
<p>Inserting <span class="math">\(e=f-u\)</span> in this equation and ordering terms, as in the
multi-dimensional vector case, we end up with a linear
system with a coefficient matrix <a href="#equation-fem:approx:Aij">(17)</a> and
right-hand side vector <a href="#equation-fem:approx:bi">(18)</a>.</p>
<p>Whether we work with vectors in the plane, general vectors, or
functions in function spaces, the least squares principle and
the projection or Galerkin method are equivalent.</p>
</div>
<div class="section" id="example-linear-approximation">
<span id="fem-approx-global-linear"></span><h2>Example: linear approximation<a class="headerlink" href="#example-linear-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us apply the theory in the previous section to a simple problem:
given a parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> for <span class="math">\(x\in\Omega=[1,2]\)</span>, find
the best approximation <span class="math">\(u(x)\)</span> in the space of all linear functions:</p>
<div class="math">
\[V = \hbox{span}\,\{1, x\}{\thinspace .}\]</div>
<p>With our notation, <span class="math">\({\psi}_0(x)=1\)</span>, <span class="math">\({\psi}_1(x)=x\)</span>, and <span class="math">\(N=1\)</span>.
We seek</p>
<div class="math">
\[u=c_0{\psi}_0(x) + c_1{\psi}_1(x) = c_0 + c_1x,\]</div>
<p>where
<span class="math">\(c_0\)</span> and <span class="math">\(c_1\)</span> are found by solving a <span class="math">\(2\times 2\)</span> the linear system.
The coefficient matrix has elements</p>
<div class="math">
\[A_{0,0} = ({\psi}_0,{\psi}_0) = \int_1^21\cdot 1\, {\, \mathrm{d}x} = 1,\]</div>
<div class="math">
\[A_{0,1} = ({\psi}_0,{\psi}_1) = \int_1^2 1\cdot x\, {\, \mathrm{d}x} = 3/2,\]</div>
<div class="math">
\[A_{1,0} = A_{0,1} = 3/2,\]</div>
<div class="math">
\[A_{1,1} = ({\psi}_1,{\psi}_1) = \int_1^2 x\cdot x\,{\, \mathrm{d}x} = 7/3{\thinspace .}\]</div>
<p>The corresponding right-hand side is</p>
<div class="math">
\[b_1 = (f,{\psi}_0) = \int_1^2 (10(x-1)^2 - 1)\cdot 1 \, {\, \mathrm{d}x} = 7/3,\]</div>
<div class="math">
\[b_2 = (f,{\psi}_1) = \int_1^2 (10(x-1)^2 - 1)\cdot x\, {\, \mathrm{d}x} = 13/3{\thinspace .}\]</div>
<p>Solving the linear system results in</p>
<div class="math">
\[c_0 = -38/3,\quad c_1 = 10,\]</div>
<p>and consequently</p>
<div class="math">
\[u(x) = 10x - \frac{38}{3}{\thinspace .}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-linear"><em>Best approximation of a parabola by a straight line</em></a> displays the
parabola and its best approximation in the space of all linear functions.</p>
<div class="figure" id="fem-approx-global-fig-parabola-linear">
<img alt="_images/parabola_ls_linear1.png" src="_images/parabola_ls_linear1.png" style="width: 400px;" />
<p class="caption"><em>Best approximation of a parabola by a straight line</em></p>
</div>
</div>
<div class="section" id="implementation-of-the-least-squares-method">
<span id="fem-approx-global-ls-code"></span><h2>Implementation of the least squares method<a class="headerlink" href="#implementation-of-the-least-squares-method" title="Permalink to this headline">¶</a></h2>
<p>The linear system can be computed either symbolically or
numerically (a numerical integration rule is needed in the latter case).
Here is a function for symbolic computation of the linear system,
where <span class="math">\(f(x)\)</span> is given as a <tt class="docutils literal"><span class="pre">sympy</span></tt> expression <tt class="docutils literal"><span class="pre">f</span></tt> involving
the symbol <tt class="docutils literal"><span class="pre">x</span></tt>, <tt class="docutils literal"><span class="pre">psi</span></tt> is a list of expressions for <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\inI}\)</span>,
and <tt class="docutils literal"><span class="pre">Omega</span></tt> is a 2-tuple/list holding the limits of the domain <span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                                  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>Observe that we exploit the symmetry of the coefficient matrix:
only the upper triangular part is computed. Symbolic integration in
<tt class="docutils literal"><span class="pre">sympy</span></tt> is often time consuming, and (roughly) halving the
work has noticeable effect on the waiting time for the function to
finish execution.</p>
<p>Comparing the given <span class="math">\(f(x)\)</span> and the approximate <span class="math">\(u(x)\)</span> visually is
done by the following function, which with the aid of
<tt class="docutils literal"><span class="pre">sympy</span></tt>&#8216;s <tt class="docutils literal"><span class="pre">lambdify</span></tt> tool converts a <tt class="docutils literal"><span class="pre">sympy</span></tt>
expression to a Python function for numerical
computations:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&#39;tmp.pdf&#39;</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">u</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">resolution</span> <span class="o">=</span> <span class="mi">401</span>  <span class="c"># no of points in plot</span>
    <span class="n">xcoor</span>  <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">resolution</span><span class="p">)</span>
    <span class="n">exact</span>  <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">approx</span> <span class="o">=</span> <span class="n">u</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">approx</span><span class="p">)</span>
    <span class="n">hold</span><span class="p">(</span><span class="s">&#39;on&#39;</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">exact</span><span class="p">)</span>
    <span class="n">legend</span><span class="p">([</span><span class="s">&#39;approximation&#39;</span><span class="p">,</span> <span class="s">&#39;exact&#39;</span><span class="p">])</span>
    <span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">modules='numpy'</span></tt> argument to <tt class="docutils literal"><span class="pre">lambdify</span></tt> is important
if there are mathematical functions, such as <tt class="docutils literal"><span class="pre">sin</span></tt> or <tt class="docutils literal"><span class="pre">exp</span></tt>
in the symbolic expressions in <tt class="docutils literal"><span class="pre">f</span></tt> or <tt class="docutils literal"><span class="pre">u</span></tt>, and these
mathematical functions are to be used with vector arguments, like
<tt class="docutils literal"><span class="pre">xcoor</span></tt> above.</p>
<p>Both the <tt class="docutils literal"><span class="pre">least_squares</span></tt> and
<tt class="docutils literal"><span class="pre">comparison_plot</span></tt>
are found and coded in the file
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/approx1D.py">approx1D.py</a>.
The forthcoming examples on their use appear in
<tt class="docutils literal"><span class="pre">ex_approx1D.py</span></tt>.</p>
</div>
<div class="section" id="perfect-approximation">
<span id="fem-approx-global-exact"></span><h2>Perfect approximation<a class="headerlink" href="#perfect-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us use the code above to recompute the problem from
the section <a class="reference internal" href="#fem-approx-global-linear"><em>Example: linear approximation</em></a> where we want to approximate
a parabola. What happens if we add an element <span class="math">\(x^2\)</span> to the basis and test what
the best approximation is if <span class="math">\(V\)</span> is the space of all parabolic functions?
The answer is quickly found by running</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">10*x**2 - 20*x + 9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">10*x**2 - 20*x + 9</span>
</pre></div>
</div>
<p>Now, what if we use <span class="math">\({\psi}_i(x)=x^i\)</span> for <span class="math">\(i=0,1,\ldots,N=40\)</span>?
The output from <tt class="docutils literal"><span class="pre">least_squares</span></tt> gives <span class="math">\(c_i=0\)</span> for <span class="math">\(i&gt;2\)</span>, which
means that the method finds the perfect approximation.</p>
<p>In fact, we have a general result that
if <span class="math">\(f\in V\)</span>, the least squares and projection/Galerkin methods compute
the exact solution <span class="math">\(u=f\)</span>.
The proof is straightforward: if <span class="math">\(f\in V\)</span>, <span class="math">\(f\)</span> can be expanded in
terms of the basis functions, <span class="math">\(f=\sum_{j\inI} d_j{\psi}_j\)</span>, for
some coefficients <span class="math">\(\left\{ {d}_i \right\}_{i\inI}\)</span>,
and the right-hand side then has entries</p>
<div class="math">
\[b_i = (f,{\psi}_i) = \sum_{j\inI} d_j({\psi}_j, {\psi}_i) = \sum_{j\inI} d_jA_{i,j}
{\thinspace .}\]</div>
<p>The linear system <span class="math">\(\sum_jA_{i,j}c_j = b_i\)</span>, <span class="math">\(i\inI\)</span>, is then</p>
<div class="math">
\[\sum_{j\inI} c_jA_{i,j} = \sum_{j\inI}d_jA_{i,j},
\quad i\inI,\]</div>
<p>which implies that <span class="math">\(c_i=d_i\)</span> for <span class="math">\(i\inI\)</span>.</p>
</div>
<div class="section" id="ill-conditioning">
<span id="fem-approx-global-illconditioning"></span><h2>Ill-conditioning<a class="headerlink" href="#ill-conditioning" title="Permalink to this headline">¶</a></h2>
<p>The computational example in the section <a class="reference internal" href="#fem-approx-global-exact"><em>Perfect approximation</em></a>
applies the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function which invokes symbolic
methods to calculate and solve the linear system. The correct
solution <span class="math">\(c_0=9, c_1=-20, c_2=10, c_i=0\)</span> for <span class="math">\(i\geq 3\)</span> is perfectly
recovered.</p>
<p>Suppose we
convert the matrix and right-hand side to floating-point arrays
and then solve the system using finite-precision arithmetics, which
is what one will (almost) always do in real life. This time we
get astonishing results! Up to about <span class="math">\(N=7\)</span> we get a solution that
is reasonably close to the exact one. Increasing <span class="math">\(N\)</span> shows that
seriously wrong coefficients are computed.
Below is a table showing the solution of the linear system arising from
approximating a parabola
by functions on the form <span class="math">\(u(x)=c_0 + c_1x + c_2x^2 + \cdots + c_{10}x^{10}\)</span>.
Analytically, we know that <span class="math">\(c_j=0\)</span> for <span class="math">\(j&gt;2\)</span>, but numerically we may get
<span class="math">\(c_j\neq 0\)</span> for <span class="math">\(j&gt;2\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">exact</th>
<th class="head"><tt class="docutils literal"><span class="pre">sympy</span></tt></th>
<th class="head"><tt class="docutils literal"><span class="pre">numpy32</span></tt></th>
<th class="head"><tt class="docutils literal"><span class="pre">numpy64</span></tt></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>9</td>
<td>9.62</td>
<td>5.57</td>
<td>8.98</td>
</tr>
<tr class="row-odd"><td>-20</td>
<td>-23.39</td>
<td>-7.65</td>
<td>-19.93</td>
</tr>
<tr class="row-even"><td>10</td>
<td>17.74</td>
<td>-4.50</td>
<td>9.96</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>-9.19</td>
<td>4.13</td>
<td>-0.26</td>
</tr>
<tr class="row-even"><td>0</td>
<td>5.25</td>
<td>2.99</td>
<td>0.72</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>0.18</td>
<td>-1.21</td>
<td>-0.93</td>
</tr>
<tr class="row-even"><td>0</td>
<td>-2.48</td>
<td>-0.41</td>
<td>0.73</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>1.81</td>
<td>-0.013</td>
<td>-0.36</td>
</tr>
<tr class="row-even"><td>0</td>
<td>-0.66</td>
<td>0.08</td>
<td>0.11</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>0.12</td>
<td>0.04</td>
<td>-0.02</td>
</tr>
<tr class="row-even"><td>0</td>
<td>-0.001</td>
<td>-0.02</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<p>The exact value of <span class="math">\(c_j\)</span>, <span class="math">\(j=0,1,\ldots,10\)</span>, appears in the first
column while the other columns correspond to results obtained
by three different methods:</p>
<blockquote>
<div><ul class="simple">
<li>Column 2: The matrix and vector are converted to
the data structure  <tt class="docutils literal"><span class="pre">sympy.mpmath.fp.matrix</span></tt> and the
<tt class="docutils literal"><span class="pre">sympy.mpmath.fp.lu_solve</span></tt> function is used to solve the system.</li>
<li>Column 3: The matrix and vector are converted to
<tt class="docutils literal"><span class="pre">numpy</span></tt> arrays with data type <tt class="docutils literal"><span class="pre">numpy.float32</span></tt>
(single precision floating-point number) and solved by
the <tt class="docutils literal"><span class="pre">numpy.linalg.solve</span></tt> function.</li>
<li>Column 4: As column 3, but the data type is
<tt class="docutils literal"><span class="pre">numpy.float64</span></tt> (double
precision floating-point number).</li>
</ul>
</div></blockquote>
<p>We see from the numbers in the table that
double precision performs much better than single precision.
Nevertheless, when plotting all these solutions the curves cannot be
visually distinguished (!). This means that the approximations look
perfect, despite the partially very wrong values of the coefficients.</p>
<p>Increasing <span class="math">\(N\)</span> to 12 makes the numerical solver in <tt class="docutils literal"><span class="pre">numpy</span></tt>
abort with the message: &#8220;matrix is numerically singular&#8221;.
A matrix has to be non-singular to be invertible, which is a requirement
when solving a linear system. Already when the matrix is close to
singular, it is <em>ill-conditioned</em>, which here implies that
the numerical solution algorithms are sensitive to round-off
errors and may produce (very) inaccurate results.</p>
<p>The reason why the coefficient matrix is nearly singular and
ill-conditioned is that our basis functions <span class="math">\({\psi}_i(x)=x^i\)</span> are
nearly linearly dependent for large <span class="math">\(i\)</span>.  That is, <span class="math">\(x^i\)</span> and <span class="math">\(x^{i+1}\)</span>
are very close for <span class="math">\(i\)</span> not very small. This phenomenon is
illustrated in Figure <a class="reference internal" href="#fem-approx-global-fig-illconditioning"><em>The 15 first basis functions , </em></a>.
There are 15 lines in this figure, but only half of them are
visually distinguishable.
Almost linearly dependent basis functions give rise to an
ill-conditioned and almost singular matrix.  This fact can be
illustrated by computing the determinant, which is indeed very close
to zero (recall that a zero determinant implies a singular and
non-invertible matrix): <span class="math">\(10^{-65}\)</span> for <span class="math">\(N=10\)</span> and <span class="math">\(10^{-92}\)</span> for
<span class="math">\(N=12\)</span>. Already for <span class="math">\(N=28\)</span> the numerical determinant computation
returns a plain zero.</p>
<div class="figure" id="fem-approx-global-fig-illconditioning">
<img alt="_images/ill_conditioning1.png" src="_images/ill_conditioning1.png" style="width: 600px;" />
<p class="caption">The 15 first basis functions <span class="math">\(x^i\)</span>, <span class="math">\(i=0,\ldots,14\)</span></p>
</div>
<p>On the other hand, the double precision <tt class="docutils literal"><span class="pre">numpy</span></tt> solver do run for
<span class="math">\(N=100\)</span>, resulting in answers that are not significantly worse than
those in the table above, and large powers are
associated with small coefficients (e.g., <span class="math">\(c_j&lt;10^{-2}\)</span> for <span class="math">\(10\leq
j\leq 20\)</span> and <span class="math">\(c&lt;10^{-5}\)</span> for <span class="math">\(j&gt;20\)</span>). Even for <span class="math">\(N=100\)</span> the
approximation still lies on top of the exact curve in a plot (!).</p>
<p>The conclusion is that visual inspection of the quality of the approximation
may not uncover fundamental numerical problems with the computations.
However, numerical analysts have studied approximations and ill-conditioning
for decades, and it is well known that the basis <span class="math">\(\{1,x,x^2,x^3,\ldots,\}\)</span>
is a bad basis. The best basis from a matrix conditioning point of view
is to have orthogonal functions such that <span class="math">\((\psi_i,\psi_j)=0\)</span> for
<span class="math">\(i\neq j\)</span>. There are many known sets of orthogonal polynomials and
other functions.
The functions used in the finite element methods are almost orthogonal,
and this property helps to avoid problems with solving matrix systems.
Almost orthogonal is helpful, but not enough when it comes to
partial differential equations, and ill-conditioning
of the coefficient matrix is a theme when solving large-scale matrix
systems arising from finite element discretizations.</p>
</div>
<div class="section" id="fourier-series">
<span id="fem-approx-global-fourier"></span><h2>Fourier series<a class="headerlink" href="#fourier-series" title="Permalink to this headline">¶</a></h2>
<p id="index-10">A set of sine functions is widely used for approximating functions
(the sines are also orthogonal as explained more in the section <a class="reference internal" href="#fem-approx-global-illconditioning"><em>Ill-conditioning</em></a>).  Let us take</p>
<div class="math">
\[V = \hbox{span}\,\{ \sin \pi x, \sin 2\pi x,\ldots,\sin (N+1)\pi x\}
{\thinspace .}\]</div>
<p>That is,</p>
<div class="math">
\[{\psi}_i(x) = \sin ((i+1)\pi x),\quad i\inI{\thinspace .}\]</div>
<p>An approximation to the <span class="math">\(f(x)\)</span> function from
the section <a class="reference internal" href="#fem-approx-global-linear"><em>Example: linear approximation</em></a> can then be computed by the
<tt class="docutils literal"><span class="pre">least_squares</span></tt> function from the section <a class="reference internal" href="#fem-approx-global-ls-code"><em>Implementation of the least squares method</em></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">pi</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sin</span><span class="p">(</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> (left) shows the oscillatory approximation
of <span class="math">\(\sum_{j=0}^Nc_j\sin ((j+1)\pi x)\)</span> when <span class="math">\(N=3\)</span>.
Changing <span class="math">\(N\)</span> to 11 improves the approximation considerably, see
Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> (right).</p>
<div class="figure" id="fem-approx-global-fig-parabola-sine1">
<img alt="_images/parabola_ls_sines4_121.png" src="_images/parabola_ls_sines4_121.png" style="width: 800px;" />
<p class="caption"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></p>
</div>
<p>There is an error <span class="math">\(f(0)-u(0)=9\)</span> at <span class="math">\(x=0\)</span> in Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> regardless of how large <span class="math">\(N\)</span> is, because all <span class="math">\({\psi}_i(0)=0\)</span> and hence
<span class="math">\(u(0)=0\)</span>. We may help the approximation to be correct at <span class="math">\(x=0\)</span> by
seeking</p>
<div class="math">
\[u(x) = f(0) + \sum_{j\inI} c_j{\psi}_j(x)
{\thinspace .}\]</div>
<p>However, this adjustment introduces a new problem at <span class="math">\(x=1\)</span> since
we now get an error <span class="math">\(f(1)-u(1)=f(1)-0=-1\)</span> at this point. A more
clever adjustment is to replace the <span class="math">\(f(0)\)</span> term by a term that
is <span class="math">\(f(0)\)</span> at <span class="math">\(x=0\)</span> and <span class="math">\(f(1)\)</span> at <span class="math">\(x=1\)</span>. A simple linear combination
<span class="math">\(f(0)(1-x) + xf(1)\)</span> does the job:</p>
<div class="math">
\[u(x) = f(0)(1-x) + xf(1) + \sum_{j\inI} c_j{\psi}_j(x)
{\thinspace .}\]</div>
<p>This adjustment of <span class="math">\(u\)</span> alters the linear system slightly as we get an extra
term <span class="math">\(-(f(0)(1-x) + xf(1),{\psi}_i)\)</span> on the right-hand side.
Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine2"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term</em></a> shows the result
of this technique for
ensuring right boundary values: even 3 sines can now adjust the
<span class="math">\(f(0)(1-x) + xf(1)\)</span> term such that <span class="math">\(u\)</span> approximates the parabola really
well, at least visually.</p>
<div class="figure" id="fem-approx-global-fig-parabola-sine2">
<img alt="_images/parabola_ls_sines4_12_wfterm1.png" src="_images/parabola_ls_sines4_12_wfterm1.png" style="width: 800px;" />
<p class="caption"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term</em></p>
</div>
</div>
<div class="section" id="orthogonal-basis-functions">
<span id="fem-approx-global-orth"></span><h2>Orthogonal basis functions<a class="headerlink" href="#orthogonal-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>The choice of sine functions <span class="math">\({\psi}_i(x)=\sin ((i+1)\pi x)\)</span> has a great
computational advantage: on <span class="math">\(\Omega=[0,1]\)</span> these basis functions are
<em>orthogonal</em>, implying that <span class="math">\(A_{i,j}=0\)</span> if <span class="math">\(i\neq j\)</span>. This
result is realized by trying</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">integrate</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">j</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>in <a class="reference external" href="http://wolframalpha.com">WolframAlpha</a>
(avoid <tt class="docutils literal"><span class="pre">i</span></tt> in the integrand as this symbol means
the imaginary unit <span class="math">\(\sqrt{-1}\)</span>).
Also by asking WolframAlpha
about <span class="math">\(\int_0^1\sin^2 (j\pi x) {\, \mathrm{d}x}\)</span>, we find it
to equal 1/2.
With a diagonal matrix we can easily solve for the coefficients
by hand:</p>
<div class="math">
\[c_i = 2\int_0^1 f(x)\sin ((i+1)\pi x) {\, \mathrm{d}x},\quad i\inI,\]</div>
<p>which is nothing but the classical formula for the coefficients of
the Fourier sine series of <span class="math">\(f(x)\)</span> on <span class="math">\([0,1]\)</span>. In fact, when
<span class="math">\(V\)</span> contains the basic functions used in a Fourier series expansion,
the approximation method derived in the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a>
results in the classical Fourier series for <span class="math">\(f(x)\)</span> (see <a class="reference internal" href="#fem-approx-exer-fourier"><em>Exercise 7: Fourier series as a least squares approximation</em></a>
for details).</p>
<p>With orthogonal basis functions we can make the
<tt class="docutils literal"><span class="pre">least_squares</span></tt> function (much) more efficient since we know that
the matrix is diagonal and only the diagonal elements need to be computed:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares_orth</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span>  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">))]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>This function is found in the file <tt class="docutils literal"><span class="pre">approx1D.py</span></tt>.</p>
</div>
<div class="section" id="the-interpolation-or-collocation-method">
<span id="fem-approx-global-interp"></span><h2>The interpolation (or collocation) method<a class="headerlink" href="#the-interpolation-or-collocation-method" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-11"></span><p id="index-12">The principle of minimizing the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span> is
an intuitive way of computing a best approximation <span class="math">\(u\in V\)</span> to <span class="math">\(f\)</span>.
However, there are other approaches as well.
One is to demand that <span class="math">\(u(x_{i}) = f(x_{i})\)</span> at some selected points
<span class="math">\(x_{i}\)</span>, <span class="math">\(i\inI\)</span>:</p>
<div class="math">
\[u(x_{i}) = \sum_{j\inI} c_j {\psi}_j(x_{i}) = f(x_{i}),
\quad i\inI{\thinspace .}\]</div>
<p>This criterion also gives a linear system
with <span class="math">\(N+1\)</span> unknown coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\inI}\)</span>:</p>
<div class="math">
\[\sum_{j\inI} A_{i,j}c_j = b_i,\quad i\inI,\]</div>
<p>with</p>
<div class="math">
\[A_{i,j} = {\psi}_j(x_{i}),\]</div>
<div class="math">
\[b_i = f(x_{i}){\thinspace .}\]</div>
<p>This time the coefficient matrix is not symmetric because
<span class="math">\({\psi}_j(x_{i})\neq {\psi}_i(x_{j})\)</span> in general.
The method is often referred to as an <em>interpolation method</em>
since some point values of <span class="math">\(f\)</span> are given (<span class="math">\(f(x_{i})\)</span>) and we
fit a continuous function <span class="math">\(u\)</span> that goes through the <span class="math">\(f(x_{i})\)</span> points.
In this case the <span class="math">\(x_{i}\)</span> points are called <em>interpolation points</em>.
When the same approach is used to approximate differential equations,
one usually applies the name <em>collocation method</em> and
<span class="math">\(x_{i}\)</span> are known as <em>collocation points</em>.</p>
<span class="target" id="index-13"></span><p id="index-14">Given <span class="math">\(f\)</span>  as a <tt class="docutils literal"><span class="pre">sympy</span></tt> symbolic expression <tt class="docutils literal"><span class="pre">f</span></tt>, <span class="math">\(\left\{ {{\psi}}_i \right\}_{i\inI}\)</span>
as a list <tt class="docutils literal"><span class="pre">psi</span></tt>, and a set of points <span class="math">\(\left\{ {x}_i \right\}_{i\inI}\)</span>  as a list or array
<tt class="docutils literal"><span class="pre">points</span></tt>, the following Python function sets up and solves the matrix system
for the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\inI}\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="c"># Turn psi and f into Python functions</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">interpolation</span></tt> function is a part of the <tt class="docutils literal"><span class="pre">approx1D</span></tt>
module.</p>
<p>We found it convenient in the above function to turn the expressions <tt class="docutils literal"><span class="pre">f</span></tt> and
<tt class="docutils literal"><span class="pre">psi</span></tt> into ordinary Python functions of <tt class="docutils literal"><span class="pre">x</span></tt>, which can be called with
<tt class="docutils literal"><span class="pre">float</span></tt> values in the list <tt class="docutils literal"><span class="pre">points</span></tt> when building the matrix and
the right-hand side. The alternative is to use the <tt class="docutils literal"><span class="pre">subs</span></tt> method
to substitute the <tt class="docutils literal"><span class="pre">x</span></tt> variable in an expression by an element from
the <tt class="docutils literal"><span class="pre">points</span></tt> list. The following session illustrates both approaches
in a simple setting:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>              <span class="c"># symbolic expression involving x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>               <span class="c"># a value of x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>      <span class="c"># evaluate e for x=p</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>
<span class="go">0.250000000000000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="go">sympy.core.numbers.Float</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">e</span><span class="p">)</span>  <span class="c"># make Python function of e</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">e</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>              <span class="c"># evaluate e(x) for x=p</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="go">float</span>
</pre></div>
</div>
<p>A nice feature of the interpolation or collocation method is that it
avoids computing integrals. However, one has to decide on the location
of the <span class="math">\(x_{i}\)</span> points.  A simple, yet common choice, is to
distribute them uniformly throughout <span class="math">\(\Omega\)</span>.</p>
<div class="section" id="example-1">
<h3>Example  (1)<a class="headerlink" href="#example-1" title="Permalink to this headline">¶</a></h3>
<p>Let us illustrate the interpolation or collocation method by approximating
our parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> by a linear function on <span class="math">\(\Omega=[1,2]\)</span>,
using two collocation points <span class="math">\(x_0=1+1/3\)</span> and <span class="math">\(x_1=1+2/3\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting linear system becomes</p>
<div class="math">
\[\begin{split}\left(\begin{array}{ll}
1 &amp; 4/3\\
1 &amp; 5/3\\
\end{array}\right)
\left(\begin{array}{l}
c_0\\
c_1\\
\end{array}\right)
=
\left(\begin{array}{l}
1/9\\
31/9\\
\end{array}\right)\end{split}\]</div>
<p>with solution <span class="math">\(c_0=-119/9\)</span> and <span class="math">\(c_1=10\)</span>.
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></a> (left) shows the resulting
approximation <span class="math">\(u=-119/9 + 10x\)</span>.
We can easily test other interpolation points, say <span class="math">\(x_0=1\)</span> and <span class="math">\(x_1=2\)</span>.
This changes the line quite significantly, see
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></a> (right).</p>
<div class="figure" id="fem-approx-global-linear-interp-fig1">
<img alt="_images/parabola_inter1.png" src="_images/parabola_inter1.png" style="width: 800px;" />
<p class="caption"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></p>
</div>
</div>
</div>
<div class="section" id="lagrange-polynomials">
<span id="fem-approx-global-lagrange"></span><h2>Lagrange polynomials<a class="headerlink" href="#lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-15">In the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a> we explain the advantage with having
a diagonal matrix: formulas for the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\inI}\)</span> can
then be derived by hand. For an interpolation/collocation method a
diagonal matrix implies that
<span class="math">\({\psi}_j(x_{i}) = 0\)</span> if <span class="math">\(i\neq j\)</span>. One set of basis functions <span class="math">\({\psi}_i(x)\)</span>
with this property is the <em>Lagrange interpolating polynomials</em>,
or just <em>Lagrange polynomials</em>. (Although the functions are named
after Lagrange, they were first discovered by Waring in 1779,
rediscovered by Euler in 1783, and published by Lagrange in 1795.)
The Lagrange polynomials have the form</p>
<div class="math" id="equation-fem:approx:global:Lagrange:poly">
<span class="eqno">(21)</span>\[     {\psi}_i(x) =
     \prod_{j=0,j\neq i}^N
     \frac{x-x_{j}}{x_{i}-x_{j}}
     = \frac{x-x_0}{x_{i}-x_0}\cdots\frac{x-x_{i-1}}{x_{i}-x_{i-1}}\frac{x-x_{i+1}}{x_{i}-x_{i+1}}
     \cdots\frac{x-x_N}{x_{i}-x_N},\]</div>
<p>for <span class="math">\(i\inI\)</span>.
We see from <a href="#equation-fem:approx:global:Lagrange:poly">(21)</a> that all the <span class="math">\({\psi}_i\)</span>
functions are polynomials of degree <span class="math">\(N\)</span> which have the property</p>
<div class="math" id="equation-fem:inter:prop">
<span id="index-16"></span><span class="eqno">(22)</span>\[\begin{split}     {\psi}_i(x_s) = \delta_{is},\quad \delta_{is} =
     \left\lbrace\begin{array}{ll}
     1, &amp; i=s,\\
     0, &amp; i\neq s,
     \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_s\)</span> is an interpolation/collocation point.
Here we have used the <em>Kronecker delta</em> symbol <span class="math">\(\delta_{is}\)</span>.
This property implies that <span class="math">\(A_{i,j}=0\)</span> for <span class="math">\(i\neq j\)</span> and
<span class="math">\(A_{i,j}=1\)</span> when <span class="math">\(i=j\)</span>. The solution of the linear system is
them simply</p>
<div class="math">
\[c_i = f(x_{i}),\quad i\inI,\]</div>
<p>and</p>
<div class="math">
\[u(x) = \sum_{j\inI} f(x_{i}){\psi}_i(x){\thinspace .}\]</div>
<p>The following function computes the Lagrange interpolating polynomial
<span class="math">\({\psi}_i(x)\)</span>, given the interpolation points <span class="math">\(x_{0},\ldots,x_{N}\)</span> in
the list or array <tt class="docutils literal"><span class="pre">points</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>The next function computes a complete basis using equidistant points throughout
<span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span>
</pre></div>
</div>
<p>When <tt class="docutils literal"><span class="pre">x</span></tt> is an <tt class="docutils literal"><span class="pre">sm.Symbol</span></tt> object, we let the
spacing between
the interpolation points, <tt class="docutils literal"><span class="pre">h</span></tt>, be a <tt class="docutils literal"><span class="pre">sympy</span></tt> rational number
for nice end results in the formulas for <span class="math">\({\psi}_i\)</span>.
The other case, when <tt class="docutils literal"><span class="pre">x</span></tt> is a plain Python <tt class="docutils literal"><span class="pre">float</span></tt>,
signifies numerical computing, and then we let <tt class="docutils literal"><span class="pre">h</span></tt> be a floating-point
number.
Observe that the <tt class="docutils literal"><span class="pre">Lagrange_polynomial</span></tt> function works equally well
in the symbolic and numerical case - just think of <tt class="docutils literal"><span class="pre">x</span></tt> being an
<tt class="docutils literal"><span class="pre">sm.Symbol</span></tt> object or a Python <tt class="docutils literal"><span class="pre">float</span></tt>.
A little interactive session illustrates the difference between symbolic
and numerical computing of the basis functions and points:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">points</span>
<span class="go">[0, 1/2, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span>
<span class="go">[(1 - x)*(1 - 2*x), 2*x*(2 - 2*x), -x*(1 - 2*x)]</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c"># numerical computing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">points</span>
<span class="go">[0.0, 0.5, 1.0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psi</span>
<span class="go">[-0.0, 1.0, 0.0]</span>
</pre></div>
</div>
<p>The Lagrange polynomials are very much used in finite element methods
because of their property <a href="#equation-fem:inter:prop">(22)</a>.</p>
<div class="section" id="approximation-of-a-polynomial">
<h3>Approximation of a polynomial<a class="headerlink" href="#approximation-of-a-polynomial" title="Permalink to this headline">¶</a></h3>
<p>The Galerkin or least squares method lead to an exact approximation
if <span class="math">\(f\)</span> lies in the space spanned by the basis functions. It could be
interest to see how the interpolation method with Lagrange
polynomials as basis is able to approximate a polynomial, e.g.,
a parabola. Running</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
</pre></div>
</div>
<p>shows the result that up to <tt class="docutils literal"><span class="pre">N=4</span></tt> we achieve an exact approximation,
and then round-off errors start to grow, such that
<tt class="docutils literal"><span class="pre">N=15</span></tt> leads to a 15-degree polynomial for <span class="math">\(u\)</span> where
the coefficients in front of <span class="math">\(x^r\)</span> for <span class="math">\(r&gt;2\)</span> are
of size <span class="math">\(10^{-5}\)</span> and smaller.</p>
</div>
<div class="section" id="successful-example">
<h3>Successful example<a class="headerlink" href="#successful-example" title="Permalink to this headline">¶</a></h3>
<p>Trying out the Lagrange polynomial basis for approximating
<span class="math">\(f(x)=\sin 2\pi x\)</span> on <span class="math">\(\Omega =[0,1]\)</span> with the least squares
and the interpolation techniques can be done by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">psi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-sine-ls-colloc"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3</em></a> shows the results.
There is little difference between the least squares and the interpolation
technique. Increasing <span class="math">\(N\)</span> gives visually better approximations.</p>
<div class="figure" id="fem-approx-global-lagrange-fig-sine-ls-colloc">
<img alt="_images/Lagrange_ls_interp_sin_41.png" src="_images/Lagrange_ls_interp_sin_41.png" style="width: 800px;" />
<p class="caption"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 3</em></p>
</div>
</div>
<div class="section" id="less-successful-example">
<span id="index-17"></span><h3>Less successful example<a class="headerlink" href="#less-successful-example" title="Permalink to this headline">¶</a></h3>
<p>The next example concerns interpolating <span class="math">\(f(x)=|1-2x|\)</span> on
<span class="math">\(\Omega =[0,1]\)</span> using Lagrange polynomials. Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></a> shows a peculiar effect: the approximation starts to oscillate
more and more as <span class="math">\(N\)</span> grows. This numerical artifact is not surprising
when looking at the individual Lagrange polynomials. Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></a> shows two such polynomials, <span class="math">\(\psi_2(x)\)</span> and
<span class="math">\(\psi_7(x)\)</span>, both of degree 11 and computed from uniformly spaced
points <span class="math">\(x_{x_i}=i/11\)</span>, <span class="math">\(i=0,\ldots,11\)</span>, marked with circles.
We clearly see the property of Lagrange polynomials:
<span class="math">\(\psi_2(x_{i})=0\)</span> and <span class="math">\(\psi_7(x_{i})=0\)</span> for all <span class="math">\(i\)</span>,
except <span class="math">\(\psi_2(x_{2})=1\)</span> and <span class="math">\(\psi_7(x_{7})=1\)</span>.
The most striking feature, however, is the significant oscillation
near the boundary. The reason is easy to understand:
since we force the functions to zero at so many points,
a polynomial of high degree is forced to oscillate between
the points.
The phenomenon is named <em>Runge&#8217;s phenomenon</em> and you can read
a more detailed explanation on <a class="reference external" href="http://en.wikipedia.org/wiki/Runge%27s_phenomenon">Wikipedia</a>.</p>
</div>
<div class="section" id="remedy-for-strong-oscillations">
<span id="index-18"></span><h3>Remedy for strong oscillations<a class="headerlink" href="#remedy-for-strong-oscillations" title="Permalink to this headline">¶</a></h3>
<p>The oscillations can be reduced by a more clever choice of
interpolation points, called the <em>Chebyshev nodes</em>:</p>
<div class="math">
\[x_{i} = \frac{1}{2} (a+b) + \frac{1}{2}(b-a)\cos\left( \frac{2i+1}{2(N+1)}pi\right),\quad i=0\ldots,N,\]</div>
<p>on the interval <span class="math">\(\Omega = [a,b]\)</span>.
Here is a flexible version of the <tt class="docutils literal"><span class="pre">Lagrange_polynomials_01</span></tt> function above,
valid for any interval <span class="math">\(\Omega =[a,b]\)</span> and with the possibility to generate
both uniformly distributed points and Chebyshev nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">point_distribution</span><span class="o">=</span><span class="s">&#39;uniform&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s">&#39;uniform&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s">&#39;Chebyshev&#39;</span><span class="p">:</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">Chebyshev_nodes</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">psi</span><span class="p">,</span> <span class="n">points</span>

<span class="k">def</span> <span class="nf">Chebyshev_nodes</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">cos</span><span class="p">,</span> <span class="n">pi</span>
    <span class="k">return</span> <span class="p">[</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">cos</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">pi</span><span class="p">)</span> \
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>All the functions computing Lagrange polynomials listed
above are found in the module file <tt class="docutils literal"><span class="pre">Lagrange.py</span></tt>.
Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></a> shows the improvement of
using Chebyshev nodes (compared with Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></a>). The reason is that the corresponding Lagrange
polynomials have much smaller oscillations as seen in
Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-osc"><em>Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles)</em></a>
(compare with Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></a>).</p>
<p>Another cure for undesired oscillation of higher-degree interpolating
polynomials is to use lower-degree Lagrange
polynomials on many small patches of the domain, which is the idea
pursued in the finite element method. For instance, linear Lagrange
polynomials on <span class="math">\([0,1/2]\)</span> and <span class="math">\([1/2,1]\)</span> would yield a perfect
approximation to <span class="math">\(f(x)=|1-2x|\)</span> on <span class="math">\(\Omega = [0,1]\)</span>
since <span class="math">\(f\)</span> is piecewise linear.</p>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-unif-7-14">
<img alt="_images/Lagrange_interp_abs_8_151.png" src="_images/Lagrange_interp_abs_8_151.png" style="width: 800px;" />
<p class="caption"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-unif-osc">
<img alt="_images/Lagrange_basis_121.png" src="_images/Lagrange_basis_121.png" style="width: 400px;" />
<p class="caption"><em>Illustration of the oscillatory behavior of two Lagrange polynomials based on 12 uniformly spaced points (marked by circles)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-cheb-7-14">
<img alt="_images/Lagrange_interp_abs_Cheb_8_151.png" src="_images/Lagrange_interp_abs_Cheb_8_151.png" style="width: 800px;" />
<p class="caption"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-cheb-osc">
<img alt="_images/Lagrange_basis_121.png" src="_images/Lagrange_basis_121.png" style="width: 400px;" />
<p class="caption"><em>Illustration of the less oscillatory behavior of two Lagrange polynomials based on 12 Chebyshev points (marked by circles)</em></p>
</div>
<p>How does the least squares or projection methods work with Lagrange
polynomials?
Unfortunately, <tt class="docutils literal"><span class="pre">sympy</span></tt> has problems integrating the <span class="math">\(f(x)=|1-2x|\)</span>
function times a polynomial. Other choices of <span class="math">\(f(x)\)</span> can also
make the symbolic integration fail. Therefore, we should extend
the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function such that it falls back on
numerical integration if the symbolic integration is unsuccessful.
In the latter case, the returned value from <tt class="docutils literal"><span class="pre">sympy</span></tt>&#8216;s
<tt class="docutils literal"><span class="pre">integrate</span></tt> function is an object of type <tt class="docutils literal"><span class="pre">Integral</span></tt>.
We can test on this type and utilize the <tt class="docutils literal"><span class="pre">mpmath</span></tt> module in
<tt class="docutils literal"><span class="pre">sympy</span></tt> to perform numerical integration of high precision.
Here is the code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="c"># Could not integrate symbolically, fallback</span>
                <span class="c"># on numerical integration with mpmath.quad</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="finite-element-basis-functions">
<span id="fem-approx-fe"></span><h1>Finite element basis functions<a class="headerlink" href="#finite-element-basis-functions" title="Permalink to this headline">¶</a></h1>
<p>The specific basis functions exemplified in the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> are in general nonzero on the entire domain
<span class="math">\(\Omega\)</span>, see Figure <a class="reference internal" href="#fem-approx-fe-fig-u-sin"><em>A function resulting from adding two sine basis functions</em></a> for an example
where we plot <span class="math">\(\psi_0(x)=\sin\frac{1}{2}\pi x\)</span> and
<span class="math">\(\psi_1(x)=\sin 2\pi x\)</span> together with a possible sum
<span class="math">\(u(x)=4\psi_0(x) - \frac{1}{2}\psi_1(x)\)</span>. We shall
now turn the attention to basis functions that have <em>compact support</em>,
meaning that they are nonzero on only a small portion of
<span class="math">\(\Omega\)</span>. Moreover, we shall restrict the functions to be <em>piecewise
polynomials</em>. This means that the domain is split into subdomains and
the function is a polynomial on one or more subdomains, see Figure
<a class="reference internal" href="#fem-approx-fe-fig-u-fe"><em>A function resulting from adding three local piecewise linear (hat) functions</em></a> for a sketch involving locally defined
hat functions that make <span class="math">\(u=\sum_jc_j{\psi}_j\)</span> piecewise linear. At
the boundaries between subdomains one normally forces continuity of
the function only so that when connecting two polynomials from two
subdomains, the derivative becomes discontinuous. These type
of basis functions are fundamental in the finite element method.</p>
<div class="figure" id="fem-approx-fe-fig-u-sin">
<img alt="_images/u_example_sin1.png" src="_images/u_example_sin1.png" style="width: 600px;" />
<p class="caption"><em>A function resulting from adding two sine basis functions</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-u-fe">
<img alt="_images/u_example_P11.png" src="_images/u_example_P11.png" style="width: 600px;" />
<p class="caption"><em>A function resulting from adding three local piecewise linear (hat) functions</em></p>
</div>
<p>We first introduce the concepts of elements and nodes in a simplistic fashion
as often met in the literature. Later, we shall generalize the concept
of an element, which is a necessary step to treat a wider class of
approximations within the family of finite element methods.
The generalization is also compatible with
the concepts used in the <a class="reference external" href="http://fenicsproject.org">FEniCS</a> finite
element software.</p>
<div class="section" id="elements-and-nodes">
<span id="fem-approx-fe-def-elements-nodes"></span><h2>Elements and nodes<a class="headerlink" href="#elements-and-nodes" title="Permalink to this headline">¶</a></h2>
<p>Let us divide the interval <span class="math">\(\Omega\)</span> on which <span class="math">\(f\)</span> and <span class="math">\(u\)</span> are defined
into non-overlapping subintervals <span class="math">\(\Omega^{(e)}\)</span>, <span class="math">\(e=0,\ldots,N_e\)</span>:</p>
<div class="math">
\[\Omega = \Omega^{(0)}\cup \cdots \cup \Omega^{(N_e)}{\thinspace .}\]</div>
<p>We shall for now
refer to <span class="math">\(\Omega^{(e)}\)</span> as an <em>element</em>, having number <span class="math">\(e\)</span>.
On each element we introduce a set of points called <em>nodes</em>.
For now we assume that the nodes are uniformly spaced throughout the
element and that the boundary points of the elements are also nodes.
The nodes are given numbers both within an element and in the global
domain. These are
referred to as <em>local</em> and <em>global</em> node numbers, respectively.
Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p1"><em>Finite element mesh with 5 elements and 6 nodes</em></a> shows
element boundaries with small vertical lines, nodes as small disks,
element numbers in circles, and global node numbers under the nodes.</p>
<div class="figure" id="fem-approx-fe-def-elements-nodes-fig-p1">
<img alt="_images/fe_mesh1D1.png" src="_images/fe_mesh1D1.png" style="width: 500px;" />
<p class="caption"><em>Finite element mesh with 5 elements and 6 nodes</em></p>
</div>
<span class="target" id="index-19"></span><p id="index-20">Nodes and elements uniquely define a <em>finite element mesh</em>, which is our
discrete representation of the domain in the computations.
A common special case is that of a <em>uniformly partitioned mesh</em> where
each element has the same length and the distance between nodes is constant.</p>
<div class="section" id="example-2">
<h3>Example  (2)<a class="headerlink" href="#example-2" title="Permalink to this headline">¶</a></h3>
<p>On <span class="math">\(\Omega =[0,1]\)</span> we may introduce two elements,
<span class="math">\(\Omega^{(0)}=[0,0.4]\)</span> and <span class="math">\(\Omega^{(1)}=[0.4,1]\)</span>. Furthermore,
let us introduce three nodes
per element, equally spaced within each element.
Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p2"><em>Finite element mesh with 2 elements and 5 nodes</em></a> shows the
mesh.
The three nodes in element number 0 are <span class="math">\(x_0=0\)</span>, <span class="math">\(x_1=0.2\)</span>, and <span class="math">\(x_2=0.4\)</span>.
The local and global node numbers are here equal.
In element number 1, we have the local nodes <span class="math">\(x_0=0.4\)</span>, <span class="math">\(x_1=0.7\)</span>, and <span class="math">\(x_2=1\)</span>
and the corresponding
global nodes <span class="math">\(x_2=0.4\)</span>, <span class="math">\(x_3=0.7\)</span>, and <span class="math">\(x_4=1\)</span>. Note that
the global node <span class="math">\(x_2=0.4\)</span> is shared by the two elements.</p>
<div class="figure" id="fem-approx-fe-def-elements-nodes-fig-p2">
<img alt="_images/fe_mesh1D_P21.png" src="_images/fe_mesh1D_P21.png" style="width: 500px;" />
<p class="caption"><em>Finite element mesh with 2 elements and 5 nodes</em></p>
</div>
<p>For the purpose of implementation, we introduce two lists or arrays:
<tt class="docutils literal"><span class="pre">nodes</span></tt> for storing the coordinates of the nodes, with the
global node numbers as indices, and <tt class="docutils literal"><span class="pre">elements</span></tt> for holding
the global node numbers in each element, with the local node numbers
as indices. The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists for the sample mesh
above take the form</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
</pre></div>
</div>
<p>Looking up the coordinate of local node number 2 in element 1
is here done by <tt class="docutils literal"><span class="pre">nodes[elements[1][2]]</span></tt> (recall that nodes and
elements start their numbering at 0).</p>
<p>The numbering of elements and nodes does not need to be regular.
Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p1-irregular"><em>Example on irregular numbering of elements and nodes</em></a> shows
and example corresponding to</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<div class="figure" id="fem-approx-fe-def-elements-nodes-fig-p1-irregular">
<img alt="_images/fe_mesh1D_random_numbering1.png" src="_images/fe_mesh1D_random_numbering1.png" style="width: 500px;" />
<p class="caption"><em>Example on irregular numbering of elements and nodes</em></p>
</div>
</div>
</div>
<div class="section" id="the-basis-functions">
<h2>The basis functions<a class="headerlink" href="#the-basis-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="construction-principles">
<h3>Construction principles<a class="headerlink" href="#construction-principles" title="Permalink to this headline">¶</a></h3>
<p>Finite element basis functions are in this text recognized by
the notation <span class="math">\({\varphi}_i(x)\)</span>, where the index now in the beginning corresponds to
a global node number. In the current approximation problem we shall
simply take <span class="math">\({\psi}_i = {\varphi}_i\)</span>.</p>
<p>Let <span class="math">\(i\)</span> be the global node number corresponding to local node <span class="math">\(r\)</span> in
element number <span class="math">\(e\)</span>.  The finite element basis functions <span class="math">\({\varphi}_i\)</span>
are now defined as follows.</p>
<blockquote>
<div><ul class="simple">
<li>If local node number <span class="math">\(r\)</span> is not on the boundary of the element,
take <span class="math">\({\varphi}_i(x)\)</span> to be the Lagrange
polynomial that is 1 at the local node number <span class="math">\(r\)</span> and zero
at all other nodes in the element. On all other elements, <span class="math">\({\varphi}_i=0\)</span>.</li>
<li>If local node number <span class="math">\(r\)</span> is on the boundary of the element,
let <span class="math">\({\varphi}_i\)</span> be made up of the Lagrange polynomial that is 1 at this node
in element number <span class="math">\(e\)</span> and its neighboring element.
On all other elements, <span class="math">\({\varphi}_i=0\)</span>.</li>
</ul>
</div></blockquote>
<p>A visual impression of three such basis functions are given in
Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>.</p>
<div class="figure" id="fem-approx-fe-fig-p2">
<img alt="_images/mpl_fe_basis_p2_4e_lab1.png" src="_images/mpl_fe_basis_p2_4e_lab1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise quadratic basis functions associated with nodes in element 1</em></p>
</div>
</div>
<div class="section" id="properties-of">
<h3>Properties of <span class="math">\({\varphi}_i\)</span><a class="headerlink" href="#properties-of" title="Permalink to this headline">¶</a></h3>
<p>The construction of basis functions according to the principles above
lead to two important properties of <span class="math">\({\varphi}_i(x)\)</span>. First,</p>
<div class="math" id="equation-fem:approx:fe:phi:prop1">
<span id="index-21"></span><span class="eqno">(23)</span>\[\begin{split}     {\varphi}_i(x_{j}) =\delta_{ij},\quad \delta_{ij} =
     \left\lbrace\begin{array}{ll}
     1, &amp; i=j,\\
     0, &amp; i\neq j,
     \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_{j}\)</span> is a node in the mesh with global node number <span class="math">\(j\)</span>.
The
result <span class="math">\({\varphi}_i(x_{j}) =\delta_{ij}\)</span> arises
because the Lagrange polynomials are constructed to have
exactly this property.
The property also implies a convenient interpretation of <span class="math">\(c_i\)</span>
as the value of <span class="math">\(u\)</span> at node <span class="math">\(i\)</span>. To show this, we expand <span class="math">\(u\)</span>
in the usual way as <span class="math">\(\sum_jc_j{\psi}_j\)</span> and choose <span class="math">\({\psi}_i = {\varphi}_i\)</span>:</p>
<div class="math">
\[u(x_{i}) = \sum_{j\inI} c_j {\psi}_j (x_{i}) =
\sum_{j\inI} c_j {\varphi}_j (x_{i}) = c_i {\varphi}_i (x_{i}) = c_i
{\thinspace .}\]</div>
<p>Because of this interpretation,
the coefficient <span class="math">\(c_i\)</span> is by many named <span class="math">\(u_i\)</span> or <span class="math">\(U_i\)</span>.</p>
<p>Second,
<span class="math">\({\varphi}_i(x)\)</span> is mostly zero throughout the domain:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\({\varphi}_i(x) \neq 0\)</span> only on those elements that contain global node <span class="math">\(i\)</span>,</li>
<li><span class="math">\({\varphi}_i(x){\varphi}_j(x) \neq 0\)</span> if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are global node
numbers in the same element.</li>
</ul>
</div></blockquote>
<p>Since <span class="math">\(A_{i,j}\)</span> is the integral of
<span class="math">\({\varphi}_i{\varphi}_j\)</span> it means that
<em>most of the elements in the coefficient matrix will be zero</em>.
We will come back to these properties and use
them actively in computations to save memory and CPU time.</p>
<p>We let each element have <span class="math">\(d+1\)</span> nodes, resulting in local Lagrange
polynomials of degree <span class="math">\(d\)</span>. It is not a requirement to have the same
<span class="math">\(d\)</span> value in each element, but for now we will assume so.</p>
</div>
</div>
<div class="section" id="example-on-piecewise-quadratic-finite-element-functions">
<h2>Example on piecewise quadratic finite element functions<a class="headerlink" href="#example-on-piecewise-quadratic-finite-element-functions" title="Permalink to this headline">¶</a></h2>
<p>Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em> illustrates how piecewise
quadratic basis functions can look like (<span class="math">\(d=2\)</span>). We work with the
domain <span class="math">\(\Omega = [0,1]\)</span> divided into four equal-sized elements, each having
three nodes.
The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists in this particular example become</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.375</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.625</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.875</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-p2-mesh"><em>Sketch of mesh with 4 elements and 3 nodes per element</em></a> sketches the mesh and the
numbering.
Nodes are marked with circles on the <span class="math">\(x\)</span> axis and
element boundaries are marked with vertical dashed lines
in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>.</p>
<div class="figure" id="id1">
<img alt="_images/mpl_fe_basis_p2_4e_lab1.png" src="_images/mpl_fe_basis_p2_4e_lab1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise quadratic basis functions associated with nodes in element 1</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-p2-mesh">
<img alt="_images/fe_mesh1D_P2_ne41.png" src="_images/fe_mesh1D_P2_ne41.png" style="width: 500px;" />
<p class="caption"><em>Sketch of mesh with 4 elements and 3 nodes per element</em></p>
</div>
<p>Let us explain in detail how the basis functions are constructed
according to the principles.
Consider element number 1 in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>,
<span class="math">\(\Omega^{(1)}=[0.25, 0.5]\)</span>, with local nodes
0, 1, and 2 corresponding to global nodes 2, 3, and 4.
The coordinates of these nodes are
<span class="math">\(0.25\)</span>, <span class="math">\(0.375\)</span>, and <span class="math">\(0.5\)</span>, respectively.
We define three Lagrange
polynomials on this element:</p>
<ol class="arabic simple">
<li>The polynomial that is 1 at local node 1
(<span class="math">\(x=0.375\)</span>, global node 3) makes up the basis function
<span class="math">\({\varphi}_3(x)\)</span> over this element,
with <span class="math">\({\varphi}_3(x)=0\)</span> outside the element.</li>
<li>The Lagrange polynomial that is 1 at local node 0 is the &#8220;right
part&#8221; of the global basis function
<span class="math">\({\varphi}_2(x)\)</span>. The &#8220;left part&#8221; of <span class="math">\({\varphi}_2(x)\)</span> consists of
a Lagrange polynomial associated with local node 2 in
the neighboring element <span class="math">\(\Omega^{(0)}=[0, 0.25]\)</span>.</li>
<li>Finally, the polynomial that is 1 at local node 2 (global node 4)
is the &#8220;left part&#8221; of the global basis function <span class="math">\({\varphi}_4(x)\)</span>.
The &#8220;right part&#8221; comes from the Lagrange polynomial that is 1 at
local node 0 in the neighboring element <span class="math">\(\Omega^{(2)}=[0.5, 0.75]\)</span>.</li>
</ol>
<p>As mentioned earlier,
any global basis function <span class="math">\({\varphi}_i(x)\)</span> is zero on elements that
do not contain the node with global node number <span class="math">\(i\)</span>.</p>
<p>The other global functions associated with internal
nodes, <span class="math">\({\varphi}_1\)</span>, <span class="math">\({\varphi}_5\)</span>, and <span class="math">\({\varphi}_7\)</span>, are all of the
same shape as the drawn <span class="math">\({\varphi}_3\)</span>, while the global basis functions
associated with shared nodes also have the same shape, provided the
elements are of the same length.</p>
<div class="figure" id="fem-approx-fe-fig-p1">
<img alt="_images/mpl_fe_basis_p1_4e_lab1.png" src="_images/mpl_fe_basis_p1_4e_lab1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></p>
</div>
</div>
<div class="section" id="example-on-piecewise-linear-finite-element-functions">
<h2>Example on piecewise linear finite element functions<a class="headerlink" href="#example-on-piecewise-linear-finite-element-functions" title="Permalink to this headline">¶</a></h2>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a> shows
piecewise linear basis functions (<span class="math">\(d=1\)</span>). Also here we have four elements on
<span class="math">\(\Omega = [0,1]\)</span>. Consider the element <span class="math">\(\Omega^{(1)}=[0.25,0.5]\)</span>.
Now there are no internal nodes in the elements so that all basis
functions are associated with nodes at the element boundaries and hence
made up of two Lagrange polynomials from neighboring elements.
For example, <span class="math">\({\varphi}_1(x)\)</span> results from the Lagrange polynomial in
element 0 that is 1 at local node 1 and 0 at local node 0, combined with
the Lagrange polynomial in
element 1 that is 1 at local node 0 and 0 at local node 1.
The other basis functions are constructed similarly.</p>
<p>Explicit mathematical formulas are needed for <span class="math">\({\varphi}_i(x)\)</span> in computations.
In the
piecewise linear case, one can show that</p>
<div class="math" id="equation-fem:approx:fe:phi:1:formula1">
<span class="eqno">(24)</span>\[\begin{split}     {\varphi}_i(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     (x - x_{i-1})/(x_{i} - x_{i-1}),
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     1 -
     (x - x_{i})/(x_{i+1} - x_{i}),
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}{\thinspace .}  \end{array}
     \right.\end{split}\]</div>
<p>Here, <span class="math">\(x_{j}\)</span>, <span class="math">\(j=i-1,i,i+1\)</span>, denotes the coordinate of node <span class="math">\(j\)</span>.
For elements of equal length <span class="math">\(h\)</span> the formulas can be simplified to</p>
<div class="math" id="equation-fem:approx:fe:phi:1:formula2">
<span class="eqno">(25)</span>\[\begin{split}     {\varphi}_i(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     (x - x_{i-1})/h,
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     1 -
     (x - x_{i})/h,
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}
     \end{array}
     \right.\end{split}\]</div>
</div>
<div class="section" id="example-on-piecewise-cubic-finite-element-basis-functions">
<h2>Example on piecewise cubic finite element basis functions<a class="headerlink" href="#example-on-piecewise-cubic-finite-element-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>Piecewise cubic basis functions can be defined by introducing four
nodes per element. Figure <a class="reference internal" href="#fem-approx-fe-fig-p3"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></a> shows
examples on <span class="math">\({\varphi}_i(x)\)</span>, <span class="math">\(i=3,4,5,6\)</span>, associated with element number 1.
Note that <span class="math">\({\varphi}_4\)</span> and <span class="math">\({\varphi}_5\)</span> are nonzero on element number 1,
while
<span class="math">\({\varphi}_3\)</span> and <span class="math">\({\varphi}_6\)</span> are made up of Lagrange polynomials on two
neighboring elements.</p>
<div class="figure" id="fem-approx-fe-fig-p3">
<img alt="_images/mpl_fe_basis_p3_4e1.png" src="_images/mpl_fe_basis_p3_4e1.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></p>
</div>
<span class="target" id="index-22"></span><span class="target" id="index-23"></span><p id="index-24">We see that all the piecewise linear basis functions have the same
&#8220;hat&#8221; shape. They are naturally referred to as <em>hat functions</em>,
also called <em>chapeau functions</em>.
The piecewise quadratic functions in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>
are seen to be of two types. &#8220;Rounded hats&#8221; associated with internal
nodes in the elements and some more &#8220;sombrero&#8221; shaped hats associated
with element boundary nodes. Higher-order basis functions also have
hat-like shapes, but the functions have pronounced oscillations in addition,
as illustrated in Figure <a class="reference internal" href="#fem-approx-fe-fig-p3"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></a>.</p>
<span class="target" id="index-25"></span><span class="target" id="index-26"></span><span class="target" id="index-27"></span><p id="index-28">A common terminology is to speak about <em>linear elements</em> as
elements with two local nodes associated with
piecewise linear basis functions. Similarly, <em>quadratic elements</em> and
<em>cubic elements</em> refer to piecewise quadratic or cubic functions
over elements with three or four local nodes, respectively.
Alternative names, frequently used later, are P1 elements for linear
elements, P2 for quadratic elements, and so forth: P$d$ signifies
degree <span class="math">\(d\)</span> of the polynomial basis functions.</p>
</div>
<div class="section" id="calculating-the-linear-system">
<span id="fem-approx-global-linearsystem"></span><h2>Calculating the linear system<a class="headerlink" href="#calculating-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>The elements in the coefficient matrix and right-hand side are given
by the formulas <a href="#equation-fem:approx:Aij">(17)</a> and <a href="#equation-fem:approx:bi">(18)</a>, but
now the choice of <span class="math">\({\psi}_i\)</span> is <span class="math">\({\varphi}_i\)</span>.
Consider P1 elements where <span class="math">\({\varphi}_i(x)\)</span> piecewise linear. Nodes and elements
numbered consecutively from left to right in a uniformly partitioned
mesh imply the nodes</p>
<div class="math">
\[x_i=i h,\quad i=0,\ldots,N,\]</div>
<p>and the elements</p>
<div class="math">
\[\Omega^{(i)} = [x_{i},x_{i+1}] = [i h, (i+1)h],\quad
i=0,\ldots,N_e=N-1
{\thinspace .}\]</div>
<p>We have in this case <span class="math">\(N\)</span> elements and <span class="math">\(N+1\)</span> nodes,
and <span class="math">\(\Omega=[x_{0},x_{N}]\)</span>.
The formula for <span class="math">\({\varphi}_i(x)\)</span> is given by
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a> and a graphical illustration is
provided in Figures <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a> and
<a class="reference internal" href="#fem-approx-fe-fig-phi-i-im1"><em>Illustration of two neighboring linear (hat) functions with general node numbers</em></a>. First we clearly see
from the figures the very important property
<span class="math">\({\varphi}_i(x){\varphi}_j(x)\neq 0\)</span> if and only if <span class="math">\(j=i-1\)</span>, <span class="math">\(j=i\)</span>, or
<span class="math">\(j=i+1\)</span>, or alternatively expressed, if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are
nodes in the same element. Otherwise, <span class="math">\({\varphi}_i\)</span> and <span class="math">\({\varphi}_j\)</span> are
too distant to have an overlap and consequently their product vanishes.</p>
<div class="figure" id="fem-approx-fe-fig-phi-2-3">
<img alt="_images/fe_mesh1D_phi_2_31.png" src="_images/fe_mesh1D_phi_2_31.png" style="width: 500px;" />
<p class="caption"><em>Illustration of the piecewise linear basis functions corresponding to global node 2 and 3</em></p>
</div>
<div class="section" id="calculating-a-specific-matrix-entry">
<h3>Calculating a specific matrix entry<a class="headerlink" href="#calculating-a-specific-matrix-entry" title="Permalink to this headline">¶</a></h3>
<p>Let us calculate the specific matrix entry <span class="math">\(A_{2,3} = \int_\Omega
{\varphi}_2{\varphi}_3{\, \mathrm{d}x}\)</span>. Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-2-3"><em>Illustration of the piecewise linear basis functions corresponding to global node 2 and 3</em></a>
shows how <span class="math">\({\varphi}_2\)</span> and <span class="math">\({\varphi}_3\)</span> look like. We realize
from this figure that the product <span class="math">\({\varphi}_2{\varphi}_3\neq 0\)</span>
only over element 2, which contains node 2 and 3.
The particular formulas for <span class="math">\({\varphi}_{2}(x)\)</span> and <span class="math">\({\varphi}_3(x)\)</span> on
<span class="math">\([x_{2},x_{3}]\)</span> are found from <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>.
The function
<span class="math">\({\varphi}_3\)</span> has positive slope over <span class="math">\([x_{2},x_{3}]\)</span> and corresponds
to the interval <span class="math">\([x_{i-1},x_{i}]\)</span> in
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>. With <span class="math">\(i=3\)</span> we get</p>
<div class="math">
\[{\varphi}_3(x) = (x-x_2)/h,\]</div>
<p>while <span class="math">\({\varphi}_2(x)\)</span> has negative slope over <span class="math">\([x_{2},x_{3}]\)</span>
and corresponds to setting <span class="math">\(i=2\)</span> in <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>,</p>
<div class="math">
\[{\varphi}_2(x) = 1- (x-x_2)/h{\thinspace .}\]</div>
<p>We can now easily integrate,</p>
<div class="math">
\[A_{2,3} = \int_\Omega {\varphi}_2{\varphi}_{3}{\, \mathrm{d}x} =
\int_{x_{2}}^{x_{3}}
\left(1 - \frac{x - x_{2}}{h}\right) \frac{x - x_{2}}{h}
 {\, \mathrm{d}x} = \frac{h}{6}{\thinspace .}\]</div>
<p>The diagonal entry in the coefficient matrix becomes</p>
<div class="math">
\[A_{2,2} =
\int_{x_{1}}^{x_{2}}
\left(\frac{x - x_{1}}{h}\right)^2{\, \mathrm{d}x} +
\int_{x_{2}}^{x_{3}}
\left(1 - \frac{x - x_{2}}{h}\right)^2{\, \mathrm{d}x}
= \frac{h}{3}{\thinspace .}\]</div>
<p>The entry <span class="math">\(A_{2,1}\)</span> has an
the integral that is geometrically similar to the situation in
Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-2-3"><em>Illustration of the piecewise linear basis functions corresponding to global node 2 and 3</em></a>, so we get
<span class="math">\(A_{2,1}=h/6\)</span>.</p>
</div>
<div class="section" id="calculating-a-general-row-in-the-matrix">
<h3>Calculating a general row in the matrix<a class="headerlink" href="#calculating-a-general-row-in-the-matrix" title="Permalink to this headline">¶</a></h3>
<p>We can now generalize the calculation of matrix entries to
a general row number <span class="math">\(i\)</span>. The entry
<span class="math">\(A_{i,i-1}=\int_\Omega{\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}\)</span> involves
hat functions as depicted in
Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-i-im1"><em>Illustration of two neighboring linear (hat) functions with general node numbers</em></a>. Since the integral
is geometrically identical to the situation with specific nodes
2 and 3, we realize that <span class="math">\(A_{i,i-1}=A_{i,i+1}=h/6\)</span> and
<span class="math">\(A_{i,i}=h/3\)</span>. However, we can compute the integral directly
too:</p>
<div class="math">
\[\begin{split}A_{i,i-1} &amp;= \int_\Omega {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}\\
&amp;=
\underbrace{\int_{x_{i-2}}^{x_{i-1}} {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}}_{{\varphi}_i=0} +
\int_{x_{i}}^{x_{i}} {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x} +
\underbrace{\int_{x_{i}}^{x_{i+1}} {\varphi}_i{\varphi}_{i-1}{\, \mathrm{d}x}}_{{\varphi}_{i-1}=0}\\
&amp;= \int_{x_{i-1}}^{x_{i}}
\underbrace{\frac{x - x_{i}}{h}}_{{\varphi}_i(x)}
\underbrace{\left(1 - \frac{x - x_{i-1}}{h}\right)}_{{\varphi}_{i-1}(x)} {\, \mathrm{d}x} =
\frac{h}{6}
{\thinspace .}\end{split}\]</div>
<p>The particular formulas for <span class="math">\({\varphi}_{i-1}(x)\)</span> and <span class="math">\({\varphi}_i(x)\)</span> on
<span class="math">\([x_{i-1},x_{i}]\)</span> are found from <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>:
<span class="math">\({\varphi}_i\)</span> is the linear function with positive slope, corresponding
to the interval <span class="math">\([x_{i-1},x_{i}]\)</span> in
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>, while <span class="math">\(\phi_{i-1}\)</span> has a
negative slope so the definition in interval
<span class="math">\([x_{i},x_{i+1}]\)</span> in <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a> must be
used. (The appearance of <span class="math">\(i\)</span> in <a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>
and the integral might be confusing, as we speak about two different
<span class="math">\(i\)</span> indices.)</p>
<div class="figure" id="fem-approx-fe-fig-phi-i-im1">
<img alt="_images/fe_mesh1D_phi_i_im11.png" src="_images/fe_mesh1D_phi_i_im11.png" style="width: 500px;" />
<p class="caption"><em>Illustration of two neighboring linear (hat) functions with general node numbers</em></p>
</div>
<p>The first and last row of the coefficient matrix lead to slightly
different integrals:</p>
<div class="math">
\[A_{0,0} = \int_\Omega {\varphi}_0^2{\, \mathrm{d}x} = \int_{x_{0}}^{x_{1}}
\left(1 - \frac{x-x_0}{h}\right)^2{\, \mathrm{d}x} = \frac{h}{3}{\thinspace .}\]</div>
<p>Similarly, <span class="math">\(A_{N,N}\)</span> involves an integral over only one element
and equals hence <span class="math">\(h/3\)</span>.</p>
<div class="figure" id="fem-approx-fe-fig-phi-i-f">
<img alt="_images/fe_mesh1D_phi_i_f1.png" src="_images/fe_mesh1D_phi_i_f1.png" style="width: 500px;" />
<p class="caption"><em>Right-hand side integral with the product of a basis function and the given function to approximate</em></p>
</div>
<p>The general formula for <span class="math">\(b_i\)</span>,
see Figure <a class="reference internal" href="#fem-approx-fe-fig-phi-i-f"><em>Right-hand side integral with the product of a basis function and the given function to approximate</em></a>, is now easy to set up</p>
<div class="math" id="equation-fem:approx:fe:bi:formula1">
<span class="eqno">(26)</span>\[     b_i = \int_\Omega{\varphi}_i(x)f(x){\, \mathrm{d}x}
     = \int_{x_{i-1}}^{x_{i}} \frac{x - x_{i-1}}{h} f(x){\, \mathrm{d}x}
     + \int_{x_{i}}^{x_{i+1}} \left(1 - \frac{x - x_{i}}{h}\right) f(x)
     {\, \mathrm{d}x}{\thinspace .}\]</div>
<p>We need a specific <span class="math">\(f(x)\)</span> function to compute these integrals.
With two equal-sized elements in <span class="math">\(\Omega=[0,1]\)</span> and <span class="math">\(f(x)=x(1-x)\)</span>, one gets</p>
<div class="math">
\[\begin{split}A = \frac{h}{6}\left(\begin{array}{ccc}
2 &amp; 1 &amp; 0\\
1 &amp; 4 &amp; 1\\
0 &amp; 1 &amp; 2
\end{array}\right),\quad
b = \frac{h^2}{12}\left(\begin{array}{c}
2 - 3h\\
12 - 14h\\
10 -17h
\end{array}\right){\thinspace .}\end{split}\]</div>
<p>The solution becomes</p>
<div class="math">
\[c_0 = \frac{h^2}{6},\quad c_1 = h - \frac{5}{6}h^2,\quad
c_2 = 2h - \frac{23}{6}h^2{\thinspace .}\]</div>
<p>The resulting function</p>
<div class="math">
\[u(x)=c_0{\varphi}_0(x) + c_1{\varphi}_1(x) + c_2{\varphi}_2(x)\]</div>
<p>is displayed in Figure <a class="reference internal" href="#fem-approx-fe-fig-ls-p1-2-4"><em>Least squares approximation of a parabola using 2 (left) and 4 (right) P1 elements</em></a> (left).
Doubling the number of elements to four leads to the improved
approximation in the right part of Figure <a class="reference internal" href="#fem-approx-fe-fig-ls-p1-2-4"><em>Least squares approximation of a parabola using 2 (left) and 4 (right) P1 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-fig-ls-p1-2-4">
<img alt="_images/fe_p1_x2_2e_4e1.png" src="_images/fe_p1_x2_2e_4e1.png" style="width: 800px;" />
<p class="caption"><em>Least squares approximation of a parabola using 2 (left) and 4 (right) P1 elements</em></p>
</div>
</div>
</div>
<div class="section" id="assembly-of-elementwise-computations">
<span id="fem-approx-fe-elementwise"></span><h2>Assembly of elementwise computations<a class="headerlink" href="#assembly-of-elementwise-computations" title="Permalink to this headline">¶</a></h2>
<p>The integrals above are naturally split into integrals over individual elements
since the formulas change with the elements. This idea of splitting the
integral is fundamental in all practical implementations of the finite
element method.</p>
<p>Let us split the integral over <span class="math">\(\Omega\)</span> into a sum of contributions from
each element:</p>
<div class="math" id="equation-fem:approx:fe:elementwise:Asplit">
<span class="eqno">(27)</span>\[     A_{i,j} = \int_\Omega{\varphi}_i{\varphi}_j {\, \mathrm{d}x} = \sum_{e} A^{(e)}_{i,j},\quad
     A^{(e)}_{i,j}=\int_{\Omega^{(e)}} {\varphi}_i{\varphi}_j {\, \mathrm{d}x}
     {\thinspace .}\]</div>
<p>Now, <span class="math">\(A^{(e)}_{i,j}\neq 0\)</span> if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in element
<span class="math">\(e\)</span>. Introduce <span class="math">\(i=q(e,r)\)</span> as the mapping of local node number <span class="math">\(r\)</span> in element
<span class="math">\(e\)</span> to the global node number <span class="math">\(i\)</span>. This is just a short mathematical notation
for the expression <tt class="docutils literal"><span class="pre">i=elements[e][r]</span></tt> in a program.
Let <span class="math">\(r\)</span> and <span class="math">\(s\)</span> be the local node numbers corresponding to the global
node numbers <span class="math">\(i=q(e,r)\)</span> and
<span class="math">\(j=q(e,s)\)</span>. With <span class="math">\(d\)</span> nodes per element, all the nonzero elements
in <span class="math">\(A^{(e)}_{i,j}\)</span> arise from the integrals involving basis functions with
indices corresponding to the global node numbers in element number <span class="math">\(e\)</span>:</p>
<div class="math" id="index-29">
\[\int_{\Omega^{(e)}}{\varphi}_{q(e,r)}{\varphi}_{q(e,s)} {\, \mathrm{d}x},
\quad r,s=0,\ldots, d{\thinspace .}\]</div>
<p>These contributions can be collected in a <span class="math">\((d+1)\times (d+1)\)</span> matrix known as
the <em>element matrix</em>. Let <span class="math">\({I_d}=\{0,\ldots,d\}\)</span> be the valid indices
of <span class="math">\(r\)</span> and <span class="math">\(s\)</span>.
We introduce the notation</p>
<div class="math">
\[\tilde A^{(e)} = \{ \tilde A^{(e)}_{r,s}\},\quad
r,s\in{I_d},\]</div>
<p>for the element matrix. For the case <span class="math">\(d=2\)</span> we have</p>
<div class="math">
\[\begin{split}\tilde A^{(e)} = \left\lbrack\begin{array}{lllll}
\tilde A^{(e)}_{0,0} &amp; \tilde A^{(e)}_{0,1} &amp; \tilde A^{(e)}_{0,2}\\
\tilde A^{(e)}_{1,0} &amp; \tilde A^{(e)}_{1,1} &amp; \tilde A^{(e)}_{1,2}\\
\tilde A^{(e)}_{2,0} &amp; \tilde A^{(e)}_{2,1} &amp; \tilde A^{(e)}_{2,2}
\end{array}\right\rbrack
{\thinspace .}\end{split}\]</div>
<p>Given the numbers <span class="math">\(\tilde A^{(e)}_{r,s}\)</span>,
we should according to <a href="#equation-fem:approx:fe:elementwise:Asplit">(27)</a>
add the contributions to the global coefficient matrix by</p>
<div class="math" id="index-30">
\[ A_{q(e,r),q(e,s)} := A_{q(e,r),q(e,s)} + \tilde A^{(e)}_{r,s},\quad
r,s\in{I_d}{\thinspace .}\]</div>
<p>This process of adding in elementwise contributions to the global matrix
is called <em>finite element assembly</em> or simply <em>assembly</em>.
Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly-2x2"><em>Illustration of matrix assembly: regularly numbered P1 elements</em></a> illustrates how element matrices
for elements with two nodes are added into the global matrix.
More specifically, the figure shows how the element matrix associated with
elements 1 and 2 assembled, assuming that global nodes are numbered
from left to right in the domain. With regularly numbered P3 elements, where
the element matrices have size <span class="math">\(4\times 4\)</span>, the assembly of elements 1 and 2
are sketched in Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly-4x4"><em>Illustration of matrix assembly: regularly numbered P3 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-fig-assembly-2x2">
<img alt="_images/fe_assembly_regular_2x21.png" src="_images/fe_assembly_regular_2x21.png" style="width: 700px;" />
<p class="caption"><em>Illustration of matrix assembly: regularly numbered P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-assembly-4x4">
<img alt="_images/fe_assembly_regular_4x41.png" src="_images/fe_assembly_regular_4x41.png" style="width: 700px;" />
<p class="caption"><em>Illustration of matrix assembly: regularly numbered P3 elements</em></p>
</div>
<p>After assembly of element matrices corresponding to regularly numbered elements
and nodes are understood, it is wise to study the assembly process for
irregularly numbered elements and nodes. Figure <a class="reference internal" href="#fem-approx-fe-def-elements-nodes-fig-p1-irregular"><em>Example on irregular numbering of elements and nodes</em></a> shows a mesh where the <tt class="docutils literal"><span class="pre">elements</span></tt> array, or <span class="math">\(q(e,r)\)</span>
mapping in mathematical notation, is given as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>The associated assembly of element matrices 1 and 2 is sketched in
Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly-irr2x2"><em>Illustration of matrix assembly: irregularly numbered P1 elements</em></a>.</p>
<p>These three assembly processes can also be <a class="reference external" href="http://tinyurl.com/k3sdbuv/pub/mov-fem/fe_assembly.html">animated</a>.</p>
<div class="figure" id="fem-approx-fe-fig-assembly-irr2x2">
<img alt="_images/fe_assembly_irregular1.png" src="_images/fe_assembly_irregular1.png" style="width: 700px;" />
<p class="caption"><em>Illustration of matrix assembly: irregularly numbered P1 elements</em></p>
</div>
<p>The right-hand side of the linear system is also computed elementwise:</p>
<div class="math">
\[b_i = \int_\Omega{\varphi}_i{\varphi}_j {\, \mathrm{d}x} = \sum_{e} b^{(e)}_{i},\quad
b^{(e)}_{i}=\int_{\Omega^{(e)}} f(x){\varphi}_i(x){\, \mathrm{d}x}
{\thinspace .}\]</div>
<p>We observe that
<span class="math">\(b_i^{(e)}\neq 0\)</span> if and only if global node <span class="math">\(i\)</span> is a node in element <span class="math">\(e\)</span>.
With <span class="math">\(d\)</span> nodes per element we can collect the <span class="math">\(d+1\)</span> nonzero contributions
<span class="math">\(b_i^{(e)}\)</span>, for <span class="math">\(i=q(e,r)\)</span>, <span class="math">\(r\in{I_d}\)</span>, in an <em>element vector</em></p>
<div class="math">
\[\tilde b_r^{(e)}=\{ \tilde b_r^{(e)}\},\quad r\in{I_d}{\thinspace .}\]</div>
<p>These contributions are added to the
global right-hand side by an assembly process similar to that for the
element matrices:</p>
<div class="math">
\[b_{q(e,r)} := b_{q(e,r)} + \tilde b^{(e)}_{r},\quad
r\in{I_d}{\thinspace .}\]</div>
</div>
<div class="section" id="mapping-to-a-reference-element">
<span id="fem-approx-fe-mapping"></span><h2>Mapping to a reference element<a class="headerlink" href="#mapping-to-a-reference-element" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-31"></span><p id="index-32">Instead of computing the integrals</p>
<div class="math">
\[\tilde A^{(e)}_{r,s} = \int_{\Omega^{(e)}}{\varphi}_{q(e,r)}(x){\varphi}_{q(e,s)}(x){\, \mathrm{d}x}\]</div>
<p>over some element
<span class="math">\(\Omega^{(e)} = [x_L, x_R]\)</span>,
it is convenient to map the element domain <span class="math">\([x_L, x_R]\)</span>
to a standardized reference element domain <span class="math">\([-1,1]\)</span>.
(We have now introduced
<span class="math">\(x_L\)</span> and <span class="math">\(x_R\)</span> as the left and right boundary points of an arbitrary element.
With a natural, regular numbering of nodes and elements from left to right
through the domain, we have <span class="math">\(x_L=x_{e}\)</span> and <span class="math">\(x_R=x_{e+1}\)</span> for P1 elements.)</p>
<p>Let <span class="math">\(X\in [-1,1]\)</span> be the coordinate
in the reference element. A linear or <em>affine mapping</em> from <span class="math">\(X\)</span> to <span class="math">\(x\)</span> reads</p>
<div class="math" id="equation-fem:approx:fe:affine:mapping">
<span class="eqno">(28)</span>\[     x = \frac{1}{2} (x_L + x_R) + \frac{1}{2} (x_R - x_L)X{\thinspace .}\]</div>
<p>This relation can alternatively be expressed by</p>
<div class="math" id="equation-fem:approx:fe:affine:mapping2">
<span class="eqno">(29)</span>\[     x = x_m + \frac{1}{2}hX,\]</div>
<p>where we have introduced the element midpoint <span class="math">\(x_m=(x_L+x_R)/2\)</span> and
the element length <span class="math">\(h=x_R-x_L\)</span>.</p>
<p>Integrating on
the reference element is a matter of just changing the integration
variable from <span class="math">\(x\)</span> to <span class="math">\(X\)</span>. Let</p>
<div class="math">
\[{\tilde{\varphi}}_r(X) = {\varphi}_{q(e,r)}(x(X))\]</div>
<p>be the basis function associated with local node number <span class="math">\(r\)</span> in the
reference element. The integral transformation reads</p>
<div class="math">
\[\tilde A^{(e)}_{r,s} =
\int_{\Omega^{(e)}}{\varphi}_{q(e,r)}(x){\varphi}_{q(e,s)}(x){\, \mathrm{d}x}
= \int_{-1}^1 {\tilde{\varphi}}_r(X){\tilde{\varphi}}_s(X)\frac{dx}{dX}{\, \mathrm{d}X}
{\thinspace .}\]</div>
<p>The stretch factor <span class="math">\(dx/dX\)</span> between the <span class="math">\(x\)</span> and <span class="math">\(X\)</span> coordinates
becomes the determinant of the Jacobian matrix of the mapping
between the coordinate systems in 2D and 3D. To obtain a uniform
notation for 1D, 2D, and 3D problems we therefore replace
<span class="math">\(dx/dX\)</span> by <span class="math">\(\det J\)</span> already now. In 1D, <span class="math">\(\det J = dx/dX = h/2\)</span>.
The integration over the reference element is then written as</p>
<div class="math" id="equation-fem:approx:fe:mapping:Ae">
<span class="eqno">(30)</span>\[     \tilde A^{(e)}_{r,s}
     = \int_{-1}^1 {\tilde{\varphi}}_r(X){\tilde{\varphi}}_s(X)\det J\,dX\]\[     {\thinspace .}\]</div>
<p>The corresponding formula for the element vector entries becomes</p>
<div class="math" id="equation-fem:approx:fe:mapping:be">
<span class="eqno">(31)</span>\[     \tilde b^{(e)}_{r} = \int_{\Omega^{(e)}}f(x){\varphi}_{q(e,r)}(x)dx
     = \int_{-1}^1 f(x(X)){\tilde{\varphi}}_r(X)\det J\,dX\]\[     {\thinspace .}\]</div>
<p>Since we from now on will work in the reference
element, we need explicit mathematical formulas for the basis
functions <span class="math">\({\varphi}_i(x)\)</span> in the reference element only, i.e., we only need
to specify formulas for <span class="math">\({\tilde{\varphi}}_r(X)\)</span>.
This is a very convenient simplification compared to specifying
piecewise polynomials in the physical domain.</p>
<p>The <span class="math">\({\tilde{\varphi}}_r(x)\)</span> functions are simply the Lagrange
polynomials defined through the local nodes in the reference element.
For <span class="math">\(d=1\)</span> and two nodes per element, we have the linear Lagrange
polynomials</p>
<div class="math" id="equation-fem:approx:fe:mapping:P1:phi0">
<span class="eqno">(32)</span>\[     {\tilde{\varphi}}_0(X) = \frac{1}{2} (1 - X)\]</div>
<div class="math" id="equation-fem:approx:fe:mapping:P1:phi1">
<span class="eqno">(33)</span>\[     {\tilde{\varphi}}_1(X) = \frac{1}{2} (1 + X)\]</div>
<p>Quadratic polynomials, <span class="math">\(d=2\)</span>, have the formulas</p>
<div class="math">
\[{\tilde{\varphi}}_0(X) = \frac{1}{2} (X-1)X\]</div>
<div class="math">
\[{\tilde{\varphi}}_1(X) = 1 - X^2\]</div>
<div class="math">
\[{\tilde{\varphi}}_2(X) = \frac{1}{2} (X+1)X\]</div>
<p>In general,</p>
<div class="math">
\[{\tilde{\varphi}}_r(X) = \prod_{s=0,s\neq r}^d \frac{X-X_{(s)}}{X_{(r)}-X_{(s)}},\]</div>
<p>where <span class="math">\(X_{(0)},\ldots,X_{(d)}\)</span> are the coordinates of the local nodes in
the reference element.
These are normally uniformly spaced: <span class="math">\(X_{(r)} = -1 + 2r/d\)</span>,
<span class="math">\(r\in{I_d}\)</span>.</p>
<div class="admonition-why-reference-elements admonition">
<p class="first admonition-title">Why reference elements</p>
<p class="last">The great advantage of using reference elements is that
the formulas for the basis functions, <span class="math">\({\tilde{\varphi}}_r(X)\)</span>, are the
same for all elements and independent of the element geometry
(length and location in the mesh). The geometric information
is &#8220;factored out&#8221; in the simple mapping formula and the associated
<span class="math">\(\det J\)</span> quantity, but this information is (here taken as) the same for
element types. Also, the integration domain is the same for
all elements.</p>
</div>
</div>
<div class="section" id="example-integration-over-a-reference-element">
<span id="fem-approx-fe-intg-ref"></span><h2>Example: Integration over a reference element<a class="headerlink" href="#example-integration-over-a-reference-element" title="Permalink to this headline">¶</a></h2>
<p>To illustrate the concepts from the previous section in a specific
example, we now
consider calculation of the element matrix and vector for a specific choice of
<span class="math">\(d\)</span> and <span class="math">\(f(x)\)</span>. A simple choice is <span class="math">\(d=1\)</span> (P1 elements) and <span class="math">\(f(x)=x(1-x)\)</span>
on <span class="math">\(\Omega =[0,1]\)</span>. We have the general expressions
<a href="#equation-fem:approx:fe:mapping:Ae">(30)</a> and <a href="#equation-fem:approx:fe:mapping:be">(31)</a>
for <span class="math">\(\tilde A^{(e)}_{r,s}\)</span> and <span class="math">\(\tilde b^{(e)}_{r}\)</span>.
Writing these out for the choices <a href="#equation-fem:approx:fe:mapping:P1:phi0">(32)</a>
and <a href="#equation-fem:approx:fe:mapping:P1:phi1">(33)</a>, and using that <span class="math">\(\det J = h/2\)</span>,
we can do the following calculations of the element matrix entries:</p>
<div class="math">
\[\tilde A^{(e)}_{0,0}
= \int_{-1}^1 {\tilde{\varphi}}_0(X){\tilde{\varphi}}_0(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:Ae00">
<span class="eqno">(34)</span>\[     =\int_{-1}^1 \frac{1}{2}(1-X)\frac{1}{2}(1-X) \frac{h}{2} dX =
     \frac{h}{8}\int_{-1}^1 (1-X)^2 dX = \frac{h}{3},\]</div>
<div class="math">
\[\tilde A^{(e)}_{1,0}
= \int_{-1}^1 {\tilde{\varphi}}_1(X){\tilde{\varphi}}_0(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math">
\[=\int_{-1}^1 \frac{1}{2}(1+X)\frac{1}{2}(1-X) \frac{h}{2} dX =
\frac{h}{8}\int_{-1}^1 (1-X^2) dX = \frac{h}{6},\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:Ae10">
<span class="eqno">(35)</span>\[     \tilde A^{(e)}_{0,1} = \tilde A^{(e)}_{1,0},\]</div>
<div class="math">
\[\tilde A^{(e)}_{1,1}
= \int_{-1}^1 {\tilde{\varphi}}_1(X){\tilde{\varphi}}_1(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:Ae11">
<span class="eqno">(36)</span>\[     =\int_{-1}^1 \frac{1}{2}(1+X)\frac{1}{2}(1+X) \frac{h}{2} dX =
     \frac{h}{8}\int_{-1}^1 (1+X)^2 dX = \frac{h}{3}\]\[     {\thinspace .}\]</div>
<p>The corresponding entries in the element vector becomes</p>
<div class="math">
\[\tilde b^{(e)}_{0}
= \int_{-1}^1 f(x(X)){\tilde{\varphi}}_0(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math">
\[= \int_{-1}^1 (x_m + \frac{1}{2} hX)(1-(x_m + \frac{1}{2} hX))
\frac{1}{2}(1-X)\frac{h}{2} dX \nonumber\]</div>
<div class="math" id="equation-fem:approx:fe:intg:ref:be0">
<span class="eqno">(37)</span>\[     = - \frac{1}{24} h^{3} + \frac{1}{6} h^{2} x_{m} - \frac{1}{12} h^{2} - \frac{1}{2} h x_{m}^{2} + \frac{1}{2} h x_{m}\]</div>
<div class="math">
\[\tilde b^{(e)}_{1}
= \int_{-1}^1 f(x(X)){\tilde{\varphi}}_1(X)\frac{h}{2} dX\nonumber\]</div>
<div class="math">
\[= \int_{-1}^1 (x_m + \frac{1}{2} hX)(1-(x_m + \frac{1}{2} hX))
\frac{1}{2}(1+X)\frac{h}{2} dX \nonumber\]</div>
<div class="math">
\[= - \frac{1}{24} h^{3} - \frac{1}{6} h^{2} x_{m} + \frac{1}{12} h^{2} -
\frac{1}{2} h x_{m}^{2} + \frac{1}{2} h x_{m}
{\thinspace .}\]</div>
<p>In the last two expressions we have used the element midpoint <span class="math">\(x_m\)</span>.</p>
<p>Integration of lower-degree polynomials above is tedious,
and higher-degree polynomials involve very much more algebra, but <tt class="docutils literal"><span class="pre">sympy</span></tt>
may help. For example, we can easily calculate
<a href="#equation-fem:approx:fe:intg:ref:Ae00">(34)</a>,
<a href="#equation-fem:approx:fe:intg:ref:Ae00">(34)</a>, and
<a href="#equation-fem:approx:fe:intg:ref:be0">(37)</a> by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">x_m</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;x x_m h X&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">8</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">h/3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">8</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">h/6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x_m</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_0</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">b_0</span>
<span class="go">-h**3/24 + h**2*x_m/6 - h**2/12 - h*x_m**2/2 + h*x_m/2</span>
</pre></div>
</div>
<p>For inclusion of formulas in documents (like the present one), <tt class="docutils literal"><span class="pre">sympy</span></tt> can print
expressions in LaTeX format:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">latex</span><span class="p">(</span><span class="n">b_0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;plain&#39;</span><span class="p">)</span>
<span class="go">- \frac{1}{24} h^{3} + \frac{1}{6} h^{2} x_{m}</span>
<span class="go">- \frac{1}{12} h^{2} - \frac{1}{2} h x_{m}^{2}</span>
<span class="go">+ \frac{1}{2} h x_{m}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="implementation-1">
<span id="fem-approx-fe-impl"></span><h1>Implementation  (1)<a class="headerlink" href="#implementation-1" title="Permalink to this headline">¶</a></h1>
<p>Based on the experience from the previous example, it makes
sense to write some code to automate the analytical integration process
for any choice of finite element basis functions. In addition,
we can automate the assembly process and linear system
solution. Appropriate
functions for this purpose document all details of all
steps in the finite element computations and can found in the module file
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx1D.py">fe_approx1D.py</a>.
The key steps in the computational machinery are now explained in
detail in terms of code and text.</p>
<div class="section" id="integration">
<span id="fem-approx-fe-impl-intg"></span><h2>Integration<a class="headerlink" href="#integration" title="Permalink to this headline">¶</a></h2>
<p>First we need a Python function for
defining <span class="math">\({\tilde{\varphi}}_r(X)\)</span> in terms of a Lagrange polynomial
of degree <tt class="docutils literal"><span class="pre">d</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">phi_r</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>  <span class="c"># node spacing</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c"># assume X is numeric: use floats for nodes</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>Observe how we construct the <tt class="docutils literal"><span class="pre">phi_r</span></tt> function to be
a symbolic expression for <span class="math">\({\tilde{\varphi}}_r(X)\)</span> if <tt class="docutils literal"><span class="pre">X</span></tt> is a
<tt class="docutils literal"><span class="pre">Symbol</span></tt> object from <tt class="docutils literal"><span class="pre">sympy</span></tt>. Otherwise, we assume that <tt class="docutils literal"><span class="pre">X</span></tt>
is a <tt class="docutils literal"><span class="pre">float</span></tt> object and compute the corresponding
floating-point value of <span class="math">\({\tilde{\varphi}}_r(X)\)</span>. Recall that the
<tt class="docutils literal"><span class="pre">Lagrange_polynomial</span></tt> function, here simply copied
from the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>,
works with both symbolic and
numeric variables.</p>
<p>The complete basis <span class="math">\({\tilde{\varphi}}_0(X),\ldots,{\tilde{\varphi}}_d(X)\)</span>
on the reference element, represented as a list of
symbolic expressions, is constructed by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">phi_r</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">phi</span>
</pre></div>
</div>
<p>Now we are in a position to write the function for computing
the element matrix:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
    <span class="n">A_e</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;h&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>  <span class="c"># dx/dX</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">s</span><span class="p">,</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">A_e</span>
</pre></div>
</div>
<p>In the symbolic case (<tt class="docutils literal"><span class="pre">symbolic</span></tt> is <tt class="docutils literal"><span class="pre">True</span></tt>),
we introduce the element length as a symbol
<tt class="docutils literal"><span class="pre">h</span></tt> in the computations. Otherwise, the real numerical value
of the element interval <tt class="docutils literal"><span class="pre">Omega_e</span></tt>
is used and the final matrix elements are numbers,
not symbols.
This functionality can be demonstrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fe_approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span>
<span class="go">[1/2 - X/2, 1/2 + X/2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="go">[h/3, h/6]</span>
<span class="go">[h/6, h/3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="go">[0.0333333333333333, 0.0166666666666667]</span>
<span class="go">[0.0166666666666667, 0.0333333333333333]</span>
</pre></div>
</div>
<p>The computation of the element vector is done by a similar
procedure:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
    <span class="n">b_e</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c"># Make f a function of X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;h&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span>  <span class="c"># mapping</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="c"># substitute mapping formula for x</span>
    <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>  <span class="c"># dx/dX</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">b_e</span>
</pre></div>
</div>
<p>Here we need to replace the symbol <tt class="docutils literal"><span class="pre">x</span></tt> in the expression for <tt class="docutils literal"><span class="pre">f</span></tt>
by the mapping formula such that <tt class="docutils literal"><span class="pre">f</span></tt> can be integrated
in terms of <span class="math">\(X\)</span>, cf. the formula
<span class="math">\(\tilde b^{(e)}_{r} = \int_{-1}^1 f(x(X)){\tilde{\varphi}}_r(X)\frac{h}{2}dX\)</span>.</p>
<p>The integration in the element matrix function involves only products
of polynomials, which <tt class="docutils literal"><span class="pre">sympy</span></tt> can easily deal with, but for the
right-hand side <tt class="docutils literal"><span class="pre">sympy</span></tt> may face difficulties with certain types of
expressions <tt class="docutils literal"><span class="pre">f</span></tt>. The result of the integral is then an <tt class="docutils literal"><span class="pre">Integral</span></tt>
object and not a number or expression
as when symbolic integration is successful.
It may therefore be wise to introduce a fallback on numerical
integration. The symbolic integration can also take much time
before an unsuccessful conclusion so we may also introduce a parameter
<tt class="docutils literal"><span class="pre">symbolic</span></tt> and set it to <tt class="docutils literal"><span class="pre">False</span></tt> to avoid symbolic integration:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># Ensure h is numerical</span>
            <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">X</span><span class="p">],</span> <span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Numerical integration requires that the symbolic
integrand is converted
to a plain Python function (<tt class="docutils literal"><span class="pre">integrand</span></tt>) and that
the element length <tt class="docutils literal"><span class="pre">h</span></tt> is a real number.</p>
</div>
<div class="section" id="linear-system-assembly-and-solution">
<span id="fem-approx-fe-impl-linsys"></span><h2>Linear system assembly and solution<a class="headerlink" href="#linear-system-assembly-and-solution" title="Permalink to this headline">¶</a></h2>
<p>The complete algorithm
for computing and assembling the elementwise contributions
takes the following form</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">N_n</span><span class="p">,</span> <span class="n">N_e</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_n</span><span class="p">,</span> <span class="n">N_n</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>    <span class="c"># note: (N_n, 1) matrix</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_n</span><span class="p">,</span> <span class="n">N_n</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_e</span><span class="p">):</span>
        <span class="n">Omega_e</span> <span class="o">=</span> <span class="p">[</span><span class="n">nodes</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="n">nodes</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]]]</span>

        <span class="n">A_e</span> <span class="o">=</span> <span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="p">)</span>
        <span class="n">b_e</span> <span class="o">=</span> <span class="n">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">])):</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">])):</span>
                <span class="n">A</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
            <span class="n">b</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> variables represent the finite
element mesh as explained earlier.</p>
<p>Given the coefficient matrix <tt class="docutils literal"><span class="pre">A</span></tt> and the right-hand side <tt class="docutils literal"><span class="pre">b</span></tt>,
we can compute the coefficients <span class="math">\(\left\{ {c}_i \right\}_{i\inI}\)</span> in the expansion
<span class="math">\(u(x)=\sum_jc_j{\varphi}_j\)</span> as the solution vector <tt class="docutils literal"><span class="pre">c</span></tt> of the linear
system:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>When <tt class="docutils literal"><span class="pre">A</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are <tt class="docutils literal"><span class="pre">sympy</span></tt> arrays,
the solution procedure implied by <tt class="docutils literal"><span class="pre">A.LUsolve</span></tt> is symbolic.
Otherwise, <tt class="docutils literal"><span class="pre">A</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are <tt class="docutils literal"><span class="pre">numpy</span></tt> arrays and a standard
numerical solver is called.
The symbolic version is suited for small problems only
(small <span class="math">\(N\)</span> values) since the calculation time becomes prohibitively large
otherwise. Normally, the symbolic <em>integration</em> will be more time
consuming in small problems than the symbolic <em>solution</em> of the linear system.</p>
</div>
<div class="section" id="example-on-computing-symbolic-approximations">
<span id="fem-approx-fe-impl-ex1-symbolic"></span><h2>Example on computing symbolic approximations<a class="headerlink" href="#example-on-computing-symbolic-approximations" title="Permalink to this headline">¶</a></h2>
<p>We can exemplify the use of <tt class="docutils literal"><span class="pre">assemble</span></tt> on the computational
case from the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> with
two P1 elements (linear basis functions) on the domain <span class="math">\(\Omega=[0,1]\)</span>.
Let us first work with a symbolic element length:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;h x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[h/3,   h/6,   0]</span>
<span class="go">[h/6, 2*h/3, h/6]</span>
<span class="go">[  0,   h/6, h/3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[     h**2/6 - h**3/12]</span>
<span class="go">[      h**2 - 7*h**3/6]</span>
<span class="go">[5*h**2/6 - 17*h**3/12]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[                           h**2/6]</span>
<span class="go">[12*(7*h**2/12 - 35*h**3/72)/(7*h)]</span>
<span class="go">[  7*(4*h**2/7 - 23*h**3/21)/(2*h)]</span>
</pre></div>
</div>
</div>
<div class="section" id="comparison-with-finite-elements-and-interpolation-collocation">
<span id="fem-approx-fe-impl-ex1-collocation"></span><h2>Comparison with finite elements and interpolation/collocation<a class="headerlink" href="#comparison-with-finite-elements-and-interpolation-collocation" title="Permalink to this headline">¶</a></h2>
<p>We may, for comparison, compute the <tt class="docutils literal"><span class="pre">c</span></tt> vector corresponding to
an interpolation/collocation method with finite element basis functions.
Choosing the nodes as points, the principle is</p>
<div class="math">
\[u(x_{i}) = \sum_{j\inI} c_j{\varphi}_j(x_{i}) = f(x_{i}),\quad
i\inI{\thinspace .}\]</div>
<p>The coefficient matrix <span class="math">\(A_{i,j}={\varphi}_j(x_{i})\)</span> becomes
the identity matrix because basis function number <span class="math">\(j\)</span> vanishes
at all nodes, except node <span class="math">\(j\)</span>: <span class="math">\({\varphi}_j(x_{i}=\delta_{ij}\)</span>.
Therefore, <span class="math">\(c_i = f(x_{i}\)</span>.</p>
<p>The associated <tt class="docutils literal"><span class="pre">sympy</span></tt> calculations are</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">fn</span><span class="p">(</span><span class="n">xc</span><span class="p">)</span> <span class="k">for</span> <span class="n">xc</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[0, h*(1 - h), 2*h*(1 - 2*h)]</span>
</pre></div>
</div>
<p>These expressions are much simpler than those based on least squares
or projection in combination with finite element basis functions.</p>
</div>
<div class="section" id="example-on-computing-numerical-approximations">
<span id="fem-approx-fe-impl-ex1-numeric"></span><h2>Example on computing numerical approximations<a class="headerlink" href="#example-on-computing-numerical-approximations" title="Permalink to this headline">¶</a></h2>
<p>The numerical computations corresponding to the
symbolic ones in the section <a class="reference internal" href="#fem-approx-fe-impl-ex1-symbolic"><em>Example on computing symbolic approximations</em></a>,
and still done by <tt class="docutils literal"><span class="pre">sympy</span></tt> and the <tt class="docutils literal"><span class="pre">assemble</span></tt> function, go as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[ 0.166666666666667, 0.0833333333333333,                  0]</span>
<span class="go">[0.0833333333333333,  0.333333333333333, 0.0833333333333333]</span>
<span class="go">[                 0, 0.0833333333333333,  0.166666666666667]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[          0.03125]</span>
<span class="go">[0.104166666666667]</span>
<span class="go">[          0.03125]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[0.0416666666666666]</span>
<span class="go">[ 0.291666666666667]</span>
<span class="go">[0.0416666666666666]</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">fe_approx1D</span></tt> module contains functions for generating the
<tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists for equal-sized elements with
any number of nodes per element. The coordinates in <tt class="docutils literal"><span class="pre">nodes</span></tt>
can be expressed either through the element length symbol <tt class="docutils literal"><span class="pre">h</span></tt>
(<tt class="docutils literal"><span class="pre">symbolic=True</span></tt>) or by real numbers (<tt class="docutils literal"><span class="pre">symbolic=False</span></tt>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span> <span class="o">=</span> <span class="n">mesh_uniform</span><span class="p">(</span><span class="n">N_e</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
                               <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>There is also a function</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">approximate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&#39;tmp.pdf&#39;</span><span class="p">):</span>
</pre></div>
</div>
<p>which computes a mesh with <tt class="docutils literal"><span class="pre">N_e</span></tt> elements, basis functions of
degree <tt class="docutils literal"><span class="pre">d</span></tt>, and approximates a given symbolic expression
<tt class="docutils literal"><span class="pre">f</span></tt> by a finite element expansion <span class="math">\(u(x) = \sum_jc_j{\varphi}_j(x)\)</span>.
When <tt class="docutils literal"><span class="pre">symbolic</span></tt> is <tt class="docutils literal"><span class="pre">False</span></tt>, <span class="math">\(u(x) = \sum_jc_j{\varphi}_j(x)\)</span>
can be computed at a (large)
number of points and plotted together with <span class="math">\(f(x)\)</span>. The construction
of <span class="math">\(u\)</span> points from the solution vector <tt class="docutils literal"><span class="pre">c</span></tt> is done
elementwise by evaluating <span class="math">\(\sum_rc_r{\tilde{\varphi}}_r(X)\)</span> at a (large)
number of points in each element in the local coordinate system,
and the discrete <span class="math">\((x,u)\)</span> values on
each element are stored in separate arrays that are finally
concatenated to form a global array for <span class="math">\(x\)</span> and for <span class="math">\(u\)</span>.
The details are found in the <tt class="docutils literal"><span class="pre">u_glob</span></tt> function in
<tt class="docutils literal"><span class="pre">fe_approx1D.py</span></tt>.</p>
</div>
<div class="section" id="the-structure-of-the-coefficient-matrix">
<span id="fem-approx-fe-a-structure"></span><h2>The structure of the coefficient matrix<a class="headerlink" href="#the-structure-of-the-coefficient-matrix" title="Permalink to this headline">¶</a></h2>
<p>Let us first see how the global matrix looks like if we assemble
symbolic element matrices, expressed in terms of <tt class="docutils literal"><span class="pre">h</span></tt>, from
several elements:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">8</span><span class="p">;</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>  <span class="c"># 8 linear elements on [0,1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span> <span class="o">=</span> <span class="n">mesh_symbolic</span><span class="p">(</span><span class="n">N_e</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[h/3,   h/6,     0,     0,     0,     0,     0,     0,   0]</span>
<span class="go">[h/6, 2*h/3,   h/6,     0,     0,     0,     0,     0,   0]</span>
<span class="go">[  0,   h/6, 2*h/3,   h/6,     0,     0,     0,     0,   0]</span>
<span class="go">[  0,     0,   h/6, 2*h/3,   h/6,     0,     0,     0,   0]</span>
<span class="go">[  0,     0,     0,   h/6, 2*h/3,   h/6,     0,     0,   0]</span>
<span class="go">[  0,     0,     0,     0,   h/6, 2*h/3,   h/6,     0,   0]</span>
<span class="go">[  0,     0,     0,     0,     0,   h/6, 2*h/3,   h/6,   0]</span>
<span class="go">[  0,     0,     0,     0,     0,     0,   h/6, 2*h/3, h/6]</span>
<span class="go">[  0,     0,     0,     0,     0,     0,     0,   h/6, h/3]</span>
</pre></div>
</div>
<p>The reader is encouraged to assemble the element matrices by hand and verify
this result, as this exercise will give a hands-on understanding of
what the assembly is about. In general we have a coefficient matrix that is
tridiagonal:</p>
<div class="math">
\[\begin{split}A = \frac{h}{6}
\left(
\begin{array}{cccccccccc}
2 &amp; 1 &amp; 0
&amp;\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; 0 \\
1 &amp; 4 &amp; 1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
0 &amp; 1 &amp; 4 &amp; 1 &amp;
\ddots &amp; &amp;  &amp;  &amp; \vdots \\
\vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
\vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; &amp;  &amp; 0 &amp; 1 &amp; 4 &amp; 1 &amp; \ddots &amp; \vdots \\
\vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
\vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; 1  &amp; 4  &amp; 1 \\
0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 1 &amp; 2
\end{array}
\right)\end{split}\]</div>
<p>The structure of the right-hand side is more difficult to reveal since
it involves an assembly of elementwise integrals of
<span class="math">\(f(x(X)){\tilde{\varphi}}_r(X)h/2\)</span>, which obviously depend on the
particular choice of <span class="math">\(f(x)\)</span>.
Numerical integration can give some insight into the nature of
the right-hand side. For this purpose it
is easier to look at the integration in <span class="math">\(x\)</span> coordinates, which
gives the general formula <a href="#equation-fem:approx:fe:bi:formula1">(26)</a>.
For equal-sized elements of length <span class="math">\(h\)</span>, we can apply the
Trapezoidal rule at the global node points to arrive at</p>
<div class="math">
\[b_i = h\left( \frac{1}{2} {\varphi}_i(x_{0})f(x_{0}) +
\frac{1}{2} {\varphi}_i(x_{N})f(x_{N}) + \sum_{j=1}^{N-1}
{\varphi}_i(x_{j})f(x_{j})\right)\]</div>
<div class="math">
\[ =
\left\lbrace\begin{array}{ll}
\frac{1}{2} hf(x_i), i=0\hbox{ or }i=N,\]</div>
<div class="math">
\[h f(x_i),  1 \leq i \leq N-1
\end{array}\right.\]</div>
<p>The reason for this simple formula is simply that <span class="math">\({\varphi}_i\)</span> is either
0 or 1 at the nodes and 0 at all but one of them.</p>
<p>Going to P2 elements (<tt class="docutils literal"><span class="pre">d=2</span></tt>) leads
to the element matrix</p>
<div class="math">
\[\begin{split}A^{(e)} = \frac{h}{30}
\left(\begin{array}{ccc}
4 &amp; 2 &amp; -1\\
2 &amp; 16 &amp; 2\\
-1 &amp; 2 &amp; 4
\end{array}\right)\end{split}\]</div>
<p>and the following global assembled matrix from four elements:</p>
<div class="math">
\[\begin{split}A = \frac{h}{30}
\left(
\begin{array}{ccccccccc}
4 &amp; 2 &amp; - 1 &amp; 0
  &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
  2 &amp; 16 &amp; 2
  &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\- 1 &amp; 2 &amp;
  8 &amp; 2 &amp; - 1 &amp; 0 &amp; 0 &amp; 0 &amp;
  0\\0 &amp; 0 &amp; 2 &amp; 16 &amp; 2 &amp; 0 &amp; 0
  &amp; 0 &amp; 0\\0 &amp; 0 &amp; - 1 &amp; 2 &amp; 8
  &amp; 2 &amp; - 1 &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 0 &amp;
  2 &amp; 16 &amp; 2 &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0
  &amp; 0 &amp; - 1 &amp; 2 &amp; 8 &amp;
  2 &amp; - 1\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;
  2 &amp; 16 &amp; 2\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
  &amp; 0 &amp; - 1 &amp; 2 &amp; 4
\end{array}
\right)\end{split}\]</div>
<p>In general, for <span class="math">\(i\)</span> odd we have the nonzeroes</p>
<div class="math">
\[A_{i,i-2} = -1,\quad A_{i-1,i}=2,\quad A_{i,i} = 8,\quad A_{i+1,i}=2,
\quad A_{i+2,i}=-1,\]</div>
<p>multiplied by <span class="math">\(h/30\)</span>, and for <span class="math">\(i\)</span> even we have the nonzeros</p>
<div class="math">
\[A_{i-1,i}=2,\quad A_{i,i} = 16,\quad A_{i+1,i}=2,\]</div>
<p>multiplied by <span class="math">\(h/30\)</span>. The rows with odd numbers correspond to
nodes at the element boundaries and get contributions from two
neighboring elements in the assembly process,
while the even numbered rows correspond to
internal nodes in the elements where the only one element contributes
to the values in the global matrix.</p>
</div>
<div class="section" id="applications">
<span id="fem-approx-fe-impl-ex2"></span><h2>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<p>With the aid of the <tt class="docutils literal"><span class="pre">approximate</span></tt> function in the <tt class="docutils literal"><span class="pre">fe_approx1D</span></tt>
module we can easily investigate the quality of various finite element
approximations to some given functions. Figure <a class="reference internal" href="#fem-approx-fe-x9-sin"><em>Comparison of the finite element approximations: 4 P1 elements with 5 nodes (upper left), 2 P2 elements with 5 nodes (upper right), 8 P1 elements with 9 nodes (lower left), and 4 P2 elements with 9 nodes (lower right)</em></a>
shows how linear and quadratic elements approximates the polynomial
<span class="math">\(f(x)=x(1-x)^8\)</span> on <span class="math">\(\Omega =[0,1]\)</span>, using equal-sized elements.
The results arise from the program</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">fe_approx1D</span> <span class="kn">import</span> <span class="n">approximate</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>

<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>The quadratic functions are seen to be better than the linear ones for the same
value of <span class="math">\(N\)</span>, as we increase <span class="math">\(N\)</span>. This observation has some generality:
higher degree is not necessarily better on a coarse mesh, but it is as
we refined the mesh.</p>
<div class="figure" id="fem-approx-fe-x9-sin">
<img alt="_images/fe_p1_p2_x9_248e1.png" src="_images/fe_p1_p2_x9_248e1.png" style="width: 800px;" />
<p class="caption"><em>Comparison of the finite element approximations: 4 P1 elements with 5 nodes (upper left), 2 P2 elements with 5 nodes (upper right), 8 P1 elements with 9 nodes (lower left), and 4 P2 elements with 9 nodes (lower right)</em></p>
</div>
</div>
<div class="section" id="sparse-matrix-storage-and-solution">
<span id="fem-approx-fe-impl-sparse"></span><h2>Sparse matrix storage and solution<a class="headerlink" href="#sparse-matrix-storage-and-solution" title="Permalink to this headline">¶</a></h2>
<p id="index-33">Some of the examples in the preceding section took several minutes to
compute, even on small meshes consisting of up to eight elements.
The main explanation for slow computations is unsuccessful
symbolic integration: <tt class="docutils literal"><span class="pre">sympy</span></tt> may use a lot of energy on
integrals like <span class="math">\(\int f(x(X)){\tilde{\varphi}}_r(X)h/2 dx\)</span> before
giving up, and the program then resorts to numerical integration.
Codes that can deal with a large number of basis functions and
accept flexible choices of <span class="math">\(f(x)\)</span> should compute all integrals
numerically and replace the matrix objects from <tt class="docutils literal"><span class="pre">sympy</span></tt> by
the far more efficient array objects from <tt class="docutils literal"><span class="pre">numpy</span></tt>.</p>
<p>Another reason for slow code is related to the fact that most of the
matrix entries <span class="math">\(A_{i,j}\)</span> are zero, because <span class="math">\(({\varphi}_i,{\varphi}_j)=0\)</span>
unless <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in the same element.  A matrix whose
majority of entries are zeros, is known as a <em>sparse</em> matrix.  The
sparsity should be utilized in software as it dramatically decreases
the storage demands and the CPU-time needed to compute the solution of
the linear system. This optimization is not critical in 1D problems
where modern computers can afford computing with all the zeros in the
complete square matrix, but in 2D and especially in 3D, sparse
matrices are fundamental for feasible finite element computations.</p>
<p>In 1D problems, using a
numbering of nodes and elements from left to right over the domain,
the assembled coefficient matrix has only a few diagonals different
from zero. More precisely, <span class="math">\(2d+1\)</span> diagonals are different from
zero. With a different numbering of global nodes, say a random
ordering, the diagonal structure is lost, but the number of
nonzero elements is unaltered. Figures <a class="reference internal" href="#fem-approx-fe-sparsity-p1"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P1 elements</em></a>
and <a class="reference internal" href="#fem-approx-fe-sparsity-p3"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P3 elements</em></a> exemplify sparsity patterns.</p>
<div class="figure" id="fem-approx-fe-sparsity-p1">
<img alt="_images/sparsity_pattern_1D_301.png" src="_images/sparsity_pattern_1D_301.png" style="width: 800px;" />
<p class="caption"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-sparsity-p3">
<img alt="_images/sparsity_pattern_1DP3_301.png" src="_images/sparsity_pattern_1DP3_301.png" style="width: 800px;" />
<p class="caption"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P3 elements</em></p>
</div>
<p>The <tt class="docutils literal"><span class="pre">scipy.sparse</span></tt> library supports creation of sparse matrices
and linear system solution.</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">scipy.sparse.diags</span></tt> for matrix defined via diagonals</li>
<li><tt class="docutils literal"><span class="pre">scipy.sparse.lil_matrix</span></tt> for creation via setting matrix entries</li>
<li><tt class="docutils literal"><span class="pre">scipy.sparse.dok_matrix</span></tt> for creation via setting matrix entries</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="comparison-of-finite-element-and-finite-difference-approximation">
<span id="fem-approx-fe-fd"></span><h1>Comparison of finite element and finite difference approximation<a class="headerlink" href="#comparison-of-finite-element-and-finite-difference-approximation" title="Permalink to this headline">¶</a></h1>
<p>The previous sections on approximating <span class="math">\(f\)</span> by a finite element function <span class="math">\(u\)</span>
utilize the projection/Galerkin or
least squares approaches to minimize the approximation
error. We may, alternatively, use the collocation/interpolation method
as described in the section <a class="reference internal" href="#fem-approx-fe-impl-ex1-collocation"><em>Comparison with finite elements and interpolation/collocation</em></a>.
Here we shall compare these three approaches with what one does in
the finite difference method when representing a given function on a mesh.</p>
<div class="section" id="finite-difference-approximation-of-given-functions">
<span id="fem-approx-fe-fd-fdproj"></span><h2>Finite difference approximation of given functions<a class="headerlink" href="#finite-difference-approximation-of-given-functions" title="Permalink to this headline">¶</a></h2>
<p>Approximating a given function <span class="math">\(f(x)\)</span> on a mesh in a finite difference
context will typically just sample <span class="math">\(f\)</span> at the mesh points. If <span class="math">\(u_i\)</span>
is the value of the approximate <span class="math">\(u\)</span> at the mesh point <span class="math">\(x_{i}\)</span>, we have
<span class="math">\(u_i = f(x_{i})\)</span>.
The collocation/interpolation method using finite element basis
functions gives exactly the same representation,
as shown the section <a class="reference internal" href="#fem-approx-fe-impl-ex1-collocation"><em>Comparison with finite elements and interpolation/collocation</em></a>,</p>
<div class="math">
\[u(x_{i}) = c_i = f(x_{i}){\thinspace .}\]</div>
<p>How does a finite element Galerkin or least squares approximation differ
from this straightforward interpolation of <span class="math">\(f\)</span>? This is the question
to be addressed next.
We now limit the scope to P1 elements since this is the element type
that gives formulas closest to those arising in the finite difference
method.</p>
</div>
<div class="section" id="finite-difference-interpretation-of-a-finite-element-approximation">
<span id="fem-approx-fe-fd-feproj"></span><h2>Finite difference interpretation of a finite element approximation<a class="headerlink" href="#finite-difference-interpretation-of-a-finite-element-approximation" title="Permalink to this headline">¶</a></h2>
<p>The linear system arising from a Galerkin or least squares approximation
reads in general</p>
<div class="math">
\[\sum_{j\inI} c_j ({\psi}_i,{\psi}_j) = (f,{\psi}_i),\quad i\inI{\thinspace .}\]</div>
<p>In the finite element approximation we choose <span class="math">\({\psi}_i ={\varphi}_i\)</span>.
With <span class="math">\({\varphi}_i\)</span> corresponding to P1 elements and a uniform mesh of
element length <span class="math">\(h\)</span> we have in the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> calculated the matrix with entries
<span class="math">\(({\varphi}_i,{\varphi}_j)\)</span>.  Equation number <span class="math">\(i\)</span> reads</p>
<div class="math" id="equation-fem:deq:1D:approx:deq:massmat:diffeq2">
<span class="eqno">(38)</span>\[     \frac{h}{6}(u_{i-1} + 4u_i + u_{i+1}) = (f,{\varphi}_i)
     {\thinspace .}\]</div>
<p>The first and last equation, corresponding to <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span> are slightly
different, see the section <a class="reference internal" href="#fem-approx-fe-a-structure"><em>The structure of the coefficient matrix</em></a>.</p>
<p>The finite difference counterpart to
<a href="#equation-fem:deq:1D:approx:deq:massmat:diffeq2">(38)</a> is just <span class="math">\(u_i=f_i\)</span>
as explained in the section <a class="reference internal" href="#fem-approx-fe-fd-fdproj"><em>Finite difference approximation of given functions</em></a>.
To easier compare this result to
the finite element approach to approximating functions, we can rewrite
the left-hand side of <a href="#equation-fem:deq:1D:approx:deq:massmat:diffeq2">(38)</a>
as</p>
<div class="math">
\[h(u_i + \frac{1}{6}(u_{i-1} - 2u_i + u_{i+1}))
{\thinspace .}\]</div>
<p>Thinking in terms of finite differences, we can write this expression
using finite difference operator notation:</p>
<div class="math">
\[[h(u + \frac{h^2}{6}D_x D_x u)]_i,\]</div>
<p>which is nothing but the standard discretization of</p>
<div class="math">
\[h(u + \frac{h^2}{6}u''){\thinspace .}\]</div>
<p>Before interpreting the approximation procedure as solving a
differential equation, we need to work out what the right-hand side is
in the context of P1 elements.
Since <span class="math">\({\varphi}_i\)</span> is the linear function that is 1 at
<span class="math">\(x_{i}\)</span> and zero at all other nodes, only the interval <span class="math">\([x_{i-1},x_{i+1}]\)</span>
contribute to the integral on the right-hand side. This integral is
naturally split into two parts according to
<a href="#equation-fem:approx:fe:phi:1:formula2">(25)</a>:</p>
<div class="math">
\[(f,{\varphi}_i) = \int_{x_{i-1}}^{x_{i}} f(x)\frac{1}{h} (x - x_{i-1}) dx
+ \int_{x_{i}}^{x_{i+1}} f(x)\frac{1}{h}(1 - (x - x_{i})) dx
{\thinspace .}\]</div>
<p>However, if <span class="math">\(f\)</span> is not known we cannot do much else with this expression.
It is clear that many values of
<span class="math">\(f\)</span> around <span class="math">\(x_{i}\)</span> contributes to the right-hand side, not just
the single point value <span class="math">\(f(x_{i})\)</span>
as in the finite difference method.</p>
<p>To proceed with the right-hand side, we can
turn to numerical integration schemes.
The Trapezoidal method for <span class="math">\((f,{\varphi}_i)\)</span>, based on
sampling the integrand <span class="math">\(f{\varphi}_i\)</span> at the node points <span class="math">\(x_{i}=i h\)</span>
gives</p>
<div class="math">
\[(f,{\varphi}_i) = \int_\Omega f{\varphi}_i dx\approx h\frac{1}{2}(
f(x_{0}){\varphi}_i(x_{0}) + f(x_{N}){\varphi}_i(x_{N}))
+ h\sum_{j=1}^{N-1} f(x_{j}){\varphi}_i(x_{j})
{\thinspace .}\]</div>
<p>Since <span class="math">\({\varphi}_i\)</span> is zero at all these points, except at <span class="math">\(x_{i}\)</span>, the
Trapezoidal rule collapses to one term:</p>
<div class="math">
\[(f,{\varphi}_i) \approx hf(x_{i}),\]</div>
<p>for <span class="math">\(i=1,\ldots,N-1\)</span>,
which is the same result as with collocation/interpolation, and of course
the same result as in the finite difference method.
For <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span> we get contribution from only one element so</p>
<div class="math">
\[(f,{\varphi}_i) \approx \frac{1}{2}hf(x_{i}),\quad i=0,\ i=N
{\thinspace .}\]</div>
<p>Simpson&#8217;s rule with sample points also in the middle of
the elements, at <span class="math">\(x_{i+\frac{1}{2}}=(x_{i} + x_{i+1})/2\)</span>,
can be written as</p>
<div class="math">
\[\int_\Omega g(x)dx \approx \frac{\tilde h}{3}\left( g(x_{0}) +
2\sum_{j=1}^{N-1} g(x_{j})
+ 4\sum_{j=0}^{N-1} g(x_{j+\frac{1}{2}}) + f(x_{2N})\right),\]</div>
<p>where <span class="math">\(\tilde h= h/2\)</span> is the spacing between the sample points.
Our integrand is <span class="math">\(g=f{\varphi}_i\)</span>. For all the node points,
<span class="math">\({\varphi}_i(x_{j})=\delta_{ij}\)</span>, and therefore
<span class="math">\(\sum_{j=1}^{N-1} f(x_{j}){\varphi}_i(x_{j})=f(x_{i})\)</span>.
At the midpoints, <span class="math">\({\varphi}_i(x_{i\pm\frac{1}{2}})=1/2\)</span> and
<span class="math">\({\varphi}_i(x_{j+\frac{1}{2}})=0\)</span> for <span class="math">\(j&gt;1\)</span> and <span class="math">\(j&lt;i-1\)</span>.
Consequently,</p>
<div class="math">
\[\sum_{j=0}^{N-1} f(x_{j+\frac{1}{2}}){\varphi}_i(x_{j+\frac{1}{2}})
= \frac{1}{2}(fx_{j-\frac{1}{2}} + x_{j+\frac{1}{2}}){\thinspace .}\]</div>
<p>When <span class="math">\(1\leq i\leq N-1\)</span> we then get</p>
<div class="math">
\[(f,{\varphi}_i) \approx
\frac{h}{3}(f_{i-\frac{1}{2}} + f_i + f_{i+\frac{1}{2}})
{\thinspace .}\]</div>
<p>This result shows that, with Simpson&#8217;s rule, the finite element method
operates with the average of <span class="math">\(f\)</span> over three points, while the finite difference
method just applies <span class="math">\(f\)</span> at one point. We may interpret this as
a &#8220;smearing&#8221; or smoothing of <span class="math">\(f\)</span> by the finite element method.</p>
<p>We can now summarize our findings. With the approximation of
<span class="math">\((f,{\varphi}_i)\)</span> by the Trapezoidal rule, P1 elements give rise
to equations that can be expressed as a finite difference
discretization of</p>
<div class="math">
\[u + \frac{h^2}{6} u'' = f,\quad u'(0)=u'(L)=0,\]</div>
<p>expressed with operator notation as</p>
<div class="math">
\[[u + \frac{h^2}{6} D_x D_x u = f]_i{\thinspace .}\]</div>
<p>As <span class="math">\(h\rightarrow 0\)</span>, the extra term proportional to <span class="math">\(u''\)</span> goes to zero,
and the two methods are then equal.</p>
<p>With the Simpson&#8217;s rule, we may say that we solve</p>
<div class="math">
\[[u + \frac{h^2}{6} D_x D_x u = \bar f]_i,\]</div>
<p>where <span class="math">\(\bar f_i\)</span> means the average <span class="math">\(\frac{1}{3}(f_{i-1/2} + f_i + f_{i+1/2})\)</span>.</p>
<p>The extra term <span class="math">\(\frac{h^2}{6} u''\)</span> represents a smoothing effect: with
just this term, we would find <span class="math">\(u\)</span> by integrating <span class="math">\(f\)</span> twice and thereby
smooth <span class="math">\(f\)</span> considerably. In addition, the finite element
representation of <span class="math">\(f\)</span> involves an average, or a smoothing, of <span class="math">\(f\)</span> on
the right-hand side of the equation system. If <span class="math">\(f\)</span> is a noisy
function, direct interpolation <span class="math">\(u_i=f_i\)</span> may result in a noisy <span class="math">\(u\)</span>
too, but with a Galerkin or least squares formulation and P1 elements,
we should expect that <span class="math">\(u\)</span> is smoother than <span class="math">\(f\)</span> unless <span class="math">\(h\)</span> is very
small.</p>
<p>The interpretation that finite elements tend to smooth the solution
is valid in applications far beyond approximation of 1D functions.</p>
</div>
<div class="section" id="making-finite-elements-behave-as-finite-differences">
<h2>Making finite elements behave as finite differences<a class="headerlink" href="#making-finite-elements-behave-as-finite-differences" title="Permalink to this headline">¶</a></h2>
<p>With a simple trick, using numerical integration, we can easily produce
the result <span class="math">\(u_i=f_i\)</span> with the Galerkin or least square formulation
with P1 elements. This is useful in many occasions when we deal
with more difficult differential equations and want the finite element
method to have properties like the finite difference method (solving
standard linear wave equations is one primary example).</p>
<div class="section" id="computations-in-physical-space">
<h3>Computations in physical space<a class="headerlink" href="#computations-in-physical-space" title="Permalink to this headline">¶</a></h3>
<p>We have already seen that applying the Trapezoidal rule to the
right-hand side <span class="math">\((f,{\varphi}_i)\)</span> simply gives <span class="math">\(f\)</span> sampled at <span class="math">\(x_{i}\)</span>.
Using the Trapezoidal rule on the  matrix entries
<span class="math">\(A_{i,j}=({\varphi}_i,{\varphi}_j)\)</span> involves a sum</p>
<div class="math">
\[\sum_k {\varphi}_i(x_{k}){\varphi}_j(x_{k}),\]</div>
<p>but <span class="math">\({\varphi}_i(x_{k})=\delta_{ik}\)</span> and
<span class="math">\({\varphi}_j(x_{k})=\delta_{jk}\)</span>.
The product <span class="math">\({\varphi}_i{\varphi}_j\)</span> is then different from zero only
when sampled at <span class="math">\(x_{i}\)</span> and <span class="math">\(i=j\)</span>. The Trapezoidal
approximation to the integral
is then</p>
<div class="math">
\[({\varphi}_i,{\varphi}_j) \approx h,\quad i=j,\]</div>
<p>and zero if <span class="math">\(i\neq j\)</span>. This means that we have obtained a diagonal matrix!
The first and last diagonal elements, <span class="math">\(({\varphi}_0,{\varphi}_0)\)</span> and
<span class="math">\(({\varphi}_N,{\varphi}_N)\)</span> get contribution only from the first and last
element, respectively, resulting in the approximate integral value <span class="math">\(h/2\)</span>.
The corresponding right-hand side also has a factor <span class="math">\(1/2\)</span> for <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span>.
Therefore, the least squares or Galerkin approach with P1 elements and
Trapezoidal integration results in</p>
<div class="math">
\[c_i = f_i,\quad i\inI{\thinspace .}\]</div>
<p>Simpsons&#8217;s rule can be used to achieve a similar result for P2 elements, i.e,
a diagonal coefficient matrix, but with the previously derived
average of <span class="math">\(f\)</span> on the right-hand side.</p>
</div>
<div class="section" id="elementwise-computations">
<h3>Elementwise computations<a class="headerlink" href="#elementwise-computations" title="Permalink to this headline">¶</a></h3>
<p>Identical results to those above will arise if we perform elementwise
computations. The idea is to use the Trapezoidal rule on the reference
element for computing the element matrix and vector. When assembled,
the same equations <span class="math">\(c_i=f(x_{i})\)</span> arise. <a class="reference internal" href="#fem-approx-fe-exer-1d-trapez"><em>Exercise 18: Use the Trapezoidal rule and P1 elements</em></a> encourages you to carry out the
details.</p>
<span class="target" id="index-34"></span><span class="target" id="index-35"></span></div>
<div class="section" id="terminology">
<span id="index-36"></span><h3>Terminology<a class="headerlink" href="#terminology" title="Permalink to this headline">¶</a></h3>
<p>The matrix with entries <span class="math">\(({\varphi}_i,{\varphi}_j)\)</span> typically arises from
terms proportional to <span class="math">\(u\)</span> in a differential equation where <span class="math">\(u\)</span> is the
unknown function. This matrix is often called the <em>mass matrix</em>,
because in the early days of the finite element method, the matrix
arose from the mass times acceleration term in Newton&#8217;s second law of
motion. Making the mass matrix diagonal by, e.g., numerical
integration, as demonstrated above, is a widely used technique and is
called <em>mass lumping</em>. In time-dependent problems it can sometimes
enhance the numerical accuracy and computational efficiency of the
finite element method.  However, there are also examples where mass
lumping destroys accuracy.</p>
</div>
</div>
</div>
<div class="section" id="a-generalized-element-concept">
<span id="fem-approx-fe-element"></span><h1>A generalized element concept<a class="headerlink" href="#a-generalized-element-concept" title="Permalink to this headline">¶</a></h1>
<p>So far, finite element computing has employed the <tt class="docutils literal"><span class="pre">nodes</span></tt> and
<tt class="docutils literal"><span class="pre">element</span></tt> lists together with the definition of the basis functions
in the reference element. Suppose we want to introduce a piecewise
constant approximation with one basis function <span class="math">\({\tilde{\varphi}}_0(x)=1\)</span> in
the reference element, corresponding to a <span class="math">\({\varphi}_i(x)\)</span> function that
is 1 on element number <span class="math">\(i\)</span> and zero on all other elements.
Although we could associate the function value
with a node in the middle of the elements, there are no nodes at the
ends, and the previous code snippets will not work because we
cannot find the element boundaries from the <tt class="docutils literal"><span class="pre">nodes</span></tt> list.</p>
<div class="section" id="cells-vertices-and-degrees-of-freedom">
<span id="fem-approx-fe-element-terminology"></span><h2>Cells, vertices, and degrees of freedom<a class="headerlink" href="#cells-vertices-and-degrees-of-freedom" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-37"></span><span class="target" id="index-38"></span><span class="target" id="index-39"></span><p id="index-40">We now introduce <em>cells</em> as the subdomains <span class="math">\(\Omega^{(e)}\)</span> previously
referred as elements. The cell boundaries are denoted as <em>vertices</em>.
The reason for this name is that cells are recognized by their vertices
in 2D and 3D. We also define a set of <em>degrees of freedom</em>, which are
the quantities we aim to compute. The most common type of degree
of freedom is the value of the unknown function <span class="math">\(u\)</span> at some point.
(For example, we can introduce nodes as before and say the degrees of
freedom are the values of <span class="math">\(u\)</span> at the nodes.) The basis functions are
constructed so that they equal unity for one particular degree of
freedom and zero for the rest. This property ensures that when
we evaluate <span class="math">\(u=\sum_j c_j{\varphi}_j\)</span> for degree of freedom number <span class="math">\(i\)</span>,
we get <span class="math">\(u=c_i\)</span>. Integrals are performed over cells, usually by
mapping the cell of interest to a <em>reference cell</em>.</p>
<p>With the concepts of cells, vertices, and degrees of freedom we
increase the decoupling of the geometry (cell, vertices) from the
space of basis functions. We will associate different
sets of basis functions with a cell. In 1D, all cells are intervals,
while in 2D we can have cells that are triangles with straight sides,
or any polygon, or in fact any two-dimensional geometry. Triangles and
quadrilaterals are most common, though. The popular cell types in 3D
are tetrahedra and hexahedra.</p>
</div>
<div class="section" id="extended-finite-element-concept">
<span id="fem-approx-fe-element-def"></span><h2>Extended finite element concept<a class="headerlink" href="#extended-finite-element-concept" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-41"></span><p id="index-42">The concept of a <em>finite element</em> is now</p>
<blockquote>
<div><ul class="simple">
<li>a <em>reference cell</em> in a local reference coordinate system;</li>
<li>a set of <em>basis functions</em> <span class="math">\({\tilde{\varphi}}_i\)</span> defined on the cell;</li>
<li>a set of <em>degrees of freedom</em> that uniquely determines
the basis functions such that <span class="math">\({\tilde{\varphi}}_i=1\)</span> for degree of freedom
number <span class="math">\(i\)</span> and <span class="math">\({\tilde{\varphi}}_i=0\)</span> for all other degrees of freedom;</li>
<li>a mapping between local and global degree of freedom numbers,
here called the <em>dof map</em>;</li>
<li>a geometric <em>mapping</em> of the reference cell onto to cell in the physical
domain.</li>
</ul>
</div></blockquote>
<p>There must be a geometric description of a cell. This is trivial in 1D
since the cell is an interval and is described by the interval limits,
here called vertices. If the cell is <span class="math">\(\Omega^{(e)}=[x_L,x_R]\)</span>,
vertex 0 is <span class="math">\(x_L\)</span> and vertex 1 is <span class="math">\(x_R\)</span>. The reference cell in 1D
is <span class="math">\([-1,1]\)</span> in the reference coordinate system <span class="math">\(X\)</span>.</p>
<p id="index-43">The expansion of <span class="math">\(u\)</span> over one cell is often used:</p>
<div class="math">
\[u(x) = \tilde u(X) = \sum_{r} c_r{\tilde{\varphi}}_r(X),\quad x\in\Omega^{(e)},\
X\in [-1,1],\]</div>
<p>where the sum is taken over the numbers of the degrees of freedom and
<span class="math">\(c_r\)</span> is the value of <span class="math">\(u\)</span> for degree of freedom number <span class="math">\(r\)</span>.</p>
<p>Our previous P1, P2, etc., elements are defined by introducing <span class="math">\(d+1\)</span>
equally spaced nodes in the reference cell and saying that the degrees
of freedom are the <span class="math">\(d+1\)</span> function values at these nodes.  The basis
functions must be 1 at one node and 0 at the others, and the Lagrange
polynomials have exactly this property.  The nodes can be numbered
from left to right with associated degrees of freedom that are
numbered in the same way.  The degree of freedom mapping becomes what
was previously represented by the <tt class="docutils literal"><span class="pre">elements</span></tt> lists.  The cell mapping
is the same affine mapping <a href="#equation-fem:approx:fe:affine:mapping">(28)</a> as
before.</p>
</div>
<div class="section" id="implementation-2">
<span id="fem-approx-fe-element-impl"></span><h2>Implementation  (2)<a class="headerlink" href="#implementation-2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-44"></span><span class="target" id="index-45"></span><p id="index-46">Implementationwise,</p>
<blockquote>
<div><ul class="simple">
<li>we replace <tt class="docutils literal"><span class="pre">nodes</span></tt> by <tt class="docutils literal"><span class="pre">vertices</span></tt>;</li>
<li>we introduce <tt class="docutils literal"><span class="pre">cells</span></tt> such that <tt class="docutils literal"><span class="pre">cell[e][r]</span></tt> gives the mapping
from local vertex <tt class="docutils literal"><span class="pre">r</span></tt> in cell <tt class="docutils literal"><span class="pre">e</span></tt> to the global vertex number
in <tt class="docutils literal"><span class="pre">vertices</span></tt>;</li>
<li>we replace <tt class="docutils literal"><span class="pre">elements</span></tt> by <tt class="docutils literal"><span class="pre">dof_map</span></tt> (the contents are the same
for P$d$ elements).</li>
</ul>
</div></blockquote>
<p>Consider the example from the section <a class="reference internal" href="#fem-approx-fe-def-elements-nodes"><em>Elements and nodes</em></a>
where <span class="math">\(\Omega =[0,1]\)</span> is divided into two cells,
<span class="math">\(\Omega^{(0)}=[0,0.4]\)</span> and <span class="math">\(\Omega^{(1)}=[0.4,1]\)</span>.
The vertices are <span class="math">\([0,0.4,1]\)</span>. Local vertex 0 and 1 are
<span class="math">\(0\)</span> and <span class="math">\(0.4\)</span> in cell 0 and <span class="math">\(0.4\)</span> and <span class="math">\(1\)</span> in cell 1.
A P2 element means that the degrees of freedom are
the value of <span class="math">\(u\)</span> at three equally spaced points (nodes) in each
cell. The data structures become</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">cells</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
</pre></div>
</div>
<p>If we would approximate <span class="math">\(f\)</span> by piecewise constants, known as
P0 elements, we simply
introduce one point or node in an element, preferably <span class="math">\(X=0\)</span>,
and define one degree of freedom, which is the function value
at this node. Moreover, we set <span class="math">\({\tilde{\varphi}}_0(X)=1\)</span>.
The <tt class="docutils literal"><span class="pre">cells</span></tt> and <tt class="docutils literal"><span class="pre">vertices</span></tt> arrays remain the same, but
<tt class="docutils literal"><span class="pre">dof_map</span></tt> is altered:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>We use the <tt class="docutils literal"><span class="pre">cells</span></tt> and <tt class="docutils literal"><span class="pre">vertices</span></tt> lists to retrieve information
on the geometry of a cell, while <tt class="docutils literal"><span class="pre">dof_map</span></tt> is the
<span class="math">\(q(e,r)\)</span> mapping introduced earlier in the
assembly of element matrices and vectors.
For example, the <tt class="docutils literal"><span class="pre">Omega_e</span></tt> variable (representing the cell interval)
in previous code snippets must now be computed as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">Omega_e</span> <span class="o">=</span> <span class="p">[</span><span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
<p>The assembly is done by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">A</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span> <span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
<span class="n">b</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
</pre></div>
</div>
<p>We will hereafter drop the <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> arrays
and work exculsively with <tt class="docutils literal"><span class="pre">cells</span></tt>, <tt class="docutils literal"><span class="pre">vertices</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt>.
The module <tt class="docutils literal"><span class="pre">fe_approx1D_numint.py</span></tt> now replaces the module
<tt class="docutils literal"><span class="pre">fe_approx1D</span></tt> and offers similar functions that work with
the new concepts:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">fe_approx1D_numint</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
<span class="n">N_e</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span> <span class="o">=</span> <span class="n">mesh_uniform</span><span class="p">(</span><span class="n">N_e</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">basis</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_e</span><span class="p">)]</span>
<span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="c"># Make very fine mesh and sample u(x) on this mesh for plotting</span>
<span class="n">x_u</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">u_glob</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span><span class="p">,</span>
                <span class="n">resolution_per_element</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x_u</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
</pre></div>
</div>
<p>These steps are offered in the <tt class="docutils literal"><span class="pre">approximate</span></tt> function, which we here
apply to see how well four P0 elements (piecewise constants)
can approximate a parabola:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">fe_approx1D_numint</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">x</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&quot;x&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">N_e</span> <span class="ow">in</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span>
    <span class="n">approximate</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">),</span> <span class="n">d</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">N_e</span><span class="o">=</span><span class="n">N_e</span><span class="p">,</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-element-impl-fig-p0-x2"><em>Approximation of a parabola by 4 (left) and 8 (right) P0 elements</em></a> shows the result.</p>
<div class="figure" id="fem-approx-fe-element-impl-fig-p0-x2">
<img alt="_images/fe_p0_x2_4e_8e1.png" src="_images/fe_p0_x2_4e_8e1.png" style="width: 600px;" />
<p class="caption"><em>Approximation of a parabola by 4 (left) and 8 (right) P0 elements</em></p>
</div>
</div>
<div class="section" id="computing-the-error-of-the-approximation">
<span id="fem-approx-fe-element-impl-error"></span><h2>Computing the error of the approximation<a class="headerlink" href="#computing-the-error-of-the-approximation" title="Permalink to this headline">¶</a></h2>
<p>So far we have focused on computing the coefficients <span class="math">\(c_j\)</span> in the
approximation <span class="math">\(u(x)=\sum_jc_j{\varphi}_j\)</span> as well as on plotting <span class="math">\(u\)</span> and
<span class="math">\(f\)</span> for visual comparison. A more quantitative comparison needs to
investigate the error <span class="math">\(e(x)=f(x)-u(x)\)</span>. We mostly want a single number to
reflect the error and use a norm for this purpose, usually the <span class="math">\(L^2\)</span> norm</p>
<div class="math">
\[||e||_{L^2} = \left(\int_{\Omega} e^2 dx\right)^{\frac{1}{2}}{\thinspace .}\]</div>
<p>Since the finite element approximation is defined for all <span class="math">\(x\in\Omega\)</span>,
and we are interested in how <span class="math">\(u(x)\)</span> deviates from <span class="math">\(f(x)\)</span> through all
the elements,
we can either integrate analytically or use an accurate numerical
approximation. The latter is more convenient as it is a generally
feasible and simple approach. The idea is to sample <span class="math">\(e(x)\)</span>
at a large number of points in each element. The function <tt class="docutils literal"><span class="pre">u_glob</span></tt>
in the <tt class="docutils literal"><span class="pre">fe_approx1D_numint</span></tt> module does this for <span class="math">\(u(x)\)</span> and returns
an array <tt class="docutils literal"><span class="pre">x</span></tt> with coordinates and an array <tt class="docutils literal"><span class="pre">u</span></tt> with the <span class="math">\(u\)</span> values:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">u_glob</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">vertices</span><span class="p">,</span> <span class="n">cells</span><span class="p">,</span> <span class="n">dof_map</span><span class="p">,</span>
              <span class="n">resolution_per_element</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">u</span>
</pre></div>
</div>
<p>Let us use the Trapezoidal method to approximate the integral. Because
different elements may have different lengths, the <tt class="docutils literal"><span class="pre">x</span></tt> array has
a non-uniformly distributed set of coordinates. Also, the <tt class="docutils literal"><span class="pre">u_glob</span></tt>
function works in an element by element fashion such that coordinates
at the boundaries between elements appear twice. We therefore need
to use a &#8220;raw&#8221; version of the Trapezoidal rule where we just add up
all the trapezoids:</p>
<div class="math">
\[\int_\Omega g(x) dx \approx \sum_{j=0}^{n-1} \frac{1}{2}(g(x_j) +
g(x_{j+1}))(x_{j+1}-x_j),\]</div>
<p>if <span class="math">\(x_0,\ldots,x_n\)</span> are all the coordinates in <tt class="docutils literal"><span class="pre">x</span></tt>. In
vectorized Python code,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">g_x</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">integral</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">g_x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">g_x</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>Computing the <span class="math">\(L^2\)</span> norm of the error, here named <tt class="docutils literal"><span class="pre">E</span></tt>, is now achieved by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">e2</span> <span class="o">=</span> <span class="n">e</span><span class="o">**</span><span class="mi">2</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">e2</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">e2</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<div class="admonition-how-does-the-error-depend-on-math-h-and-math-d admonition">
<p class="first admonition-title">How does the error depend on <span class="math">\(h\)</span> and <span class="math">\(d\)</span></p>
<p>Theory and experiments show that the least squares or projection/Galerkin
method in combination with P$d$ elements of equal length <span class="math">\(h\)</span> has an error</p>
<div class="math" id="equation-fem:approx:fe:error:theorem">
<span class="eqno">(39)</span>\[     ||e||_{L^2} = Ch^{d+1},\]</div>
<p class="last">where <span class="math">\(C\)</span> is a constant depending on <span class="math">\(f\)</span>, but not on <span class="math">\(h\)</span> or <span class="math">\(d\)</span>.</p>
</div>
</div>
<div class="section" id="example-cubic-hermite-polynomials">
<span id="fem-approx-fe-element-impl-hermite"></span><h2>Example: Cubic Hermite polynomials<a class="headerlink" href="#example-cubic-hermite-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-47">The finite elements considered so far represent <span class="math">\(u\)</span> as piecewise
polynomials with discontinuous derivatives at the cell boundaries.
Sometimes it is desirable to have continuous derivatives. A primary
examples is the solution of differential equations with fourth-order
derivatives where standard finite element formulations lead to
a need for basis functions with continuous first-order derivatives.
The most common type of such basis functions in 1D is the
so-called cubic Hermite polynomials.
The construction of such polynomials, as explained next, will further
exemplify the concepts of a cell, vertex, degree of freedom, and dof map.</p>
<p>Given a reference cell <span class="math">\([-1,1]\)</span>, we seek cubic polynomials
with the values of the <em>function</em> and its <em>first-order derivative</em> at
<span class="math">\(X=-1\)</span> and <span class="math">\(X=1\)</span> as the four degrees of freedom. Let us number
the degrees of freedom as</p>
<blockquote>
<div><ul class="simple">
<li>0: value of function at <span class="math">\(X=-1\)</span></li>
<li>1: value of first derivative at <span class="math">\(X=-1\)</span></li>
<li>2: value of function at <span class="math">\(X=1\)</span></li>
<li>3: value of first derivative at <span class="math">\(X=1\)</span></li>
</ul>
</div></blockquote>
<p>By having the derivatives as unknowns, we ensure that
the derivative of a basis function in two neighboring elements
is the same at the node points.</p>
<p>The four basis functions can be written in a general form</p>
<div class="math">
\[{\tilde{\varphi}}_i (X) = \sum_{j=0}^3 C_{i,j}X^j,\]</div>
<p>with four coefficients <span class="math">\(C_{i,j}\)</span>, <span class="math">\(j=0,1,2,3\)</span>, to be determined for
each <span class="math">\(i\)</span>. The constraints
that basis function number <span class="math">\(i\)</span> must be 1 for degree of
freedom number <span class="math">\(i\)</span> and zero for the other three degrees of freedom,
gives four equations to determine <span class="math">\(C_{i,j}\)</span> for each <span class="math">\(i\)</span>. In mathematical
detail,</p>
<div class="math">
\[\begin{split}{\tilde{\varphi}}_0 (-1) &amp;= 1,\quad {\tilde{\varphi}}_0 (1)={\tilde{\varphi}}_0'(-1)={\tilde{\varphi}}_i' (1)=0,\\
{\tilde{\varphi}}_1' (-1) &amp;= 1,\quad {\tilde{\varphi}}_1 (-1)={\tilde{\varphi}}_1(1)={\tilde{\varphi}}_1' (1)=0,\\
{\tilde{\varphi}}_2 (1) &amp;= 1,\quad {\tilde{\varphi}}_2 (-1)={\tilde{\varphi}}_2'(-1)={\tilde{\varphi}}_2' (1)=0,\\
{\tilde{\varphi}}_3' (1) &amp;= 1,\quad {\tilde{\varphi}}_3 (-1)={\tilde{\varphi}}_3'(-1)={\tilde{\varphi}}_3 (1)=0
{\thinspace .}\end{split}\]</div>
<p>These four <span class="math">\(4\times 4\)</span> linear equations can be solved, yielding the
following formulas
for the cubic basis functions:</p>
<div class="math">
\[{\tilde{\varphi}}_0(X) = 1 - \frac{3}{4}(X+1)^2 + \frac{1}{4}(X+1)^3\]</div>
<div class="math">
\[{\tilde{\varphi}}_1(X) = -(X+1)(1 - \frac{1}{2}(X+1))^2\]</div>
<div class="math">
\[{\tilde{\varphi}}_2(X) = \frac{3}{4}(X+1)^2 - \frac{1}{2}(X+1)^3\]</div>
<div class="math">
\[{\tilde{\varphi}}_3(X) = -\frac{1}{2}(X+1)(\frac{1}{2}(X+1)^2 - (X+1))\]</div>
<div class="math">
</div>
<p>The construction of the dof map needs a scheme for numbering the
global degrees of freedom. A natural left-to-right numbering
has the function value at vertex <span class="math">\(x_{i}\)</span>
as degree of freedom number <span class="math">\(2i\)</span> and the value of the derivative
at <span class="math">\(x_{i}\)</span> as degree of freedom number <span class="math">\(2i+1\)</span>, <span class="math">\(i=0,\ldots,N_e+1\)</span>.</p>
</div>
</div>
<div class="section" id="numerical-integration">
<h1>Numerical integration<a class="headerlink" href="#numerical-integration" title="Permalink to this headline">¶</a></h1>
<p>Finite element codes usually apply numerical approximations to
integrals. Since the integrands in the coefficient matrix often
are (lower-order) polynomials, integration rules that can
integrate polynomials exactly are popular.</p>
<p>The numerical integration rules can be expressed in a common form,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx \sum_{j=0}^M w_j\bar X_j,\]</div>
<p>where <span class="math">\(\bar X_j\)</span> are <em>integration points</em> and <span class="math">\(w_j\)</span> are
<em>integration weights</em>, <span class="math">\(j=0,\ldots,M\)</span>.
Different rules correspond to different choices of points and weights.</p>
<p>The very simplest method is the <em>Midpoint rule</em>,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx 2g(0),\quad \bar X_0=0,\ w_0=2,\]</div>
<p>which integrates linear functions exactly.</p>
<div class="section" id="newton-cotes-rules">
<span id="fem-approx-fe-numint1"></span><h2>Newton-Cotes rules<a class="headerlink" href="#newton-cotes-rules" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-48"></span><span class="target" id="index-49"></span><span class="target" id="index-50"></span><span class="target" id="index-51"></span><span class="target" id="index-52"></span><span class="target" id="index-53"></span><span class="target" id="index-54"></span><p id="index-55">The <a class="reference external" href="http://en.wikipedia.org/wiki/Newton%E2%80%93Cotes_formulas">Newton-Cotes</a>
rules are based on a fixed uniform distribution of the integration points.
The first two formulas in this family are the well-known
<em>Trapezoidal rule</em>,</p>
<div class="math" id="equation-fem:approx:fe:numint1:trapez">
<span class="eqno">(40)</span>\[     \int_{-1}^{1} g(X)dX \approx g(-1) + g(1),\quad \bar X_0=-1,\ \bar X_1=1,\ w_0=w_1=1,\]</div>
<p>and <em>Simpson&#8217;s rule</em>,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx \frac{1}{3}\left(g(-1) + 4g(0)
+ g(1)\right),\]</div>
<p>where</p>
<div class="math">
\[\bar X_0=-1,\ \bar X_1=0,\ \bar X_2=1,\ w_0=w_2=\frac{1}{3},\ w_1=\frac{4}{3}{\thinspace .}\]</div>
<p>Newton-Cotes rules up to five points is supported in the
module file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/numint.py">numint.py</a>.</p>
<p>For higher accuracy one can divide the reference cell into a set of
subintervals and use the rules above on each subinterval. This approach
results in <em>composite</em> rules, well-known from basic introductions
to numerical integration of <span class="math">\(\int_{a}^{b}f(x)dx\)</span>.</p>
</div>
<div class="section" id="gauss-legendre-rules-with-optimized-points">
<h2>Gauss-Legendre rules with optimized points<a class="headerlink" href="#gauss-legendre-rules-with-optimized-points" title="Permalink to this headline">¶</a></h2>
<p id="index-56">More accurate rules, for a given <span class="math">\(M\)</span>, arise if the location of the
integration points are optimized for polynomial integrands.  The
<a class="reference external" href="http://en.wikipedia.org/wiki/Gaussian_quadrature">Gauss-Legendre rules</a> (also known as
Gauss-Legendre quadrature or Gaussian quadrature) constitute one such
class of integration methods. Two widely applied Gauss-Legendre rules
in this family have the choice</p>
<div class="math">
\[M=1:\quad \bar X_0=-\frac{1}{\sqrt{3}},\
\bar X_1=\frac{1}{\sqrt{3}},\ w_0=w_1=1\]</div>
<div class="math">
\[M=2:\quad \bar X_0=-\sqrt{\frac{3}{{5}}},\ \bar X_0=0,\
\bar X_2= \sqrt{\frac{3}{{5}}},\ w_0=w_2=\frac{5}{9},\ w_1=\frac{8}{9}{\thinspace .}\]</div>
<p>These rules integrate 3rd and 5th degree polynomials exactly.
In general, an <span class="math">\(M\)</span>-point Gauss-Legendre rule integrates a polynomial
of degree <span class="math">\(2M+1\)</span> exactly.
The code <tt class="docutils literal"><span class="pre">numint.py</span></tt> contains a large collection of Gauss-Legendre rules.</p>
</div>
</div>
<div class="section" id="approximation-of-functions-in-2d">
<span id="fem-approx-2d"></span><h1>Approximation of functions in 2D<a class="headerlink" href="#approximation-of-functions-in-2d" title="Permalink to this headline">¶</a></h1>
<p>All the concepts and algorithms developed for approximation of 1D functions
<span class="math">\(f(x)\)</span> can readily be extended to 2D functions <span class="math">\(f(x,y)\)</span> and 3D functions
<span class="math">\(f(x,y,z)\)</span>. Basically, the extensions consists of defining basis functions
<span class="math">\({\psi}_i(x,y)\)</span> or <span class="math">\({\psi}_i(x,y,z)\)</span> over some domain <span class="math">\(\Omega\)</span>, and
for the least squares and Galerkin methods, the integration is done over
<span class="math">\(\Omega\)</span>.</p>
<div class="section" id="global-basis-functions">
<span id="fem-approx-2d-global"></span><h2>Global basis functions<a class="headerlink" href="#global-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>An example will demonstrate the necessary extensions to use global
basis functions and the least squares, projection/Galerkin,
or interpolation/collocation
methods in 2D. The former two lead to linear systems</p>
<div class="math">
\[\begin{split}\sum_{j\inI} A_{i,j}c_j &amp;= b_i,\quad i\inI,\\
A_{i,j} &amp;= ({\psi}_i,{\psi}_j),\\
b_i &amp;= (f,{\psi}_i),\end{split}\]</div>
<p>where the inner product of two functions <span class="math">\(f(x,y)\)</span> and <span class="math">\(g(x,y)\)</span> is defined
completely analogously to the 1D case <a href="#equation-fem:approx:LS:innerprod">(15)</a>:</p>
<div class="math">
\[(f,g) = \int_\Omega f(x,y)g(x,y) dx dy\]</div>
<div class="section" id="constructing-2d-basis-functions-from-1d-functions">
<h3>Constructing 2D basis functions from 1D functions<a class="headerlink" href="#constructing-2d-basis-functions-from-1d-functions" title="Permalink to this headline">¶</a></h3>
<p>One straightforward
way to construct a basis in 2D is to combine
1D basis functions. Say we have the 1D basis</p>
<div class="math">
\[\{ \hat{\psi}_0(x),\ldots,\hat{\psi}_{N_x}(x)\}
{\thinspace .}\]</div>
<p>We can now form 2D basis functions as products of 1D basis functions:
<span class="math">\(\hat{\psi}_p(x)\hat{\psi}_q(y)\)</span> for <span class="math">\(p\in{\mathcal{I}_x}=\{0,\ldots,N_x\}\)</span>
and <span class="math">\(q\in{\mathcal{I}_y}=\{0,\ldots,N_y\}\)</span>.
We can either work with double indices,
<span class="math">\({\psi}_{p,q}(x,y) = \hat{\psi}_p(x)\hat{\psi}_q(y)\)</span>, and write</p>
<div class="math">
\[u = \sum_{p\in{\mathcal{I}_x}}\sum_{q\in{\mathcal{I}_y}} c_{p,q}{\psi}_{p,q}(x,y),\]</div>
<p>or we may transform the double index <span class="math">\((p,q)\)</span> to a single index <span class="math">\(i\)</span>,
using <span class="math">\(i=p N_y + q\)</span> or <span class="math">\(i=q N_x + p\)</span>.</p>
<p>Suppose we choose <span class="math">\(\hat{\psi}_p(x)=x^p\)</span>, and try an approximation with
<span class="math">\(N_x=N_y=1\)</span>:</p>
<div class="math">
\[{\psi}_{0,0}=1,\quad {\psi}_{1,0}=x, \quad {\psi}_{0,1}=y,
\quad {\psi}_{1,1}=xy
{\thinspace .}\]</div>
<p>Using a mapping to one index like <span class="math">\(i=q N_x + p\)</span>, we get</p>
<div class="math">
\[{\psi}_0=1,\quad {\psi}_1=x, \quad {\psi}_2=y,\quad{\psi}_3 =xy
{\thinspace .}\]</div>
</div>
<div class="section" id="hand-calculations">
<h3>Hand calculations<a class="headerlink" href="#hand-calculations" title="Permalink to this headline">¶</a></h3>
<p>With the specific choice <span class="math">\(f(x,y) = (1+x^2)(1+2y^2)\)</span> on
<span class="math">\(\Omega = [0,L_x]\times [0,L_y]\)</span>, we can perform actual calculations:</p>
<div class="math">
\[\begin{split}A_{0,0} &amp;= ({\psi}_0,{\psi}_0) = \int_0^{L_y}\int_{0}^{L_x}
{\psi}_0(x,y)^2 dx dy = \int_0^{L_y}\int_{0}^{L_x}dx dy = L_xL_y,\\
A_{1,0} &amp;= ({\psi}_1,{\psi}_0) = \int_0^{L_y}\int_{0}^{L_x} x dxdy =
\frac{1}{2}L_x^2L_y,\\
A_{0,1} &amp;= ({\psi}_0,{\psi}_1) = \int_0^{L_y}\int_{0}^{L_x} y dxdy =
\frac{1}{2}L_y^2L_x,\\
A_{0,1} &amp;= ({\psi}_0,{\psi}_1) = \int_0^{L_y}\int_{0}^{L_x} xy dxdy =
\int_0^{L_y}ydy \int_{0}^{L_x} xdx =
\frac{1}{4}L_y^2L_x^2
{\thinspace .}\end{split}\]</div>
<p>The right-hand side vector has the entries</p>
<div class="math">
\[\begin{split}b_{0} &amp;= ({\psi}_0,f) = \int_0^{L_y}\int_{0}^{L_x}1\cdot (1+x^2)(1+2y^2) dxdy\\
&amp;= \int_0^{L_y}(1+2y^2)dy \int_{0}^{L_x} (1+x^2)dx
= (L_y + \frac{2}{3}L_y^3)(L_x + \frac{1}{3}L_x^3)\\
b_{1} &amp;= ({\psi}_1,f) = \int_0^{L_y}\int_{0}^{L_x} x(1+x^2)(1+2y^2) dxdy\\
&amp;=\int_0^{L_y}(1+2y^2)dy \int_{0}^{L_x} x(1+x^2)dx
= (L_y + \frac{2}{3}L_y^3)(\frac{1}{2}L_x^2 + \frac{1}{4}L_x^4)\\
b_{2} &amp;= ({\psi}_2,f) = \int_0^{L_y}\int_{0}^{L_x} y(1+x^2)(1+2y^2) dxdy\\
&amp;= \int_0^{L_y}y(1+2y^2)dy \int_{0}^{L_x} (1+x^2)dx
= (\frac{1}{2}L_y + \frac{1}{2}L_y^4)(L_x + \frac{1}{3}L_x^3)\\
b_{3} &amp;= ({\psi}_2,f) = \int_0^{L_y}\int_{0}^{L_x} xy(1+x^2)(1+2y^2) dxdy\\
&amp;= \int_0^{L_y}y(1+2y^2)dy \int_{0}^{L_x} x(1+x^2)dx
= (\frac{1}{2}L_y^2 + \frac{1}{2}L_y^4)(\frac{1}{2}L_x^2 + \frac{1}{4}L_x^4)
{\thinspace .}\end{split}\]</div>
<p>There is a general pattern in these calculations that we can explore.
An arbitrary matrix entry has the formula</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= ({\psi}_i,{\psi}_j) = \int_0^{L_y}\int_{0}^{L_x}
{\psi}_i{\psi}_j dx dy \\
&amp;= \int_0^{L_y}\int_{0}^{L_x}
{\psi}_{p,q}{\psi}_{r,s} dx dy
= \int_0^{L_y}\int_{0}^{L_x}
\hat{\psi}_p(x)\hat{\psi}_q(y)\hat{\psi}_r(x)\hat{\psi}_s(y) dx dy\\
&amp;= \int_0^{L_y} \hat{\psi}_q(y)\hat{\psi}_s(y)dy
\int_{0}^{L_x} \hat{\psi}_p(x) \hat{\psi}_r(x) dx\\
&amp;= \hat A^{(x)}_{p,r}\hat A^{(y)}_{q,s},\end{split}\]</div>
<p>where</p>
<div class="math">
\[\hat A^{(x)}_{p,r} = \int_{0}^{L_x} \hat{\psi}_p(x) \hat{\psi}_r(x) dx,
\quad
\hat A^{(y)}_{q,s} = \int_0^{L_y} \hat{\psi}_q(y)\hat{\psi}_s(y)dy,\]</div>
<p>are matrix entries for one-dimensional approximations. Moreover,
<span class="math">\(i=q N_y+q\)</span> and <span class="math">\(j=s N_y+r\)</span>.</p>
<p>With <span class="math">\(\hat{\psi}_p(x)=x^p\)</span> we have</p>
<div class="math">
\[\hat A^{(x)}_{p,r} = \frac{1}{p+r+1}L_x^{p+r+1},\quad
\hat A^{(y)}_{q,s} = \frac{1}{q+s+1}L_y^{q+s+1},\]</div>
<p>and</p>
<div class="math">
\[A_{i,j} = \hat A^{(x)}_{p,r} \hat A^{(y)}_{q,s} =
\frac{1}{p+r+1}L_x^{p+r+1} \frac{1}{q+s+1}L_y^{q+s+1},\]</div>
<p>for <span class="math">\(p,r\in{\mathcal{I}_x}\)</span> and <span class="math">\(q,s\in{\mathcal{I}_y}\)</span>.</p>
<p>Corresponding reasoning for the right-hand side leads to</p>
<div class="math">
\[\begin{split}b_i &amp;= ({\psi}_i,f) = \int_0^{L_y}\int_{0}^{L_x}{\psi}_i f\,dxdx\\
&amp;= \int_0^{L_y}\int_{0}^{L_x}\hat{\psi}_p(x)\hat{\psi}_q(y) f\,dxdx\\
&amp;= \int_0^{L_y}\hat{\psi}_q(y) (1+2y^2)dy
\int_0^{L_y}\hat{\psi}_p(x) x^p (1+x^2)dx\\
&amp;= \int_0^{L_y} y^q (1+2y^2)dy
\int_0^{L_y}x^p (1+x^2)dx\\
&amp;= (\frac{1}{q+1} L_y^{q+1} + \frac{2}{q+3}L_y^{q+3})
(\frac{1}{p+1} L_x^{p+1} + \frac{2}{q+3}L_x^{p+3})\end{split}\]</div>
<p>Choosing <span class="math">\(L_x=L_y=2\)</span>, we have</p>
<div class="math">
\[\begin{split}A =
\left[\begin{array}{cccc}
4 &amp; 4 &amp; 4 &amp; 4\\
4 &amp; \frac{16}{3} &amp; 4 &amp; \frac{16}{3}\\
4 &amp; 4 &amp; \frac{16}{3} &amp; \frac{16}{3}\\
4 &amp; \frac{16}{3} &amp; \frac{16}{3} &amp; \frac{64}{9}
\end{array}\right],\quad
b = \left[\begin{array}{c}
\frac{308}{9}\\\frac{140}{3}\\44\\60\end{array}\right],
\quad c = \left[
\begin{array}{r}
-\frac{1}{9} \\
\frac{4}{3} \\
 - \frac{2}{3} \\
 8
\end{array}\right]
{\thinspace .}\end{split}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-ubilinear"><em>Approximation of a 2D quadratic function (left) by a 2D bilinear function (right) using the Galerkin or least squares method</em></a> illustrates the result.</p>
<div class="figure" id="fem-approx-fe-2d-fig-ubilinear">
<img alt="_images/approx2D_bilinear1.png" src="_images/approx2D_bilinear1.png" style="width: 800px;" />
<p class="caption"><em>Approximation of a 2D quadratic function (left) by a 2D bilinear function (right) using the Galerkin or least squares method</em></p>
</div>
</div>
</div>
<div class="section" id="implementation-3">
<span id="fem-approx-2d-global-code"></span><h2>Implementation  (3)<a class="headerlink" href="#implementation-3" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="docutils literal"><span class="pre">least_squares</span></tt> function from
the section <a class="reference internal" href="#fem-approx-global-orth"><em>Orthogonal basis functions</em></a> and/or the
file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx1D.py">approx1D.py</a>
can with very small modifications solve 2D approximation problems.
First, let <tt class="docutils literal"><span class="pre">Omega</span></tt> now be a list of the intervals in <span class="math">\(x\)</span> and <span class="math">\(y\)</span> direction.
For example, <span class="math">\(\Omega = [0,L_x]\times [0,L_y]\)</span> can be represented
by <tt class="docutils literal"><span class="pre">Omega</span> <span class="pre">=</span> <span class="pre">[[0,</span> <span class="pre">L_x],</span> <span class="pre">[0,</span> <span class="pre">L_y]]</span></tt>.</p>
<p>Second, the symbolic integration must be extended to 2D:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="n">integrand</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span>
                 <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span>
                 <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>provided <tt class="docutils literal"><span class="pre">integrand</span></tt> is an expression involving the <tt class="docutils literal"><span class="pre">sympy</span></tt> symbols <tt class="docutils literal"><span class="pre">x</span></tt>
and <tt class="docutils literal"><span class="pre">y</span></tt>.
The 2D version of numerical integration becomes</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
    <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span>
                       <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span>
                       <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
<p>The right-hand side integrals are modified in a similar way.</p>
<p>Third, we must construct a list of 2D basis functions, e.g.,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Nx</span><span class="p">,</span> <span class="n">Ny</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="o">**</span><span class="n">i</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="n">j</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ny</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">sines</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Nx</span><span class="p">,</span> <span class="n">Ny</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ny</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>The complete code appears in
<a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx2D.py">approx2D.py</a>.</p>
<p>The previous hand calculation where a quadratic <span class="math">\(f\)</span> was approximated by
a bilinear function can be computed symbolically by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">approx2D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Omega</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">8*x*y - 2*x/3 + 4*y/3 - 1/9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">2*x**2*y**2 + x**2 + 2*y**2 + 1</span>
</pre></div>
</div>
<p>We may continue with adding higher powers to the basis:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">2*x**2*y**2 + x**2 + 2*y**2 + 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span><span class="o">-</span><span class="n">f</span>
<span class="go">0</span>
</pre></div>
</div>
<p>For <span class="math">\(N_x\geq 2\)</span> and <span class="math">\(N_y\geq 2\)</span> we recover the exact function <span class="math">\(f\)</span>, as
expected, since in that case <span class="math">\(f\in V\)</span> (see
the section <a class="reference internal" href="#fem-approx-global-exact"><em>Perfect approximation</em></a>).</p>
</div>
</div>
<div class="section" id="finite-elements-in-2d-and-3d">
<h1>Finite elements in 2D and 3D<a class="headerlink" href="#finite-elements-in-2d-and-3d" title="Permalink to this headline">¶</a></h1>
<p>Finite element approximation is particularly powerful in 2D and 3D because
the method can handle a geometrically complex domain <span class="math">\(\Omega\)</span> with ease.
The principal idea is, as in 1D, to divide the domain into cells
and use polynomials for approximating a function over a cell.
Two popular cell shapes are triangles and the quadrilaterals.
Figures <a class="reference internal" href="#fem-approx-fe-2d-fig-rectp1"><em>Examples on 2D P1 elements</em></a>, <a class="reference internal" href="#fem-approx-fe-2d-fig-circp1"><em>Examples on 2D P1 elements in a deformed geometry</em></a>,
and <a class="reference internal" href="#fem-approx-fe-2d-fig-rectq1"><em>Examples on 2D Q1 elements</em></a> provide examples. P1 elements
means linear functions (<span class="math">\(a_0 + a_1x + a_2y\)</span>) over triangles, while Q1 elements
have bilinear functions (<span class="math">\(a_0 + a_1x + a_2y + a_3xy\)</span>) over rectangular cells.
Higher-order elements can easily be defined.</p>
<div class="figure" id="fem-approx-fe-2d-fig-rectp1">
<img alt="_images/mesh2D_rect_P11.png" src="_images/mesh2D_rect_P11.png" style="width: 800px;" />
<p class="caption"><em>Examples on 2D P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-circp1">
<img alt="_images/mesh2D_quarter_circle1.png" src="_images/mesh2D_quarter_circle1.png" style="width: 400px;" />
<p class="caption"><em>Examples on 2D P1 elements in a deformed geometry</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-rectq1">
<img alt="_images/mesh2D_rect_Q11.png" src="_images/mesh2D_rect_Q11.png" style="width: 400px;" />
<p class="caption"><em>Examples on 2D Q1 elements</em></p>
</div>
<div class="section" id="basis-functions-over-triangles-in-the-physical-domain">
<h2>Basis functions over triangles in the physical domain<a class="headerlink" href="#basis-functions-over-triangles-in-the-physical-domain" title="Permalink to this headline">¶</a></h2>
<p>Cells with triangular shape will be in main focus here.  With the P1
triangular element, <span class="math">\(u\)</span> is a linear function over each cell, as
depicted in Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-femfunc"><em>Example on piecewise linear 2D functions defined on triangles</em></a>, with
discontinuous derivatives at the cell boundaries.</p>
<div class="figure" id="fem-approx-fe-2d-fig-femfunc">
<img alt="_images/demo2D_4x3r1.png" src="_images/demo2D_4x3r1.png" style="width: 400px;" />
<p class="caption"><em>Example on piecewise linear 2D functions defined on triangles</em></p>
</div>
<p>We give the vertices of the cells global and local numbers as in 1D.
The degrees of freedom in the P1 element are the function values at
a set of nodes, which are the three vertices.
The basis function <span class="math">\({\varphi}_i(x,y)\)</span> is then 1 at the vertex with global vertex
number <span class="math">\(i\)</span> and zero at all other vertices.
On an element, the three degrees of freedom uniquely determine
the linear basis functions in that element, as usual.
The global
<span class="math">\({\varphi}_i(x,y)\)</span> function is then a combination of the linear functions
(planar surfaces)
over all the neighboring cells
that have vertex number <span class="math">\(i\)</span> in common. Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-basphi"><em>Example on a piecewise linear 2D basis function over a patch of triangles</em></a>
tries to illustrate the shape of such a &#8220;pyramid&#8221;-like function.</p>
<div class="figure" id="fem-approx-fe-2d-fig-basphi">
<img alt="_images/demo2D_basisfunc1.png" src="_images/demo2D_basisfunc1.png" style="width: 400px;" />
<p class="caption"><em>Example on a piecewise linear 2D basis function over a patch of triangles</em></p>
</div>
<div class="section" id="element-matrices-and-vectors">
<h3>Element matrices and vectors<a class="headerlink" href="#element-matrices-and-vectors" title="Permalink to this headline">¶</a></h3>
<p>As in 1D, we split the integral over <span class="math">\(\Omega\)</span> into a sum of integrals
over cells. Also as in 1D, <span class="math">\({\varphi}_i\)</span> overlaps <span class="math">\({\varphi}_j\)</span>
(i.e., <span class="math">\({\varphi}_i{\varphi}_j\neq 0\)</span>) if and only if
<span class="math">\(i\)</span> and <span class="math">\(j\)</span> are vertices in the same cell. Therefore, the integral
of <span class="math">\({\varphi}_i{\varphi}_j\)</span> over an element is nonzero only when <span class="math">\(i\)</span> and <span class="math">\(j\)</span>
run over the vertex numbers in the element. These nonzero contributions
to the coefficient matrix are, as in 1D, collected in an element matrix.
The size of the element matrix becomes <span class="math">\(3\times 3\)</span> since there are
three degrees of freedom
that <span class="math">\(i\)</span> and <span class="math">\(j\)</span> run over. Again, as in 1D, we number the
local vertices in a cell, starting at 0, and add the entries in
the element matrix into the global system matrix, exactly as in 1D.
All details and code appear below.</p>
</div>
</div>
<div class="section" id="basis-functions-over-triangles-in-the-reference-cell">
<h2>Basis functions over triangles in the reference cell<a class="headerlink" href="#basis-functions-over-triangles-in-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<p>As in 1D, we can define the basis functions and the degrees of freedom
in a reference cell and then use a mapping from the reference coordinate
system to the physical coordinate system.
We also have a mapping of local degrees of freedom numbers to global degrees
of freedom numbers.</p>
<p>The reference cell in an <span class="math">\((X,Y)\)</span> coordinate system has vertices
<span class="math">\((0,0)\)</span>, <span class="math">\((1,0)\)</span>, and <span class="math">\((0,1)\)</span>, corresponding to local vertex numbers
0, 1, and 2, respectively. The P1 element has linear functions
<span class="math">\({\tilde{\varphi}}_r(X,Y)\)</span> as basis functions, <span class="math">\(r=0,1,2\)</span>.
Since a linear function <span class="math">\({\tilde{\varphi}}_r(X,Y)\)</span> in 2D is on
the form <span class="math">\(C_{r,0} + C_{r,1}X + C_{r,2}Y\)</span>, and hence has three
parameters <span class="math">\(C_{r,0}\)</span>, <span class="math">\(C_{r,1}\)</span>, and <span class="math">\(C_{r,2}\)</span>, we need three
degrees of freedom. These are in general taken as the function values at a
set of nodes. For the P1 element the set of nodes is the three vertices.
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p12d"><em>2D P1 element</em></a> displays the geometry of the
element and the location of the nodes.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p12d">
<img alt="_images/P1_2d1.png" src="_images/P1_2d1.png" style="width: 100px;" />
<p class="caption"><em>2D P1 element</em></p>
</div>
<p>Requiring <span class="math">\({\tilde{\varphi}}_r=1\)</span> at node number <span class="math">\(r\)</span> and
<span class="math">\({\tilde{\varphi}}_r=0\)</span> at the two other nodes, gives three linear equations to
determine <span class="math">\(C_{r,0}\)</span>, <span class="math">\(C_{r,1}\)</span>, and <span class="math">\(C_{r,2}\)</span>. The result is</p>
<div class="math">
\[{\tilde{\varphi}}_0(X,Y) = 1 - X - Y,\]</div>
<div class="math">
\[{\tilde{\varphi}}_1(X,Y) = X,\]</div>
<div class="math">
\[{\tilde{\varphi}}_2(X,Y) = Y\]</div>
<p>Higher-order approximations are obtained by increasing the polynomial order,
adding additional nodes, and letting the degrees of freedom be
function values at the nodes. Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p22d"><em>2D P2 element</em></a>
shows the location of the six nodes in the P2 element.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p22d">
<img alt="_images/P2_2d1.png" src="_images/P2_2d1.png" style="width: 100px;" />
<p class="caption"><em>2D P2 element</em></p>
</div>
<p>A polynomial of degree <span class="math">\(p\)</span> in <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> has <span class="math">\(n_p=(p+1)(p+2)/2\)</span> terms
and hence needs <span class="math">\(n_p\)</span> nodes. The values at the nodes constitute <span class="math">\(n_p\)</span>
degrees of freedom. The location of the nodes for
<span class="math">\({\tilde{\varphi}}_r\)</span> up to degree 6 is displayed in Figure
<a class="reference internal" href="#fem-approx-fe-2d-fig-p162d"><em>2D P1, P2, P3, P4, P5, and P6 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p162d">
<img alt="_images/P1-6_2d1.png" src="_images/P1-6_2d1.png" style="width: 400px;" />
<p class="caption"><em>2D P1, P2, P3, P4, P5, and P6 elements</em></p>
</div>
<p>The generalization to 3D is straightforward: the reference element is a
<a class="reference external" href="http://en.wikipedia.org/wiki/Tetrahedron">tetrahedron</a>
with vertices <span class="math">\((0,0,0)\)</span>, <span class="math">\((1,0,0)\)</span>, <span class="math">\((0,1,0)\)</span>, and <span class="math">\((0,0,1)\)</span>
in a <span class="math">\(X,Y,Z\)</span> reference coordinate system. The P1 element has its degrees
of freedom as four nodes, which are the four vertices, see Figure
<a class="reference internal" href="#fem-approx-fe-2d-fig-p1-123d"><em>P1 elements in 1D, 2D, and 3D</em></a>. The P2 element adds additional
nodes along the edges of the cell, yielding a total of 10 nodes and
degrees of freedom, see
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p2-123d"><em>P2 elements in 1D, 2D, and 3D</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p1-123d">
<img alt="_images/P1-1d2d3d1.png" src="_images/P1-1d2d3d1.png" style="width: 400px;" />
<p class="caption"><em>P1 elements in 1D, 2D, and 3D</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-p2-123d">
<img alt="_images/P2-1d2d3d1.png" src="_images/P2-1d2d3d1.png" style="width: 400px;" />
<p class="caption"><em>P2 elements in 1D, 2D, and 3D</em></p>
</div>
<span class="target" id="index-57"></span><span class="target" id="index-58"></span><span class="target" id="index-59"></span><p id="index-60">The interval in 1D, the triangle in 2D, the tetrahedron in 3D, and
its generalizations to higher space dimensions are known
as <em>simplex</em> cells (the geometry) or <em>simplex</em> elements (the geometry,
basis functions, degrees of freedom, etc.). The plural forms
<a class="reference external" href="http://en.wikipedia.org/wiki/Simplex">simplices</a> and
simplexes are
also a much used shorter terms when referring to this type of cells or elements.
The side of a simplex is called a <em>face</em>, while the tetrahedron also
has <em>edges</em>.</p>
<p><em>Acknowledgment.</em> Figures <a class="reference internal" href="#fem-approx-fe-2d-fig-p12d"><em>2D P1 element</em></a> to <a class="reference internal" href="#fem-approx-fe-2d-fig-p2-123d"><em>P2 elements in 1D, 2D, and 3D</em></a>
are created by Anders Logg and taken from the <a class="reference external" href="https://launchpad.net/fenics-book">FEniCS book</a>: <em>Automated Solution of Differential Equations by the Finite Element Method</em>, edited by A. Logg, K.-A. Mardal, and G. N. Wells, published
by <a class="reference external" href="http://goo.gl/lbyVMH">Springer</a>, 2012.</p>
</div>
<div class="section" id="affine-mapping-of-the-reference-cell">
<h2>Affine mapping of the reference cell<a class="headerlink" href="#affine-mapping-of-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\({\tilde{\varphi}}_r^{(1)}\)</span> denote the basis functions associated
with the P1 element in 1D, 2D, or 3D, and let <span class="math">\(\boldsymbol{x}_{q(e,r)}\)</span> be
the physical coordinates of local vertex number <span class="math">\(r\)</span> in cell <span class="math">\(e\)</span>.
Furthermore,
let <span class="math">\(\boldsymbol{X}\)</span> be a point in the reference coordinate system corresponding
to the point <span class="math">\(\boldsymbol{x}\)</span> in the physical coordinate system.
The affine mapping of any <span class="math">\(\boldsymbol{X}\)</span> onto <span class="math">\(\boldsymbol{x}\)</span> is
then defined by</p>
<div class="math" id="equation-fem:approx:fe:affine:map">
<span id="index-61"></span><span class="eqno">(41)</span>\[     \boldsymbol{x} = \sum_{r} {\tilde{\varphi}}_r^{(1)}(\boldsymbol{X})\boldsymbol{x}_{q(e,r)},\]</div>
<p>where <span class="math">\(r\)</span> runs over the local vertex numbers in the cell.
The affine mapping essentially stretches, translates, and rotates
the triangle. Straight or planar faces of the reference cell are
therefore mapped onto
straight or planar faces in the physical coordinate system. The mapping can
be used for both P1 and higher-order elements, but note that the
mapping itself always applies the P1 basis functions.</p>
<div class="figure" id="fem-approx-fe-map-fig-2dp1">
<img alt="_images/ElmT3n2D_map1.png" src="_images/ElmT3n2D_map1.png" style="width: 400px;" />
<p class="caption"><em>Affine mapping of a P1 element</em></p>
</div>
</div>
<div class="section" id="isoparametric-mapping-of-the-reference-cell">
<h2>Isoparametric mapping of the reference cell<a class="headerlink" href="#isoparametric-mapping-of-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-62"></span><p id="index-63">Instead of using the P1 basis functions in the mapping
<a href="#equation-fem:approx:fe:affine:map">(41)</a>,
we may use the basis functions of the actual P$d$ element:</p>
<div class="math" id="equation-fem:approx:fe:isop:map">
<span class="eqno">(42)</span>\[     \boldsymbol{x} = \sum_{r} {\tilde{\varphi}}_r(\boldsymbol{X})\boldsymbol{x}_{q(e,r)},\]</div>
<p>where <span class="math">\(r\)</span> runs over all nodes, i.e., all points associated with the
degrees of freedom. This is called an <em>isoparametric mapping</em>.
For P1 elements it is identical to the affine mapping
<a href="#equation-fem:approx:fe:affine:map">(41)</a>, but for higher-order elements
the mapping of the straight or planar faces of the reference cell will
result in a <em>curved</em> face in the physical coordinate system.
For example, when we use the basis functions of the triangular P2 element
in 2D in <a href="#equation-fem:approx:fe:isop:map">(42)</a>, the straight faces of the
reference triangle are mapped onto curved faces of parabolic shape in
the physical coordinate system, see Figure <a class="reference internal" href="#fem-approx-fe-map-fig-2dp2"><em>Isoparametric mapping of a P2 element</em></a>.</p>
<div class="figure" id="fem-approx-fe-map-fig-2dp2">
<img alt="_images/ElmT6n2D_map1.png" src="_images/ElmT6n2D_map1.png" style="width: 400px;" />
<p class="caption"><em>Isoparametric mapping of a P2 element</em></p>
</div>
<p>From <a href="#equation-fem:approx:fe:affine:map">(41)</a> or
<a href="#equation-fem:approx:fe:isop:map">(42)</a> it is easy to realize that the
vertices are correctly mapped. Consider a vertex with local number <span class="math">\(s\)</span>.
Then <span class="math">\({\tilde{\varphi}}_s=1\)</span> at this vertex and zero at the others.
This means that only one term in the sum is nonzero and <span class="math">\(\boldsymbol{x}=\boldsymbol{x}_{q(e,s)}\)</span>,
which is the coordinate of this vertex in the global coordinate system.</p>
</div>
<div class="section" id="computing-integrals">
<h2>Computing integrals<a class="headerlink" href="#computing-integrals" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\tilde\Omega^r\)</span> denote the reference cell and <span class="math">\(\Omega^{(e)}\)</span>
the cell in the physical coordinate system. The transformation of
the integral from the physical to the reference coordinate system reads</p>
<div class="math">
\[\int_{\Omega^{(e)}}{\varphi}_i (\boldsymbol{x}) {\varphi}_j (\boldsymbol{x}) {\, \mathrm{d}x} =
\int_{\tilde\Omega^r} {\tilde{\varphi}}_i (\boldsymbol{X}) {\tilde{\varphi}}_j (\boldsymbol{X})
\det J\, {\, \mathrm{d}X},\]</div>
<div class="math">
\[\int_{\Omega^{(e)}}{\varphi}_i (\boldsymbol{x}) f(\boldsymbol{x}) {\, \mathrm{d}x} =
\int_{\tilde\Omega^r} {\tilde{\varphi}}_i (\boldsymbol{X}) f(\boldsymbol{x}(\boldsymbol{X})) \det J\, {\, \mathrm{d}X},\]</div>
<p>where <span class="math">\({\, \mathrm{d}x}\)</span> means the infinitesimal area element <span class="math">\(dx dy\)</span> in 2D and
<span class="math">\(dx dy dz\)</span> in 3D, with a similar
definition of <span class="math">\({\, \mathrm{d}X}\)</span>. The quantity <span class="math">\(\det J\)</span> is the determinant of the
Jacobian of the mapping <span class="math">\(\boldsymbol{x}(\boldsymbol{X})\)</span>. In 2D,</p>
<div class="math" id="equation-fem:approx:fe:2D:mapping:J:detJ">
<span class="eqno">(43)</span>\[\begin{split}     J = \left[\begin{array}{cc}
     \frac{\partial x}{\partial X} &amp; \frac{\partial x}{\partial Y}\\
     \frac{\partial y}{\partial X} &amp; \frac{\partial y}{\partial Y}
     \end{array}\right], \quad
     \det J = \frac{\partial x}{\partial X}\frac{\partial y}{\partial Y}
     - \frac{\partial x}{\partial Y}\frac{\partial y}{\partial X}
     {\thinspace .}\end{split}\]</div>
<p>With the affine mapping
<a href="#equation-fem:approx:fe:affine:map">(41)</a>, <span class="math">\(\det J=2\Delta\)</span>, where <span class="math">\(\Delta\)</span> is
the area or volume of the cell in the physical coordinate system.</p>
<p><em>Remark.</em> Observe that finite elements in 2D and 3D builds on the same
<em>ideas</em> and <em>concepts</em> as in 1D, but there is simply much
more to compute because the
specific mathematical formulas in 2D and 3D are more complicated
and the book keeping with dof maps also gets more complicated.
The manual work is tedious, lengthy, and error-prone
so automation by the computer is a must.</p>
</div>
</div>
<div class="section" id="exercises">
<h1>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h1>
<div class="section" id="exercise-1-linear-algebra-refresher-i">
<span id="fem-approx-exer-linalg1"></span><h2>Exercise 1: Linear algebra refresher I<a class="headerlink" href="#exercise-1-linear-algebra-refresher-i" title="Permalink to this headline">¶</a></h2>
<p>Look up the topic of <em>vector space</em> in your favorite linear algebra
book or search for the term at Wikipedia.
Prove that vectors in the plane <span class="math">\((a,b)\)</span> form a vector space
by showing that all the axioms of a vector space
are satisfied. Similarly,
prove that all linear functions of the form <span class="math">\(ax+b\)</span> constitute a vector space,
<span class="math">\(a,b\in\mathbb{R}\)</span>.</p>
<p>On the contrary,
show that all quadratic functions of the form <span class="math">\(1 + ax^2 + bx\)</span> <em>do not</em>
constitute a vector space.
Filename: <tt class="docutils literal"><span class="pre">linalg1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-2-linear-algebra-refresher-ii">
<span id="fem-approx-exer-linalg2"></span><h2>Exercise 2: Linear algebra refresher II<a class="headerlink" href="#exercise-2-linear-algebra-refresher-ii" title="Permalink to this headline">¶</a></h2>
<p>As an extension of <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a>, check out
the topic of <em>inner product spaces</em>. Suggest a possible inner product
for the space of all linear functions of the form <span class="math">\(ax+b\)</span>, <span class="math">\(a,b\in\mathbb{R}\)</span>.
Show that this inner product satisfies the
general requirements of an inner product in a vector space.
Filename: <tt class="docutils literal"><span class="pre">linalg2.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-3-approximate-a-three-dimensional-vector-in-a-plane">
<span id="fem-approx-exer-vec-3dby2d"></span><h2>Exercise 3: Approximate a three-dimensional vector in a plane<a class="headerlink" href="#exercise-3-approximate-a-three-dimensional-vector-in-a-plane" title="Permalink to this headline">¶</a></h2>
<p>Given <span class="math">\(\boldsymbol{f} = (1,1,1)\)</span> in <span class="math">\(\mathbb{R}^3\)</span>, find the best approximation vector
<span class="math">\(\boldsymbol{u}\)</span> in the plane spanned by the unit vectors <span class="math">\((1,0)\)</span> and <span class="math">\((0,1)\)</span>.
Repeat the calculations using the vectors <span class="math">\((2,1)\)</span> and <span class="math">\((1,2)\)</span>.
Filename: <tt class="docutils literal"><span class="pre">vec111_approx.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-4-approximate-the-exponential-function-by-power-functions">
<span id="fem-approx-exer-exp-powers"></span><h2>Exercise 4: Approximate the exponential function by power functions<a class="headerlink" href="#exercise-4-approximate-the-exponential-function-by-power-functions" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(V\)</span> be a function space with basis functions
<span class="math">\(x^{2i+1}\)</span>, <span class="math">\(i=0,1,\ldots,N\)</span>.
Find the best approximation to <span class="math">\(f(x)=\exp(-x)\)</span> on <span class="math">\(\Omega =[0,4]\)</span>
among all functions in <span class="math">\(V\)</span>
for <span class="math">\(N=2,3,4\)</span>. Illustrate the three approximations in three separate plots.
Filename: <tt class="docutils literal"><span class="pre">exp_powers.py</span></tt>.</p>
</div>
<div class="section" id="exercise-5-approximate-the-sine-function-by-power-functions">
<span id="fem-approx-exer-sin-powers"></span><h2>Exercise 5: Approximate the sine function by power functions<a class="headerlink" href="#exercise-5-approximate-the-sine-function-by-power-functions" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(V\)</span> be a function space with basis functions
<span class="math">\(x^{2i+1}\)</span>, <span class="math">\(i=0,1,\ldots,N\)</span>.
Find the best approximation to <span class="math">\(f(x)=\sin(x)\)</span> among all functions in <span class="math">\(V\)</span>,
using <span class="math">\(N=8\)</span> for a domain that includes more and more half-periods of
the sine function: <span class="math">\(\Omega = [0, k\pi/2]\)</span>, <span class="math">\(k=2,3,\ldots,12\)</span>.
How does a Taylor series of <span class="math">\(\sin(x)\)</span> around <span class="math">\(x\)</span> up to degree 9
behave for the largest domain?</p>
<p><em>Hint.</em> One can make a loop over <span class="math">\(k\)</span> and call the functions <tt class="docutils literal"><span class="pre">least_squares</span></tt> and
<tt class="docutils literal"><span class="pre">comparison_plot</span></tt> from the <tt class="docutils literal"><span class="pre">approx1D</span></tt> module.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">sin_powers.py</span></tt>.</p>
</div>
<div class="section" id="exercise-6-approximate-a-steep-function-by-sines">
<span id="fem-approx-exer-tanh-sine1"></span><h2>Exercise 6: Approximate a steep function by sines<a class="headerlink" href="#exercise-6-approximate-a-steep-function-by-sines" title="Permalink to this headline">¶</a></h2>
<p>Find the best approximation of <span class="math">\(f(x) = \tanh (s(x-\pi))\)</span> on
<span class="math">\([0, 2\pi]\)</span> in the space <span class="math">\(V\)</span> with basis
<span class="math">\({\varphi}_i(x) = \sin((2i+1)x)\)</span>, <span class="math">\(i\inI\)</span>.
Make a movie showing how <span class="math">\(u=\sum_{j\inI}c_j{\varphi}_j(x)\)</span>
approximates <span class="math">\(f(x)\)</span> as <span class="math">\(N\)</span> grows. Choose <span class="math">\(s\)</span> such that <span class="math">\(f\)</span> is
steep (<span class="math">\(s=20\)</span> may be appropriate).</p>
<p><em>Hint.</em> One may naively call the <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> and <tt class="docutils literal"><span class="pre">comparison_plot</span></tt>
from the <tt class="docutils literal"><span class="pre">approx1D</span></tt> module in a loop and extend the basis with
one new element in each pass. This approach
implies a lot of recomputations.
A more efficient strategy is to let <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt>
compute with only one basis function at a time and accumulate
the corresponding <tt class="docutils literal"><span class="pre">u</span></tt> in the total solution.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">tanh_sines_approx1.py</span></tt>.</p>
</div>
<div class="section" id="exercise-7-fourier-series-as-a-least-squares-approximation">
<span id="fem-approx-exer-fourier"></span><h2>Exercise 7: Fourier series as a least squares approximation<a class="headerlink" href="#exercise-7-fourier-series-as-a-least-squares-approximation" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span> on an interval <span class="math">\([0,L]\)</span>, look up the formula
for the coefficients <span class="math">\(a_j\)</span> and <span class="math">\(b_j\)</span> in the Fourier series of <span class="math">\(f\)</span>:</p>
<div class="math">
\[f(x) = a_0 + \sum_{j=1}^\infty a_j\cos \left(j\frac{\pi x}{L}\right)
+ \sum_{j=1}^\infty b_j\sin \left(j\frac{\pi x}{L}\right){\thinspace .}\]</div>
<p>Let an infinite-dimensional vector space <span class="math">\(V\)</span> have the basis functions
<span class="math">\(\cos j\frac{\pi x}{L}\)</span> for <span class="math">\(j=0,1,\dots,\infty\)</span> and
<span class="math">\(\sin j\frac{\pi x}{L}\)</span> for <span class="math">\(j=1,\dots,\infty\)</span>.  Show that the least squares
approximation method from the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> leads to a
linear system whose solution coincides with the standard formulas for
the coefficients in a Fourier series of <span class="math">\(f(x)\)</span> (see also
the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>). You may choose</p>
<div class="math">
\[{\varphi}_{2i} = \cos\left( i\frac{\pi}{L}x\right),\quad
{\varphi}_{2i+1} = \sin\left( i\frac{\pi}{L}x\right),\]</div>
<p>for <span class="math">\(i=0,1,\ldots,N\rightarrow\infty\)</span>.</p>
<p>Choose <span class="math">\(f(x) = \tanh(s(x-\frac{1}{2}))\)</span> on <span class="math">\(\Omega=[0,1]\)</span>, which is
a smooth function, but with considerable steepness around <span class="math">\(x=1/2\)</span>
as <span class="math">\(s\)</span> grows in size.
Calculate the coefficients in the Fourier expansion by
solving the linear system, arising from the least squares or Galerkin
methods, by hand. Plot
some truncated versions of the series together with <span class="math">\(f(x)\)</span> to show how
the series expansion converges for <span class="math">\(s=10\)</span> and <span class="math">\(s=100\)</span>.
Filename: <tt class="docutils literal"><span class="pre">Fourier_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-8-approximate-a-steep-function-by-lagrange-polynomials">
<span id="fem-approx-exer-tanh"></span><h2>Exercise 8: Approximate a steep function by Lagrange polynomials<a class="headerlink" href="#exercise-8-approximate-a-steep-function-by-lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p>Use interpolation/collocation with uniformly distributed
points and Chebychev nodes to approximate</p>
<div class="math">
\[f(x) = -\tanh(s(x-\frac{1}{2})),\quad x\in [0,1],\]</div>
<p>by Lagrange polynomials for <span class="math">\(s=10,100\)</span> and <span class="math">\(N=3,6,9,11\)</span>.
Make separate plots of the approximation for each combination of
<span class="math">\(s\)</span>, point type (Chebyshev or uniform), and <span class="math">\(N\)</span>.
Filename: <tt class="docutils literal"><span class="pre">tanh_Lagrange.py</span></tt>.</p>
</div>
<div class="section" id="exercise-9-define-nodes-and-elements">
<span id="fem-approx-fe-exer-mesh1"></span><h2>Exercise 9: Define nodes and elements<a class="headerlink" href="#exercise-9-define-nodes-and-elements" title="Permalink to this headline">¶</a></h2>
<p>Consider a domain <span class="math">\(\Omega =[0,2]\)</span> divided into the three elements
<span class="math">\([0,1]\)</span>, <span class="math">\([1,1.2]\)</span>, and <span class="math">\([1.2,2]\)</span>, with two nodes in each element
(P1 elements).
Set up the list of coordinates and nodes (<tt class="docutils literal"><span class="pre">nodes</span></tt>) and the
numbers of the nodes that belong to each element (<tt class="docutils literal"><span class="pre">elements</span></tt>) in
two cases: 1) nodes and elements numbered from left to right, and 2)
nodes and elements numbered from right to left.</p>
<p>Thereafter, subdivide the element <span class="math">\([1.2,2]\)</span> into two new equal-sized elements.
Add the new node and the two new elements to the data structures created above,
and try to minimize the modifications.
Filename: <tt class="docutils literal"><span class="pre">fe_numberings1.py.</span></tt>.</p>
</div>
<div class="section" id="exercise-10-define-vertices-cells-and-dof-maps">
<span id="fem-approx-fe-exer-mesh2"></span><h2>Exercise 10: Define vertices, cells, and dof maps<a class="headerlink" href="#exercise-10-define-vertices-cells-and-dof-maps" title="Permalink to this headline">¶</a></h2>
<p>Repeat <a class="reference internal" href="#fem-approx-fe-exer-mesh2"><em>Exercise 10: Define vertices, cells, and dof maps</em></a>, but define the
data structures <tt class="docutils literal"><span class="pre">vertices</span></tt>, <tt class="docutils literal"><span class="pre">cells</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt> instead of
<tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt>.
Filename: <tt class="docutils literal"><span class="pre">fe_numberings2.py.</span></tt>.</p>
</div>
<div class="section" id="exercise-11-construct-matrix-sparsity-patterns">
<span id="fem-approx-fe-exer-defmesh-sparsity"></span><h2>Exercise 11: Construct matrix sparsity patterns<a class="headerlink" href="#exercise-11-construct-matrix-sparsity-patterns" title="Permalink to this headline">¶</a></h2>
<p><em class="xref std std-ref">fem:approx:fe:exer:defmesh</em> describes a element mesh
with a total of five elements, but with two different element and
node orderings. For each of the two orderings,
make a <span class="math">\(5\times 5\)</span> matrix and fill in the entries that will be nonzero.</p>
<p><em>Hint.</em> A matrix entry <span class="math">\((i,j)\)</span> is nonzero if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in the
same element.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">fe_sparsity_pattern.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-12-perform-symbolic-finite-element-computations">
<span id="fem-approx-fe-exer-asinwt-symbolic"></span><h2>Exercise 12: Perform symbolic finite element computations<a class="headerlink" href="#exercise-12-perform-symbolic-finite-element-computations" title="Permalink to this headline">¶</a></h2>
<p>Find formulas for the coefficient matrix and right-hand side
when approximating <span class="math">\(f(x) = sin (x)\)</span> on
<span class="math">\(\Omega=[0, \pi]\)</span> by two P1 elements of size <span class="math">\(\pi/2\)</span>.
Solve the system and compare <span class="math">\(u(\pi/2\)</span> with
the exact value 1.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">sin_approx_P1.py</span></tt>.</p>
</div>
<div class="section" id="exercise-13-approximate-a-steep-function-by-p1-and-p2-elements">
<span id="id3"></span><h2>Exercise 13: Approximate a steep function by P1 and P2 elements<a class="headerlink" href="#exercise-13-approximate-a-steep-function-by-p1-and-p2-elements" title="Permalink to this headline">¶</a></h2>
<p>Given</p>
<div class="math">
\[f(x) = \tanh(s(x-\frac{1}{2}))\]</div>
<p>use the Galerkin or least squares method with finite elements to find
an approximate function <span class="math">\(u(x)\)</span>. Choose <span class="math">\(s=40\)</span> and try
<span class="math">\(N_e=4,8,16\)</span> P1 elements and
<span class="math">\(N_e=2,4,8\)</span> P2 elements.
Integrate <span class="math">\(f{\varphi}_i\)</span> numerically.
Filename: <tt class="docutils literal"><span class="pre">tanh_fe_P1P2_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-14-approximate-a-function-by-p3-and-p4-elements">
<span id="fem-approx-exer-tanh2"></span><h2>Exercise 14: Approximate a <span class="math">\(\tanh\)</span> function by P3 and P4 elements<a class="headerlink" href="#exercise-14-approximate-a-function-by-p3-and-p4-elements" title="Permalink to this headline">¶</a></h2>
<p>Solve <em class="xref std std-ref">fem:approx:exer:tanh</em> using <span class="math">\(N_e=1,2,4\)</span> P3 and P4
elements. How will a collocation/interpolation method work in
this case with the same number of nodes?
Filename: <tt class="docutils literal"><span class="pre">tanh_fe_P3P4_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-15-investigate-the-approximation-error-in-finite-elements">
<span id="fem-approx-fe-exer-asinwt-interpol-error"></span><h2>Exercise 15: Investigate the approximation error in finite elements<a class="headerlink" href="#exercise-15-investigate-the-approximation-error-in-finite-elements" title="Permalink to this headline">¶</a></h2>
<p>The theory <a href="#equation-fem:approx:fe:error:theorem">(39)</a> from
the section <em class="xref std std-ref">fem:approx:fe:error</em> predicts that the
error in the P$d$ approximation of a function
should behave as <span class="math">\(h^{d+1}\)</span>. Use experiments to verify this
asymptotic behavior (i.e., for small enough <span class="math">\(h\)</span>).
Choose two examples: <span class="math">\(f(x)=Ae^{-\omega x}\)</span> on <span class="math">\([0,3/\omega]\)</span>
and <span class="math">\(f(x) = A\sin (\omega x)\)</span> on <span class="math">\(\Omega=[0, 2\pi/\omega]\)</span> for
constants <span class="math">\(A\)</span> and <span class="math">\(\omega\)</span>. What happens if you try
<span class="math">\(f(x)=\sqrt{x}\)</span> on <span class="math">\([0,1]\)</span>?</p>
<p><em>Hint.</em> Run a series of experiments: <span class="math">\((h_i,E_)\)</span>, <span class="math">\(i=0,\ldots,m\)</span>, where <span class="math">\(E_i\)</span>
is the <span class="math">\(L^2\)</span> norm of the error corresponding to element length <span class="math">\(h_i\)</span>.
Assume an error model <span class="math">\(E=Ch^r\)</span> and compute <span class="math">\(r\)</span> from two successive
experiments:</p>
<div class="math">
\[r_i = \ln (E_{i+1}/E_i)/\ln (h_{i+1}/h_i),\quad i=0,\ldots,m-1{\thinspace .}\]</div>
<p>Hopefully, the sequence <span class="math">\(r_0,\ldots,r_{m-1}\)</span> converges to the true
<span class="math">\(r\)</span>, and <span class="math">\(r_{m-1}\)</span> can be taken as an approximation to <span class="math">\(r\)</span>.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">Asinwt_interpolation_error.py</span></tt>.</p>
</div>
<div class="section" id="exercise-16-approximate-a-step-function-by-finite-elements">
<span id="fem-approx-fe-exer-heaviside"></span><h2>Exercise 16: Approximate a step function by finite elements<a class="headerlink" href="#exercise-16-approximate-a-step-function-by-finite-elements" title="Permalink to this headline">¶</a></h2>
<p>Approximate the step function</p>
<div class="math">
\[\begin{split}f(x) = \left\lbrace\begin{array}{ll}
1 &amp; x &lt; {1/2},\\
2 &amp; x \geq {1/2}
\end{array}\right.\end{split}\]</div>
<p>by 2, 4, and 8 P1 and P2 elements. Compare
approximations visually.</p>
<p><em>Hint.</em> This <span class="math">\(f\)</span> can also be expressed in terms of the Heaviside function <span class="math">\(H(x)\)</span>:
<span class="math">\(f(x) = H(x-{1/2})\)</span>.
Therefore, <span class="math">\(f\)</span> can be defined by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Heaviside</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span>  <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>making the <tt class="docutils literal"><span class="pre">approximate</span></tt> function in the
<tt class="docutils literal"><span class="pre">fe_approx1D.py</span></tt> module an obvious candidate to solve the
problem. However, <tt class="docutils literal"><span class="pre">sympy</span></tt> does not handle symbolic integration
with this particular integrand, and the <tt class="docutils literal"><span class="pre">approximate</span></tt> function faces a problem
when converting <tt class="docutils literal"><span class="pre">f</span></tt> to a Python function (for plotting) since
<tt class="docutils literal"><span class="pre">Heaviside</span></tt> is not an available function in <tt class="docutils literal"><span class="pre">numpy</span></tt>. It is better to make
special-purpose code for this case or perform all
calculations by hand.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">Heaviside_approx_P1P2.py.</span></tt>.</p>
</div>
<div class="section" id="exercise-17-2d-approximation-with-orthogonal-functions">
<span id="fem-approx-fe-exer-2dsines-symbolic"></span><h2>Exercise 17: 2D approximation with orthogonal functions<a class="headerlink" href="#exercise-17-2d-approximation-with-orthogonal-functions" title="Permalink to this headline">¶</a></h2>
<p>Assume we have basis functions <span class="math">\({\varphi}_i(x,y)\)</span> in 2D that are
orthogonal
such that <span class="math">\(({\varphi}_i,{\varphi}_j)=0\)</span> when <span class="math">\(i\neq j\)</span>.
The function <tt class="docutils literal"><span class="pre">least_squares</span></tt> in the
file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx2D.py">approx2D.py</a> will then spend much time on computing off-diagonal terms
in the coefficient matrix that we know are zero.
To speed up the computations, make a
version <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> that utilizes the orthogonality among the
basis functions. Apply the function to approximate</p>
<div class="math">
\[f(x,y) = x(1-x)y(1-y)e^{-x-y}\]</div>
<p>on <span class="math">\(\Omega = [0,1]\times [0,1]\)</span> via basis functions</p>
<div class="math">
\[{\varphi}_i(x,y) = \sin (p\pi x)\sin(q\pi y),\quad i=q N_x + p
{\thinspace .}\]</div>
<p><em>Hint.</em> Get ideas from the function <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> in
the section <a class="reference internal" href="#fem-approx-global-orth"><em>Orthogonal basis functions</em></a> and
file <a class="reference external" href="http://tinyurl.com/jvzzcfn/fem/fe_approx1D.py">approx1D.py</a>.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">approx2D_lsorth_sin.py</span></tt>.</p>
</div>
<div class="section" id="exercise-18-use-the-trapezoidal-rule-and-p1-elements">
<span id="fem-approx-fe-exer-1d-trapez"></span><h2>Exercise 18: Use the Trapezoidal rule and P1 elements<a class="headerlink" href="#exercise-18-use-the-trapezoidal-rule-and-p1-elements" title="Permalink to this headline">¶</a></h2>
<p>Consider approximation of some <span class="math">\(f(x)\)</span> on an interval <span class="math">\(\Omega\)</span> using
the least squares or Galerkin methods with P1 elements. Derive
the element matrix and vector using the
Trapezoidal rule <a href="#equation-fem:approx:fe:numint1:trapez">(40)</a> for calculating
integrals on the reference element. Assemble the contributions, assuming
a uniform cell partitioning, and show that the resulting linear system
has the form <span class="math">\(c_i=f(x_{i})\)</span> for <span class="math">\(i\inI\)</span>.
Filename: <tt class="docutils literal"><span class="pre">fe_trapez.pdf</span></tt>.</p>
</div>
<div class="section" id="problem-19-compare-p1-elements-and-interpolation">
<span id="fem-approx-fe-exer-1d-p1-vs-interp"></span><h2>Problem 19: Compare P1 elements and interpolation<a class="headerlink" href="#problem-19-compare-p1-elements-and-interpolation" title="Permalink to this headline">¶</a></h2>
<p>We shall approximate the function</p>
<div class="math">
\[f(x) = 1 + \epsilon\sin (2\pi nx),\quad x\in \Omega = [0,1],\]</div>
<p>where <span class="math">\(n\in\mathbb{Z}\)</span> and <span class="math">\(\epsilon \geq 0\)</span>.</p>
<p><em>a)</em> Sketch <span class="math">\(f(x)\)</span> and find the wave length of the function.</p>
<p><em>b)</em> We want to use <span class="math">\(N_P\)</span> elements per wave length. Show that the number
of elements is then <span class="math">\(nN_P\)</span>.</p>
<p><em>c)</em> The critical quantity for accuracy is the number of elements per
wave length, not the element size in itself. It therefore suffices
to study an <span class="math">\(f\)</span> with just one wave length in <span class="math">\(\Omega = [0,1]\)</span>.
Set <span class="math">\(\epsilon = 0.5\)</span>.</p>
<p>Run the least squares or projection/Galerkin method for
<span class="math">\(N_P=2,4,8,16,32\)</span>. Compute the error <span class="math">\(E=||u-f||_{L^2}\)</span>.</p>
<p><em>Hint.</em> Use the <tt class="docutils literal"><span class="pre">fe_approx1D_numint</span></tt> module to compute <span class="math">\(u\)</span> and use
the technique from the section <a class="reference internal" href="#fem-approx-fe-element-impl-error"><em>Computing the error of the approximation</em></a> to
compute the norm of the error.</p>
<p><em>d)</em> Repeat the set of experiments in the above point, but
use interpolation/collocation based on the node points to
compute <span class="math">\(u(x)\)</span> (recall that <span class="math">\(c_i\)</span> is now simply <span class="math">\(f(x_{i})\)</span>).
Compute the error <span class="math">\(E=||u-f||_{L^2}\)</span>.
Which method seems to be most accurate?</p>
<p>Filename: <tt class="docutils literal"><span class="pre">P1_vs_interp.py</span></tt>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Approximation of functions with finite elements</a></li>
<li><a class="reference internal" href="#approximation-of-vectors">Approximation of vectors</a><ul>
<li><a class="reference internal" href="#approximation-of-planar-vectors">Approximation of planar vectors</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-1">The least squares method  (1)</a></li>
<li><a class="reference internal" href="#the-projection-method">The projection method</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-general-vectors">Approximation of general vectors</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-2">The least squares method  (2)</a></li>
<li><a class="reference internal" href="#the-galerkin-or-projection-method">The Galerkin or projection method</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-functions">Approximation of functions</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-3">The least squares method  (3)</a></li>
<li><a class="reference internal" href="#the-projection-or-galerkin-method">The projection (or Galerkin) method</a></li>
<li><a class="reference internal" href="#example-linear-approximation">Example: linear approximation</a></li>
<li><a class="reference internal" href="#implementation-of-the-least-squares-method">Implementation of the least squares method</a></li>
<li><a class="reference internal" href="#perfect-approximation">Perfect approximation</a></li>
<li><a class="reference internal" href="#ill-conditioning">Ill-conditioning</a></li>
<li><a class="reference internal" href="#fourier-series">Fourier series</a></li>
<li><a class="reference internal" href="#orthogonal-basis-functions">Orthogonal basis functions</a></li>
<li><a class="reference internal" href="#the-interpolation-or-collocation-method">The interpolation (or collocation) method</a><ul>
<li><a class="reference internal" href="#example-1">Example  (1)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lagrange-polynomials">Lagrange polynomials</a><ul>
<li><a class="reference internal" href="#approximation-of-a-polynomial">Approximation of a polynomial</a></li>
<li><a class="reference internal" href="#successful-example">Successful example</a></li>
<li><a class="reference internal" href="#less-successful-example">Less successful example</a></li>
<li><a class="reference internal" href="#remedy-for-strong-oscillations">Remedy for strong oscillations</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#finite-element-basis-functions">Finite element basis functions</a><ul>
<li><a class="reference internal" href="#elements-and-nodes">Elements and nodes</a><ul>
<li><a class="reference internal" href="#example-2">Example  (2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-basis-functions">The basis functions</a><ul>
<li><a class="reference internal" href="#construction-principles">Construction principles</a></li>
<li><a class="reference internal" href="#properties-of">Properties of <span class="math">\({\varphi}_i\)</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-on-piecewise-quadratic-finite-element-functions">Example on piecewise quadratic finite element functions</a></li>
<li><a class="reference internal" href="#example-on-piecewise-linear-finite-element-functions">Example on piecewise linear finite element functions</a></li>
<li><a class="reference internal" href="#example-on-piecewise-cubic-finite-element-basis-functions">Example on piecewise cubic finite element basis functions</a></li>
<li><a class="reference internal" href="#calculating-the-linear-system">Calculating the linear system</a><ul>
<li><a class="reference internal" href="#calculating-a-specific-matrix-entry">Calculating a specific matrix entry</a></li>
<li><a class="reference internal" href="#calculating-a-general-row-in-the-matrix">Calculating a general row in the matrix</a></li>
</ul>
</li>
<li><a class="reference internal" href="#assembly-of-elementwise-computations">Assembly of elementwise computations</a></li>
<li><a class="reference internal" href="#mapping-to-a-reference-element">Mapping to a reference element</a></li>
<li><a class="reference internal" href="#example-integration-over-a-reference-element">Example: Integration over a reference element</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-1">Implementation  (1)</a><ul>
<li><a class="reference internal" href="#integration">Integration</a></li>
<li><a class="reference internal" href="#linear-system-assembly-and-solution">Linear system assembly and solution</a></li>
<li><a class="reference internal" href="#example-on-computing-symbolic-approximations">Example on computing symbolic approximations</a></li>
<li><a class="reference internal" href="#comparison-with-finite-elements-and-interpolation-collocation">Comparison with finite elements and interpolation/collocation</a></li>
<li><a class="reference internal" href="#example-on-computing-numerical-approximations">Example on computing numerical approximations</a></li>
<li><a class="reference internal" href="#the-structure-of-the-coefficient-matrix">The structure of the coefficient matrix</a></li>
<li><a class="reference internal" href="#applications">Applications</a></li>
<li><a class="reference internal" href="#sparse-matrix-storage-and-solution">Sparse matrix storage and solution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comparison-of-finite-element-and-finite-difference-approximation">Comparison of finite element and finite difference approximation</a><ul>
<li><a class="reference internal" href="#finite-difference-approximation-of-given-functions">Finite difference approximation of given functions</a></li>
<li><a class="reference internal" href="#finite-difference-interpretation-of-a-finite-element-approximation">Finite difference interpretation of a finite element approximation</a></li>
<li><a class="reference internal" href="#making-finite-elements-behave-as-finite-differences">Making finite elements behave as finite differences</a><ul>
<li><a class="reference internal" href="#computations-in-physical-space">Computations in physical space</a></li>
<li><a class="reference internal" href="#elementwise-computations">Elementwise computations</a></li>
<li><a class="reference internal" href="#terminology">Terminology</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#a-generalized-element-concept">A generalized element concept</a><ul>
<li><a class="reference internal" href="#cells-vertices-and-degrees-of-freedom">Cells, vertices, and degrees of freedom</a></li>
<li><a class="reference internal" href="#extended-finite-element-concept">Extended finite element concept</a></li>
<li><a class="reference internal" href="#implementation-2">Implementation  (2)</a></li>
<li><a class="reference internal" href="#computing-the-error-of-the-approximation">Computing the error of the approximation</a></li>
<li><a class="reference internal" href="#example-cubic-hermite-polynomials">Example: Cubic Hermite polynomials</a></li>
</ul>
</li>
<li><a class="reference internal" href="#numerical-integration">Numerical integration</a><ul>
<li><a class="reference internal" href="#newton-cotes-rules">Newton-Cotes rules</a></li>
<li><a class="reference internal" href="#gauss-legendre-rules-with-optimized-points">Gauss-Legendre rules with optimized points</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-functions-in-2d">Approximation of functions in 2D</a><ul>
<li><a class="reference internal" href="#global-basis-functions">Global basis functions</a><ul>
<li><a class="reference internal" href="#constructing-2d-basis-functions-from-1d-functions">Constructing 2D basis functions from 1D functions</a></li>
<li><a class="reference internal" href="#hand-calculations">Hand calculations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-3">Implementation  (3)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#finite-elements-in-2d-and-3d">Finite elements in 2D and 3D</a><ul>
<li><a class="reference internal" href="#basis-functions-over-triangles-in-the-physical-domain">Basis functions over triangles in the physical domain</a><ul>
<li><a class="reference internal" href="#element-matrices-and-vectors">Element matrices and vectors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#basis-functions-over-triangles-in-the-reference-cell">Basis functions over triangles in the reference cell</a></li>
<li><a class="reference internal" href="#affine-mapping-of-the-reference-cell">Affine mapping of the reference cell</a></li>
<li><a class="reference internal" href="#isoparametric-mapping-of-the-reference-cell">Isoparametric mapping of the reference cell</a></li>
<li><a class="reference internal" href="#computing-integrals">Computing integrals</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises">Exercises</a><ul>
<li><a class="reference internal" href="#exercise-1-linear-algebra-refresher-i">Exercise 1: Linear algebra refresher I</a></li>
<li><a class="reference internal" href="#exercise-2-linear-algebra-refresher-ii">Exercise 2: Linear algebra refresher II</a></li>
<li><a class="reference internal" href="#exercise-3-approximate-a-three-dimensional-vector-in-a-plane">Exercise 3: Approximate a three-dimensional vector in a plane</a></li>
<li><a class="reference internal" href="#exercise-4-approximate-the-exponential-function-by-power-functions">Exercise 4: Approximate the exponential function by power functions</a></li>
<li><a class="reference internal" href="#exercise-5-approximate-the-sine-function-by-power-functions">Exercise 5: Approximate the sine function by power functions</a></li>
<li><a class="reference internal" href="#exercise-6-approximate-a-steep-function-by-sines">Exercise 6: Approximate a steep function by sines</a></li>
<li><a class="reference internal" href="#exercise-7-fourier-series-as-a-least-squares-approximation">Exercise 7: Fourier series as a least squares approximation</a></li>
<li><a class="reference internal" href="#exercise-8-approximate-a-steep-function-by-lagrange-polynomials">Exercise 8: Approximate a steep function by Lagrange polynomials</a></li>
<li><a class="reference internal" href="#exercise-9-define-nodes-and-elements">Exercise 9: Define nodes and elements</a></li>
<li><a class="reference internal" href="#exercise-10-define-vertices-cells-and-dof-maps">Exercise 10: Define vertices, cells, and dof maps</a></li>
<li><a class="reference internal" href="#exercise-11-construct-matrix-sparsity-patterns">Exercise 11: Construct matrix sparsity patterns</a></li>
<li><a class="reference internal" href="#exercise-12-perform-symbolic-finite-element-computations">Exercise 12: Perform symbolic finite element computations</a></li>
<li><a class="reference internal" href="#exercise-13-approximate-a-steep-function-by-p1-and-p2-elements">Exercise 13: Approximate a steep function by P1 and P2 elements</a></li>
<li><a class="reference internal" href="#exercise-14-approximate-a-function-by-p3-and-p4-elements">Exercise 14: Approximate a <span class="math">\(\tanh\)</span> function by P3 and P4 elements</a></li>
<li><a class="reference internal" href="#exercise-15-investigate-the-approximation-error-in-finite-elements">Exercise 15: Investigate the approximation error in finite elements</a></li>
<li><a class="reference internal" href="#exercise-16-approximate-a-step-function-by-finite-elements">Exercise 16: Approximate a step function by finite elements</a></li>
<li><a class="reference internal" href="#exercise-17-2d-approximation-with-orthogonal-functions">Exercise 17: 2D approximation with orthogonal functions</a></li>
<li><a class="reference internal" href="#exercise-18-use-the-trapezoidal-rule-and-p1-elements">Exercise 18: Use the Trapezoidal rule and P1 elements</a></li>
<li><a class="reference internal" href="#problem-19-compare-p1-elements-and-interpolation">Problem 19: Compare P1 elements and interpolation</a></li>
</ul>
</li>
</ul>

  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/main_fem_approx.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li><a href="index.html">Approximation of functions with finite elements</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
  <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
  </div>
</div>

  </body>
</html>