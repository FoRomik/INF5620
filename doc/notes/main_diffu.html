<?xml version="1.0" encoding="utf-8" ?>
<!--
Automatically generated HTML file from Doconce source
(http://code.google.com/p/doconce/)
-->

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Doconce: http://code.google.com/p/doconce/" />

<!--
Color definitions:  http://www.december.com/html/spec/color0.html
CSS examples:       http://www.w3schools.com/css/css_examples.asp
-->

<style type="text/css">
    body {
      margin-top: 1.0em;
      background-color: #ffffff;
      font-family: Helvetica, Arial, FreeSans, san-serif;
      color: #000000;
    }
    h1 { font-size: 1.8em; color: #1e36ce; }
    h2 { font-size: 1.5em; color: #1e36ce; }
    h3 { color: #1e36ce; }
    a { color: #1e36ce; text-decoration:none; }
    tt { font-family: "Courier New", Courier; }
    pre { background: #ededed; color: #000; padding: 15px;}
    p { text-indent: 0px; }
    hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    p.caption { width: 80%; font-style: normal; text-align: left; }
    hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}

    .notice, .summary, .warning, .hint, .question {
    border: 1px solid; margin: 10px 0px; padding:15px 10px 15px 50px;
    background-repeat: no-repeat; background-position: 10px center;
    }
    .notice   { color: #00529B; background-color: #BDE5F8;
                background-image: url('https://doconce.googlecode.com/hg/lib/doconce/misc_software/html_images/Knob_Message.png'); }
    .summary  { color: #4F8A10; background-color: #DFF2BF;
                background-image:url('https://doconce.googlecode.com/hg/lib/doconce/misc_software/html_images/Knob_Valid_Green.png'); }
    .warning  { color: #9F6000; background-color: #FEEFB3;
                background-image: url('https://doconce.googlecode.com/hg/lib/doconce/misc_software/html_images/Knob_Attention.png'); }
    .hint     { color: #00529B; background-color: #BDE5F8;
                background-image: url('https://doconce.googlecode.com/hg/lib/doconce/misc_software/html_images/Knob_Info.png'); }
    .question { color: #4F8A10; background-color: #DFF2BF;
                background-image:url('https://doconce.googlecode.com/hg/lib/doconce/misc_software/html_images/Knob_Forward.png'); }

</style>

<!-- Use MathJax to render mathematics -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- Fix slow MathJax rendering in IE8 -->
<meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7">

</head>

<body>
    
<!-- newcommands_keep.tex -->
$$
\newcommand{\uex}{u_{\small\mbox{e}}}
\newcommand{\Aex}{A_{\small\mbox{e}}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\halfi}{{1/2}}

\newcommand{\Ddt}[1]{\frac{D #1}{dt}}

\newcommand{\xpoint}{\pmb{x}}
\newcommand{\normalvec}{\pmb{n}}

\newcommand{\x}{\pmb{x}}
\newcommand{\X}{\pmb{X}}
\renewcommand{\u}{\pmb{u}}
\renewcommand{\v}{\pmb{v}}
\newcommand{\w}{\pmb{w}}
\newcommand{\V}{\pmb{V}}
\newcommand{\e}{\pmb{e}}
\newcommand{\f}{\pmb{f}}
\newcommand{\F}{\pmb{F}}
\newcommand{\stress}{\pmb{\sigma}}
\newcommand{\strain}{\pmb{\varepsilon}}
\newcommand{\stressc}{{\sigma}}
\newcommand{\strainc}{{\varepsilon}}
\newcommand{\I}{\pmb{I}}
\newcommand{\T}{\pmb{T}}

% Unit vectors
\newcommand{\ii}{\pmb{i}}
\newcommand{\jj}{\pmb{j}}
\newcommand{\kk}{\pmb{k}}
\newcommand{\ir}{\pmb{i}_r}
\newcommand{\ith}{\pmb{i}_{\theta}}
\newcommand{\iz}{\pmb{i}_z}

% Finite elements
\newcommand{\basphi}{\varphi}
\newcommand{\refphi}{\tilde\basphi}
\newcommand{\phib}{\pmb{\varphi}}
\newcommand{\sinL}[1]{\sin\left((#1+1)\pi\frac{x}{L}\right)}
\newcommand{\xno}[1]{x_{#1}}
%\newcommand{\xno}[1]{x^{(#1)}}
\newcommand{\Xno}[1]{X_{(#1)}}
\newcommand{\yno}[1]{y_{#1}}
\newcommand{\Yno}[1]{Y_{(#1)}}
\newcommand{\xdno}[1]{\pmb{x}_{#1}}

% FEniCS commands
\newcommand{\dX}{\, \mathrm{d}X}
\newcommand{\dx}{\, \mathrm{d}x}
\newcommand{\ds}{\, \mathrm{d}s}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Integerp}{\mathbb{N}}
\newcommand{\Integer}{\mathbb{Z}}
$$



<!-- ------------------- main content ------------------------>

<title>Finite difference methods for diffusion processes</title>

<center><h1>Finite difference methods for diffusion processes</h1></center>  <! -- document title -->

<p>
<! -- author(s) -->

<center>
<b>Hans Petter Langtangen</b> [1, 2]
</center>


<p>
<!-- institution(s) -->

<center>[1] <b>Center for Biomedical Computing, Simula Research Laboratory</b></center>
<center>[2] <b>Department of Informatics, University of Oslo</b></center>


<p>
<center><h4>Dec 11, 2012</h4></center> <!-- date -->
<p>
Note: <b>VERY PRELIMINARY VERSION</b>

<p>

<h2>Table of contents</h2>

<p>

<a href="#___sec0"> A simple 1D diffusion equation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:FE"> Forward Euler scheme </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:BE"> Backward Euler Scheme </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:impl:sparse"> Sparse matrix implementation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:theta"> The \( \theta \) Rule </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec5"> The Laplace and Poisson equation as the steady state limit </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec6"> Extensions </a><br>
<a href="#___sec7"> Analysis of schemes for the diffusion equation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:analysis:uex"> Properties of the solution </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:analysis"> Analysis of the finite difference schemes </a><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#___sec10"> Stability </a><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#___sec11"> Accuracy </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:analysis:FE"> Analysis of the Forward Euler scheme </a><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#___sec13"> Stability </a><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#___sec14"> Accuracy </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:analysis:BE"> Analysis of the Backward Euler scheme </a><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#___sec16"> Stability </a><br>
&nbsp; &nbsp; &nbsp; <a href="#diffu:pde1:analysis:CN"> Analysis of the Crank-Nicolson scheme </a><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#___sec18"> Stability </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec19"> Summary of accuracy of amplification factors </a><br>

<p>




<h2>A simple 1D diffusion equation  <a name="___sec0"></a></h2>
<p>
We consider a diffusion problem for a quantity \( u(x,t) \):
$$
\begin{align}
\frac{\partial u}{\partial t} &=
\alpha \frac{\partial^2 u}{\partial x^2}, \quad x\in (0,L),\ t\in (0,T]
\label{diffu:pde1}\\
u(x,0) &= I(x), \quad  x\in [0,L]
\label{diffu:pde1:ic:u}\\
u(0,t) & = 0, \quad  t>0,
\label{diffu:pde1:bc:0}\\
u(L,t) & = 0, \quad  t>0\thinspace .
\label{diffu:pde1:bc:L}
\end{align}
$$
Equation \eqref{diffu:pde1} is known as a one-dimensional
<em>diffusion equation</em>, also often referred to as a
<em>heat equation</em>. With only a first-order derivative in time,
only one <em>initial condition</em> is needed, while the second-order
derivative in time leads to a demand for two <em>boundary conditions</em>.
The parameter \( \alpha \) must be given and is referred to as the
<em>diffusion coefficient</em>.

<p>
Diffusion equations like \eqref{diffu:pde1} have a wide range of
applications throughout physical, biological, and financial sciences.
One of the most common applications is propagation of heat, where
\( u(x,t) \) represents the temperature of some substance at point \( x \) and
time \( t \). the chapter ref{diffu:app} goes into several widely occurring
applications.

<p>

<h3>Forward Euler scheme <a name="diffu:pde1:FE"></a></h3>
<p>
The first step in the discretization procedure is to replace the
domain \( [0,L]\times [0,T] \) by a set of mesh points. Here we apply
equally spaced mesh points

<p>
$$
\begin{equation*} x_i=i\Delta x,\quad i=0,\ldots,N_x,\end{equation*}
$$
and

<p>
$$
\begin{equation*} t_n=n\Delta t,\quad n=0,\ldots,N \thinspace . \end{equation*}
$$
Moreover, \( u^n_i \) denotes the numerical approximation of \( u(x_i,t_n) \).
Approximating the PDE \eqref{diffu:pde1} at a mesh point \( (x_i,t_n) \)
leads to

<p>
$$
\begin{equation}
\frac{\partial}{\partial t} u(x_i, t_n) =
\alpha\frac{\partial^2}{\partial x^2} u(x_i, t_n),
\label{diffu:pde1:step2}
\end{equation}
$$
Let us first replace
the time derivative by a forward difference and the spatial
derivative by a central difference:

<p>
$$
\begin{equation}
[D_t^+ u = \alpha D_xD_x u]^n_i \thinspace .
\label{diffu:pde1:step3a}
\end{equation}
$$
Written out,

<p>
$$
\begin{equation}
\frac{u^{n+1}_i-u^n_i}{\Delta t} = \alpha \frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2} \thinspace .
\label{diffu:pde1:step3b}
\end{equation}
$$
As usual, we anticipate that \( u^n_i \) is already computed such that
\( u^{n+1}_i \) is the only unknown, which we can easily solve for:

<p>
$$
\begin{equation}
u^{n+1}_i = u^n_i + \alpha\frac{\Delta t}{\Delta x^2}\left(
u^{n}_{i+1} - 2u^n_i + u^n_{i-1}\right) \thinspace .
\label{diffu:pde1:step4}
\end{equation}
$$

<p>
The computational algorithm is then

<p>

<ol>
 <li> compute $u^0_i=I(x_i)$for \( i=0,\ldots,N_x \)</li>
 <li> for \( n=0,1,\ldots,N \):</li>

<ol>
   <li> apply \eqref{diffu:pde1:step4} for all the internal
      spatial points \( i=1,\ldots,N_x-1 \)</li>
   <li> set the boundary values
      \( u^{n+1}_i=0 \) for \( i=0 \) and \( i=N_x \)</li>
</ol>

</ol>

The algorithm is compactly fully specified in Python:

<p>


<!-- code typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%">x = linspace(0, L, Nx+1)   # mesh points in space
dx = x[1] - x[0]
t = linspace(0, T, N+1)    # mesh points in time
dt = t[1] - t[0]
C = a*dt/dx**2
u   = zeros(Nx+1)
u_1 = zeros(Nx+1)

# Set initial condition u(x,0) = I(x)
for i in range(0, Nx+1):
    u_1[i] = I(x[i])

for n in range(0, N):
    # Compute u at inner mesh points
    for i in range(1, Nx):
        u[i] = u_1[i] + C*(u_1[i-1] - 2*u_1[i] + u_1[i+1])

    # Insert boundary conditions
    u[0] = 0;  u[Nx] = 0

    # Update u_1 before next step
    u_1[:]= u
</pre></div>
<p>


<h3>Backward Euler Scheme <a name="diffu:pde1:BE"></a></h3>
<p>

We now apply a backward difference in time in \eqref{diffu:pde1:step2},
but the same central difference in space:

<p>
$$
\begin{equation}
[D_t^- u = D_xD_x u]^n_i,
\label{diffu:pde1:step3aBE}
\end{equation}
$$
which written out reads

<p>
$$
\begin{equation}
\frac{u^{n}_i-u^{n-1}_i}{\Delta t} = \alpha\frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2} \thinspace .
\label{diffu:pde1:step3bBE}
\end{equation}
$$
Now we assume \( u^{n-1}_i \) is computed, but all quantities at the "new"
time level \( n \) are unknown. This time it is not possible to solve
with respect to \( u_i^{n} \) because this value couples to its neighbors
in space, \( u^n_{i-1} \) and \( u^n_{i+1} \), which are also unknown.
Let us examine this fact for the case when \( N_x=3 \). Equation \eqref{diffu:pde1:step3bBE} written for \( i=1,\ldots,Nx-1= 1,2 \) becomes

<p>
$$
\begin{align}
\frac{u^{n}_1-u^{n-1}_1}{\Delta t} &= \alpha\frac{u^{n}_{2} - 2u^n_1 + u^n_{0}}{\Delta x^2}\\
\frac{u^{n}_2-u^{n-1}_2}{\Delta t} &= \alpha\frac{u^{n}_{3} - 2u^n_2 + u^n_{1}}{\Delta x^2}
\end{align}
$$
The boundary values \( u^n_0 \) and \( u^n_3 \) are known as zero. Collecting the
unknown new values \( u^n_1 \) and \( u^n_2 \) on the left-hand side gives

<p>
$$
\begin{align}
\left(1+  2\alpha\frac{\Delta t}{\Delta x^2}\right) u^{n}_1
- \alpha\frac{\Delta t}{\Delta x^2} u^{n}_{2}  &= u^{n-1}_1,\\
- \alpha\frac{\Delta t}{\Delta x^2} u^{n}_{1} +
\left(1+  2\alpha\frac{\Delta t}{\Delta x^2}\right) u^{n}_2
  &= u^{n-1}_2
\thinspace .
\end{align}
$$
This is a coupled \( 2\times 2 \) system of algebraic equations for
the unknowns \( u^n_1 \) and \( u^n_2 \).
Discretization methods that lead to a coupled system of equations
for the unknown function at a new time level are said to be
<em>implicit methods</em>.The counterpart, <em>explicit methods</em>, refers to discretization
methods where there is a simple explicit formula for the values of
the unknown function at each of the spatial mesh points at the new
time level. From an implementational point of view, implicit methods
are more comprehensive to code since they require
the solution of coupled equations, i.e., a matrix system, at each time level.

<p>
In the general case, \eqref{diffu:pde1:step3bBE} gives rise to
a coupled \( (Nx-1)\times (Nx-1) \) system of algebraic equations for
all the unknown \( u^n_i \) at the interior spatial points \( i=1,\ldots,Nx-1 \).
Collecting the unknowns on the left-hand side, and
introducing the quantity

<p>
$$
\begin{equation}
C = \alpha\frac{\Delta t}{\Delta x^2},
\end{equation}
$$
\eqref{diffu:pde1:step3bBE} can be written

<p>
$$
\begin{equation}
- Cu^n_{i-1} + \left(1+  2C\right) u^{n}_i - Cu^n_{i+1} = u_{i-1}^{n-1},
\label{diffu:pde1:step4BE}
\end{equation}
$$
for \( i=1,\ldots,Nx-1 \).
One can either view these equations as a system for where the
\( u^{n}_i \) values at the internal grid points, \( i=1,\ldots,N_x-1 \), are
unknown, or we may append the boundary values \( u^n_0 \) and \( u^n_{N_x} \)
to the system. In the latter case, all \( u^n_i \) for \( i=0,\ldots,N_x \)
are unknown and we must add the boundary equations to
the \( N_x-1 \) equations in \eqref{diffu:pde1:step4BE}:

<p>
$$
\begin{align}
u_0^n &= 0,label{diffu:pde1:step4BE:BC:0}\\
u_{N_x}^n &= 0\thinspace .
\label{diffu:pde1:step4BE:BC:L}
\end{align}
$$

<p>
A coupled system of algebraic equations can be written on matrix form,
and this is important if we want to call up ready-made software for
solving the system.  The equations \eqref{diffu:pde1:step4BE}
and \eqref{diffu:pde1:step4BE:BC:0}--\eqref{diffu:pde1:step4BE:BC:L}
correspond to the matrix equation

<p>
$$
\begin{equation*} AU = b\end{equation*}
$$
where \( U=(u^n_0,\ldots,u^n_{N_x}) \), and
the matrix \( A \) has the following structure:

<p>
$$
\begin{equation}
A =
\left(
\begin{array}{cccccccccc}
A_{0,0} & A_{0,1} & 0
&\cdots &
\cdots & \cdots & \cdots &
\cdots & 0 \\
A_{1,0} & A_{1,1} & 0 & \ddots &   & &  & &  \vdots \\
0 & A_{2,1} & A_{2,2} & A_{2,3} &
\ddots & &  &  & \vdots \\
\vdots & \ddots &  & \ddots & \ddots & 0 &  & & \vdots \\
\vdots &  & \ddots & \ddots & \ddots & \ddots & \ddots & & \vdots \\
\vdots & &  & 0 & A_{i,i-1} & A_{i,i} & A_{i,i+1} & \ddots & \vdots \\
\vdots & & &  & \ddots & \ddots & \ddots &\ddots  & 0 \\
\vdots & & & &  &\ddots  & \ddots &\ddots  & A_{N_x-1,N_x} \\
0 &\cdots & \cdots &\cdots & \cdots & \cdots  & 0 & A_{N_x,N_x-1} & A_{N_x,N_x}
\end{array}
\right)
\label{diffu:pde1:matrix:sparsity}
\end{equation}
$$
The nonzero elements are given by

<p>
$$
\begin{align}
A_{i,i-1} &= -C\\
A_{i,i} &= 1+ 2C\\
A_{i,i+1} &= -C
\end{align}
$$
for the equations for internal points, \( i=1,\ldots,N_x-1 \). The equations
for the boundary points correspond to

<p>
$$
\begin{align}
A_{0,0} &= 1,\\
A_{0,1} &= 0,\\
A_{N_x,N_x-1} &= 0,\\
A_{N_x,N_x} &= 1\thinspace .
\end{align}
$$
The right-hand side \( b \) is written as

<p>
$$
\begin{equation}
b = \left(\begin{array}{c}
b_0\\
b_1\\
\vdots\\
b_i\\
\vdots\\
b_{N_x}
\end{array}\right)
\end{equation}
$$
with

<p>
$$
\begin{align}
b_0 &= 0,\\
b_i &= u^{n-1}_i,\quad i=1,\ldots,N_x-1,\\
b_{N_x} &= 0 \thinspace . \end{align}
$$

<p>
We observe that the matrix \( A \) contains quantities that do not change
in time. Therefore, \( A \) can be formed once and for all before we enter
the recursive formulas for the time evolution.
The right-hand side \( b \), however, must be updated at each time step.
This leads to the following computational algorithm, here sketched
with Python code:

<p>


<!-- code typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%">x = linspace(0, L, Nx+1)   # mesh points in space
dx = x[1] - x[0]
t = linspace(0, T, N+1)    # mesh points in time
u   = zeros(Nx+1)
u_1 = zeros(Nx+1)

# Data structures for the linear system
A = zeros((Nx+1, Nx+1))
b = zeros(Nx+1)

for i in range(1, Nx):
    A[i,i-1] = -C
    A[i,i+1] = -C
    A[i,i] = 1 + 2*C
A[0,0] = A[Nx,Nx] = 1

# Set initial condition u(x,0) = I(x)
for i in range(0, Nx+1):
    u_1[i] = I(x[i])

import scipy.linalg

for n in range(0, N):
    # Compute b and solve linear system
    for i in range(1, Nx):
        b[i] = -u_1[i]
    b[0] = b[Nx] = 0
    u[:] = scipy.linalg.solve(A, b)

    # Update u_1 before next step
    u_1[:] = u
</pre></div>
<p>


<h3>Sparse matrix implementation <a name="diffu:pde1:impl:sparse"></a></h3>
<p>
We have seen from \eqref{diffu:pde1:matrix:sparsity} that the matrix \( A \)
is tridiagonal. The code segment above used a full, dense matrix
representation of \( A \), which stores a lot of values we know are zero
beforehand, and worse, the solution algorithm computes with all these zeros.
With \( N_x+1 \) unknowns, the work by the solution algorithm is \( \frac{1}{3}
(N_x+1)^3 \) and the storage requirements \( (N_x+1)^2 \). By utilizing
the fact that \( A \) is tridiagonal and employing corresponding software
tools, the work and storage demands can be proportional to \( N_x \) only.

<p>
The key idea is to apply a data structure for a
tridiagonal or sparse matrix. The <tt>scipy.sparse</tt> package has
relevant utilities. For example, we can store the nonzero diagonals of
a matrix. The package also has linear system solvers that operate on
sparse matrix data structures. The code below illustrates how we
can store only the main diagonal and the upper and lower diagonals.

<p>


<!-- code typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #408080; font-style: italic"># Representation of sparse matrix and right-hand side</span>
main  <span style="color: #666666">=</span> zeros(Nx<span style="color: #666666">+1</span>)
lower <span style="color: #666666">=</span> zeros(Nx<span style="color: #666666">-1</span>)
upper <span style="color: #666666">=</span> zeros(Nx<span style="color: #666666">-1</span>)
b     <span style="color: #666666">=</span> zeros(Nx<span style="color: #666666">+1</span>)

<span style="color: #408080; font-style: italic"># Precompute sparse matrix</span>
main[:] <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #666666">+</span> <span style="color: #666666">2*</span>C
lower[:] <span style="color: #666666">=</span> <span style="color: #666666">-</span>C  <span style="color: #408080; font-style: italic">#1</span>
upper[:] <span style="color: #666666">=</span> <span style="color: #666666">-</span>C  <span style="color: #408080; font-style: italic">#1</span>
<span style="color: #408080; font-style: italic"># Insert boundary conditions</span>
main[<span style="color: #666666">0</span>] <span style="color: #666666">=</span> <span style="color: #666666">1</span>
main[Nx] <span style="color: #666666">=</span> <span style="color: #666666">1</span>

A <span style="color: #666666">=</span> scipy<span style="color: #666666">.</span>sparse<span style="color: #666666">.</span>diags(
    diagonals<span style="color: #666666">=</span>[main, lower, upper],
    offsets<span style="color: #666666">=</span>[<span style="color: #666666">0</span>, <span style="color: #666666">-1</span>, <span style="color: #666666">1</span>], shape<span style="color: #666666">=</span>(Nx<span style="color: #666666">+1</span>, Nx<span style="color: #666666">+1</span>),
    format<span style="color: #666666">=</span><span style="color: #BA2121">&#39;csr&#39;</span>)
<span style="color: #008000; font-weight: bold">print</span> A<span style="color: #666666">.</span>todense()

<span style="color: #408080; font-style: italic"># Set initial condition</span>
<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">0</span>,Nx<span style="color: #666666">+1</span>):
    u_1[i] <span style="color: #666666">=</span> I(x[i])

<span style="color: #008000; font-weight: bold">for</span> n <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">0</span>, N):
    b <span style="color: #666666">=</span> u_1
    b[<span style="color: #666666">0</span>] <span style="color: #666666">=</span> b[<span style="color: #666666">-1</span>] <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>  <span style="color: #408080; font-style: italic"># boundary conditions</span>
    u[:] <span style="color: #666666">=</span> scipy<span style="color: #666666">.</span>sparse<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>spsolve(A, b)
    u_1[:] <span style="color: #666666">=</span> u
</pre></div>
<p>
The <tt>scipy.sparse.linalg.spsolve</tt> function utilizes the sparse storage
structure of <tt>A</tt> and performs in this case a very efficient Gaussian
elimination solve.

<p>


<h3>The \( \theta \) Rule <a name="diffu:pde1:theta"></a></h3>
<p>
The \( \theta \) rule provides a family of finite difference approximations
in time. Applied to the 1D diffusion problem we have

<p>
$$ \frac{u^{n+1}_i-u^n_i}{\Delta t} =
\alpha\left( \theta \frac{u^{n+1}_{i+1} - 2u^{n+1}_i + u^{n+1}_{i-1}}{\Delta x^2}
+ (1-\theta) \frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2}\right)
\thinspace .
$$
This scheme also leads to a matrix system with entries \( 1+2C\theta \) on
the main diagonal of the matrix, and \( -C\theta \) on the super- and sub-diagonal.
The right-hand side entry \( b_i \) is

<p>
$$ b_i = u^n_{i} + C(1-\theta)
\frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2}\thinspace .
$$

<p>


<h3>The Laplace and Poisson equation as the steady state limit  <a name="___sec5"></a></h3>
<p>
The Laplace equation, \( \nabla^2 u = 0 \), or the Poisson equation,
\( -\nabla^2 u = f \), occur in numerous applications throughout science and
engineering. We can solve 1D variants of the Laplace equations with the listed
software, because we can interpret \( u_{xx}=0 \) as the limiting solution
of \( u_t = \alpha u_{xx} \) when \( u \) reach a steady state limit where
\( u_t=0 \). Technically in a program, we just take one large time step,
or equivalently, set \( \alpha \) to a large value. All we need is to have
\( C \) large. As \( C\rightarrow\infty \), we can from the schemes see that
we get

<p>
$$ \frac{u^{n+1}_{i+1} - 2u^{n+1}_i + u^{n+1}_{i-1}}{\Delta x^2} = 0,$$
which is nothing but the discretization \( [D_xD_x u]^{n+1}_i=0 \) of
\( u_{xx}=0 \).

<p>
The Backward Euler scheme can solve the limit equation directly and
hence produce a solution of the 1D Laplace equation.
With the Forward Euler scheme we must do the time stepping since \( C>1/2 \)
is illegal and leads to instability. We may interpret this time stepping
as solving the equation system from \( u_{xx} \) by iterating on a time
pseudo time variable.

<p>

<h3>Extensions  <a name="___sec6"></a></h3>
<p>

<ul>
 <li> Variable coefficients</li>
 <li> Neumann and Robin conditions</li>
 <li> 2D and 3D</li>
</ul>

<h2>Analysis of schemes for the diffusion equation  <a name="___sec7"></a></h2>
<p>

<h3>Properties of the solution <a name="diffu:pde1:analysis:uex"></a></h3>
<p>
A particular characteristic of diffusive processes, governed
by an equation like

<p>
$$
\begin{equation}
u_t = \alpha u_{xx},
\label{diffu:pde1:eq}
\end{equation}
$$
is that the
initial shape \( u(x,0)=I(x) \) spreads out in space with time,
along with a decaying amplitude. For example, \eqref{diffu:pde1:eq}
admits a solution of the form

<p>
$$
\begin{equation}
u(x,t) = Qe^{-at}\sin\left( kx\right),
\label{diffu:pde1:sol1}
\thinspace  .
\end{equation}
$$
The parameters \( Q \) and \( k \) can be freely chosen, while
inserting \eqref{diffu:pde1:sol1} in \eqref{diffu:pde1:eq} gives the constraint

<p>
$$
\begin{equation*} a = -\alpha k^2
\thinspace .
\end{equation*}
$$

<p>

A very important feature is that the initial shape \( I(x)=Q\sin kx \)
undergoes a damping \( \exp{(-\alpha k^2t)} \), meaning that
rapid oscillations in space, corresponding to large \( k \), are very much
faster dampened than slow oscillations in space, corresponding to small
\( k \). This feature leads to a smoothing of the initial condition with time.

<p>
The following examples illustrates the damping properties of the
diffusion equation. We consider the problem

<p>
$$
\begin{align*}
u_t &= u_{xx},\quad x\in (0,1),\ t\in (0,T],\\
u(0,t) &= u(1,t) = 0,\quad t\in (0,T],\\
u(x,0) & = \sin (\pi x) + 0.1\sin(100\pi x)
\thinspace .
\end{align*}
$$
The initial condition has been chosen such that adding
two solutions like \eqref{diffu:pde1:sol1} constructs
an analytical solution to the problem:

<p>
$$
\begin{equation}
u(x,t) = e^{-\pi^2 t}\sin (\pi x) + 0.1e^{-\pi^2 10^4 t}\sin (100\pi x)
\label{diffu:pde1:sol2}
\thinspace .
\end{equation}
$$
Figure <a href="#diffu:pde1:fig:damping">1</a> illustrates the rapid damping of
rapid oscillations \( \sin (100\pi x) \) and the very much slower damping of the
slowly varying \( \sin (\pi x) \) term. After about \( t=0.5\cdot10^{-4} \) the rapid
oscillations do not have a visible amplitude, while we have to wait
until \( t\sim 0.5 \) before the amplitude of the long wave \( \sin (\pi x) \)
becomes invisible.

<p>

<center> <! -- figure -->
<hr class="figure">
<center><p class="caption">Figure 1:  Evolution of the solution of a diffusion problem: initial condition (upper left), 1/100 reduction of the small waves (upper right), 1/10 reduction of the long wave (lower left), and 1/100 reduction of the long wave (lower right). <a name="diffu:pde1:fig:damping"></a> </p></center>
<p><img src="fig-diffu/diffusion_damping.png" align="bottom" width=800></p>
</center>

<p>

<!-- x/sqrt(t) solution, kernel with integral -->

<p>
The relevance of studying the behavior of a particular solution of the form
\eqref{diffu:pde1:sol1} is related to a Fourier representation of
the solution. We first express the initial condition as a Fourier series

<p>
$$
\begin{equation}
I(x) \approx \sum_{k\in K} b_k e^{ikx},
\end{equation}
$$
where \( i=\sqrt{-1} \) and \( K \) is a set of \( k \) values needed to build
\( I(x) \) with sufficient accuracy from basic sinusoidal components
\( e^{ikx} \).  Instead of using a specific sine or cosine function for
the spatial variation, we use a complex exponential function to ease
the hand calculations later.  Letting \( K \) contain infinitely many \( k \)
values makes the sum converge to \( I(x) \) under reasonable assumptions
on the smoothness of \( I(x) \).

<p>
The corresponding
solution \( u \) can now be expressed as

<p>
$$
\begin{equation}
u(x,t) \approx \sum_{k\in K} b_k e^{-\alpha k^2t}e^{ikx},
\label{diffu:pde1:u:Fourier}
\thinspace .
\end{equation}
$$

<p>
Note that \eqref{diffu:pde1:sol2} is a special case of
\eqref{diffu:pde1:u:Fourier} where \( K=\{\pi, 100\pi\} \), \( b_{\pi}=1 \),
and \( b_{100\pi}=0.1 \).

<p>


<h3>Analysis of the finite difference schemes <a name="diffu:pde1:analysis"></a></h3>
<p>
We have seen that a general solution of the diffusion equation
can be built as a linear combination of basic components

<p>
$$
\begin{equation*} e^{-\alpha k^2t}e^{ikx} \thinspace . \end{equation*}
$$
A fundamental question is whether such components are also solutions of
the finite difference schemes. This is indeed the case, but the
amplitude \( \exp{(-\alpha k^2t)} \) might be modified (which also happens when
solving the ODE counterpart \( u'=-\alpha u \)).
We therefore look for numerical solutions of the form

<p>
$$
\begin{equation}
u^n_q = A^n e^{ikq\Delta x} = A^ne^{ikx},
\label{diffu:pde1:analysis:uni}
\end{equation}
$$
where \( A \) must be determined by inserting the component into an actual scheme.

<p>

<h4>Stability  <a name="___sec10"></a></h4>
<p>
The exact wave component decays according to \( \exp{(-\alpha k^2t)} \).
We should therefore require \( |A| < 1 \) to have a decaying numerical
solution as well. However, if
\( -1\leq A<0 \), \( A^n \) will change sign from time level to
time level, and we get stable, non-physical oscillations in the numerical
solutions that are not present in the exact solution.

<p>


<h4>Accuracy  <a name="___sec11"></a></h4>
<p>
To determine how accurately a finite difference scheme treats one
wave component \eqref{diffu:pde1:analysis:uni}, we see that the basic
deviation from the exact solution is reflected in how well
\( A^n \) approximates \( \exp{(-\alpha k^2t)}=\exp{(-\alpha k^2 n\Delta t)} \),
or how well the numerical amplification factor
\( A \) approximates the exact amplification factor
\( \Aex = \exp{(-\alpha k^2 \Delta t)} \).

<p>
<!-- We shall in particular investigate the error \( \Aex - A \) in the -->
<!-- amplification factor. -->

<p>


<h3>Analysis of the Forward Euler scheme <a name="diffu:pde1:analysis:FE"></a></h3>
<p>
<!-- 2DO: refer to vib and wave -->

<p>

The Forward Euler finite difference scheme for \( u_t = \alpha u_{xx} \) can
be written as

<p>
$$
\begin{equation*} [D_t^+ u = \alpha D_xD_x u]^n_q\thinspace . \end{equation*}
$$
Inserting a wave component \eqref{diffu:pde1:analysis:uni}
in the scheme demands calculating the terms

<p>
$$ e^{ikq\Delta x}[D_t^+ A]^n = e^{ikq\Delta x}A^n\frac{A-1}{\Delta t},$$
and

<p>
$$ A^nD_xD_x [e^{ikx}]_q = A^n\left( - e^{ikq\Delta x}\frac{4}{\Delta x^2}
\sin^2\left(\frac{k\Delta x}{2}\right)\right)
\thinspace . $$
Inserting these terms in the discrete equation and
dividing by \( A^n e^{ikq\Delta x} \) leads to

<p>

$$
\begin{equation*}
\frac{A-1}{\Delta t} = -\alpha \frac{4}{\Delta x^2}\sin^2\left(
\frac{k\Delta x}{2}\right),
\end{equation*}
$$
and consequently

<p>
$$
\begin{equation}
A = 1 -4C\sin^2\left(
\frac{k\Delta x}{2}\right),
\end{equation}
$$
where \( C \) is a constant introduced for convenience:

<p>
$$
\begin{equation}
C = \frac{\alpha\Delta t}{\Delta x^2}
\thinspace .
\end{equation}
$$
The complete numerical solution is then

<p>
$$
\begin{equation}
u^n_q = \left(1 -4C\sin^2\left(
\frac{k\Delta x}{2}\right)\right)^ne^{ikq\Delta x}
\thinspace .
\end{equation}
$$

<p>

<h4>Stability  <a name="___sec13"></a></h4>
<p>
We easily see that \( A\leq 1 \). However, the \( A \) can be less than \( -1 \),
which will lead
to growth of a numerical wave component. The criterion \( A\geq -1 \) implies

<p>
$$ 4C\sin^2 (p/2)\leq 2
\thinspace . $$
The worst case is when \( \sin^2 (p/2)=1 \), so a sufficient criterion for
stability is

<p>
$$
\begin{equation}
C\leq \frac{1}{2},
\end{equation}
$$
or expressed as a condition on \( \Delta t \):

<p>
$$
\begin{equation}
\Delta t\leq \frac{\Delta x^2}{2\alpha}\thinspace .
\end{equation}
$$
Note that halving the spatial mesh size, \( \Delta x \rightarrow \frac{1}{2}
\Delta x \), requires \( \Delta t \) to be reduced by a factor of \( 1/4 \).
The method hence becomes very expensive for fine spatial meshes.

<p>
<!-- 2DO: verification based on exact solutions -->

<p>

<h4>Accuracy  <a name="___sec14"></a></h4>
<p>
Since \( A \) is expressed in terms of \( C \) and the parameter we now call
\( p=k\Delta x \), we also express \( \Aex \) by \( C \) and \( p \):

<p>
$$ \Aex = \exp{(-\alpha k^2\Delta t)} = \exp{(-Cp^2)}
\thinspace .$$
Computing
the Taylor series expansion of \( A/\Aex \) in terms of \( C \)
can easily be done with aid of <tt>sympy</tt>:

<p>


<!-- code typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">A_exact</span>(C, p):
    <span style="color: #008000; font-weight: bold">return</span> exp(<span style="color: #666666">-</span>C<span style="color: #666666">*</span>p<span style="color: #666666">**2</span>)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">A_FE</span>(C, p):
    <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">1</span> <span style="color: #666666">-</span> <span style="color: #666666">4*</span>C<span style="color: #666666">*</span>sin(p<span style="color: #666666">/2</span>)<span style="color: #666666">**2</span>

<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sympy</span> <span style="color: #008000; font-weight: bold">import</span> <span style="color: #666666">*</span>
C, p <span style="color: #666666">=</span> symbols(<span style="color: #BA2121">&#39;C p&#39;</span>)
A_err_FE <span style="color: #666666">=</span> A_FE(C, p)<span style="color: #666666">/</span>A_exact(C, p)
<span style="color: #008000; font-weight: bold">print</span> A_err_FE<span style="color: #666666">.</span>series(C, <span style="color: #666666">0</span>, <span style="color: #666666">6</span>)
</pre></div>
<p>
The result is

<p>
$$ \frac{A}{\Aex} = 1 - 4 C \sin^{2}(p/2) + C p^{2} - 4 C^{2} p^{2} \sin^{2}(p/2) + \frac{1}{2} C^{2} p^{4} + \cdots
$$
Recalling that \( C=\alpha\Delta t/\Delta x \), \( p=k\Delta x \), and that
\( \sin^2(p/2)\leq 1 \), we
realize that the dominating error terms are at most

<p>
$$ 1 - 4\alpha \frac{\Delta t}{\Delta x^2} +
\alpha\Delta t - 4\alpha^2\Delta t^2
+ \alpha^2 \Delta t^2\Delta x^2 + \cdots
\thinspace .
$$

<p>


<h3>Analysis of the Backward Euler scheme <a name="diffu:pde1:analysis:BE"></a></h3>
<p>
Discretizing \( u_t = \alpha u_{xx} \) by a Backward Euler scheme,

<p>
$$
\begin{equation*} [D_t^- u = \alpha D_xD_x u]^n_q,\end{equation*}
$$
and inserting a wave component \eqref{diffu:pde1:analysis:uni},
leads to calculations similar to those arising from the Forward Euler scheme,
but since

<p>
$$ e^{ikq\Delta x}[D_t^- A]^n = A^ne^{ikq\Delta x}\frac{1 - A^{-1}}{\Delta t},$$
we get

<p>
$$
\begin{equation*}
\frac{1-A^{-1}}{\Delta t} = -\alpha \frac{4}{\Delta x^2}\sin^2\left(
\frac{k\Delta x}{2}\right),
\end{equation*}
$$
and then

<p>
$$
\begin{equation}
A = \left(1  + 4C\sin^2(p/2)\right)^{-1}
\label{diffu:pde1:analysis:BE:A}
\thinspace .
\end{equation}
$$
The complete numerical solution can be written

<p>
$$
\begin{equation}
u^n_q = \left(1  + 4C\sin^2 (p/2)\right)^{-n}
e^{ikq\Delta x} \thinspace .
\end{equation}
$$

<p>

<h4>Stability  <a name="___sec16"></a></h4>
<p>
We see from \eqref{diffu:pde1:analysis:BE:A} that \( 0<A<1 \), which means
that all numerical wave components are stable and non-oscillatory
for any \( \Delta t >0 \).

<p>


<h3>Analysis of the Crank-Nicolson scheme <a name="diffu:pde1:analysis:CN"></a></h3>
<p>
The Crank-Nicolson scheme can be written as

<p>
$$ [D_t u = \alpha D_xD_x \overline{u}^x]^{n+\half}_q, $$
or

<p>
$$ [D_t u]^{n+\half}_q = \half\alpha\left( [D_xD_x u]^{n}_q +
[D_xD_x u]^{n+1}_q\right)
\thinspace .
$$
Inserting \eqref{diffu:pde1:analysis:uni} in the time derivative approximation
leads to

<p>
$$ [D_t A^n e^{ikq\Delta x}]^{n+\half} = A^{n+\half} e^{ikq\Delta x}\frac{A^{\half}-A^{-\half}}{\Delta t} = A^ne^{ikq\Delta x}\frac{A-1}{\Delta t}
\thinspace .$$
Inserting \eqref{diffu:pde1:analysis:uni} in the other terms
and dividing by
\( A^ne^{ikq\Delta x} \) gives the relation

<p>
$$
\frac{A-1}{\Delta t} = -\half\alpha\frac{4}{\Delta x^2}
\sin^2\left(\frac{k\Delta x}{2}\right)
(1 + A),
$$
and after some more algebra,

<p>
$$
\begin{equation}
A = \frac{ 1 - 2C\sin^2(p/2)}{1 + 2C\sin^2(p/2)}
\thinspace .
\end{equation}
$$
The exact numerical solution is hence

<p>
$$
\begin{equation}
u^n_q = \left(\frac{ 1 - 2C\sin^2(p/2)}{1 + 2C\sin^2(p/2)}\right)^ne^{ikp\Delta x}
\thinspace .
\end{equation}
$$

<p>

<h4>Stability  <a name="___sec18"></a></h4>
<p>
The criteria \( A>-1 \) and \( A<1 \) are fulfilled for any \( \Delta t >0 \).

<p>

<h3>Summary of accuracy of amplification factors  <a name="___sec19"></a></h3>
<p>
We can plot the various amplification factors against \( p=k\Delta x \) for
different choices of the \( C \) parameter. Figures <a href="#diffu:pde1:fig:A:err:C20">2</a>,
<a href="#diffu:pde1:fig:A:err:C0.5">3</a>, and <a href="#diffu:pde1:fig:A:err:C0.1">4</a>
show how long and small waves are damped by the various schemes compared
to the exact damping. As long as all schemes are stable, the amplification
factor is positive, except for Crank-Nicolson when \( C>0.5 \).

<p>

<center> <! -- figure -->
<hr class="figure">
<center><p class="caption">Figure 2:  Amplification factors for large time steps. <a name="diffu:pde1:fig:A:err:C20"></a> </p></center>
<p><img src="fig-diffu/diffusion_A_C20_C2_FDM.png" align="bottom" width=800></p>
</center>

<p>

<center> <! -- figure -->
<hr class="figure">
<center><p class="caption">Figure 3:  Amplification factors for time steps around the Forward Euler stability limit. <a name="diffu:pde1:fig:A:err:C0.5"></a> </p></center>
<p><img src="fig-diffu/diffusion_A_C05_C025_FDM.png" align="bottom" width=800></p>
</center>

<p>

<center> <! -- figure -->
<hr class="figure">
<center><p class="caption">Figure 4:  Amplification factors for small time steps. <a name="diffu:pde1:fig:A:err:C0.1"></a> </p></center>
<p><img src="fig-diffu/diffusion_A_C01_C001_FDM.png" align="bottom" width=800></p>
</center>

<p>

The effect of negative amplification factors is that \( A^n \) changes sign
from one time level to the next, thereby giving rise to oscillations in
time in an animation of the solution. We see from Figure <a href="#diffu:pde1:fig:A:err:C20">2</a> that for \( C=20 \), waves with \( p\geq \pi/2 \) undergo a damping close to
\( -1 \), which means that the amplitude does not decay and that the wave component
jumps up and down in time. For \( C=2 \) we have a damping of a factor of 0.5
from one time level to the next, which is very much smaller than the
exact damping. Short waves will therefore fail to be effectively dampened.
These waves will manifest themselves as high frequency
oscillatory noise in the solution.

<p>
A value \( p=\pi/2 \) corresponds to
four mesh points per wave length of \( e^{ikx} \), while
\( p=\pi \) implies only two points per wave length, which is the smallest number
of points we can have to represent the wave on the mesh.

<p>
To demonstrate the oscillatory behavior of the Crank-Nicolson scheme, we
choose an initial condition that leads to short waves with
significant amplitude. A discontinuous \( I(x) \) will in particular serve
this purpose.

<p>
Run \( C=... \)...

<p>




<!-- ------------------- end of main content ----------------->
</body>
</html>
    

