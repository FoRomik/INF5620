
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Basic finite element methods &mdash; Basic finite element methods 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Basic finite element methods 1.0 documentation" href="index.html" />
    <link rel="prev" title="Basic finite element methods" href="index.html" />
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head>
  <body>

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="index.html" title="Basic finite element methods"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Basic finite element methods 1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="basic-finite-element-methods">
<h1>Basic finite element methods<a class="headerlink" href="#basic-finite-element-methods" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Hans Petter Langtangen</td>
</tr>
<tr class="field-even field"><th class="field-name">Date:</th><td class="field-body">Nov 1, 2012</td>
</tr>
</tbody>
</table>
<p>Note: <strong>QUITE PRELIMINARY VERSION</strong></p>
<p>The finite element method is a powerful tool for solving differential
equations, especially in complicated domains and where higher-order
approximations are desired. Figure <a class="reference internal" href="#fem-motivation-fig-dolfin"><em>Domain for flow around a dolphin</em></a> shows
a two-dimensional domain with a non-trivial geometry. The idea is to
divide the domain into triangles (elements) and seek a polynomial approximations
to the unknown functions on each triangle. The method glues these
piecewise approximations together to find a global solution.
Linear and quadratic polynomials over the triangles are particularly
popular.</p>
<div class="figure" id="fem-motivation-fig-dolfin">
<img alt="_images/dolfin_mesh.png" src="_images/dolfin_mesh.png" style="width: 400px;" />
<p class="caption"><em>Domain for flow around a dolphin</em></p>
</div>
<p>Many successful numerical methods for differential equations,
including the finite element method,
aim at approximating the unknown function by a sum</p>
<div class="math" id="equation-fem:u">
<span class="eqno">(1)</span>\[      u(x) = \sum_{i=0}^N c_i\varphi_i(x),\]</div>
<p>where <span class="math">\(\varphi_i(x)\)</span> are prescribed functions and <span class="math">\(c_i\)</span>, <span class="math">\(i=0,\ldots,N\)</span>,
are unknown coefficients to be determined.
Solution methods for differential equations
utilizing <a href="#equation-fem:u">(1)</a> must
have a <em>principle</em> for constructing <span class="math">\(N+1\)</span> equations to
determine <span class="math">\(c_0,\ldots,c_N\)</span>. Then there is a <em>machinery</em> regarding
the actual constructions of the equations for <span class="math">\(c_0,\ldots,c_N\)</span> in a
particular problem. Finally, there is a <em>solve</em> phase for computing
the solution <span class="math">\(c_0,\ldots,c_N\)</span> of the <span class="math">\(N+1\)</span> equations.</p>
<p>Especially in the finite element method, the machinery for constructing
the discrete equations to be implemented on a computer is quite
comprehensive, with many mathematical and implementational
details entering the scene at the
same time. From an ease-of-learning perspective it can therefore be
wise to introduce the computational machinery for a trivial equation:
<span class="math">\(u=f\)</span>. Solving this equation with <span class="math">\(f\)</span> given and <span class="math">\(u\)</span> on the form
<a href="#equation-fem:u">(1)</a> means that we seek an approximation
<span class="math">\(u\)</span> to <span class="math">\(f\)</span>.
This approximation problem has the advantage of introducing most of the
finite element toolbox, but with postponing demanding topics related to
differential equations (e.g., integration by parts, boundary conditions,
and coordinate mappings).
This is the reason why we shall first become familiar
with finite element <em>approximation</em> before addressing
finite element methods for differential equations.</p>
<p>First, we refresh some linear algebra concepts about approximating
vectors in vector spaces. Second, we extend these concepts to
approximating functions in function spaces, using the same
principles and the same notation.
We present examples on approximating functions by  global basis functions with
support throughout the entire domain.
Third, we introduce the finite element type of local basis functions
and explain the computational algorithms for working with such functions.
Three types of approximation principles are covered: 1) the least squares
method, 2) the Galerkin or <span class="math">\(L_2\)</span> projection method,
and 3) interpolation or collocation.</p>
</div>
<div class="section" id="approximation-of-vectors">
<span id="fem-approx-vec"></span><h1>Approximation of vectors<a class="headerlink" href="#approximation-of-vectors" title="Permalink to this headline">¶</a></h1>
<p>We shall start with introducing two fundamental methods for
determining the coefficients <span class="math">\(c_i\)</span> in <a href="#equation-fem:u">(1)</a> and illustrate
the methods on approximation of vectors, because vectors in vector
spaces is more intuitive than working with functions in function spaces.
The extension from vectors to functions will be trivial as soon as
the fundamental ideas are understood.</p>
<p>The first method of approximation is called the <em>least squares method</em>
and consists in finding <span class="math">\(c_i\)</span> such that the difference <span class="math">\(u-f\)</span>, measured
in some norm, is minimized. That is, we aim at finding the best
approximation <span class="math">\(u\)</span> to <span class="math">\(f\)</span> (in some norm). The second method is not
as intuitive: we find <span class="math">\(u\)</span> such that the error <span class="math">\(u-f\)</span> is orthogonal to
the space where we seek <span class="math">\(u\)</span>. This is known as <em>projection</em>, or
we may also call it a <em>Galerkin method</em>.
When approximating vectors and functions, the two methods are
equivalent, but this is no longer the case when working with differential
equations.</p>
<div class="section" id="approximation-of-planar-vectors">
<span id="fem-approx-vec-plane"></span><h2>Approximation of planar vectors<a class="headerlink" href="#approximation-of-planar-vectors" title="Permalink to this headline">¶</a></h2>
<p id="index-0">Suppose we have given a vector <span class="math">\(\pmb{f} = (3,5)\)</span> in the <span class="math">\(xy\)</span> plane
and that we want to approximate this vector by a vector aligned
in the direction of the vector <span class="math">\((a,b)\)</span>. Figure <a class="reference internal" href="#fem-approx-vec-plane-fig"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></a>
depicts the situation.</p>
<div class="figure" id="fem-approx-vec-plane-fig">
<img alt="_images/vecapprox_plane.png" src="_images/vecapprox_plane.png" style="width: 400px;" />
<p class="caption"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></p>
</div>
<p>We introduce the vector space <span class="math">\(V\)</span>
spanned by the vector <span class="math">\(\pmb{\varphi}_0=(a,b)\)</span>:</p>
<div class="math">
\[V = \mbox{span}\,\{ \pmb{\varphi}_0\}\thinspace .\]</div>
<p>We say that <span class="math">\(\pmb{\varphi}_0\)</span> is a basis vector in the space <span class="math">\(V\)</span>.
Our aim is to find the vector <span class="math">\(\pmb{u} = c_0\pmb{\varphi}_0\in V\)</span> which best approximates
the given vector <span class="math">\(\pmb{f} = (3,5)\)</span>. A reasonable criterion for a best
approximation could be to minimize the length of the difference between
the approximate <span class="math">\(\pmb{u}\)</span> and the given <span class="math">\(\pmb{f}\)</span>. The difference, or error,
<span class="math">\(\pmb{e} = \pmb{f} -\pmb{u}\)</span> has its length given by the <em>norm</em></p>
<div class="math">
\[||\pmb{e}|| = (\pmb{e},\pmb{e})^{\frac{1}{2}},\]</div>
<p>where <span class="math">\((\pmb{e},\pmb{e})\)</span> is the <em>inner product</em> of <span class="math">\(\pmb{e}\)</span> and itself. The inner
product, also called <em>scalar product</em> or <em>dot product</em>, of two vectors
<span class="math">\(\pmb{u}=(u_0,u_1)\)</span> and <span class="math">\(\pmb{v} =(v_0,v_1)\)</span> is defined as</p>
<div class="math">
\[(\pmb{u}, \pmb{v}) = u_0v_0 + u_1v_1\thinspace .\]</div>
<p><em>Remark 1.</em> We should point out that we use the notation
<span class="math">\((\cdot,\cdot)\)</span> for two different things:
<span class="math">\((a,b)\)</span> for scalar quantities <span class="math">\(a\)</span> and <span class="math">\(b\)</span> means the vector starting in
the origin and ending in the point <span class="math">\((a,b)\)</span>, while <span class="math">\((\pmb{u},\pmb{v})\)</span> with
vectors <span class="math">\(\pmb{u}\)</span> and <span class="math">\(\pmb{v}\)</span> means the inner product of these vectors.
Since vectors are here written in boldface font there should be no
confusion.
Note that the norm associated with this inner product is the usual Eucledian length
of a vector.</p>
<p><em>Remark 2.</em> It might be wise to refresh some basic linear algebra by consulting a
textbook.  <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a> and
<a class="reference internal" href="#fem-approx-exer-linalg2"><em>Exercise 2: Linear algebra refresher II</em></a> suggest specific tasks to regain
familiarity with fundamental operations on inner product vector
spaces.</p>
<div class="section" id="the-least-squares-method-1">
<span id="index-1"></span><h3>The least squares method  (1)<a class="headerlink" href="#the-least-squares-method-1" title="Permalink to this headline">¶</a></h3>
<p>We now want to find <span class="math">\(c_0\)</span> such that it minimizes <span class="math">\(||\pmb{e}||\)</span>. The algebra
is simplified if we minimize the square of the norm, <span class="math">\(||\pmb{e}||^2 = (\pmb{e}, \pmb{e})\)</span>.
Define</p>
<div class="math">
\[E(c_0) = (\pmb{e},\pmb{e}) = (\pmb{f} - c_0\pmb{\varphi}_0, \pmb{f} - c_0\pmb{\varphi}_0)
\thinspace .\]</div>
<p>We can rewrite the expressions of the right-hand side to a more
convenient form for further work:</p>
<div class="math" id="equation-fem:vec:E">
<span class="eqno">(2)</span>\[     E(c_0) = (\pmb{f},\pmb{f}) - 2c_0(\pmb{f},\pmb{\varphi}_0) + c_0^2(\pmb{\varphi}_0,\pmb{\varphi}_0)\thinspace .\]</div>
<p>The rewrite results from using the following fundamental rules for inner
product spaces:</p>
<div class="math">
\[(\alpha\pmb{u},\pmb{v})=\alpha(\pmb{u},\pmb{v}),\quad \alpha\in\mathbb{R},\]</div>
<div class="math">
\[(\pmb{u} +\pmb{v},\pmb{w}) = (\pmb{u},\pmb{w}) + (\pmb{v}, \pmb{w}),\]</div>
<div class="math">
\[(\pmb{u}, \pmb{v}) = (\pmb{v}, \pmb{u})\thinspace .\]</div>
<p>Minimizing <span class="math">\(E(c_0)\)</span> implies finding <span class="math">\(c_0\)</span> such that</p>
<div class="math">
\[\frac{\partial E}{\partial c_0} = 0\thinspace .\]</div>
<p>Differentiating <a href="#equation-fem:vec:E">(2)</a> with respect to <span class="math">\(c_0\)</span> gives</p>
<div class="math" id="equation-fem:vec:dEdc0:v1">
<span class="eqno">(3)</span>\[     \frac{\partial E}{\partial c_0} = -2(\pmb{f},\pmb{\varphi}_0) + 2c_0 (\pmb{\varphi}_0,\pmb{\varphi}_0)
     \thinspace .\]</div>
<p>Setting the above expression equal to zero and solving for <span class="math">\(c_0\)</span> gives</p>
<div class="math" id="equation-fem:vec:c0">
<span class="eqno">(4)</span>\[     c_0 = \frac{(\pmb{f},\pmb{\varphi}_0)}{(\pmb{\varphi}_0,\pmb{\varphi}_0)},\]</div>
<p>which in the present case with <span class="math">\(\pmb{\varphi}_0=(a,b)\)</span> results in</p>
<div class="math">
\[c_0 = \frac{3a + 5b}{a^2 + b^2}\thinspace .\]</div>
<p>For later, it is worth mentioning that setting
the key equation <a href="#equation-fem:vec:dEdc0:v1">(3)</a> to zero can be rewritten
as</p>
<div class="math">
\[(\pmb{f}-c0\pmb{\varphi}_0,\pmb{\varphi}_0) = 0,\]</div>
<p>or</p>
<div class="math" id="equation-fem:vec:dEdc0:Galerkin">
<span class="eqno">(5)</span>\[     (\pmb{e}, \pmb{\varphi}_0) = 0
     \thinspace .\]</div>
<span class="target" id="index-2"></span></div>
<div class="section" id="the-galerkin-or-projection-method-1">
<span id="index-3"></span><h3>The Galerkin or projection method  (1)<a class="headerlink" href="#the-galerkin-or-projection-method-1" title="Permalink to this headline">¶</a></h3>
<p>Minimizing <span class="math">\(||\pmb{e}||^2\)</span> implies that <span class="math">\(\pmb{e}\)</span> is
orthogonal to <em>any</em> vector <span class="math">\(\pmb{v}\)</span> in the space <span class="math">\(V\)</span>. This result is
visually quite clear from Figure <a class="reference internal" href="#fem-approx-vec-plane-fig"><em>Approximation of a two-dimensional vector by a one-dimensional vector</em></a> (think of
other vectors along the line <span class="math">\((a,b)\)</span>: all of them will lead to
a larger distance between the approximation and <span class="math">\(\pmb{f}\)</span>).
To see this result mathematically, we
express any <span class="math">\(\pmb{v}\in V\)</span> as <span class="math">\(\pmb{v}=s\pmb{\varphi}_0\)</span> for any scalar parameter <span class="math">\(s\)</span>,
recall that two vectors are orthogonal when their inner product vanishes,
and calculate the inner product</p>
<div class="math">
\[\begin{split}(\pmb{e}, s\pmb{\varphi}_0) &amp;= (\pmb{f} - c_0\pmb{\varphi}_0, s\pmb{\varphi}_0)\\
&amp;= (\pmb{f},s\pmb{\varphi}_0) - (c_0\pmb{\varphi}_0, s\pmb{\varphi}_0)\\
&amp;= s(\pmb{f},\pmb{\varphi}_0) - sc_0(\pmb{\varphi}_0, \pmb{\varphi}_0)\\
&amp;= s(\pmb{f},\pmb{\varphi}_0) - s\frac{(\pmb{f},\pmb{\varphi}_0)}{(\pmb{\varphi}_0,\pmb{\varphi}_0)}(\pmb{\varphi}_0,\pmb{\varphi}_0)\\
&amp;= s\left( (\pmb{f},\pmb{\varphi}_0) - (\pmb{f},\pmb{\varphi}_0)\right)\\
&amp;=0\thinspace .\end{split}\]</div>
<p>Therefore, instead of minimizing the square of the norm, we could
demand that <span class="math">\(\pmb{e}\)</span> is orthogonal to any vector in <span class="math">\(V\)</span>.
This approach is known as <em>projection</em>, because we it is the same as
projecting the vector onto the subspace.
We may also use the term <em>Galerkin&#8217;s method</em>.
Mathematically the approach is stated
by the equation</p>
<div class="math" id="equation-fem:vec:Galerkin1">
<span class="eqno">(6)</span>\[     (\pmb{e}, \pmb{v}) = 0,\quad\forall\pmb{v}\in V\thinspace .\]</div>
<p>Since an arbitrary <span class="math">\(\pmb{v}\in V\)</span> can be expressed as
<span class="math">\(s\pmb{\varphi}_0\)</span>, <span class="math">\(s\in\mathbb{R}\)</span>,
<a href="#equation-fem:vec:Galerkin1">(6)</a> implies</p>
<div class="math">
\[(\pmb{e},s\pmb{\varphi}_0) = s(\pmb{e}, \pmb{\varphi}_0) = 0,\]</div>
<p>which means that the error must be orthogonal to the basis vector in
the space <span class="math">\(V\)</span>:</p>
<div class="math">
\[(\pmb{e}, \pmb{\varphi}_0)=0\quad\Leftrightarrow\quad
(\pmb{f} - c_0\pmb{\varphi}_0, \pmb{\varphi}_0)=0
\thinspace .\]</div>
<p>The latter equation gives <a href="#equation-fem:vec:c0">(4)</a> for <span class="math">\(c_0\)</span>.
Furthermore, the latter equation also arose
from least squares computations in
<a href="#equation-fem:vec:dEdc0:Galerkin">(5)</a>.</p>
</div>
</div>
<div class="section" id="approximation-of-general-vectors">
<span id="fem-approx-vec-np1dim"></span><h2>Approximation of general vectors<a class="headerlink" href="#approximation-of-general-vectors" title="Permalink to this headline">¶</a></h2>
<p id="index-4">Let us generalize the vector approximation from the previous section
to vectors in spaces with arbitrary dimension. Given some vector <span class="math">\(\pmb{f}\)</span>,
we want to find the best approximation to this vector in
the space</p>
<div class="math">
\[V = \hbox{span}\,\{\pmb{\varphi}_0,\ldots,\pmb{\varphi}_N\}
\thinspace .\]</div>
<p>We assume that the <em>basis vectors</em> <span class="math">\(\pmb{\varphi}_0,\ldots,\pmb{\varphi}_N\)</span> are
linearly independent so that none of them are redundant and
the space has dimension <span class="math">\(N+1\)</span>.
Any vector <span class="math">\(\pmb{u}\in V\)</span> can be written as a linear combination
of the basis vectors,</p>
<div class="math">
\[\pmb{u} = \sum_{j=0}^Nc_j\pmb{\varphi}_j,\]</div>
<p>where <span class="math">\(c_j\in\mathbb{R}\)</span> are scalar coefficients to be determined.</p>
<div class="section" id="the-least-squares-method-2">
<h3>The least squares method  (2)<a class="headerlink" href="#the-least-squares-method-2" title="Permalink to this headline">¶</a></h3>
<p>Now we want to find <span class="math">\(c_0,\ldots,c_N\)</span> such that <span class="math">\(\pmb{u}\)</span> is the best
approximation to <span class="math">\(\pmb{f}\)</span> in the sense that the distance, or error,
<span class="math">\(\pmb{e} = \pmb{f} - \pmb{u}\)</span> is minimized. Again, we define
the squared distance as a function of the free parameters
<span class="math">\(c_0,\ldots,c_N\)</span>,</p>
<div class="math" id="equation-fem:vec:genE">
<span class="eqno">(7)</span>\[\begin{split}     E(c_0,\ldots,c_N) &amp;= (\pmb{e},\pmb{e}) = (\pmb{f} -\sum_jc_j\pmb{\varphi}_j,\pmb{f} -\sum_jc_j\pmb{\varphi}_j)
     \nonumber\\
     &amp;= (\pmb{f},\pmb{f}) - 2\sum_{j=0}^Nc_j(\pmb{f},\pmb{\varphi}_j) +
     \sum_{p=0}^N\sum_{q=0}^N c_pc_q(\pmb{\varphi}_p,\pmb{\varphi}_q)\thinspace .\end{split}\]</div>
<p>Minimizing this <span class="math">\(E\)</span> with respect to the independent variables
<span class="math">\(c_0,\ldots,c_N\)</span> is obtained by setting</p>
<div class="math">
\[\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N
\thinspace .\]</div>
<p>The second term in <a href="#equation-fem:vec:genE">(7)</a> is differentiated as follows:</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{j=0}^Nc_j(\pmb{f},\pmb{\varphi}_j) = (\pmb{f},\pmb{\varphi}_i),\]</div>
<p>since the expression to be differentiated is a sum and only one term,
<span class="math">\(c_i(\pmb{f},\pmb{\varphi}_i)\)</span>,
contains <span class="math">\(c_i\)</span> and this term is linear in <span class="math">\(c_i\)</span>.
To understand this differentiation in detail, write out the sum specifically for,
e.g, <span class="math">\(N=3\)</span> and <span class="math">\(i=1\)</span>.</p>
<p>The last term in <a href="#equation-fem:vec:genE">(7)</a>
is more tedious to differentiate. We start with</p>
<div class="math">
\[\begin{split}\frac{\partial}{\partial c_i}
c_pc_q =
\left\lbrace\begin{array}{ll}
0, &amp; \hbox{ if } p\neq i\hbox{ and } q\neq i,\\
c_q, &amp; \hbox{ if } p=i\hbox{ and } q\neq i,\\
c_p, &amp; \hbox{ if } p\neq i\hbox{ and } q=i,\\
2c_i, &amp; \hbox{ if } p=q= i,\\
\end{array}\right.\end{split}\]</div>
<p>Then</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\pmb{\varphi}_p,\pmb{\varphi}_q)
= \sum_{p=0, p\neq i}^N c_p(\pmb{\varphi}_p,\pmb{\varphi}_i)
+ \sum_{q=0, q\neq i}^N c_q(\pmb{\varphi}_q,\pmb{\varphi}_i)
+2c_i(\pmb{\varphi}_i,\pmb{\varphi}_i)\thinspace .\]</div>
<p>The last term can be included in the other two sums, resulting in</p>
<div class="math">
\[\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\pmb{\varphi}_p,\pmb{\varphi}_q)
= 2\sum_{j=0}^N c_i(\pmb{\varphi}_j,\pmb{\varphi}_i)\thinspace .\]</div>
<p>It then follows that setting</p>
<div class="math">
\[\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N,\]</div>
<p>leads to a linear system
for <span class="math">\(c_0,\ldots,c_N\)</span>:</p>
<div class="math" id="equation-fem:approx:vec:Np1dim:eqsys">
<span class="eqno">(8)</span>\[     \sum_{j=0}^N A_{i,j} c_j = b_i, \quad i=0,\ldots,N,\]</div>
<p>where</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= (\pmb{\varphi}_i,\pmb{\varphi}_j),\\
b_i &amp;= (\pmb{\varphi}_i, \pmb{f})\thinspace .\end{split}\]</div>
<p>(Note that we can change the order of the two vectors in the inner
product as desired.)</p>
</div>
<div class="section" id="the-galerkin-or-projection-method-2">
<h3>The Galerkin or projection method  (2)<a class="headerlink" href="#the-galerkin-or-projection-method-2" title="Permalink to this headline">¶</a></h3>
<p>In analogy with the &#8220;one-dimensional&#8221; example in
the section <a class="reference internal" href="#fem-approx-vec-plane"><em>Approximation of planar vectors</em></a>, it holds also here in the general
case that minimizing the distance
(error) <span class="math">\(\pmb{e}\)</span> is equivalent to demanding that <span class="math">\(\pmb{e}\)</span> is orthogonal to
all <span class="math">\(\pmb{v}\in V\)</span>:</p>
<span class="target" id="index-5"></span><div class="math" id="equation-fem:approx:vec:Np1dim:Galerkin">
<span id="index-6"></span><span class="eqno">(9)</span>\[     (\pmb{e},\pmb{v})=0,\quad \forall\pmb{v}\in V\thinspace .\]</div>
<p>Since any <span class="math">\(\pmb{v}\in V\)</span> can be written as <span class="math">\(\pmb{v} =\sum_{i=0}^N c_i\pmb{\varphi}_i\)</span>,
the statement <a href="#equation-fem:approx:vec:Np1dim:Galerkin">(9)</a> is equivalent to
saying that</p>
<div class="math">
\[(\pmb{e}, \sum_{i=0}^N c_i\pmb{\varphi}_i) = 0,\]</div>
<p>for any choice of coefficients <span class="math">\(c_0,\ldots,c_N\in\mathbb{R}\)</span>.
The latter equation can be rewritten as</p>
<div class="math">
\[\sum_{i=0}^Nc_i (\pmb{e},\pmb{\varphi}_i) =0\thinspace .\]</div>
<p>If this is to hold for arbitrary values of <span class="math">\(c_0,\ldots,c_N\)</span>,
we must require that each term in the sum vanishes,</p>
<div class="math" id="equation-fem:approx:vec:Np1dim:Galerkin0">
<span class="eqno">(10)</span>\[     (\pmb{e},\pmb{\varphi}_i)=0,\quad i=0,\ldots,N\thinspace .\]</div>
<p>These <span class="math">\(N+1\)</span> equations result in the same linear system as
<a href="#equation-fem:approx:vec:Np1dim:eqsys">(8)</a>:</p>
<div class="math">
\[(\pmb{f} - \sum_{j=0}^Nc_j\pmb{\varphi}_j, \pmb{\varphi}_i) = (\pmb{f}, \pmb{\varphi}_i) - \sum_{j=0}^N
(\pmb{\varphi}_i,\pmb{\varphi}_j)c_j = 0,\]</div>
<p>and hence</p>
<div class="math">
\[\sum_{j=0}^N (\pmb{\varphi}_i,\pmb{\varphi}_j)c_j = (\pmb{f}, \pmb{\varphi}_i),\quad i=0,\ldots, N
\thinspace .\]</div>
<p>So, instead of differentiating the
<span class="math">\(E(c_0,\ldots,c_N)\)</span> function, we could simply use
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(9)</a> as the principle for
determining <span class="math">\(c_0,\ldots,c_N\)</span>, resulting in the <span class="math">\(N+1\)</span>
equations <a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(10)</a>.</p>
<p>The names <em>least squares method</em> or <em>least squares approximation</em>
are natural since the calculations consists of
minimizing <span class="math">\(||\pmb{e}||^2\)</span>, and <span class="math">\(||\pmb{e}||^2\)</span> is a sum of squares
of differences between the components in <span class="math">\(\pmb{f}\)</span> and <span class="math">\(\pmb{u}\)</span>.
We find <span class="math">\(\pmb{u}\)</span> such that this sum of squares is minimized.</p>
<p>The principle <a href="#equation-fem:approx:vec:Np1dim:Galerkin">(9)</a>,
or the equivalent form <a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(10)</a>,
is known as <em>projection</em>. Almost the same mathematical idea
was used by the Russian mathematician <a class="reference external" href="http://en.wikipedia.org/wiki/Boris_Galerkin">Boris Galerkin</a> to solve
differential equations, resulting in what is widely known as
<em>Galerkin&#8217;s method</em>.</p>
</div>
</div>
</div>
<div class="section" id="approximation-of-functions">
<span id="fem-approx-global"></span><h1>Approximation of functions<a class="headerlink" href="#approximation-of-functions" title="Permalink to this headline">¶</a></h1>
<p id="index-7">Let <span class="math">\(V\)</span> be a function space spanned by a set of <em>basis functions</em>
<span class="math">\(\varphi_0,\ldots,\varphi_N\)</span>,</p>
<div class="math">
\[V = \hbox{span}\,\{\varphi_0,\ldots,\varphi_N\},\]</div>
<p>such that any function <span class="math">\(u\in V\)</span> can be written as a linear
combination of the basis functions:</p>
<div class="math" id="equation-fem:approx:ufem">
<span class="eqno">(11)</span>\[     u = \sum_{j=0}^N c_j\varphi_j\thinspace .\]</div>
<p>For now, in this introduction, we shall look at functions of a
single variable <span class="math">\(x\)</span>:
<span class="math">\(u=u(x)\)</span>, <span class="math">\(\varphi_i=\varphi_i(x)\)</span>, <span class="math">\(i=0,\ldots,N\)</span>. Later, we will extend
the scope to functions of two- or three-dimensional physical spaces.
The approximation <a href="#equation-fem:approx:ufem">(11)</a> is typically used
to discretize a problem in space. Other methods, most notably
finite differences, are common for time discretization (although the
form <a href="#equation-fem:approx:ufem">(11)</a> can be used in time too).</p>
<div class="section" id="the-least-squares-method-3">
<span id="fem-approx-ls"></span><h2>The least squares method  (3)<a class="headerlink" href="#the-least-squares-method-3" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span>, how can we determine its best approximation
<span class="math">\(u(x)\in V\)</span>? A natural starting point is to apply the same reasoning
as we did for vectors in the section <a class="reference internal" href="#fem-approx-vec-np1dim"><em>Approximation of general vectors</em></a>. That is,
we minimize the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span>. However, this requires
a norm for measuring distances, and a norm is most conveniently
defined through an
inner product. Viewing a function as a vector of infinitely
many point values, one for each value of <span class="math">\(x\)</span>, the inner product could
intuitively be defined as the usual summation of
pairwise components, with summation replaced by integration:</p>
<div class="math">
\[(f,g) = \int f(x)g(x)\, dx
\thinspace .\]</div>
<p>To fix the integration domain, we let <span class="math">\(f(x)\)</span> and <span class="math">\(\varphi_i(x)\)</span>
be defined for a domain <span class="math">\(\Omega\subset\mathbb{R}\)</span>.
The inner product of two functions <span class="math">\(f(x)\)</span> and <span class="math">\(g(x)\)</span> is then</p>
<div class="math" id="equation-fem:approx:LS:innerprod">
<span class="eqno">(12)</span>\[     (f,g) = \int_\Omega f(x)g(x)\, dx\]\[     \thinspace .\]</div>
<p>The distance between <span class="math">\(f\)</span> and any function <span class="math">\(u\in V\)</span> is simply
<span class="math">\(f-u\)</span>, and the squared norm of this distance is</p>
<div class="math" id="equation-fem:approx:LS:E">
<span class="eqno">(13)</span>\[     E = (f(x)-\sum_{j=0}^Nc_j\varphi_j(x), f(x)-\sum_{j=0}^Nc_j\varphi_j(x))\thinspace .\]</div>
<p>Note the analogy with <a href="#equation-fem:vec:genE">(7)</a>: the given function
<span class="math">\(f\)</span> plays the role of the given vector <span class="math">\(\pmb{f}\)</span>, and the basis function
<span class="math">\(\varphi_i\)</span> plays the role of the basis vector <span class="math">\(\pmb{\varphi}_i\)</span>.
We get can rewrite <a href="#equation-fem:approx:LS:E">(13)</a>,
through similar steps as used for the result
<a href="#equation-fem:vec:genE">(7)</a>, leading to</p>
<div class="math">
\[E(c_0,\ldots,c_N) = (f,f) -2\sum_{j=0}^N c_j(f,\varphi_i)
+ \sum_{p=0}^N\sum_{q=0}^N c_pc_q(\varphi_p,\varphi_q)\thinspace .\]</div>
<p>Minimizing this function of <span class="math">\(N+1\)</span> scalar variables
<span class="math">\(c_0,\ldots,c_N\)</span> requires differentiation
with respect to <span class="math">\(c_i\)</span>, for <span class="math">\(i=0,\ldots,N\)</span>. The resulting
equations are very similar to those we had in the vector case,
and we hence end up with a
linear system of the form <a href="#equation-fem:approx:vec:Np1dim:eqsys">(8)</a>, with</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= (\varphi_i,\varphi_j),
\\
b_i &amp;= (f,\varphi_i)\thinspace .\end{split}\]</div>
</div>
<div class="section" id="the-galerkin-or-projection-method-3">
<h2>The Galerkin or projection method  (3)<a class="headerlink" href="#the-galerkin-or-projection-method-3" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-8"></span><p id="index-9">As in the section <a class="reference internal" href="#fem-approx-vec-np1dim"><em>Approximation of general vectors</em></a>, the minimization of <span class="math">\((e,e)\)</span>
is equivalent to</p>
<div class="math" id="equation-fem:approx:Galerkin">
<span class="eqno">(14)</span>\[     (e,v)=0,\quad\forall v\in V\thinspace .\]</div>
<p>This is known as a projection of a function <span class="math">\(f\)</span> onto the subspace <span class="math">\(V\)</span>.
We may also call it a Galerkin method for approximating functions.
Using the same reasoning as
in
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(9)</a>-<a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(10)</a>,
it follows that <a href="#equation-fem:approx:Galerkin">(14)</a> is equivalent to</p>
<div class="math" id="equation-fem:approx:Galerkin0">
<span class="eqno">(15)</span>\[     (e,\varphi_i)=0,\quad i=0,\ldots,N\thinspace .\]</div>
<p>Inserting <span class="math">\(e=f-u\)</span> in this equation and ordering terms, as in the
multi-dimensional vector case, we end up with a linear
system with a coefficient matrix (<em class="xref std std-ref">fem:approx:Aij</em>) and
right-hand side vector (<em class="xref std std-ref">fem:approx:bi</em>).</p>
<p>Whether we work with vectors in the plane, general vectors, or
functions in function spaces, the least squares principle and
the Galerkin or projection method are equivalent.</p>
</div>
<div class="section" id="example-linear-approximation">
<span id="fem-approx-global-linear"></span><h2>Example: linear approximation<a class="headerlink" href="#example-linear-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us apply the theory in the previous section to a simple problem:
given a parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> for <span class="math">\(x\in\Omega=[1,2]\)</span>, find
the best approximation <span class="math">\(u(x)\)</span> in the space of all linear functions:</p>
<div class="math">
\[V = \hbox{span}\,\{1, x\}\thinspace .\]</div>
<p>That is, <span class="math">\(\varphi_0(x)=1\)</span>, <span class="math">\(\varphi_1(x)=x\)</span>, and <span class="math">\(N=1\)</span>.
We seek</p>
<div class="math">
\[u=c_0\varphi_0(x) + c_1\varphi_1(x) = c_0 + c_1x,\]</div>
<p>where
<span class="math">\(c_0\)</span> and <span class="math">\(c_1\)</span> are found by solving a <span class="math">\(2\times 2\)</span> the linear system.
The coefficient matrix has elements</p>
<div class="math">
\[\begin{split}A_{0,0} &amp;= (\varphi_0,\varphi_0) = \int_1^21\cdot 1\, dx = 1,\\
A_{0,1} &amp;= (\varphi_0,\varphi_1) = \int_1^2 1\cdot x\, dx = 3/2,\\
A_{1,0} &amp;= A_{0,1} = 3/2,\\
A_{1,1} &amp;= (\varphi_1,\varphi_1) = \int_1^2 x\cdot x\,dx = 7/3\thinspace .\end{split}\]</div>
<p>The corresponding right-hand side is</p>
<div class="math">
\[\begin{split}b_1 &amp;= (f,\varphi_0) = \int_1^2 (10(x-1)^2 - 1)\cdot 1 \, dx = 7/3,\\
b_2 &amp;= (f,\varphi_1) = \int_1^2 (10(x-1)^2 - 1)\cdot x\, dx = 13/3\thinspace .\end{split}\]</div>
<p>Solving the linear system results in</p>
<div class="math">
\[c_0 = -38/3,\quad c_1 = 10,\]</div>
<p>and consequently</p>
<div class="math">
\[u(x) = 10x - \frac{38}{3}\thinspace .\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-linear"><em>Best approximation of a parabola by a straight line</em></a> displays the
parabola and its best approximation in the space of all linear functions.</p>
<div class="figure" id="fem-approx-global-fig-parabola-linear">
<img alt="_images/parabola_ls_linear.png" src="_images/parabola_ls_linear.png" style="width: 400px;" />
<p class="caption"><em>Best approximation of a parabola by a straight line</em></p>
</div>
</div>
<div class="section" id="implementation-of-the-least-squares-method">
<span id="fem-approx-global-ls-code"></span><h2>Implementation of the least squares method<a class="headerlink" href="#implementation-of-the-least-squares-method" title="Permalink to this headline">¶</a></h2>
<p>The linear system can be computed either symbolically or
numerically (a numerical integration rule is needed in the latter case).
Here is a function for symbolic computation of the linear system,
where <span class="math">\(f(x)\)</span> is given as a <tt class="docutils literal"><span class="pre">sympy</span></tt> expression <tt class="docutils literal"><span class="pre">f</span></tt> (involving
the symbol <tt class="docutils literal"><span class="pre">x</span></tt>), <tt class="docutils literal"><span class="pre">phi</span></tt> is a list of <span class="math">\(\varphi_0,\ldots,\varphi_N\)</span>,
and <tt class="docutils literal"><span class="pre">Omega</span></tt> is a 2-tuple/list holding the domain <span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                                  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>Observe that we exploit the symmetry of the coefficient matrix:
only the upper triangular part is computed. Symbolic integration in
<tt class="docutils literal"><span class="pre">sympy</span></tt> is often time consuming, and (roughly) halving the
work has noticeable effect on the waiting time for the function to
finish execution.</p>
<p>Comparing the given <span class="math">\(f(x)\)</span> and the approximate <span class="math">\(u(x)\)</span> visually is
done by the following function, which with the aid of
<cite>sympy</cite>&#8216;s <tt class="docutils literal"><span class="pre">lambdify</span></tt> tool converts a <tt class="docutils literal"><span class="pre">sympy</span></tt>
functional expression to a Python function for numerical
computations:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&#39;tmp.pdf&#39;</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">u</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="s">&quot;numpy&quot;</span><span class="p">)</span>
    <span class="n">resolution</span> <span class="o">=</span> <span class="mi">401</span>  <span class="c"># no of points in plot</span>
    <span class="n">xcoor</span>  <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">resolution</span><span class="p">)</span>
    <span class="n">exact</span>  <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">approx</span> <span class="o">=</span> <span class="n">u</span><span class="p">(</span><span class="n">xcoor</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">approx</span><span class="p">)</span>
    <span class="n">hold</span><span class="p">(</span><span class="s">&#39;on&#39;</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">xcoor</span><span class="p">,</span> <span class="n">exact</span><span class="p">)</span>
    <span class="n">legend</span><span class="p">([</span><span class="s">&#39;approximation&#39;</span><span class="p">,</span> <span class="s">&#39;exact&#39;</span><span class="p">])</span>
    <span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">modules='numpy'</span></tt> argument to <tt class="docutils literal"><span class="pre">lambdify</span></tt> is important
if there are mathematical functions, such as <tt class="docutils literal"><span class="pre">sin</span></tt> or <tt class="docutils literal"><span class="pre">exp</span></tt>
in the symbolic expressions in <tt class="docutils literal"><span class="pre">f</span></tt> or <tt class="docutils literal"><span class="pre">u</span></tt>, and these
mathematical functions are to be used with vector arguments, like
<tt class="docutils literal"><span class="pre">xcoor</span></tt> above.</p>
<p>Both the <tt class="docutils literal"><span class="pre">least_squares</span></tt> and
<tt class="docutils literal"><span class="pre">comparison_plot</span></tt>
are found and coded in the file
<a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/approx1D.py">approx1D.py</a>.
The forthcoming examples on their use appear in
<tt class="docutils literal"><span class="pre">ex_approx1D.py</span></tt>.</p>
</div>
<div class="section" id="perfect-approximation">
<span id="fem-approx-global-exact"></span><h2>Perfect approximation<a class="headerlink" href="#perfect-approximation" title="Permalink to this headline">¶</a></h2>
<p>Let us use the code above to recompute the problem from
the section <a class="reference internal" href="#fem-approx-global-linear"><em>Example: linear approximation</em></a> where we want to approximate
a parabola. What happens if we add an element <span class="math">\(x^2\)</span> to the basis and test what
the best approximation is if <span class="math">\(V\)</span> is the space of all parabolic functions?
The answer is quickly found by running</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">10*x**2 - 20*x + 9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">10*x**2 - 20*x + 9</span>
</pre></div>
</div>
<p>Now, what if we use <span class="math">\(\phi_i(x)=x^i\)</span> for <span class="math">\(i=0,\ldots,N=40\)</span>?
The output from <tt class="docutils literal"><span class="pre">least_squares</span></tt> gives <span class="math">\(c_i=0\)</span> for <span class="math">\(i&gt;2\)</span>.
In fact, we have a general result that
if <span class="math">\(f\in V\)</span>, the least squares and Galerkin/projection methods compute
the exact solution <span class="math">\(u=f\)</span>.</p>
<p>The proof is straightforward: if <span class="math">\(f\in V\)</span>, <span class="math">\(f\)</span> can be expanded in
terms of the basis functions, <span class="math">\(f=\sum_{j=0}^Nd_j\varphi_j\)</span>, for
some coefficients <span class="math">\(d_0,\ldots,d_N\)</span>,
and the right-hand side then has entries</p>
<div class="math">
\[b_i = (f,\varphi_i) = \sum_{j=0}^Nd_j(\varphi_j, \varphi_i) = \sum_{j=0}^Nd_jA_{i,j}
\thinspace .\]</div>
<p>The linear system <span class="math">\(\sum_jA_{i,j}c_j = b_i\)</span>, <span class="math">\(i=0,\ldots,N\)</span>, is then</p>
<div class="math">
\[\sum_{j=0}^Nc_jA_{i,j} = \sum_{j=0}^Nd_jA_{i,j},\quad i=0,\ldots,N,\]</div>
<p>which implies that <span class="math">\(c_i=d_i\)</span> for <span class="math">\(i=0,\ldots,N\)</span>.</p>
</div>
<div class="section" id="ill-conditioning">
<span id="fem-approx-global-illconditioning"></span><h2>Ill-conditioning<a class="headerlink" href="#ill-conditioning" title="Permalink to this headline">¶</a></h2>
<p>The computational example in the section <a class="reference internal" href="#fem-approx-global-exact"><em>Perfect approximation</em></a>
applies the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function which invokes symbolic
methods to calculate and solve the linear system. The correct
solution <span class="math">\(c_0=9, c_1=-20, c_2=10, c_i=0\)</span> for <span class="math">\(i\geq 3\)</span> is perfectly
recovered.</p>
<p>Suppose we
convert the matrix and right-hand side to floating-point arrays
and then solve the system using finite-precision arithmetics, which
is what one will (almost) always do in real life. This time we
get astonishing results! Up to about <span class="math">\(N=7\)</span> we get a solution that
is reasonably close to the exact one. Increasing <span class="math">\(N\)</span> shows that
seriously wrong coefficients are computed.
Below is a table showing the solution of the linear system arising from
approximating a parabola
by functions on the form <span class="math">\(u(x)=\sum_{j=0}^Nc_jx^j\)</span>, <span class="math">\(N=10\)</span>.
Analytically, we know that <span class="math">\(c_j=0\)</span> for <span class="math">\(j&gt;2\)</span>, but ill-conditioning
may produce <span class="math">\(c_j\neq 0\)</span> for <span class="math">\(j&gt;2\)</span>.</p>
<p>The exact value of <span class="math">\(c_j\)</span>, <span class="math">\(j=0,\ldots,10\)</span>, appears in the first
column while the other columns correspond to results obtained
by three different methods:</p>
<blockquote>
<div><ul class="simple">
<li>Column 2: The matrix and vector are converted to
the data structure  <tt class="docutils literal"><span class="pre">sympy.mpmath.fp.matrix</span></tt> and the
<tt class="docutils literal"><span class="pre">sympy.mpmath.fp.lu_solve</span></tt> function is used to solve the system.</li>
<li>Column 3: The matrix and vector are converted to
<tt class="docutils literal"><span class="pre">numpy</span></tt> arrays with data type <tt class="docutils literal"><span class="pre">numpy.float32</span></tt>
(single precision floating-point number) and solved by
the <tt class="docutils literal"><span class="pre">numpy.linalg.solve</span></tt> function.</li>
<li>Column 4: As column 3, but the data type is
<tt class="docutils literal"><span class="pre">numpy.float64</span></tt> (double
precision floating-point number).</li>
</ul>
</div></blockquote>
<p>We see from the numbers in the table that
double precision performs much better than single precision.
Nevertheless, when plotting all these solutions the curves cannot be
visually distinguished (!). This means that the approximations look
perfect, despite the partially wrong values of the coefficients.</p>
<p>Increasing <span class="math">\(N\)</span> to 12 makes the numerical solver in <tt class="docutils literal"><span class="pre">sympy</span></tt> report
abort with the message: &#8220;matrix is numerically singular&#8221;.
A matrix has to be non-singular to be invertible, which is a requirement
when solving a linear system. Already when the matrix is close to
singular, it is <em>ill-conditioned</em>, which here implies that
the numerical solution algorithms are sensitive to round-off
errors and may produce (very) inaccurate results.</p>
<p>The reason why the coefficient matrix is nearly singular and
ill-conditioned is that our basis functions <span class="math">\(\varphi_i(x)=x^i\)</span> are
nearly linearly dependent for large <span class="math">\(i\)</span>.  That is, <span class="math">\(x^i\)</span> and <span class="math">\(x^{i+1}\)</span>
are very close for <span class="math">\(i\)</span> not very small. This phenomenon is
illustrated in Figure <a class="reference internal" href="#fem-approx-global-fig-illconditioning"><em>The 15 first basis functions , </em></a>.
There are 15 lines in this figure, but only half of them are
visually distinguishable.
Almost linearly dependent basis functions give rise to an
ill-conditioned and almost singular matrix.  This fact can be
illustrated by computing the determinant, which is indeed very close
to zero (recall that a zero determinant implies a singular and
non-invertible matrix): <span class="math">\(10^{-65}\)</span> for <span class="math">\(N=10\)</span> and <span class="math">\(10^{-92}\)</span> for
<span class="math">\(N=12\)</span>. Already for <span class="math">\(N=28\)</span> the numerical determinant computation
returns a plain zero.</p>
<div class="figure" id="fem-approx-global-fig-illconditioning">
<img alt="_images/ill_conditioning.png" src="_images/ill_conditioning.png" style="width: 600px;" />
<p class="caption">The 15 first basis functions <span class="math">\(x^i\)</span>, <span class="math">\(i=0,\ldots,14\)</span></p>
</div>
<p>On the other hand, the double precision <tt class="docutils literal"><span class="pre">numpy</span></tt> solver do run for
<span class="math">\(N=100\)</span>, resulting in answers that are not significantly worse than
those in the table above, and large powers are
associated with small coefficients (e.g., <span class="math">\(c_j&lt;10^{-2}\)</span> for <span class="math">\(10\leq
j\leq 20\)</span> and <span class="math">\(c&lt;10^{-5}\)</span> for <span class="math">\(j&gt;20\)</span>). Even for <span class="math">\(N=100\)</span> the
approximation lies on top of the exact curve in a plot (!).</p>
<p>The conclusion is that visual inspection of the quality of the approximation
may not uncover fundamental numerical problems with the computations.
However, numerical analysts have studied approximations and ill-conditioning
for decades, and it is well known that the basis <span class="math">\(\{1,x,x^2,x^3,\ldots,\}\)</span>
is a bad basis. The best basis from a matrix conditioning point of view
is to have orthogonal functions such that <span class="math">\((\phi_i,\phi_j)=0\)</span> for
<span class="math">\(i\neq j\)</span>. There are many known sets of orthogonal polynomials.
The functions used in the finite element methods are almost orthogonal,
and this property helps to avoid problems with solving matrix systems.
Almost orthogonal is helpful, but not enough when it comes to
partial differential equations, and ill-conditioning
of the coefficient matrix is a theme when solving large-scale finite
element systems.</p>
</div>
<div class="section" id="fourier-series">
<span id="fem-approx-global-fourier"></span><h2>Fourier series<a class="headerlink" href="#fourier-series" title="Permalink to this headline">¶</a></h2>
<p id="index-10">A set of sine functions is widely used for approximating functions.
Let us take</p>
<div class="math">
\[V = \hbox{span}\,\{ \sin \pi x, \sin 2\pi x,\ldots,\sin (N+1)\pi x\}
\thinspace .\]</div>
<p>That is,</p>
<div class="math">
\[\varphi_i(x) = \sin ((i+1)\pi x),\quad i=0,\ldots,N\thinspace .\]</div>
<p>An approximation to the <span class="math">\(f(x)\)</span> function from
the section <a class="reference internal" href="#fem-approx-global-linear"><em>Example: linear approximation</em></a> can then be computed by the
<tt class="docutils literal"><span class="pre">least_squares</span></tt> function from the section <a class="reference internal" href="#fem-approx-global-ls-code"><em>Implementation of the least squares method</em></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">pi</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sin</span><span class="p">(</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> (left) shows the oscillatory approximation
of <span class="math">\(\sum_{j=0}^{N}c_j\sin ((j+1)\pi x)\)</span> when <span class="math">\(N=3\)</span>.
Changing <span class="math">\(N\)</span> to 11 improves the approximation considerably, see
Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> (right).</p>
<div class="figure" id="fem-approx-global-fig-parabola-sine1">
<img alt="_images/parabola_ls_sines4_12.png" src="_images/parabola_ls_sines4_12.png" style="width: 800px;" />
<p class="caption"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></p>
</div>
<p>There is an error <span class="math">\(f(0)-u(0)=9\)</span> at <span class="math">\(x=0\)</span> in Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine1"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions</em></a> regardless of how large <span class="math">\(N\)</span> is, because all <span class="math">\(\varphi_i(0)=0\)</span> and hence
<span class="math">\(u(0)=0\)</span>. We may help the approximation to be correct at <span class="math">\(x=0\)</span> by
seeking</p>
<div class="math">
\[u(x) = f(0) + \sum_{j=0}^N c_j\varphi_j(x)
\thinspace .\]</div>
<p>However, this adjustments introduces a new problem at <span class="math">\(x=1\)</span> since
we now get an error <span class="math">\(f(1)-u(1)=f(1)-0=-1\)</span> at this point. A more
clever adjustment is to replace the <span class="math">\(f(0)\)</span> term by a term that
is <span class="math">\(f(0)\)</span> at <span class="math">\(x=0\)</span> and <span class="math">\(f(1)\)</span> at <span class="math">\(x=1\)</span>. A simple linear combination
<span class="math">\(f(0)(1-x) + xf(1)\)</span> does the job:</p>
<div class="math">
\[u(x) = f(0)(1-x) + xf(1) + \sum_{j=0}^N c_j\varphi_j(x)
\thinspace .\]</div>
<p>This adjustment of <span class="math">\(u\)</span> alters the linear system slightly as we get an extra
term <span class="math">\(-(f(0)(1-x) + xf(1),\varphi_i)\)</span> on the right-hand side.
Figure <a class="reference internal" href="#fem-approx-global-fig-parabola-sine2"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term</em></a> shows the result
of ensuring right boundary values: even 3 sines can now adjust the
<span class="math">\(f(0)(1-x) + xf(1)\)</span> term such that <span class="math">\(u\)</span> approximates the parabola really
well, at least visually.</p>
<div class="figure" id="fem-approx-global-fig-parabola-sine2">
<img alt="_images/parabola_ls_sines4_12_wfterm.png" src="_images/parabola_ls_sines4_12_wfterm.png" style="width: 800px;" />
<p class="caption"><em>Best approximation of a parabola by a sum of 3 (left) and 11 (right) sine functions with a boundary term</em></p>
</div>
</div>
<div class="section" id="orthogonal-basis-functions">
<span id="fem-approx-global-orth"></span><h2>Orthogonal basis functions<a class="headerlink" href="#orthogonal-basis-functions" title="Permalink to this headline">¶</a></h2>
<p>The choice of sine functions <span class="math">\(\varphi_i(x)=\sin ((i+1)\pi x)\)</span> has a great
computational advantage: on <span class="math">\(\Omega=[0,1]\)</span> these basis functions are
<em>orthogonal</em>, implying that <span class="math">\(A_{i,j}=0\)</span> if <span class="math">\(i\neq j\)</span>. This
result is realized by trying</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">integrate</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">j</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>in <a class="reference external" href="http://wolframalpha.com">WolframAlpha</a>
(avoid <tt class="docutils literal"><span class="pre">i</span></tt> in the integrand as this symbol means
the imaginary unit <span class="math">\(\sqrt{-1}\)</span>).
Also by asking WolframAlpha
about <span class="math">\(\int_0^1\sin^2 (j\pi x) dx\)</span>, we find it
to equal 1/2.
With a diagonal matrix we can easily solve for the coefficients
by hand:</p>
<div class="math">
\[c_i = 2\int_0^1 f(x)\sin ((i+1)\pi x) dx,\quad i=0,\ldots,N,\]</div>
<p>which is nothing but the classical formula for the coefficients of
the Fourier sine series of <span class="math">\(f(x)\)</span> on <span class="math">\([0,1]\)</span>. In fact, when
<span class="math">\(V\)</span> contains the basic functions used in a Fourier series expansion,
the approximation method derived in the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a>
results in the classical Fourier series for <span class="math">\(f(x)\)</span> (see <a class="reference internal" href="#fem-approx-exer-fourier"><em>Exercise 6: Fourier series as a least squares approximation</em></a>
for details).</p>
<p>For orthogonal basis functions we can make the
<tt class="docutils literal"><span class="pre">least_squares</span></tt> function (much) more efficient since we know that
the matrix is diagonal and only the diagonal elements need to be computed:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares_orth</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span><span class="p">,</span>  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">))]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>This function is found in the file <tt class="docutils literal"><span class="pre">approx1D.py</span></tt>.</p>
</div>
<div class="section" id="the-collocation-interpolation-method">
<span id="fem-approx-global-interp"></span><h2>The collocation (interpolation) method<a class="headerlink" href="#the-collocation-interpolation-method" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-11"></span><p id="index-12">The principle of minimizing the distance between <span class="math">\(u\)</span> and <span class="math">\(f\)</span> is
an intuitive way of computing a best approximation <span class="math">\(u\in V\)</span> to <span class="math">\(f\)</span>.
However, there are other attractive approaches as well.
One is to demand that <span class="math">\(u(x_{i}) = f(x_{i})\)</span> at some selected points
<span class="math">\(x_{i}\)</span>, <span class="math">\(i=0,\ldots,N\)</span>:</p>
<div class="math">
\[u(x_{i}) = \sum_{j=0}^N c_j \varphi_j(x_{i}) = f(x_{i}),\quad i=0,\ldots,N\thinspace .\]</div>
<p>This criterion also gives a linear system
with <span class="math">\(N+1\)</span> unknown coefficients <span class="math">\(c_0,\ldots,c_N\)</span>:</p>
<div class="math">
\[\sum_{j=0}^N A_{i,j}c_j = b_i,\quad i=0,\ldots,N,\]</div>
<p>with</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= \varphi_j(x_{i}),\\
b_i &amp;= f(x_{i})\thinspace .\end{split}\]</div>
<p>This time the coefficient matrix is not symmetric because
<span class="math">\(\varphi_j(x_{i})\neq \varphi_i(x_{j})\)</span> in general.
The method is often referred to as a <em>collocation method</em>
and the <span class="math">\(x_{i}\)</span> points are known as <em>collocation points</em>.
Others view the approach as an <em>interpolation method</em>
since some point values of <span class="math">\(f\)</span> are given (<span class="math">\(f(x_{i})\)</span>) and we
fit a continuous function <span class="math">\(u\)</span> that goes through the <span class="math">\(f(x_{i})\)</span> points.
In that case the <span class="math">\(x_{i}\)</span> points are called <em>interpolation points</em>.</p>
<span class="target" id="index-13"></span><p id="index-14">Given <span class="math">\(f\)</span>  as a <tt class="docutils literal"><span class="pre">sympy</span></tt> symbolic expression <tt class="docutils literal"><span class="pre">f</span></tt>, <span class="math">\(\varphi_0,\ldots,\varphi_N\)</span>
as a list <tt class="docutils literal"><span class="pre">phi</span></tt>, and a set of points <span class="math">\(x_0,\ldots,x_N\)</span>  as a list or array
<tt class="docutils literal"><span class="pre">points</span></tt>, the following Python function sets up and solves the matrix system
for the coefficients <span class="math">\(c_0,\ldots,c_N\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="c"># Turn phi and f into Python functions</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">](</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>Note that it is convenient to turn the expressions <tt class="docutils literal"><span class="pre">f</span></tt> and
<tt class="docutils literal"><span class="pre">phi</span></tt> into Python functions which can be called with
elements of <tt class="docutils literal"><span class="pre">points</span></tt> as arguments when building the matrix and
the right-hand side.
The <tt class="docutils literal"><span class="pre">interpolation</span></tt> function is a part of the <tt class="docutils literal"><span class="pre">approx1D</span></tt>
module.</p>
<p>A nice feature of the interpolation or collocation method is that it
avoids computing integrals. However, one has to decide on the location
of the <span class="math">\(x_{i}\)</span> points.  A simple, yet common choice, is to
distribute them uniformly throughout <span class="math">\(\Omega\)</span>.</p>
<div class="section" id="example-1">
<h3>Example  (1)<a class="headerlink" href="#example-1" title="Permalink to this headline">¶</a></h3>
<p>Let us illustrate the interpolation or collocation method by approximating
our parabola <span class="math">\(f(x)=10(x-1)^2-1\)</span> by a linear function on <span class="math">\(\Omega=[1,2]\)</span>,
using two collocation points <span class="math">\(x_0=1+1/3\)</span> and <span class="math">\(x_1=1+2/3\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting linear system becomes</p>
<div class="math">
\[\begin{split}\left(\begin{array}{ll}
1 &amp; 4/3\\
1 &amp; 5/3\\
\end{array}\right)
\left(\begin{array}{l}
c_0\\
c_1\\
\end{array}\right)
=
\left(\begin{array}{l}
1/9\\
31/9\\
\end{array}\right)\end{split}\]</div>
<p>with solution <span class="math">\(c_0=-119/9\)</span> and <span class="math">\(c_1=10\)</span>.
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></a> (left) shows the resulting
approximation <span class="math">\(u=-119/9 + 10x\)</span>.
We can easily test other interpolation points, say <span class="math">\(x_0=1\)</span> and <span class="math">\(x_1=2\)</span>.
This changes the line quite significantly, see
Figure <a class="reference internal" href="#fem-approx-global-linear-interp-fig1"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></a> (right).</p>
<div class="figure" id="fem-approx-global-linear-interp-fig1">
<img alt="_images/parabola_inter.png" src="_images/parabola_inter.png" style="width: 800px;" />
<p class="caption"><em>Approximation of a parabola by linear functions computed by two interpolation points: 4/3 and 5/3 (left) versus 1 and 2 (right)</em></p>
</div>
</div>
</div>
<div class="section" id="lagrange-polynomials">
<span id="fem-approx-global-lagrange"></span><h2>Lagrange polynomials<a class="headerlink" href="#lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p id="index-15">In the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a> we explain the advantage with having
a diagonal matrix: formulas for the coefficients <span class="math">\(c_0,\ldots,c_N\)</span> can
then be derived by hand. For an interpolation/collocation method a
diagonal matrix implies that
<span class="math">\(\varphi_j(x_{i}) = 0\)</span> if <span class="math">\(i\neq j\)</span>. One set of basis functions <span class="math">\(\varphi_i(x)\)</span>
with this property is the <em>Lagrange interpolating polynomials</em>,
or just <em>Lagrange polynomials</em>. (Although the functions are named
after Lagrange, they were first discovered by Waring in 1779,
rediscovered by Euler in 1783, and published by Lagrange in 1795.)
The Lagrange polynomials have the form</p>
<div class="math" id="equation-fem:approx:global:Lagrange:poly">
<span class="eqno">(16)</span>\[     \varphi_i(x) =
     \prod_{j=0,j\neq i}^N
     \frac{x-x_{j}}{x_{i}-x_{j}}
     = \frac{x-x_0}{x_{i}-x_0}\cdots\frac{x-x_{i-1}}{x_{i}-x_{i-1}}\frac{x-x_{i+1}}{x_{i}-x_{i+1}}
     \cdots\frac{x-x_N}{x_{i}-x_N},\]</div>
<p>for <span class="math">\(i=0,\ldots,N\)</span>.
We see from <a href="#equation-fem:approx:global:Lagrange:poly">(16)</a> that all the <span class="math">\(\varphi_i\)</span>
functions are polynomials of degree <span class="math">\(N\)</span> which have the property</p>
<div class="math" id="equation-fem:inter:prop">
<span class="eqno">(17)</span>\[\begin{split}     \varphi_i(x_s) = \left\lbrace\begin{array}{ll}
     1, &amp; i=s,\\
     0, &amp; i\neq s,
     \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_s\)</span> is an interpolation/collocation point.
This property implies that <span class="math">\(A_{i,j}=0\)</span> for <span class="math">\(i\neq j\)</span> and
<span class="math">\(A_{i,j}=1\)</span> when <span class="math">\(i=j\)</span>. The solution of the linear system is
them simply</p>
<div class="math">
\[c_i = f(x_{i}),\quad i=0,\ldots,N,\]</div>
<p>and</p>
<div class="math">
\[u(x) = \sum_{j=0}^N f(x_{i})\varphi_i(x)\thinspace .\]</div>
<p>The following function computes the Lagrange interpolating polynomial
<span class="math">\(\varphi_i(x)\)</span>, given the interpolation points <span class="math">\(x_{0},\ldots,x_{N}\)</span> in
the list or array <tt class="docutils literal"><span class="pre">points</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>The next function computes a complete basis using equidistant points throughout
<span class="math">\(\Omega\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">phi</span><span class="p">,</span> <span class="n">points</span>
</pre></div>
</div>
<p>When <tt class="docutils literal"><span class="pre">x</span></tt> is an <tt class="docutils literal"><span class="pre">sm.Symbol</span></tt> object, we let the
spacing between
the interpolation points, <tt class="docutils literal"><span class="pre">h</span></tt>, be a <tt class="docutils literal"><span class="pre">sympy</span></tt> rational number
for nice end results in the formulas for <span class="math">\(\varphi_i\)</span>.
The other case, when <tt class="docutils literal"><span class="pre">x</span></tt> is a plain Python <tt class="docutils literal"><span class="pre">float</span></tt>,
signifies numerical computing, and then we let <tt class="docutils literal"><span class="pre">h</span></tt> be a floating-point
number.
Observe that the <tt class="docutils literal"><span class="pre">Lagrange_polynomial</span></tt> function works equally well
in the symbolic and numerical case (think of <tt class="docutils literal"><span class="pre">x</span></tt> being an
<tt class="docutils literal"><span class="pre">sm.Symbol</span></tt> object or a Python <tt class="docutils literal"><span class="pre">float</span></tt>).
A little interactive session illustrates the difference between symbolic
and numerical computing of the basis functions and points:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">points</span>
<span class="go">[0, 1/2, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span>
<span class="go">[(1 - x)*(1 - 2*x), 2*x*(2 - 2*x), -x*(1 - 2*x)]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c"># numerical computing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">points</span>
<span class="go">[0.0, 0.5, 1.0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span>
<span class="go">[-0.0, 1.0, 0.0]</span>
</pre></div>
</div>
<p>The Lagrange polynomials are very much used in finite element methods
because of their property <a href="#equation-fem:inter:prop">(17)</a>.</p>
<div class="section" id="successful-example">
<h3>Successful example<a class="headerlink" href="#successful-example" title="Permalink to this headline">¶</a></h3>
<p>Trying out the Lagrange polynomial basis for approximating
<span class="math">\(f(x)=\sin 2\pi x\)</span> on <span class="math">\(\Omega =[0,1]\)</span> with the least squares
and the interpolation techniques can be done by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">phi</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">Lagrange_polynomials_01</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">interpolation</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span class="n">comparison_plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
</pre></div>
</div>
<p>Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-sine-ls-colloc"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 4</em></a> shows the results.
There is little difference between the least squares and the interpolation
technique. Increasing <span class="math">\(N\)</span> gives visually better approximations.</p>
<div class="figure" id="fem-approx-global-lagrange-fig-sine-ls-colloc">
<img alt="_images/Lagrange_ls_interp_sin_4.png" src="_images/Lagrange_ls_interp_sin_4.png" style="width: 800px;" />
<p class="caption"><em>Approximation via least squares (left) and interpolation (right) of a sine function by Lagrange interpolating polynomials of degree 4</em></p>
</div>
</div>
<div class="section" id="less-successful-example">
<h3>Less successful example<a class="headerlink" href="#less-successful-example" title="Permalink to this headline">¶</a></h3>
<p>The next example concerns interpolating <span class="math">\(f(x)=|1-2x|\)</span> on
<span class="math">\(\Omega =[0,1]\)</span> using Lagrange polynomials. Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></a> shows a peculiar effect: the approximation starts to oscillate
more and more as <span class="math">\(N\)</span> grows. This numerical artifact is not surprising
when looking at the individual Lagrange polynomials: Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-osc"><em>Illustration of the oscillatory behavior of two Lagrange polynomials for 12 uniformly spaced points (marked by circles)</em></a> shows two such polynomials of degree 11, and it is clear
that the basis functions oscillate significantly. The reason is simple,
since we force the functions to be 1 at one point and 0 at many other
points. A polynomial of high degree is then forced to oscillate between
these points. The oscillations are particularly severe at the boundary.
The phenomenon is named <em>Runge&#8217;s phenomenon</em> and you can read</p>
<p id="index-16">a more detailed explanation on Wikipedia.</p>
</div>
<div class="section" id="remedy-for-strong-oscillations">
<span id="index-17"></span><h3>Remedy for strong oscillations<a class="headerlink" href="#remedy-for-strong-oscillations" title="Permalink to this headline">¶</a></h3>
<p>The oscillations can be reduced by a more clever choice of
interpolation points, called the <em>Chebyshev nodes</em>:</p>
<div class="math">
\[x_{i} = \frac{1}{2} (a+b) + \frac{1}{2}(b-a)\cos\left( \frac{2i+1}{2(N+1)}pi\right),\quad i=0\ldots,N,\]</div>
<p>on the interval <span class="math">\(\Omega = [a,b]\)</span>.
Here is a flexible version of the <tt class="docutils literal"><span class="pre">Lagrange_polynomials_01</span></tt> function above,
valid for any interval <span class="math">\(\Omega =[a,b]\)</span> and with the possibility to generate
both uniformly distributed points and Chebyshev nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">Lagrange_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">point_distribution</span><span class="o">=</span><span class="s">&#39;uniform&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s">&#39;uniform&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">point_distribution</span> <span class="o">==</span> <span class="s">&#39;Chebyshev&#39;</span><span class="p">:</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">Chebyshev_nodes</span><span class="p">(</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">phi</span><span class="p">,</span> <span class="n">points</span>

<span class="k">def</span> <span class="nf">Chebyshev_nodes</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">cos</span><span class="p">,</span> <span class="n">pi</span>
    <span class="k">return</span> <span class="p">[</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">cos</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">pi</span><span class="p">)</span> \
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>All the functions computing Lagrange polynomials listed
above are found in the module file <tt class="docutils literal"><span class="pre">Lagrange.py</span></tt>.
Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-cheb-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></a> shows the improvement of
using Chebyshev nodes (compared with Figure <a class="reference internal" href="#fem-approx-global-lagrange-fig-abs-lag-unif-7-14"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></a>).</p>
<p>Another cure for undesired oscillation of higher-degree interpolating
polynomials is to use lower-degree Lagrange
polynomials on many small patches of the domain, which is the idea
pursued in the finite element method. For instance, linear Lagrange
polynomials on <span class="math">\([0,1/2]\)</span> and <span class="math">\([1/2,1]\)</span> would yield a perfect
approximation to <span class="math">\(f(x)=|1-2x|\)</span> on <span class="math">\(\Omega = [0,1]\)</span>
since <span class="math">\(f\)</span> is piecewise linear.</p>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-unif-7-14">
<img alt="_images/Lagrange_interp_abs_8_15.png" src="_images/Lagrange_interp_abs_8_15.png" style="width: 800px;" />
<p class="caption"><em>Interpolation of an absolute value function by Lagrange polynomials and uniformly distributed interpolation points: degree 7 (left) and 14 (right)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-unif-osc">
<img alt="_images/Lagrange_basis_12.png" src="_images/Lagrange_basis_12.png" style="width: 400px;" />
<p class="caption"><em>Illustration of the oscillatory behavior of two Lagrange polynomials for 12 uniformly spaced points (marked by circles)</em></p>
</div>
<div class="figure" id="fem-approx-global-lagrange-fig-abs-lag-cheb-7-14">
<img alt="_images/Lagrange_interp_abs_Cheb_8_15.png" src="_images/Lagrange_interp_abs_Cheb_8_15.png" style="width: 800px;" />
<p class="caption"><em>Interpolation of an absolute value function by Lagrange polynomials and Chebyshev nodes as interpolation points: degree 7 (left) and 14 (right)</em></p>
</div>
<p>Unfortunately, <tt class="docutils literal"><span class="pre">sympy</span></tt> has problems integrating the <span class="math">\(f(x)=|1-2x|\)</span>
function times a polynomial. Other choices of <span class="math">\(f(x)\)</span> can also
make the symbolic integration fail. Therefore, we should extend
the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function such that it falls back on
numerical integration if the symbolic integration is unsuccessful.
In the latter case, the returned value from <cite>sympy</cite>&#8216;s
<tt class="docutils literal"><span class="pre">integrate</span></tt> function is an object of type <tt class="docutils literal"><span class="pre">Integral</span></tt>.
We can test on this type and utilize the <tt class="docutils literal"><span class="pre">mpmath</span></tt> module in
<tt class="docutils literal"><span class="pre">sympy</span></tt> to perform numerical integration of high precision.
Here is the code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="c"># Could not integrate symbolically, fallback</span>
                <span class="c"># on numerical integration with mpmath.quad</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)):</span>
        <span class="n">u</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="finite-element-basis-functions">
<span id="fem-approx-fe"></span><h1>Finite element basis functions<a class="headerlink" href="#finite-element-basis-functions" title="Permalink to this headline">¶</a></h1>
<p>The specific basis functions exemplified in the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> are in general nonzero on the entire domain
<span class="math">\(\Omega\)</span>, see Figure{fem:approx:fe:fig:u:sin} for an example. We shall
now turn the attention to basis functions that have <em>compact support</em>,
meaning that they are nonzero on only a small portion of
<span class="math">\(\Omega\)</span>. Moreover, we shall restrict the functions to be <em>piecewise
polynomials</em>. This means that the domain is split into subdomains and
the function is a polynomial on one or more subdomains, see Figure
<em class="xref std std-ref">fem:approx:fe:fig:u:sfe</em> for a sketch involving locally defined
hat functions that make <span class="math">\(u=\sum_jc_j\varphi_j\)</span> piecewise linear. At
the boundaries between subdomains one normally forces continuity of
the function only so that when connecting two polynomials from two
subdomains, the derivative usually becomes discontinuous. These type
of basis functions are fundamental in the <em>finite element method</em>.</p>
<div class="figure" id="fem-approx-fe-fig-u-sin">
<img alt="_images/u_example_sin.png" src="_images/u_example_sin.png" style="width: 600px;" />
<p class="caption"><em>Approximation based on sine basis functions</em></p>
</div>
<div class="figure" id="fem-approx-fe-fig-u-fe">
<img alt="_images/u_example_fe.png" src="_images/u_example_fe.png" style="width: 600px;" />
<p class="caption"><em>Approximation based on local piecewise linear (hat) functions</em></p>
</div>
<p>We first introduce the concepts of elements and nodes in a simplistic fashion
as often met in the literature. Later, we shall generalize the concept
of an element, which is a necessary step to treat a wider class of
approximations within the family of finite element methods.
The generalization is also compatible with
the concepts used in the <a class="reference external" href="http://fenicsproject.org">FEniCS</a> finite
element software.</p>
<div class="section" id="elements-and-nodes">
<span id="fem-approx-fe-def-elements-nodes"></span><h2>Elements and nodes<a class="headerlink" href="#elements-and-nodes" title="Permalink to this headline">¶</a></h2>
<p>Let us divide the interval <span class="math">\(\Omega\)</span> on which <span class="math">\(f\)</span> and <span class="math">\(u\)</span> are defined
into non-overlapping subintervals <span class="math">\(\Omega^{(e)}\)</span>, <span class="math">\(e=0,\ldots,n_e\)</span>:</p>
<div class="math">
\[\Omega = \Omega^{(0)}\cup \cdots \cup \Omega^{(n_e)}\thinspace .\]</div>
<p>We shall for now
refer to <span class="math">\(\Omega^{(e)}\)</span> as an <em>element</em>, having number <span class="math">\(e\)</span>.
On each element we introduce a set of points called <em>nodes</em>.
For now we assume that the nodes are uniformly spaced throughout the
element and that the boundary points of the elements are also nodes.
The nodes are given numbers both within an element and in the global
domain. These are
referred to as <em>local</em> and <em>global</em> node numbers, respectively.</p>
<p>Nodes and elements uniquely define a <em>finite element mesh</em>, which is our
discrete representation of the domain in the computations.
.. index:: finite element mesh</p>
<p id="index-18">A common special case is that of a <em>uniformly partitioned mesh</em> where
each element has the same length and the distance between nodes is constant.</p>
<div class="section" id="example-2">
<h3>Example  (2)<a class="headerlink" href="#example-2" title="Permalink to this headline">¶</a></h3>
<p>On <span class="math">\(\Omega =[0,1]\)</span> we may introduce two elements,
<span class="math">\(\Omega^{(0)}=[0,0.4]\)</span> and <span class="math">\(\Omega^{(1)}=[0.4,1]\)</span>. Furthermore,
let us introduce three nodes
per element, equally spaced within each element.
The three nodes in element number 0 are <span class="math">\(x_0=0\)</span>, <span class="math">\(x_1=0.2\)</span>, and <span class="math">\(x_2=0.4\)</span>.
The local and global node numbers are here equal.
In element number 1, we have the local nodes <span class="math">\(x_0=0.4\)</span>, <span class="math">\(x_1=0.7\)</span>, and <span class="math">\(x_2=1\)</span>
and the corresponding
global nodes <span class="math">\(x_2=0.4\)</span>, <span class="math">\(x_3=0.7\)</span>, and <span class="math">\(x_4=1\)</span>. Note that
the global node <span class="math">\(x_2=0.4\)</span> is shared by the two elements.</p>
<p>For the purpose of implementation, we introduce two lists or arrays:
<tt class="docutils literal"><span class="pre">nodes</span></tt> for storing the coordinates of the nodes, with the
global node numbers as indices, and <tt class="docutils literal"><span class="pre">elements</span></tt> for holding
the global node numbers in each element, with the local node numbers
as indices. The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists for the sample mesh
above take the form</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
</pre></div>
</div>
<p>Looking up the coordinate of local node number 2 in element 1
is here done by <tt class="docutils literal"><span class="pre">nodes[elements[1][2]]</span></tt> (recall that nodes and
elements start their numbering at 0).</p>
</div>
</div>
<div class="section" id="the-basis-functions">
<h2>The basis functions<a class="headerlink" href="#the-basis-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="construction-principles">
<h3>Construction principles<a class="headerlink" href="#construction-principles" title="Permalink to this headline">¶</a></h3>
<p>Standard finite element basis functions are now defined as follows.
Let <span class="math">\(i\)</span> be the global node number corresponding to local node <span class="math">\(r\)</span>
in element number <span class="math">\(e\)</span>.</p>
<blockquote>
<div><ul class="simple">
<li>If local node number <span class="math">\(r\)</span> is not on the boundary of the element,
take <span class="math">\(\varphi_i(x)\)</span> to be the Lagrange
polynomial that is 1 at the local node number <span class="math">\(r\)</span> and zero
at all other nodes in the element. On all other elements, <span class="math">\(\varphi_i=0\)</span>.</li>
<li>If local node number <span class="math">\(r\)</span> is on the boundary of the element,
let <span class="math">\(\varphi_i\)</span> be made up of the Lagrange polynomial that is 1 at this node
in element number <span class="math">\(e\)</span> and its neighboring element.
On all other elements, <span class="math">\(\varphi_i=0\)</span>.</li>
</ul>
</div></blockquote>
<p>A visual impression of three such basis functions are given in
Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>.
Sometimes we refer to a Lagrange polynomial on an element <span class="math">\(e\)</span>, which
means the basis function <span class="math">\(\varphi_i(x)\)</span> when <span class="math">\(x\in\Omega^{(e)}\)</span>, and
<span class="math">\(\varphi_i(x)=0\)</span> when <span class="math">\(x\notin\Omega^{(e)}\)</span>.</p>
<div class="figure" id="fem-approx-fe-fig-p2">
<img alt="_images/mpl_fe_basis_p2_4e_lab.png" src="_images/mpl_fe_basis_p2_4e_lab.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise quadratic basis functions associated with nodes in element 1</em></p>
</div>
</div>
<div class="section" id="properties-of">
<h3>Properties of <span class="math">\(\varphi_i\)</span><a class="headerlink" href="#properties-of" title="Permalink to this headline">¶</a></h3>
<p>The construction of basis functions according to the principles above
lead to two important properties of <span class="math">\(\varphi_i(x)\)</span>. First,</p>
<div class="math" id="equation-fem:approx:fe:phi:prop1">
<span class="eqno">(18)</span>\[\begin{split}     \varphi_i(x_{j}) =
     \left\lbrace\begin{array}{ll}
     1, &amp; i=j,\\
     0, &amp; i\neq j,
     \end{array}\right.\end{split}\]</div>
<p>when <span class="math">\(x_{j}\)</span> is a node in the mesh with global node number <span class="math">\(j\)</span>,
because the Lagrange polynomials are constructed to have this property.
The property also implies a convenient interpretation of <span class="math">\(c_i\)</span>
as the value of <span class="math">\(u\)</span> at node <span class="math">\(i\)</span>:</p>
<div class="math">
\[u(x_{i}) = \sum_{j=0}^N c_j \varphi_j (x_{i}) =
c_i \varphi_i (x_{i}) = c_i
\thinspace .\]</div>
<p>Because of this interpretation,
the coefficient <span class="math">\(c_i\)</span> is by many named <span class="math">\(u_i\)</span> or <span class="math">\(U_i\)</span>.</p>
<p>Second,
<span class="math">\(\varphi_i(x)\)</span> is mostly zero throughout the domain:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(\varphi_i(x) \neq 0\)</span> only on those elements that contain global node <span class="math">\(i\)</span>,</li>
<li><span class="math">\(\varphi_i(x)\varphi_j(x) \neq 0\)</span> if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are global node
numbers in the same element.</li>
</ul>
</div></blockquote>
<p>Since <span class="math">\(A_{i,j}\)</span> is the integral of
<span class="math">\(\varphi_i\varphi_j\)</span> it means that
<em>most of the elements in the coefficient matrix will be zero</em>.
We will come back to these properties and use
them actively in computations to save memory and CPU time.</p>
<p>We let each element have <span class="math">\(d+1\)</span> nodes, resulting in local Lagrange
polynomials of degree <span class="math">\(d\)</span>. It is not a requirement to have the same
<span class="math">\(d\)</span> value in each element, but for now we will assume so.</p>
</div>
<div class="section" id="example-on-quadratic">
<h3>Example on quadratic <span class="math">\(\varphi_i\)</span><a class="headerlink" href="#example-on-quadratic" title="Permalink to this headline">¶</a></h3>
<p>Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em> illustrates how piecewise
quadratic basis functions can look like (<span class="math">\(d=2\)</span>). We work with the
domain <span class="math">\(\Omega = [0,1]\)</span> divided into four equal-sized elements, each having
three nodes.
The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists in this particular example become</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.375</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.625</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.875</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
</pre></div>
</div>
<p>Nodes are marked with circles on the <span class="math">\(x\)</span> axis in the figure, and
element boundaries are marked with vertical dashed lines.</p>
<div class="figure" id="id1">
<img alt="_images/mpl_fe_basis_p2_4e_lab.png" src="_images/mpl_fe_basis_p2_4e_lab.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise quadratic basis functions associated with nodes in element 1</em></p>
</div>
<p>Let us explain in detail how the basis functions are constructed
according to the principles.
Consider element number 1 in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>,
<span class="math">\(\Omega^{(1)}=[0.25, 0.5]\)</span>, with local nodes
0, 1, and 2 corresponding to global nodes 2, 3, and 4.
The coordinates of these nodes are
<span class="math">\(0.25\)</span>, <span class="math">\(0.375\)</span>, and <span class="math">\(0.5\)</span>, respectively.
We define three Lagrange
polynomials on this element:</p>
<ol class="arabic simple">
<li>The polynomial that is 1 at local node 1
(<span class="math">\(x=0.375\)</span>, global node 3) makes up the basis function
<span class="math">\(\varphi_3(x)\)</span> over this element,
with <span class="math">\(\varphi_3(x)=0\)</span> outside the element.</li>
<li>The Lagrange polynomial that is 1 at local node 0 is the &#8220;right
part&#8221; of the global basis function
<span class="math">\(\varphi_2(x)\)</span>. The &#8220;left part&#8221; of <span class="math">\(\varphi_2(x)\)</span> consists of
a Lagrange polynomial associated with local node 2 in
the neighboring element <span class="math">\(\Omega^{(0)}=[0, 0.25]\)</span>.</li>
<li>Finally, the polynomial that is 1 at local node 2 (global node 4)
is the &#8220;left part&#8221; of the global basis function <span class="math">\(\varphi_4(x)\)</span>.
The &#8220;right part&#8221; comes from the Lagrange polynomial that is 1 at
local node 0 in the neighboring element <span class="math">\(\Omega^{(2)}=[0.5, 0.75]\)</span>.</li>
</ol>
<p>As mentioned earlier,
any global basis function <span class="math">\(\varphi_i(x)\)</span> is zero on elements that
do not share the node with global node number <span class="math">\(i\)</span>.</p>
<p>The other global functions associated with internal
nodes, <span class="math">\(\varphi_1\)</span>, <span class="math">\(\varphi_5\)</span>, and <span class="math">\(\varphi_7\)</span>, are all of the
same shape as the drawn <span class="math">\(\varphi_3\)</span>, while the global basis functions
associated with shared nodes also have the same shape, provided the
elements are of the same length.</p>
<div class="figure" id="fem-approx-fe-fig-p1">
<img alt="_images/mpl_fe_basis_p1_4e_lab.png" src="_images/mpl_fe_basis_p1_4e_lab.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></p>
</div>
</div>
<div class="section" id="example-on-linear">
<h3>Example on linear <span class="math">\(\varphi_i\)</span><a class="headerlink" href="#example-on-linear" title="Permalink to this headline">¶</a></h3>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a> shows
piecewise linear basis functions (<span class="math">\(d=1\)</span>). Also here we have four elements on
<span class="math">\(\Omega = [0,1]\)</span>. Consider the element <span class="math">\(\Omega^{(1)}=[0.25,0.5]\)</span>.
Now there are no internal nodes in the elements so that all basis
functions are associated with nodes at the element boundaries and hence
made up of two Lagrange polynomials from neighboring elements.
For example, <span class="math">\(\varphi_1(x)\)</span> results from the Lagrange polynomial in
element 0 that is 1 at local node 1 and 0 at local node 0, combined with
the Lagrange polynomial in
element 1 that is 1 at local node 0 and 0 at local node 1.
The other basis functions are constructed similarly.</p>
<p>Explicit mathematical formulas are needed for <span class="math">\(\varphi_i(x)\)</span> in computations.
In the
piecewise linear case, one can show that</p>
<div class="math" id="equation-fem:approx:fe:phi:1:formula1">
<span class="eqno">(19)</span>\[\begin{split}     \varphi_i(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     (x - x_{i-1})/(x_{i} - x_{i-1}),
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     1 -
     (x - x_{i})/(x_{i+1} - x_{i}),
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}\thinspace . \end{array}
     \right.\end{split}\]</div>
<p>Here, <span class="math">\(x_{j}\)</span>, <span class="math">\(j=i-1,i,i+1\)</span>, denotes the coordinate of node <span class="math">\(j\)</span>.
For elements of equal length <span class="math">\(h\)</span> the formulas can be simplified to</p>
<div class="math" id="equation-fem:approx:fe:phi:1:formula2">
<span class="eqno">(20)</span>\[\begin{split}     \varphi_i(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     (x - x_{i-1})/h,
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     1 -
     (x - x_{i})/h,
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}
     \end{array}
     \right.\end{split}\]</div>
</div>
<div class="section" id="example-on-cubic">
<h3>Example on cubic <span class="math">\(\varphi_i\)</span><a class="headerlink" href="#example-on-cubic" title="Permalink to this headline">¶</a></h3>
<p>Piecewise cubic basis functions can be defined by introducing four
nodes per element. Figure <a class="reference internal" href="#fem-approx-fe-fig-p3"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></a> shows
examples on <span class="math">\(\varphi_i(x)\)</span>, <span class="math">\(i=3,4,5,6\)</span>, associated with element number 1.
Note that <span class="math">\(\varphi_4\)</span> and <span class="math">\(\varphi_5\)</span> are nonzero on element number 1,
while
<span class="math">\(\varphi_3\)</span> and <span class="math">\(\varphi_6\)</span> are made up of Lagrange polynomials on two
neighboring elements.</p>
<div class="figure" id="fem-approx-fe-fig-p3">
<img alt="_images/mpl_fe_basis_p3_4e.png" src="_images/mpl_fe_basis_p3_4e.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></p>
</div>
<p>We see that all the piecewise linear basis functions have the same
&#8220;hat&#8221; shape. They are naturally referred to as <em>hat functions</em>,
also called <em>chapau functions</em>.
The piecewise quadratic functions in Figure <em class="xref std std-ref">fem:approx:fe:fig:P2</em>
are seen to be of two types. &#8220;Rounded hats&#8221; associated with internal
nodes in the elements and some more &#8220;sombrero&#8221; shaped hats associated
with element boundary nodes. Higher-order basis functions also have
hat-like shapes, but the functions have pronounced oscillations in addition,
as illustrated in Figure <a class="reference internal" href="#fem-approx-fe-fig-p3"><em>Illustration of the piecewise cubic basis functions associated with nodes in element 1</em></a>.</p>
<span class="target" id="index-19"></span><span class="target" id="index-20"></span><span class="target" id="index-21"></span><p id="index-22">A common terminology is to speak about <em>linear elements</em> as
elements with two local nodes and where the basis functions are
piecewise linear. Similarly, <em>quadratic elements</em> and
<em>cubic elements</em> refer to piecewise quadratic or cubic functions
over elements with three or four local nodes, respectively.
Alternative names, frequently used later, are P1 elements for linear
elements, P2 for quadratic elements, and so forth (P$d$ signifies
degree <span class="math">\(d\)</span> of the polynomial basis functions).</p>
</div>
</div>
<div class="section" id="calculating-the-linear-system">
<span id="fem-approx-global-linearsystem"></span><h2>Calculating the linear system<a class="headerlink" href="#calculating-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>The elements in the coefficient matrix and right-hand side, given
by the formulas (<em class="xref std std-ref">fem:approx:Aij</em>) and (<em class="xref std std-ref">fem:approx:bi</em>),
will now be calculated for piecewise polynomial basis
functions. Consider P1 (piecewise linear) elements. Nodes and elements
numbered consecutively from left to right imply the nodes
<span class="math">\(x_i=i h\)</span> and the elements</p>
<div class="math">
\[\Omega^{(i)} = [x_{i},x_{i+1}] = [i h, (i+1)h],\quad
i=0,\ldots,N-1
\thinspace .\]</div>
<p>We have in this case <span class="math">\(N\)</span> elements and <span class="math">\(N+1\)</span> nodes,
and <span class="math">\(\Omega=[x_{0},x_{N}]\)</span>.
The formula for <span class="math">\(\varphi_i(x)\)</span> is given by
<a href="#equation-fem:approx:fe:phi:1:formula2">(20)</a> and a graphical illustration is
provided in Figure <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a>.  First we clearly see
from Figure <a class="reference internal" href="#fem-approx-fe-fig-p1"><em>Illustration of the piecewise linear basis functions associated with nodes in element 1</em></a> that the important property
<span class="math">\(\varphi_i(x)\varphi_j(x)\neq 0\)</span> if and only if <span class="math">\(j=i-1\)</span>, <span class="math">\(j=i\)</span>, or
<span class="math">\(j=i+1\)</span>, or alternatively expressed, if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are
nodes in the same element. Otherwise, <span class="math">\(\varphi_i\)</span> and <span class="math">\(\varphi_j\)</span> are
too distant to have an overlap and consequently a nonzero product.</p>
<p>The element <span class="math">\(A_{i,i-1}\)</span> in the coefficient matrix can be calculated as</p>
<div class="math">
\[\int_\Omega \varphi_i\varphi_{i-1}dx = \int_{x_{i-1}}^{x_{i}}
\left(1 - \frac{x - x_{i-1}}{h}\right)\frac{x - x_{i}}{h} dx =
\frac{h}{6}
\thinspace .\]</div>
<p>It turns out that <span class="math">\(A_{i,i+1} =h/6\)</span> as well and that
<span class="math">\(A_{i,i}=2h/3\)</span>. The numbers are modified for <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span>:
<span class="math">\(A_{0,0}=h/3\)</span> and <span class="math">\(A_{N,N}=h/3\)</span>.
The general formula for the right-hand side becomes</p>
<div class="math" id="equation-fem:approx:fe:bi:formula1">
<span class="eqno">(21)</span>\[     b_i = \int_{x_{i-1}}^{x_{i}} \frac{x - x_{i-1}}{h} f(x)dx
     + \int_{x_{i}}^{x_{i+1}} \left(1 - \frac{x - x_{i}}{h}\right) f(x)dx\thinspace .\]</div>
<p>With two equal-sized elements in <span class="math">\(\Omega=[0,1]\)</span> and <span class="math">\(f(x)=x(1-x)\)</span>, one gets</p>
<div class="math">
\[\begin{split}A = \frac{h}{6}\left(\begin{array}{ccc}
2 &amp; 1 &amp; 0\\
1 &amp; 4 &amp; 1\\
0 &amp; 1 &amp; 2
\end{array}\right),\quad
b = \frac{h^2}{12}\left(\begin{array}{c}
2 - 3h\\
12 - 14h\\
10 -17h
\end{array}\right)\thinspace .\end{split}\]</div>
<p>The solution becomes</p>
<div class="math">
\[c_0 = \frac{h^2}{6},\quad c_1 = h - \frac{5}{6}h^2,\quad
c_2 = 2h - \frac{23}{6}h^2\thinspace .\]</div>
<p>The resulting function</p>
<div class="math">
\[u(x)=c_0\varphi_0(x) + c_1\varphi_1(x) + c_2\varphi_2(x)\]</div>
<p>is displayed in Figure <a class="reference internal" href="#fem-approx-fe-fig-ls-p1-2-4"><em>Least squares approximation using 2 (left) and 4 (right) P1 elements</em></a> (left).
Doubling the number of elements to four leads to the improved
approximation in the right part of Figure <a class="reference internal" href="#fem-approx-fe-fig-ls-p1-2-4"><em>Least squares approximation using 2 (left) and 4 (right) P1 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-fig-ls-p1-2-4">
<img alt="_images/fe_p1_x2_2e_4e.png" src="_images/fe_p1_x2_2e_4e.png" style="width: 800px;" />
<p class="caption"><em>Least squares approximation using 2 (left) and 4 (right) P1 elements</em></p>
</div>
</div>
<div class="section" id="assembly-of-elementwise-computations">
<span id="fem-approx-fe-elementwise"></span><h2>Assembly of elementwise computations<a class="headerlink" href="#assembly-of-elementwise-computations" title="Permalink to this headline">¶</a></h2>
<p>The integrals are naturally split into integrals over individual elements
since the formulas change with the elements. This idea of splitting the
integral is fundamental in all practical implementations of the finite
element method.</p>
<p>Let us split the integral over <span class="math">\(\Omega\)</span> into a sum of contributions from
each element:</p>
<div class="math" id="equation-fem:approx:fe:elementwise:Asplit">
<span class="eqno">(22)</span>\[     A_{i,j} = \int_\Omega\varphi_i\varphi_jdx = \sum_{e} A^{(e)}_{i,j},\quad
     A^{(e)}_{i,j}=\int_{\Omega^{(e)}} \varphi_i\varphi_jdx\thinspace .\]</div>
<p>Now, <span class="math">\(A^{(e)}_{i,j}\neq 0\)</span> if and only if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in element
<span class="math">\(e\)</span>. Introduce <span class="math">\(i=q(e,r)\)</span> as the mapping of local node number <span class="math">\(r\)</span> in element
<span class="math">\(e\)</span> to the global node number <span class="math">\(i\)</span>. This is just a short mathematical notation
for the expression <tt class="docutils literal"><span class="pre">i=elements[e][r]</span></tt> in a program.
Let <span class="math">\(r\)</span> and <span class="math">\(s\)</span> be the local node numbers corresponding to the global
node numbers <span class="math">\(i=q(e,r)\)</span> and
<span class="math">\(j=q(e,s)\)</span>. With <span class="math">\(d\)</span> nodes per element, all the nonzero elements
in <span class="math">\(A^{(e)}_{i,j}\)</span> arise from the integrals involving basis functions with
indices corresponding to the global node numbers in element number <span class="math">\(e\)</span>:</p>
<div class="math" id="index-23">
\[\int_{\Omega^{(e)}}\varphi_{q(e,r)}\varphi_{q(e,s)}dx,\quad r,s=0,\ldots, d\thinspace .\]</div>
<p>These contributions can be collected in a <span class="math">\((d+1)\times (d+1)\)</span> matrix known as
the <em>element matrix</em>.
We introduce the notation</p>
<div class="math">
\[\tilde A^{(e)} = \{ \tilde A^{(e)}_{r,s}\},\quad r,s=0,\ldots,d,\]</div>
<p>for the element matrix. For the case <span class="math">\(d=2\)</span> we have</p>
<div class="math">
\[\begin{split}\tilde A^{(e)} = \left\lbrack\begin{array}{lllll}
\tilde A^{(e)}_{0,0} &amp; \tilde A^{(e)}_{0,1} &amp; \tilde A^{(e)}_{0,2}\\
\tilde A^{(e)}_{1,0} &amp; \tilde A^{(e)}_{1,1} &amp; \tilde A^{(e)}_{1,2}\\
\tilde A^{(e)}_{2,0} &amp; \tilde A^{(e)}_{2,1} &amp; \tilde A^{(e)}_{2,2}
\end{array}\right\rbrack
\thinspace .\end{split}\]</div>
<p>Given the numbers <span class="math">\(\tilde A^{(e)}_{r,s}\)</span>,
we should according to <a href="#equation-fem:approx:fe:elementwise:Asplit">(22)</a>
add the contributions to the global coefficient matrix by</p>
<div class="math">
\[ A_{q(e,r),q(e,s)} := A_{q(e,r),q(e,s)} + \tilde A^{(e)}_{r,s},\quad
r,s=0,\ldots,d\thinspace .\]</div>
<p>This process of adding in elementwise contributions to the global matrix
is called <em>finite element assembly</em> or simply <em>assembly</em>.
.. index:: assembly</p>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-assembly"><em>Illustration of matrix assembly</em></a> illustrates how element matrices
for elements with two nodes are added into the global matrix.
More specifically, the figure shows how the element matrix associated with
elements 2 and 3 assembled, assuming that global nodes are numbered
from left to right in the domain.</p>
<div class="figure" id="fem-approx-fe-fig-assembly">
<img alt="_images/matrix-assembly.png" src="_images/matrix-assembly.png" style="width: 600px;" />
<p class="caption"><em>Illustration of matrix assembly</em></p>
</div>
<p>The right-hand side of the linear system is also computed elementwise:</p>
<div class="math">
\[b_i = \int_\Omega\varphi_i\varphi_jdx = \sum_{e} b^{(e)}_{i},\quad
b^{(e)}_{i}=\int_{\Omega^{(e)}} f(x)\varphi_i(x)dx\thinspace .\]</div>
<p>We observe that
<span class="math">\(b_i^{(e)}\neq 0\)</span> if and only if global node <span class="math">\(i\)</span> is a node in element <span class="math">\(e\)</span>.
With <span class="math">\(d\)</span> nodes per element we can collect the <span class="math">\(d+1\)</span> nonzero contributions
<span class="math">\(b_i^{(e)}\)</span>, for <span class="math">\(i=q(e,r)\)</span>, <span class="math">\(r=0,\ldots,d\)</span>, in an <em>element vector</em></p>
<div class="math">
\[\tilde b_r^{(e)}=\{ \tilde b_r^{(e)}\},\quad r=0,\ldots,d\thinspace .\]</div>
<p>These contributions are added to the
global right-hand side by an assembly process similar to that for the
element matrices:</p>
<div class="math">
\[b_{q(e,r)} := b_{q(e,r)} + \tilde b^{(e)}_{r},\quad
r,s=0,\ldots,d\thinspace .\]</div>
</div>
<div class="section" id="mapping-to-a-reference-element">
<span id="fem-approx-fe-mapping"></span><h2>Mapping to a reference element<a class="headerlink" href="#mapping-to-a-reference-element" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-24"></span><p id="index-25">Instead of computing the integrals</p>
<div class="math">
\[\tilde A^{(e)}_{r,s} = \int_{\Omega^{(e)}}\varphi_{q(e,r)}(x)\varphi_{q(e,s)}(x)dx\]</div>
<p>over some element
<span class="math">\(\Omega^{(e)} = [x_L, x_R]\)</span>,
it is convenient to map the element domain <span class="math">\([x_L, x_R]\)</span>
to a standardized reference element domain <span class="math">\([-1,1]\)</span>.
(We have now introduced
<span class="math">\(x_L\)</span> and <span class="math">\(x_R\)</span> as the left and right boundary points of an arbitrary element.
With a natural numbering of nodes and elements from left to right
through the domain, <span class="math">\(x_L=x_{e}\)</span> and <span class="math">\(x_R=x_{e+1}\)</span>.)
Let <span class="math">\(X\)</span> be the coordinate
in the reference element. A linear or <em>affine mapping</em> from <span class="math">\(X\)</span> to <span class="math">\(x\)</span> reads</p>
<div class="math" id="equation-fem:approx:fe:affine:mapping">
<span class="eqno">(23)</span>\[     x = \frac{1}{2} (x_L + x_R) + \frac{1}{2} (x_R - x_L)X\thinspace .\]</div>
<p>This relation can alternatively be expressed by</p>
<div class="math" id="equation-fem:approx:fe:affine:mapping2">
<span class="eqno">(24)</span>\[     x = x_m + \frac{1}{2}hX,\]</div>
<p>where we have introduced the element midpoint <span class="math">\(x_m=(x_L+x_R)/2\)</span> and
the element length <span class="math">\(h=x_R-x_L\)</span>.</p>
<p>Integrating on
the reference element is a matter of just changing the integration
variable from <span class="math">\(x\)</span> to <span class="math">\(X\)</span>. Let</p>
<div class="math">
\[\tilde\varphi_r(X) = \varphi_{q(e,r)}(x(X))\]</div>
<p>be the basis function associated with local node number <span class="math">\(r\)</span> in the
reference element. The integral transformation reads</p>
<div class="math">
\[\tilde A^{(e)}_{r,s} = \int_{\Omega^{(e)}}\varphi_{q(e,r)}(x)\varphi_{q(e,s)}(x)dx
= \int_{-1}^1 \tilde\varphi_r(X)\tilde\varphi_s(X)\frac{dx}{dX}dX\thinspace .\]</div>
<p>The stretch factor <span class="math">\(dx/dX\)</span> between the <span class="math">\(x\)</span> and <span class="math">\(X\)</span> coordinates
becomes the determinant of the Jacobian matrix of the mapping
between the coordinate systems in 2D and 3D. To obtain a uniform
notation for 1D, 2D, and 3D problems we therefore replace
<span class="math">\(dx/dX\)</span> by <span class="math">\(\det J\)</span> already now. In 1D, <span class="math">\(\det J = dx/dX = h/2\)</span>.
The integration over the reference element is then written as</p>
<div class="math" id="equation-fem:approx:fe:mapping:Ae">
<span class="eqno">(25)</span>\[     \tilde A^{(e)}_{r,s}
     = \int_{-1}^1 \tilde\varphi_r(X)\tilde\varphi_s(X)\det J\,dX\]\[     \thinspace .\]</div>
<p>The corresponding formula for the element vector entries becomes</p>
<div class="math" id="equation-fem:approx:fe:mapping:be">
<span class="eqno">(26)</span>\[     \tilde b^{(e)}_{r} = \int_{\Omega^{(e)}}f(x)\varphi_{q(e,r)}(x)dx
     = \int_{-1}^1 f(x(X))\tilde\varphi_r(X)\det J\,dX\]\[     \thinspace .\]</div>
<p>Since we from now on will work in the reference
element, we need explicit mathematical formulas for the basis
functions <span class="math">\(\varphi_i(x)\)</span> in the reference element only, i.e., we only need
to specify formulas for <span class="math">\(\tilde\varphi_r(X)\)</span>.
This is a very convenient simplification compared to specifying
piecewise polynomials in the physical domain.</p>
<p>The <span class="math">\(\tilde\varphi_r(x)\)</span> functions are simply the Lagrange
polynomials defined through the local nodes in the reference element.
For <span class="math">\(d=1\)</span> and two nodes per element, we have the linear Lagrange
polynomials</p>
<div class="math">
\[\begin{split}\tilde\varphi_0(X) &amp;= \frac{1}{2} (1 - X)
\\
\tilde\varphi_1(X) &amp;= \frac{1}{2} (1 + X)\end{split}\]</div>
<p>Quadratic polynomials, <span class="math">\(d=2\)</span>, have the formulas</p>
<div class="math">
\[\begin{split}\tilde\varphi_0(X) &amp;= \frac{1}{2} (X-1)X\\
\tilde\varphi_1(X) &amp;= 1 - X^2\\
\tilde\varphi_2(X) &amp;= \frac{1}{2} (X+1)X\end{split}\]</div>
<p>In general,</p>
<div class="math">
\[\tilde\varphi_r(x) = \prod_{s=0,s\neq r}^d \frac{X-X_{(s)}}{X_{(r)}-X_{(s)}},\]</div>
<p>where <span class="math">\(X_{(0)},\ldots,X_{(d)}\)</span> are the coordinates of the local nodes in
the reference element.
These are normally uniformly spaced: <span class="math">\(X_{(r)} = -1 + 2r/d\)</span>,
<span class="math">\(r=0,\ldots,d\)</span>.</p>
</div>
<div class="section" id="integration-over-a-reference-element">
<span id="fem-approx-fe-intg-ref"></span><h2>Integration over a reference element<a class="headerlink" href="#integration-over-a-reference-element" title="Permalink to this headline">¶</a></h2>
<p>To illustrate the concepts from the previous section in a specific
example, we now
consider calculation of the element matrix and vector for a specific choice of
<span class="math">\(d\)</span> and <span class="math">\(f(x)\)</span>. A simple choice is <span class="math">\(d=1\)</span> and <span class="math">\(f(x)=x(1-x)\)</span>
on <span class="math">\(\Omega =[0,1]\)</span>. We have the general expressions
<a href="#equation-fem:approx:fe:mapping:Ae">(25)</a> and <a href="#equation-fem:approx:fe:mapping:be">(26)</a>
for <span class="math">\(\tilde A^{(e)}_{r,s}\)</span> and <span class="math">\(\tilde b^{(e)}_{r}\)</span>.
Writing these out for the choices (<em class="xref std std-ref">fem:approx:fe:mapping:P1:phi0</em>)
and (<em class="xref std std-ref">fem:approx:fe:mapping:P1:phi1</em>), and using that <span class="math">\(\det J = h/2\)</span>,
we get</p>
<div class="math">
\[\begin{split}\tilde A^{(e)}_{0,0}
&amp;= \int_{-1}^1 \tilde\varphi_0(X)\tilde\varphi_0(X)\frac{h}{2} dX\nonumber\\
&amp;=\int_{-1}^1 \frac{1}{2}(1-X)\frac{1}{2}(1-X) \frac{h}{2} dX =
\frac{h}{8}\int_{-1}^1 (1-X)^2 dX = \frac{h}{3},\\
\tilde A^{(e)}_{1,0}
&amp;= \int_{-1}^1 \tilde\varphi_1(X)\tilde\varphi_0(X)\frac{h}{2} dX\nonumber\\
&amp;=\int_{-1}^1 \frac{1}{2}(1+X)\frac{1}{2}(1-X) \frac{h}{2} dX =
\frac{h}{8}\int_{-1}^1 (1-X^2) dX = \frac{h}{6},\\
\tilde A^{(e)}_{0,1} &amp;= \tilde A^{(e)}_{1,0},\\
\tilde A^{(e)}_{1,1}
&amp;= \int_{-1}^1 \tilde\varphi_1(X)\tilde\varphi_1(X)\frac{h}{2} dX\nonumber\\
&amp;=\int_{-1}^1 \frac{1}{2}(1+X)\frac{1}{2}(1+X) \frac{h}{2} dX =
\frac{h}{8}\int_{-1}^1 (1+X)^2 dX = \frac{h}{3}
\thinspace .\end{split}\]</div>
<div class="math">
\[\begin{split}\tilde b^{(e)}_{0}
&amp;= \int_{-1}^1 f(x(X))\tilde\varphi_0(X)\frac{h}{2} dX\nonumber\\
&amp;= \int_{-1}^1 (x_m + \frac{1}{2} hX)(1-(x_m + \frac{1}{2} hX))
\frac{1}{2}(1-X)\frac{h}{2} dX \nonumber\\
&amp;= - \frac{1}{24} h^{3} + \frac{1}{6} h^{2} x_{m} - \frac{1}{12} h^{2} - \frac{1}{2} h x_{m}^{2} + \frac{1}{2} h x_{m}
\tilde b^{(e)}_{1}\\
&amp;= \int_{-1}^1 f(x(X))\tilde\varphi_0(X)\frac{h}{2} dX\nonumber\\
&amp;= \int_{-1}^1 (x_m + \frac{1}{2} hX)(1-(x_m + \frac{1}{2} hX))
\frac{1}{2}(1+X)\frac{h}{2} dX \nonumber\\
&amp;= - \frac{1}{24} h^{3} - \frac{1}{6} h^{2} x_{m} + \frac{1}{12} h^{2} -
\frac{1}{2} h x_{m}^{2} + \frac{1}{2} h x_{m}
\thinspace .\end{split}\]</div>
<p>In the last two expressions we have used the element midpoint <span class="math">\(x_m\)</span>.</p>
<p>Integration of lower-degree polynomials above is tedious,
and higher-degree polynomials that very much more algebra, but <tt class="docutils literal"><span class="pre">sympy</span></tt>
may help. For example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">x_m</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;x x_m h X&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">8</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">h/3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">8</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">h/6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x_m</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_0</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">X</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">b_0</span>
<span class="go">-h**3/24 + h**2*x_m/6 - h**2/12 - h*x_m**2/2 + h*x_m/2</span>
</pre></div>
</div>
<p>For inclusion of formulas in documents 9like the present one), <tt class="docutils literal"><span class="pre">sympy</span></tt> can print
expressions in LaTeX format:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">latex</span><span class="p">(</span><span class="n">b_0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;plain&#39;</span><span class="p">)</span>
<span class="go">- \frac{1}{24} h^{3} + \frac{1}{6} h^{2} x_{m}</span>
<span class="go">- \frac{1}{12} h^{2} - \frac{1}{2} h x_{m}^{2}</span>
<span class="go">+ \frac{1}{2} h x_{m}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="implementation-1">
<span id="fem-approx-fe-impl"></span><h1>Implementation  (1)<a class="headerlink" href="#implementation-1" title="Permalink to this headline">¶</a></h1>
<p>Based on the experience from the previous example, it makes
sense to write some code to automate the integration process
for any choice of finite element basis functions. In addition,
we can automate the assembly process and linear system
solution. Appropriate
functions for this purpose document all details of all
steps in the finite element computations and can found in the module file
<a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/fe_approx1D.py">fe_approx1D.py</a>. Some of the functions are explained below.</p>
<div class="section" id="integration">
<span id="fem-approx-fe-impl-intg"></span><h2>Integration<a class="headerlink" href="#integration" title="Permalink to this headline">¶</a></h2>
<p>First we need a Python function for
defining <span class="math">\(\tilde\varphi_r(X)\)</span> in terms of a Lagrange polynomial
of degree <tt class="docutils literal"><span class="pre">d</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">phi_r</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Rational</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>  <span class="c"># node spacing</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">i</span><span class="o">*</span><span class="n">h</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c"># assume X is numeric: use floats for nodes</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Lagrange_polynomial</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">Lagrange_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">*=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
</div>
<p>Observe how we construct the <tt class="docutils literal"><span class="pre">phi_r</span></tt> function to be
a symbolic expression for <span class="math">\(\tilde\varphi_r(X)\)</span> if <tt class="docutils literal"><span class="pre">X</span></tt> is a
<tt class="docutils literal"><span class="pre">Symbol</span></tt> object from <tt class="docutils literal"><span class="pre">sympy</span></tt>. Otherwise, we assume that <tt class="docutils literal"><span class="pre">X</span></tt>
is a <tt class="docutils literal"><span class="pre">float</span></tt> object and compute the corresponding
floating-point value of <span class="math">\(\tilde\varphi_r(X)\)</span>. The
<tt class="docutils literal"><span class="pre">Lagrange_polynomial</span></tt> function, copied here
from the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>,
works with both symbolic and
numeric <tt class="docutils literal"><span class="pre">x</span></tt> and <tt class="docutils literal"><span class="pre">points</span></tt> variables.</p>
<p>The complete basis <span class="math">\(\tilde\varphi_0(X),\ldots,\tilde\varphi_d(X)\)</span>
on the reference element is constructed by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="p">[</span><span class="n">phi_r</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">phi</span>
</pre></div>
</div>
<p>Now we are in a position to write the function for computing
the element matrix:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
    <span class="n">A_e</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;h&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>  <span class="c"># dx/dX</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">A_e</span><span class="p">[</span><span class="n">s</span><span class="p">,</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">A_e</span>
</pre></div>
</div>
<p>In the symbolic case (<tt class="docutils literal"><span class="pre">symbolic</span></tt> is <tt class="docutils literal"><span class="pre">True</span></tt>),
we introduce the element length as a symbol
<tt class="docutils literal"><span class="pre">h</span></tt> in the computations. Otherwise, the real numerical value
of the element interval <tt class="docutils literal"><span class="pre">Omega_e</span></tt>
is used and the final matrix elements are numbers,
not symbols.
This functionality can be demonstrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fe_approx1D</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span>
<span class="go">[1/2 - X/2, 1/2 + X/2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="go">[h/3, h/6]</span>
<span class="go">[h/6, h/3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="go">[0.0333333333333333, 0.0166666666666667]</span>
<span class="go">[0.0166666666666667, 0.0333333333333333]</span>
</pre></div>
</div>
<p>The computation of the element vector is done by a similar
procedure:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
    <span class="n">b_e</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c"># Make f a function of X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;h&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span>  <span class="c"># mapping</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="c"># substitute mapping formula for x</span>
    <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>  <span class="c"># dx/dX</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">b_e</span>
</pre></div>
</div>
<p>Here we need to replace the symbol <tt class="docutils literal"><span class="pre">x</span></tt> in the expression for <tt class="docutils literal"><span class="pre">f</span></tt>
by the mapping formula such that <tt class="docutils literal"><span class="pre">f</span></tt> contains the variable <tt class="docutils literal"><span class="pre">X</span></tt>.</p>
<p>The integration in the element matrix function involves only products
of polynomials, which <tt class="docutils literal"><span class="pre">sympy</span></tt> can easily deal with, but for the
right-hand side <tt class="docutils literal"><span class="pre">sympy</span></tt> may face difficulties with certain types of
expressions <tt class="docutils literal"><span class="pre">f</span></tt>. The result of the integral is then an <tt class="docutils literal"><span class="pre">Integral</span></tt>
object and not a number as when symbolic integration is successful.
It may therefore be wise to introduce a fallback on numerical
integration. The symbolic integration can also take much time
before an unsuccessful conclusion so we may introduce a parameter
<tt class="docutils literal"><span class="pre">symbolic</span></tt> and set it to <tt class="docutils literal"><span class="pre">False</span></tt> to avoid symbolic integration:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">symbolic</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Omega_e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># Ensure h is numerical</span>
            <span class="n">detJ</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">X</span><span class="p">],</span> <span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">detJ</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Successful numerical integration requires that the symbolic
integrand is converted
to a plain Python function (<tt class="docutils literal"><span class="pre">integrand</span></tt>) and that
the element length <tt class="docutils literal"><span class="pre">h</span></tt> is a real number.</p>
</div>
<div class="section" id="linear-system-assembly-and-solution">
<span id="fem-approx-fe-impl-linsys"></span><h2>Linear system assembly and solution<a class="headerlink" href="#linear-system-assembly-and-solution" title="Permalink to this headline">¶</a></h2>
<p>The complete algorithm
for computing and assembling the elementwise contributions
takes the following form</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">n_n</span><span class="p">,</span> <span class="n">n_e</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_n</span><span class="p">,</span> <span class="n">n_n</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>    <span class="c"># note: (n_n, 1) matrix</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_n</span><span class="p">,</span> <span class="n">n_n</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_e</span><span class="p">):</span>
        <span class="n">Omega_e</span> <span class="o">=</span> <span class="p">[</span><span class="n">nodes</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="n">nodes</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]]]</span>

        <span class="n">A_e</span> <span class="o">=</span> <span class="n">element_matrix</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="p">)</span>
        <span class="n">b_e</span> <span class="o">=</span> <span class="n">element_vector</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega_e</span><span class="p">,</span> <span class="n">symbolic</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">])):</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">])):</span>
                <span class="n">A</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
            <span class="n">b</span><span class="p">[</span><span class="n">elements</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> variables represent the finite
element mesh as explained earlier.</p>
<p>Given the coefficient matrix <tt class="docutils literal"><span class="pre">A</span></tt> and the right-hand side <tt class="docutils literal"><span class="pre">b</span></tt>,
we can compute the coefficients <span class="math">\(c_0,\ldots,c_N\)</span> in the expansion
<span class="math">\(u(x)=\sum_jc_j\varphi_j\)</span> as the solution vector <tt class="docutils literal"><span class="pre">c</span></tt> of the linear
system:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="n">symbolic</span><span class="p">:</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>When <tt class="docutils literal"><span class="pre">A</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are <tt class="docutils literal"><span class="pre">sympy</span></tt> arrays,
solution procedure implied by <tt class="docutils literal"><span class="pre">A.LUsolve</span></tt> is symbolic,
otherwise, when <tt class="docutils literal"><span class="pre">A</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are <tt class="docutils literal"><span class="pre">numpy</span></tt> arrays, a standard
numerical solver is called.
The symbolic version is suited for small problems only
(small <span class="math">\(N\)</span> values) since the calculation time becomes prohibitively large
otherwise. Normally, the symbolic integration will be more time
consuming in small problems than the symbolic solution of the linear system.</p>
</div>
<div class="section" id="example-on-computing-approximations">
<span id="fem-approx-fe-impl-ex1"></span><h2>Example on computing approximations<a class="headerlink" href="#example-on-computing-approximations" title="Permalink to this headline">¶</a></h2>
<p>We can exemplify the use of <tt class="docutils literal"><span class="pre">assemble</span></tt> on the computational
case from the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> with
two P1 elements (linear basis functions) on the domain <span class="math">\(\Omega=[0,1]\)</span>.
Let us first work with a symbolic element length:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;h x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[h/3,   h/6,   0]</span>
<span class="go">[h/6, 2*h/3, h/6]</span>
<span class="go">[  0,   h/6, h/3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[     h**2/6 - h**3/12]</span>
<span class="go">[      h**2 - 7*h**3/6]</span>
<span class="go">[5*h**2/6 - 17*h**3/12]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[                           h**2/6]</span>
<span class="go">[12*(7*h**2/12 - 35*h**3/72)/(7*h)]</span>
<span class="go">[  7*(4*h**2/7 - 23*h**3/21)/(2*h)]</span>
</pre></div>
</div>
<p>We may, for comparison, compute the <tt class="docutils literal"><span class="pre">c</span></tt> vector for an interpolation/collocation
method, taking the nodes as collocation points.
This is carried out by evaluating <tt class="docutils literal"><span class="pre">f</span></tt> numerically at the nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">fn</span><span class="p">(</span><span class="n">xc</span><span class="p">)</span> <span class="k">for</span> <span class="n">xc</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[0, h*(1 - h), 2*h*(1 - 2*h)]</span>
</pre></div>
</div>
<p>The corresponding numerical computations, as done by <tt class="docutils literal"><span class="pre">sympy</span></tt> and
still based on symbolic integration, goes as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elements</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[ 0.166666666666667, 0.0833333333333333,                  0]</span>
<span class="go">[0.0833333333333333,  0.333333333333333, 0.0833333333333333]</span>
<span class="go">[                 0, 0.0833333333333333,  0.166666666666667]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[          0.03125]</span>
<span class="go">[0.104166666666667]</span>
<span class="go">[          0.03125]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">[0.0416666666666666]</span>
<span class="go">[ 0.291666666666667]</span>
<span class="go">[0.0416666666666666]</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">fe_approx1D</span></tt> module contains functions for generating the
<tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt> lists for equal-sized elements with
any number of nodes per element. The coordinates in <tt class="docutils literal"><span class="pre">nodes</span></tt>
can be expressed either through the element length symbol <tt class="docutils literal"><span class="pre">h</span></tt>
or by real numbers. There is also a function</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">approximate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_e</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&#39;tmp.pdf&#39;</span><span class="p">):</span>
</pre></div>
</div>
<p>which computes a mesh with <tt class="docutils literal"><span class="pre">n_e</span></tt> elements, basis functions of
degree <tt class="docutils literal"><span class="pre">d</span></tt>, and approximates a given symbolic expression
<tt class="docutils literal"><span class="pre">f</span></tt> by a finite element expansion <span class="math">\(u(x) = \sum_jc_j\varphi_j(x)\)</span>.
When <tt class="docutils literal"><span class="pre">symbolic</span></tt> is <tt class="docutils literal"><span class="pre">False</span></tt>, <span class="math">\(u(x)\)</span> can be computed at a (large)
number of points and plotted together with <span class="math">\(f(x)\)</span>. The construction
of <span class="math">\(u\)</span> points from the solution vector <tt class="docutils literal"><span class="pre">c</span></tt> is done
elementwise by evaluating <span class="math">\(\sum_rc_r\tilde\varphi_r(X)\)</span> at a (large)
number of points in each element, and the discrete <span class="math">\((x,u)\)</span> values on
each elements are stored in arrays that are finally
concatenated to form global arrays
with the <span class="math">\(x\)</span> and <span class="math">\(u\)</span> coordinates for plotting. The details are
found in the <tt class="docutils literal"><span class="pre">u_glob</span></tt> function in
<tt class="docutils literal"><span class="pre">fe_approx1D.py</span></tt>.</p>
</div>
<div class="section" id="the-structure-of-the-coefficient-matrix">
<span id="fem-approx-fe-a-structure"></span><h2>The structure of the coefficient matrix<a class="headerlink" href="#the-structure-of-the-coefficient-matrix" title="Permalink to this headline">¶</a></h2>
<p>Let us first see how the global matrix looks like if we assemble
symbolic element matrices, expressed in terms of <tt class="docutils literal"><span class="pre">h</span></tt>, from
several elements:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">n_e</span><span class="o">=</span><span class="mi">8</span><span class="p">;</span> <span class="n">Omega</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>  <span class="c"># 8 linear elements on [0,1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">basis</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span> <span class="o">=</span> <span class="n">mesh_symbolic</span><span class="p">(</span><span class="n">n_e</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">assemble</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span>
<span class="go">[h/3,   h/6,     0,     0,     0,     0,     0,     0,   0]</span>
<span class="go">[h/6, 2*h/3,   h/6,     0,     0,     0,     0,     0,   0]</span>
<span class="go">[  0,   h/6, 2*h/3,   h/6,     0,     0,     0,     0,   0]</span>
<span class="go">[  0,     0,   h/6, 2*h/3,   h/6,     0,     0,     0,   0]</span>
<span class="go">[  0,     0,     0,   h/6, 2*h/3,   h/6,     0,     0,   0]</span>
<span class="go">[  0,     0,     0,     0,   h/6, 2*h/3,   h/6,     0,   0]</span>
<span class="go">[  0,     0,     0,     0,     0,   h/6, 2*h/3,   h/6,   0]</span>
<span class="go">[  0,     0,     0,     0,     0,     0,   h/6, 2*h/3, h/6]</span>
<span class="go">[  0,     0,     0,     0,     0,     0,     0,   h/6, h/3]</span>
</pre></div>
</div>
<p>(The reader is encouraged to assemble the element matrices by hand and verify
this result, as this exercise will give a hands-on understanding of
what the assembly is about.) In general we have a coefficient matrix that is
tridiagonal:</p>
<div class="math">
\[\begin{split}A = \frac{h}{6}
\left(
\begin{array}{cccccccccc}
2 &amp; 1 &amp; 0
&amp;\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; 0 \\
1 &amp; 4 &amp; 1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
0 &amp; 1 &amp; 4 &amp; 1 &amp;
\ddots &amp; &amp;  &amp;  &amp; \vdots \\
\vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
\vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; &amp;  &amp; 0 &amp; 1 &amp; 4 &amp; 1 &amp; \ddots &amp; \vdots \\
\vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
\vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; 1  &amp; 4  &amp; 1 \\
0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 1 &amp; 2
\end{array}
\right)\end{split}\]</div>
<p>The structure of the right-hand side is more difficult to reveal since
it involves an assembly of elementwise integrals of
<span class="math">\(f(x(X))\tilde\varphi_r(X)h/2\)</span>, which obviously depend on the
particular choice of <span class="math">\(f(x)\)</span>.
It is easier to look at the integration in <span class="math">\(x\)</span> coordinates, which
gives the general formula <a href="#equation-fem:approx:fe:bi:formula1">(21)</a>.
For equal-sized elements of length <span class="math">\(h\)</span>, we can apply the
Trapezoidal rule at the global node points to arrive at a somewhat more specific
expression than <a href="#equation-fem:approx:fe:bi:formula1">(21)</a>:</p>
<div class="math">
\[\begin{split}b_i &amp;= h\left( \frac{1}{2} \phi_i(x_{0})f(x_{0}) +
\frac{1}{2} \phi_i(x_{N})f(x_{N}) + \sum_{j=1}^{N-1}
\phi_i(x_{i})f(x_{i})\right)\\
&amp; =
\left\lbrace\begin{array}{ll}
\frac{1}{2} hf(x_i),&amp; i=0\hbox{ or }i=N,\\
h f(x_i), &amp; 1 \leq i \leq N-1
\end{array}\right.\end{split}\]</div>
<p>The reason for this simple formula is simply that <span class="math">\(\phi_i\)</span> is either
0 or 1 at the nodes and 0 at all but one of them.</p>
<p>Going to P2 elements (<tt class="docutils literal"><span class="pre">d=2</span></tt>) leads
to the element matrix</p>
<div class="math">
\[\begin{split}A^{(e)} = \frac{h}{30}
\left(\begin{array}{ccc}
4 &amp; 2 &amp; -1\\
2 &amp; 16 &amp; 2\\
-1 &amp; 2 &amp; 4
\end{array}\right)\end{split}\]</div>
<p>and the following global assembled matrix from four elements:</p>
<div class="math">
\[\begin{split}A = \frac{h}{30}
\left(
\begin{array}{ccccccccc}
4 &amp; 2 &amp; - 1 &amp; 0
  &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
  2 &amp; 16 &amp; 2
  &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\- 1 &amp; 2 &amp;
  8 &amp; 2 &amp; - 1 &amp; 0 &amp; 0 &amp; 0 &amp;
  0\\0 &amp; 0 &amp; 2 &amp; 16 &amp; 2 &amp; 0 &amp; 0
  &amp; 0 &amp; 0\\0 &amp; 0 &amp; - 1 &amp; 2 &amp; 8
  &amp; 2 &amp; - 1 &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 0 &amp;
  2 &amp; 16 &amp; 2 &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0
  &amp; 0 &amp; - 1 &amp; 2 &amp; 8 &amp;
  2 &amp; - 1\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;
  2 &amp; 16 &amp; 2\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
  &amp; 0 &amp; - 1 &amp; 2 &amp; 4
\end{array}
\right)\end{split}\]</div>
<p>In general, for <span class="math">\(i\)</span> odd we have the nonzeroes</p>
<div class="math">
\[A_{i,i-2} = -1,\quad A_{i-1,i}=2,\quad A_{i,i} = 8,\quad A_{i+1,i}=2,
\quad A_{i+2,i}=-1,\]</div>
<p>multiplied by <span class="math">\(h/30\)</span>, and for <span class="math">\(i\)</span> even we have the nonzeros</p>
<div class="math">
\[A_{i-1,i}=2,\quad A_{i,i} = 16,\quad A_{i+1,i}=2,\]</div>
<p>multiplied by <span class="math">\(h/30\)</span>. The rows with odd numbers correspond to
nodes at the element boundaries and get contributions from two
neighboring elements in the assembly process,
while the even numbered rows correspond to
internal nodes in the elements where the only one element contributes
to the values in the global matrix.</p>
</div>
<div class="section" id="applications">
<span id="fem-approx-fe-impl-ex2"></span><h2>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<p>With the aid of the <tt class="docutils literal"><span class="pre">approximate</span></tt> function in the <tt class="docutils literal"><span class="pre">fe_approx1D</span></tt>
module we can easily investigate the quality of various finite element
approximations to some given functions. Figure <a class="reference internal" href="#fem-approx-fe-x9-sin"><em>Comparison of the finite element approximations: 4 P1 elements with 5 nodes (upper left), 2 P2 elements with 5 nodes (upper right), 8 P1 elements with 9 nodes (lower left), and 4 P2 elements with 9 nodes (lower right)</em></a>
shows how linear and quadratic elements approximates the polynomial
<span class="math">\(f(x)=x(1-x)^8\)</span> on <span class="math">\(\Omega =[0,1]\)</span>, using equal-sized elements.
The results arise from the program</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">fe_approx1D</span> <span class="kn">import</span> <span class="n">approximate</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>

<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_e</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_e</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_e</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">approximate</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_e</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>The quadratic functions are seen to be better than the linear ones for the same
value of <span class="math">\(N\)</span>, as we increase <span class="math">\(N\)</span>. This observation has some generality:
higher degree is not necessarily better on a coarse mesh, but it is as
we refined the mesh.</p>
<div class="figure" id="fem-approx-fe-x9-sin">
<img alt="_images/fe_p1_p2_x9_248e.png" src="_images/fe_p1_p2_x9_248e.png" style="width: 800px;" />
<p class="caption"><em>Comparison of the finite element approximations: 4 P1 elements with 5 nodes (upper left), 2 P2 elements with 5 nodes (upper right), 8 P1 elements with 9 nodes (lower left), and 4 P2 elements with 9 nodes (lower right)</em></p>
</div>
</div>
<div class="section" id="sparse-matrix-storage-and-solution">
<span id="fem-approx-fe-impl-sparse"></span><h2>Sparse matrix storage and solution<a class="headerlink" href="#sparse-matrix-storage-and-solution" title="Permalink to this headline">¶</a></h2>
<p id="index-26">Some of the examples in the preceding section took several minutes to
compute, even on small meshes consisting of up to eight elements.
The main explanation for slow computations is unsuccessful
symbolic integration: <tt class="docutils literal"><span class="pre">sympy</span></tt> may use a lot of energy on
integrals like <span class="math">\(\int f(x(X))\tilde\varphi_r(X)h/2 dx\)</span> before
giving up, and the program resorts to numerical integration.
Codes that can deal with a large number of basis functions and
accept flexible choices of <span class="math">\(f(x)\)</span> should compute all integrals
numerically and replace the matrix objects from <tt class="docutils literal"><span class="pre">sympy</span></tt> by
the far more efficient array objects from <tt class="docutils literal"><span class="pre">numpy</span></tt>.</p>
<p>A matrix whose majority of entries are zeros, are known as a <em>sparse</em>
matrix. We know beforehand that matrices from finite element
approximations are sparse.  The sparsity should be utilized in
software as it dramatically decreases the storage demands and the
CPU-time needed to compute the solution of the linear system. This
optimization is not critical in 1D problems where modern computers can
afford computing with all the zeros in the complete square matrix, but
in 2D and especially in 3D, sparse matrices are fundamental for
feasible finite element computations.</p>
<p>For one-dimensional finite element approximation problems, using a
numbering of nodes and elements from left to right over the domain,
the assembled coefficient matrix has only a few diagonals different
from zero. More precisely, <span class="math">\(2d+1\)</span> diagonals are different from
zero. With a different numbering of global nodes, say a random
ordering, the diagonal structure is lost, but the number of
nonzero elements is unaltered. Figures <a class="reference internal" href="#fem-approx-fe-sparsity-p1"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P1 elements</em></a>
and <a class="reference internal" href="#fem-approx-fe-sparsity-p3"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P3 elements</em></a> exemplifies sparsity patterns.</p>
<div class="figure" id="fem-approx-fe-sparsity-p1">
<img alt="_images/sparsity_pattern_1D_30.png" src="_images/sparsity_pattern_1D_30.png" style="width: 800px;" />
<p class="caption"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-sparsity-p3">
<img alt="_images/sparsity_pattern_1DP3_30.png" src="_images/sparsity_pattern_1DP3_30.png" style="width: 800px;" />
<p class="caption"><em>Matrix sparsity pattern for left-to-right numbering (left) and random numbering (right) of nodes in P3 elements</em></p>
</div>
<p>The <tt class="docutils literal"><span class="pre">scipy.sparse</span></tt> library supports creation of sparse matrices
and linear system solution.</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">scipy.sparse.diags</span></tt> for matrix defined via diagonals</li>
<li><tt class="docutils literal"><span class="pre">scipy.sparse.lil_matrix</span></tt> for creation via setting elements</li>
<li><tt class="docutils literal"><span class="pre">scipy.sparse.dok_matrix</span></tt> for creation via setting elements</li>
</ul>
</div></blockquote>
<p>Examples to come....</p>
</div>
</div>
<div class="section" id="comparison-of-finite-element-and-finite-difference-approximation">
<span id="fem-approx-fe-fd"></span><h1>Comparison of finite element and finite difference approximation<a class="headerlink" href="#comparison-of-finite-element-and-finite-difference-approximation" title="Permalink to this headline">¶</a></h1>
<p>The previous sections on approximating <span class="math">\(f\)</span> by a finite element function <span class="math">\(u\)</span>
utilize the projection/Galerkin or
least squares approaches to minimize the approximation
error. We may, alternatively, use the collocation/interpolation method.
Here we shall compare these three approaches with what one does in
the finite difference method when representing a given function on a mesh.</p>
<div class="section" id="collocation-or-interpolation">
<h2>Collocation or interpolation<a class="headerlink" href="#collocation-or-interpolation" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(x_{i}\)</span>, <span class="math">\(i=0,\ldots,N\)</span>, be the nodes in the mesh.
Collocation means</p>
<div class="math">
\[u(x_{i})=f(x_{i}),\quad i=0,\ldots,N,\]</div>
<p>which translates to</p>
<div class="math">
\[\sum_{j=0}^N c_j \varphi_j(x_{i}) = f(x_{i}),\]</div>
<p>but <span class="math">\(\varphi_j(x_{i})=0\)</span> if <span class="math">\(i\neq j\)</span> so the sum collapses to one
term <span class="math">\(c_i\varphi_i(x_{i}) = c_i\)</span>, and we have the result</p>
<div class="math">
\[c_i = f(x_{i})
\thinspace .\]</div>
<p>That is, <span class="math">\(u\)</span> <em>interpolates</em> <span class="math">\(f\)</span> at the node points (the values coincide
at these points, but the variation between the points is dictated by
the type of polynomials used in the expansion for <span class="math">\(u\)</span>).
The collocation/interpolation approach is obviously much simpler and
faster to use than the least squares  or projection/Galerkin approach.</p>
<p><em>Remark.</em> When dealing with approximation of functions via finite elements,
all the three methods are in use, while the least squares and collocation
methods are used to only a small extend when solving differential equations.</p>
</div>
<div class="section" id="finite-difference-approximation-of-given-functions">
<h2>Finite difference approximation of given functions<a class="headerlink" href="#finite-difference-approximation-of-given-functions" title="Permalink to this headline">¶</a></h2>
<p>Approximating a given function <span class="math">\(f(x)\)</span> on a mesh in a finite difference
context will typically just sample <span class="math">\(f\)</span> at the grid points. That is,
the discrete version of <span class="math">\(f(x)\)</span> is the set of point values
<span class="math">\(f(x_i)\)</span>, <span class="math">\(i=0,\ldots,N\)</span>, where <span class="math">\(x_i\)</span> denotes a mesh point.
The collocation/interpolation method above gives exactly the same
representation.</p>
<p>How does a finite element Galerkin or least squares approximation differ
from this straightforward interpolation of <span class="math">\(f\)</span>? This is the question
to be addressed next.</p>
</div>
<div class="section" id="finite-difference-interpretation-of-a-finite-element-approximation">
<h2>Finite difference interpretation of a finite element approximation<a class="headerlink" href="#finite-difference-interpretation-of-a-finite-element-approximation" title="Permalink to this headline">¶</a></h2>
<p>We now limit the scope to P1 elements since this is the element type
that gives formulas closest to what one gets from the finite difference
method.</p>
<p>The linear system arising from a Galerkin or least squares approximation
reads</p>
<div class="math">
\[\sum_{j=0}^N c_j (\varphi_i,\varphi_j) = (f,\varphi_i),\quad i=0,\ldots,N
\thinspace .\]</div>
<p>For P1 elements and a uniform mesh of element length <span class="math">\(h\)</span>
we have calculated the matrix with entries
<span class="math">\((\varphi_i,\varphi_j)\)</span> in the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a>.
Equation number <span class="math">\(i\)</span> reads</p>
<div class="math" id="equation-fem:deq:1D:approx:deq:massmat:diffeq2">
<span class="eqno">(27)</span>\[     \frac{h}{6}(u_{i-1} + 4u_i + u_{i+1}) = (f,\varphi_i)
     \thinspace .\]</div>
<p>The finite difference counterpart of this equation is just <span class="math">\(u_i=f_i\)</span>.
(The first and last equation, corresponding to <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span> are slightly
different, see the section <a class="reference internal" href="#fem-approx-fe-a-structure"><em>The structure of the coefficient matrix</em></a>.)</p>
<p>The left-hand side of <a href="#equation-fem:deq:1D:approx:deq:massmat:diffeq2">(27)</a> can
be manipulated to equal</p>
<div class="math">
\[h(u_i - \frac{1}{6}(-u_{i-1} + 2u_i - u_{i+1}))
\thinspace .\]</div>
<p>Thinking in terms of finite differences, this
is nothing but the standard discretization of</p>
<div class="math">
\[h(u - \frac{h^2}{6}u''),\]</div>
<p>or written as</p>
<div class="math">
\[[h(u - \frac{h^2}{6}D_x D_x u]_i,\]</div>
<p>with difference operators.</p>
<p>Before interpreting the approximation procedure as solving a
differential equation, we need to work out what the right-hand side is
in the context of P1 elements.
Since <span class="math">\(\varphi_i\)</span> is the linear function that is 1 at
<span class="math">\(x_{i}\)</span> and zero at all other nodes, only the interval <span class="math">\([x_{i-1},x_{i+1}]\)</span>
contributes to the integral on the right-hand side. This integral is
naturally split into two parts according to
<a href="#equation-fem:approx:fe:phi:1:formula2">(20)</a>:</p>
<div class="math">
\[(f,\varphi_i) = \int_{x_{i-1}}^{x_{i}} f(x)\frac{1}{h} (x - x_{i-1}) dx
+ \int_{x_{i}}^{x_{i+1}} f(x)\frac{1}{h}(1 - (x - x_{i})) dx
\thinspace .\]</div>
<p>However, if <span class="math">\(f\)</span> is not known we cannot do much else with this expression.
It is clear that many values of
<span class="math">\(f\)</span> around <span class="math">\(x_{i}\)</span> contributes to the right-hand side, not just
the single point value <span class="math">\(f(x_{i})\)</span>
as in the finite difference method.</p>
<p>To proceed with the right-hand side, we turn to numerical integration schemes.
Let us say we use the Trapezoidal method for <span class="math">\((f,\varphi_i)\)</span>, based on
the node points <span class="math">\(x_{i}=i h\)</span>:</p>
<div class="math">
\[(f,\varphi_i) = \int_\Omega f\varphi_i dx\approx h\frac{1}{2}(
f(x_{0})\varphi_i(x_{0}) + f(x_{N})\varphi_i(x_{N}))
+ h\sum_{j=1}^{N-1} f(x_{j})\varphi_i(x_{j})
\thinspace .\]</div>
<p>Since <span class="math">\(\varphi_i\)</span> is zero at all these points, except at <span class="math">\(x_{i}\)</span>, the
Trapezoidal rule collapses to one term:</p>
<div class="math">
\[(f,\varphi_i) \approx hf(x_{i}),\]</div>
<p>for <span class="math">\(i=1,\ldots,N-1\)</span>,
which is the same result as with collocation/interpolation, and of course
the same result as in the finite difference method.
For <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span> we get contribution from only one element so</p>
<div class="math">
\[(f,\varphi_i) \approx \frac{1}{2}hf(x_{i}),\quad i=0,\ i=N
\thinspace .\]</div>
<p>Turning to Simpson&#8217;s rule with sample points also in the middle of
the elements, <span class="math">\(x_i=i h/2\)</span>, <span class="math">\(i=0,\ldots,2N\)</span>, it reads in general</p>
<div class="math">
\[\int_\Omega f(x)dx \approx \frac{\tilde h}{3}\left( f(x_0) +
2\sum_{j=2,4,6,\ldots} f(x_j)
+ 4\sum_{j=1,3,5,\ldots} f(x_j) + f(x_{2N})\right),\]</div>
<p>where <span class="math">\(\tilde h = x_i - x_{i-1}= h/2\)</span> is the spacing between the sample points.
We see that the midpoints with odd numbers have
the weight <span class="math">\(2h/3\)</span> while the node points with even numbers have the
weight <span class="math">\(h/3\)</span>. Since <span class="math">\(\varphi_i=0\)</span> at the even numbers, except
for <span class="math">\(x_{2i}=x_{i}\)</span>, and <span class="math">\(\varphi_i=0\)</span> at all the midpoints,
on the midpoints and <span class="math">\(4h/3\)</span> on the node points. Since <span class="math">\(\varphi_i\)</span>
vanishes at all the node points, except <span class="math">\(\xi{i}\)</span>, and
except <span class="math">\(x_{2i-1}=\xi{i}-h/2\)</span> and
<span class="math">\(x_{2i+1}=\xi{i}+h/2\)</span>, where <span class="math">\(\varphi_i=1/2\)</span>, we get</p>
<div class="math">
\[(f,\varphi_i) \approx \frac{h}{3}(f(x_{i}-\frac{1}{2}h)
+ f(x_{i}) + f(x_{i}+\frac{1}{2}h)
\thinspace .\]</div>
<p>In a finite difference context we would typically express this formula as</p>
<div class="math">
\[\frac{h}{3}(f_{i-\frac{1}{2}} + f_i + f_{i+\frac{1}{2}})
\thinspace .\]</div>
<p>This shows that, with Simpson&#8217;s rule, the finite element method
operates with the average of <span class="math">\(f\)</span> over three points, while the finite difference
method just applies <span class="math">\(f\)</span> at one point. We may interpret this as
a &#8220;smearing&#8221; or smoothing of <span class="math">\(f\)</span> by the finite element method.</p>
<p>We can now summarize our findings. With the approximation of
<span class="math">\((f,\varphi_i)\)</span> by the Trapezoidal rule, P1 elements give rise
to equations that can be expressed as a finite difference
discretization of</p>
<div class="math">
\[u + \frac{h^2}{6} u'' = f,\quad u'(0)=u'(L)=0,\]</div>
<p>expressed with operator notation as</p>
<div class="math">
\[[u + \frac{h^2}{6} Dx Dx u = f]_i\thinspace .\]</div>
<p>As <span class="math">\(h\rightarrow 0\)</span>, the extra term proportional to <span class="math">\(u''\)</span> goes to zero,
and the two methods are then equal.</p>
<p>With the Simpson&#8217;s rule, we may say that we solve</p>
<div class="math">
\[[u + \frac{h^2}{6} Dx Dx u = \bar f]_i,\]</div>
<p>where <span class="math">\(\bar f_i\)</span> means the average <span class="math">\(\frac{1}{3}(f_{i-1/2} + f_i + f_{i+1/2})\)</span>.</p>
<p>The extra term <span class="math">\(\frac{h^2}{6} u''\)</span> represents a smoothing: with just this
term, we would find u by integrating <span class="math">\(f\)</span> twice and thereby smooth <span class="math">\(f\)</span>
considerably. In addition, the finite element representation of <span class="math">\(f\)</span>
involves an average, or a smoothing, of <span class="math">\(f\)</span> on the right-hand side of
the equation system. If <span class="math">\(f\)</span> is a noisy function, direct interpolation
<span class="math">\(u_i=f_i\)</span> may result in a noisy <span class="math">\(u\)</span> too, but with a Galerkin or least
squares formulation and P1 elements, we should expect that <span class="math">\(u\)</span> is
smoother than <span class="math">\(f\)</span> unless <span class="math">\(h\)</span> is very small.</p>
<p>The interpretation that finite elements tend to smooth the solution
is valid in applications far beyond approximation of 1D function.</p>
</div>
<div class="section" id="making-finite-elements-behave-as-finite-differences">
<h2>Making finite elements behave as finite differences<a class="headerlink" href="#making-finite-elements-behave-as-finite-differences" title="Permalink to this headline">¶</a></h2>
<p>With a simple trick, using numerical integration, we can easily produce
the same result <span class="math">\(u_i=f_i\)</span> with the Galerkin or least square formulation
with P1 elements. This is useful in many occasions when we deal
with more difficult differential equations and want the finite element
method to have properties like the finite difference method (solving
standard linear wave equations is one primary example).</p>
<p>We have already seen that applying the Trapezoidal rule to the
right-hand side <span class="math">\((f,\varphi_i)\)</span> simply gives <span class="math">\(f\)</span> sampled at <span class="math">\(x_{i}\)</span>.
Using the Trapezoidal rule on the  matrix entries
<span class="math">\((\varphi_i,\varphi_j)\)</span> involves a sum</p>
<div class="math">
\[\sum_k \varphi_i(x_{k})\varphi_j(x_{k}),\]</div>
<p>but <span class="math">\(\varphi_i(x_{k})=0\)</span> for all <span class="math">\(k\)</span>, except <span class="math">\(k=i\)</span>, and
<span class="math">\(\varphi_j(x_{k})=0\)</span> for all <span class="math">\(k\)</span>, except <span class="math">\(k=j\)</span>.
The product <span class="math">\(\varphi_i\varphi_j\)</span> is then different from zero only
when sampled at <span class="math">\(x_{i}\)</span> and <span class="math">\(i=j\)</span>. The approximation to the integral
is then</p>
<div class="math">
\[(\varphi_i,\varphi_j) \approx h,\quad i=j,\]</div>
<p>and zero if <span class="math">\(i\neq j\)</span>. This means that we have obtained a diagonal matrix!
The first and last diagonal elements, <span class="math">\((\varphi_0,\varphi_0)\)</span> and
<span class="math">\((\varphi_N,\varphi_N)\)</span> get contribution only from the first and last
element, respectively, resulting in the approximate integral value <span class="math">\(h/2\)</span>.
The corresponding right-hand side also has a factor <span class="math">\(1/2\)</span> for <span class="math">\(i=0\)</span> and <span class="math">\(i=N\)</span>.
Therefore, the least squares or Galerkin approach with P1 elements and
<em>Trapezoidal</em> integration results in</p>
<div class="math">
\[c_i = f_i\thinspace .\]</div>
<p>Simpsons&#8217;s rule can be used to achieve a similar result for P2 elements, i.e,
a diagonal coefficient matrix, but with the previously derived
average of <span class="math">\(f\)</span> on the right-hand side.</p>
<div class="section" id="elementwise-computations-1">
<h3>Elementwise computations  (1)<a class="headerlink" href="#elementwise-computations-1" title="Permalink to this headline">¶</a></h3>
<p>Identical results to those above will arise if we perform elementwise
computations. The idea is to use the Trapezoidal rule on the reference
element for computing the element matrix and vector. When assembled,
the same equations <span class="math">\(c_i=f(x_{i})\)</span> arise. <a class="reference internal" href="#fem-approx-fe-exer-1d-trapez"><em>Exercise 16: Use the Trapezoidal rule and P1 elements</em></a> encourages you to carry out the
details.</p>
<span class="target" id="index-27"></span><span class="target" id="index-28"></span></div>
<div class="section" id="terminology">
<span id="index-29"></span><h3>Terminology<a class="headerlink" href="#terminology" title="Permalink to this headline">¶</a></h3>
<p>The matrix with entries <span class="math">\((\varphi_i,\varphi_j)\)</span> typically arises
from terms proportional to <span class="math">\(u\)</span> in a differential equation where <span class="math">\(u\)</span>
is the unknown function. This matrix is often called the <em>mass matrix</em>,
because in the early days of the finite element method, the matrix
arose from the mass times acceleration term in Newton&#8217;s second law of
motion. Making the mass matrix diagonal by, e.g., numerical integration,
as demonstrated above, is a widely used technique and is called
<em>mass lumping</em>. In time-dependent problems it can enhance the numerical
accuracy and computational efficiency of the finite element method.
However, there are also examples where mass lumping destroys accuracy.</p>
</div>
</div>
</div>
<div class="section" id="a-generalized-element-concept">
<span id="fem-approx-fe-element"></span><h1>A generalized element concept<a class="headerlink" href="#a-generalized-element-concept" title="Permalink to this headline">¶</a></h1>
<p>So far, finite element computing has employed the <tt class="docutils literal"><span class="pre">nodes</span></tt> and
<tt class="docutils literal"><span class="pre">element</span></tt> lists together with the definition of the basis functions
in the reference element. Suppose we want to introduce a piecewise
constant approximation with one basis function <span class="math">\(\tilde\varphi_0(x)=1\)</span> in
the reference element. Although we could associate the function value
with a node in the middle of the elements, there are no nodes at the
ends, and the previous code snippets will not work because we
cannot find the element boundaries from the <tt class="docutils literal"><span class="pre">nodes</span></tt> list.</p>
<div class="section" id="cells-vertices-and-degrees-of-freedom">
<span id="fem-approx-fe-element-terminology"></span><h2>Cells, vertices, and degrees of freedom<a class="headerlink" href="#cells-vertices-and-degrees-of-freedom" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-30"></span><span class="target" id="index-31"></span><span class="target" id="index-32"></span><p id="index-33">We now introduce <em>cells</em> as the subdomains <span class="math">\(\Omega^{(e)}\)</span> previously
referred as elements. The cell boundaries are denoted as <em>vertices</em>.
The reason for this name is that cells are recognized by their vertices
in 2D and 3D. Then we define a set of <em>degrees of freedom</em>, which are
the quantities we aim to compute. The most common type of degree
of freedom is the value of the unknown function <span class="math">\(u\)</span> at some point.
For example, we can introduce nodes as before and say the degrees of
freedom are the values of <span class="math">\(u\)</span> at the nodes. The basis functions are
constructed so that they equal unity for one particular degree of
freedom and zero for the rest. This property ensures that when
we evaluate <span class="math">\(u=\sum_j c_j\varphi_j\)</span> for degree of freedom number <span class="math">\(i\)</span>,
we get <span class="math">\(u=c_i\)</span>. Integrals are performed over cells, usually by
mapping the cell of interest to a <em>reference cell</em>.</p>
<p>With the concepts of cells, vertices, and degrees of freedom we increase
the decoupling the geometry (cell, vertices) from the space of
basis functions. We can associate different sets of basis functions
with a cell. In 1D, all cells are intervals, while in 2D we can have
cells that are triangles with straight sides, or any polygon, or in fact
any two-dimensional geometry. Triangles and quadrilaterals are most
common, though. The popular cell types in 3D are tetrahedra and hexahedra.</p>
</div>
<div class="section" id="extended-finite-element-concept">
<span id="fem-approx-fe-element-def"></span><h2>Extended finite element concept<a class="headerlink" href="#extended-finite-element-concept" title="Permalink to this headline">¶</a></h2>
<p id="index-34">The concept of a <em>finite element</em> is now</p>
<blockquote>
<div><ul class="simple">
<li>a <em>reference cell</em> in a local reference coordinate system;</li>
<li>a set of <em>basis functions</em> <span class="math">\(\tilde\varphi_i\)</span> defined on the cell;</li>
<li>a set of <em>degrees of freedom</em> that uniquely determine
the basis functions such that <span class="math">\(\tilde\varphi_i=1\)</span> for degree of freedom
number <span class="math">\(i\)</span> and <span class="math">\(\tilde\varphi_i=0\)</span> for all other degrees of freedom;</li>
<li>a mapping between local and global degree of freedom numbers;</li>
<li>a <em>mapping</em> of the reference cell onto to cell in the physical
domain.</li>
</ul>
</div></blockquote>
<p>There must be a geometric description of a cell. This is trivial in 1D
since the cell is an interval and is described by the interval limits,
here called vertices. If the cell is <span class="math">\(\Omega^{(e)}=[x_L,x_R]\)</span>,
vertex 0 is <span class="math">\(x_L\)</span> and vertex 1 is <span class="math">\(x_R\)</span>. The reference cell in 1D
is <span class="math">\([-1,1]\)</span> in the reference coordinate system <span class="math">\(X\)</span>.</p>
<p>Our previous P1, P2, etc., elements are defined by introducing <span class="math">\(d+1\)</span>
equally spaced nodes in the reference cell and saying that the degrees
of freedom are the <span class="math">\(d+1\)</span> function values at these nodes.  The basis
functions must be 1 at one node and 0 at the others, and the Lagrange
polynomials have exactly this property.  The nodes can be numbered
from left to right with associated degrees of freedom that are
numbered in the same way.  The degree of freedom mapping becomes what
was previously represented by the <tt class="docutils literal"><span class="pre">elements</span></tt> lists.  The cell mapping
is the same affine mapping <a href="#equation-fem:approx:fe:affine:mapping">(23)</a> as
before.</p>
<p id="index-35">The expansion of <span class="math">\(u\)</span> over one cell is often used. In terms of reference
coordinates we have</p>
<div class="math">
\[u(x) = \sum_{r} c_r\tilde\varphi_r(X),\]</div>
<p>where the sum is taken over the numbers of the degrees of freedom and
<span class="math">\(c_r\)</span> is the value of <span class="math">\(u\)</span> for degree of freedom number <span class="math">\(r\)</span>.</p>
</div>
<div class="section" id="implementation-2">
<span id="fem-approx-fe-element-impl"></span><h2>Implementation  (2)<a class="headerlink" href="#implementation-2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-36"></span><span class="target" id="index-37"></span><p id="index-38">Implementationwise,</p>
<blockquote>
<div><ul class="simple">
<li>we replace <tt class="docutils literal"><span class="pre">nodes</span></tt> by <tt class="docutils literal"><span class="pre">vertices</span></tt>;</li>
<li>we introduce <tt class="docutils literal"><span class="pre">cells</span></tt> such that <tt class="docutils literal"><span class="pre">cell[e][r]</span></tt> gives the mapping
from local vertex <tt class="docutils literal"><span class="pre">r</span></tt> in cell <tt class="docutils literal"><span class="pre">e</span></tt> to the global vertex number
in <tt class="docutils literal"><span class="pre">vertices</span></tt>;</li>
<li>we replace <tt class="docutils literal"><span class="pre">elements</span></tt> by <tt class="docutils literal"><span class="pre">dof_map</span></tt> (the contents are the same).</li>
</ul>
</div></blockquote>
<p>Consider the example from the section <a class="reference internal" href="#fem-approx-fe-def-elements-nodes"><em>Elements and nodes</em></a>
where <span class="math">\(\Omega =[0,1]\)</span> is divided into two cells,
<span class="math">\(\Omega^{(0)}=[0,0.4]\)</span> and <span class="math">\(\Omega^{(1)}=[0.4,1]\)</span>.
The vertices are <span class="math">\([0,0.4,1]\)</span>. Local vertex 0 and 1 are
<span class="math">\(0\)</span> and <span class="math">\(0.4\)</span> in cell 0 and <span class="math">\(0.4\)</span> and <span class="math">\(1\)</span> in cell 1.
A P2 element means that the degrees of freedom are
the value of <span class="math">\(u\)</span> at three equally spaced points (nodes) in each
cell. The data structures become</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">cells</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
</pre></div>
</div>
<p>If we would approximate <span class="math">\(f\)</span> by piecewise constants, we simply
introduce one point or node in an element, preferably <span class="math">\(X=0\)</span>,
and choose <span class="math">\(\tilde\varphi_0(X)=1\)</span>. Only the <tt class="docutils literal"><span class="pre">dof_map</span></tt> is altered:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dof_map</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>We use the <tt class="docutils literal"><span class="pre">cells</span></tt> and <tt class="docutils literal"><span class="pre">vertices</span></tt> lists to retrieve information
on the geometry of a cell, while <tt class="docutils literal"><span class="pre">dof_map</span></tt> is used in the
assembly of element matrices and vectors.
For example, the <tt class="docutils literal"><span class="pre">Omega_e</span></tt> variable (representing the cell interval)
in previous code snippets must now be computed as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">Omega_e</span> <span class="o">=</span> <span class="p">[</span><span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">vertices</span><span class="p">[</span><span class="n">cells</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
<p>The assembly is done by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">A</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">],</span> <span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">s</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">A_e</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">s</span><span class="p">]</span>
<span class="n">b</span><span class="p">[</span><span class="n">dof_map</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">r</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">b_e</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
</pre></div>
</div>
<p>We will hereafter work with <tt class="docutils literal"><span class="pre">cells</span></tt>, <tt class="docutils literal"><span class="pre">vertices</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt>.</p>
</div>
<div class="section" id="cubic-hermite-polynomials">
<h2>Cubic Hermite polynomials<a class="headerlink" href="#cubic-hermite-polynomials" title="Permalink to this headline">¶</a></h2>
<p>The finite elements considered so far represent <span class="math">\(u\)</span> as piecewise
polynomials with discontinuous derivatives at the cell boundaries.
Sometimes it is desired to have continuous derivatives. A primary
examples is the solution of differential equations with fourth-order
derivatives where standard finite element formulations lead to
a need for basis functions with continuous first-order derivatives.
The most common type of such basis functions in 1D is the
cubic Hermite polynomials.</p>
<p>There are ready-made formulas for the cubic Hermite polynomials, but
it is instructive to apply the principles for constructing basis
functions in detail.
Given a reference cell <span class="math">\([-1,1]\)</span>, we seek cubic polynomials
with the values of the function its first-order derivative at
<span class="math">\(X=-1\)</span> and <span class="math">\(X=1\)</span> as the four degrees of freedom. Let us number
the degrees of freedom as</p>
<blockquote>
<div><ul class="simple">
<li>0: value of function at <span class="math">\(X=-1\)</span></li>
<li>1: value of first derivative at <span class="math">\(X=-1\)</span></li>
<li>2: value of function at <span class="math">\(X=1\)</span></li>
<li>3: value of first derivative at <span class="math">\(X=1\)</span></li>
</ul>
</div></blockquote>
<p>By having the derivatives as unknowns, we ensure that
the derivative for the a basis function in two neighboring elements
is the same at the node points.</p>
<p>The four basis functions can be written in a general form</p>
<div class="math">
\[\tilde\varphi_i (X) = \sum_{j=0}^3 C_{i,j}X^j,\]</div>
<p>with four coefficients <span class="math">\(C_{i,j}\)</span>, <span class="math">\(j=0,1,2,3\)</span>, to be determined for
each <span class="math">\(i\)</span>. The constraints
that basis function number <span class="math">\(i\)</span> must be 1 for degree of
freedom number <span class="math">\(i\)</span> and zero for the other three degrees of freedom
gives four equations to determine <span class="math">\(C_{i,j}\)</span> for each <span class="math">\(i\)</span>. In mathematical
detail,</p>
<div class="math">
\[\begin{split}\tilde\varphi_0 (-1) &amp;= 1,\quad \tilde\varphi_0 (1)=\tilde\varphi_0'(-1)=\tilde\varphi_i' (1)=0,\\
\tilde\varphi_1' (-1) &amp;= 1,\quad \tilde\varphi_1 (-1)=\tilde\varphi_1(1)=\tilde\varphi_1' (1)=0,\\
\tilde\varphi_2 (1) &amp;= 1,\quad \tilde\varphi_2 (-1)=\tilde\varphi_2'(-1)=\tilde\varphi_2' (1)=0,\\
\tilde\varphi_3' (1) &amp;= 1,\quad \tilde\varphi_3 (-1)=\tilde\varphi_3'(-1)=\tilde\varphi_3 (1)=0
\thinspace .\end{split}\]</div>
<p>The 4 <span class="math">\(4\times 4\)</span> linear equations can be solved, yielding these formulas
for the cubic basis functions:</p>
<div class="math">
\[\begin{split}\tilde\varphi_0(X) &amp;= 1 - \frac{3}{4}(X+1)^2 + \frac{1}{4}(X+1)^3\\
\tilde\varphi_1(X) &amp;= -(X+1)(1 - \frac{1}{2}(X+1))^2\\
\tilde\varphi_2(X) &amp;= \frac{3}{4}(X+1)^2 - \frac{1}{2}(X+1)^3\\
\tilde\varphi_3(X) &amp;= -\frac{1}{2}(X+1)(\frac{1}{2}(X+1)^2 - (X+1))\\\end{split}\]</div>
<p>Remaining tasks:</p>
<blockquote>
<div><ul class="simple">
<li>Global numbering of the dofs</li>
<li><tt class="docutils literal"><span class="pre">dof_map</span></tt></li>
<li>4x4 element matrix</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="numerical-integration-1">
<h1>Numerical integration  (1)<a class="headerlink" href="#numerical-integration-1" title="Permalink to this headline">¶</a></h1>
<p>Finite element codes usually apply numerical approximations to
integrals. Since the integrands in the coefficient matrix often
are (lower-order) polynomials, integration rules that can
integrate polynomials exactly are popular.</p>
<p>The numerical integration rules can be expressed in a common form,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx \sum_{j=0}^M w_j\bar X_j,\]</div>
<p>where <span class="math">\(\bar X_j\)</span> are <em>integration points</em> and <span class="math">\(w_j\)</span> are
<em>integration weights</em>, <span class="math">\(j=0,\ldots,M\)</span>.
Different rules correspond to different choices of points and weights.</p>
<p>The very simplest method is the <em>Midpoint rule</em>,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx 2g(0),\quad \bar X_0=0,\ w_0=2,\]</div>
<p>which integrates linear functions exactly.</p>
<div class="section" id="newton-cotes-rules">
<span id="fem-approx-fe-numint1"></span><h2>Newton-Cotes rules<a class="headerlink" href="#newton-cotes-rules" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-39"></span><span class="target" id="index-40"></span><span class="target" id="index-41"></span><span class="target" id="index-42"></span><span class="target" id="index-43"></span><span class="target" id="index-44"></span><span class="target" id="index-45"></span><p id="index-46">The <a class="reference external" href="http://en.wikipedia.org/wiki/Newton%E2%80%93Cotes_formulas">Newton-Cotes</a>
rules are based on a fixed uniform distribution of the points.
The first two formulas in this family is the well-known
<em>Trapezoidal rule</em>,</p>
<div class="math" id="equation-fem:approx:fe:numint1:trapez">
<span class="eqno">(28)</span>\[     \int_{-1}^{1} g(X)dX \approx g(-1) + g(1),\quad \bar X_0=-1,\ \bar X_1=1,\ w_0=w_1=1,\]</div>
<p>and <em>Simpson&#8217;s rule</em>,</p>
<div class="math">
\[\int_{-1}^{1} g(X)dX \approx \frac{1}{3}\left(g(-1) + 4g(0)
+ g(1)\right),\]</div>
<p>where</p>
<div class="math">
\[\bar X_0=-1,\ \bar X_1=0,\ \bar X_2=1,\ w_0=w_2=\frac{1}{3},\ w_1=\frac{4}{3}\thinspace .\]</div>
<p>Newton-Cotes rules up to five points is supported in the
module file <a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/numint.py">numint.py</a>.</p>
<p>For higher accuracy one can divide the reference cell into a set of
subintervals and use the rules above on each subinterval. This approach
results in <em>composite</em> rules, well-known from basic introductions
to numerical integration of <span class="math">\(\int_{a}^{b}f(x)dx\)</span>.</p>
</div>
<div class="section" id="gauss-legendre-rules-with-optimized-points">
<h2>Gauss-Legendre rules with optimized points<a class="headerlink" href="#gauss-legendre-rules-with-optimized-points" title="Permalink to this headline">¶</a></h2>
<p id="index-47">All these rules apply equally spaced points. More accurate rules, for
a given <span class="math">\(M\)</span>, arise if the location of the points are optimized for
polynomial integrands.  The <a class="reference external" href="http://en.wikipedia.org/wiki/Gaussian_quadrature">Gauss-Legendre rules</a> (also known as
Gauss-Legendre quadrature or Gaussian quadrature) constitute one such
class of integration methods. Two widely applied Gauss-Legendre rules
in this family have the choice</p>
<div class="math">
\[\begin{split}M=1&amp;:\quad \bar X_0=-\frac{1}{\sqrt{3}},\
\bar X_1=\frac{1}{\sqrt{3}},\ w_0=w_1=1\\
M=2&amp;:\quad \bar X_0=-\sqrt{\frac{3}{{5}}},\ \bar X_0=0,\
\bar X_2= \sqrt{\frac{3}{{5}}},\ w_0=w_2=\frac{5}{9},\ w_1=\frac{8}{9}\thinspace .\end{split}\]</div>
<p>These rules integrate 3rd and 5th degree polynomials exactly.
In general, an <span class="math">\(M\)</span>-point Gauss-Legendre rule integrates a polynomial
of degree <span class="math">\(2M+1\)</span> exactly.
The code <a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/numint.py">numint.py</a> contains a large collection of Gauss-Legendre rules.</p>
</div>
</div>
<div class="section" id="approximation-of-functions-in-2d">
<span id="fem-approx-2d"></span><h1>Approximation of functions in 2D<a class="headerlink" href="#approximation-of-functions-in-2d" title="Permalink to this headline">¶</a></h1>
<p>All the concepts and algorithms developed for approximation of 1D functions
<span class="math">\(f(x)\)</span> can readily be extended to 2D functions <span class="math">\(f(x,y)\)</span> and 3D functions
<span class="math">\(f(x,y,z)\)</span>. Basically, the extensions consists of defining basis functions
<span class="math">\(\varphi_i(x,y)\)</span> or <span class="math">\(\varphi_i(x,y,z)\)</span> over some domain <span class="math">\(\Omega\)</span>, and
for the least squares and Galerkin methods, the integration is done over
<span class="math">\(\Omega\)</span>.</p>
<div class="section" id="global-basis-functions-1">
<span id="fem-approx-2d-global"></span><h2>Global basis functions  (1)<a class="headerlink" href="#global-basis-functions-1" title="Permalink to this headline">¶</a></h2>
<p>An example will demonstrate the necessary extensions to use global
basis functions and the least squares, Galerkin/projection,
or interpolation/collocation
methods in 2D. The former two lead to linear systems</p>
<div class="math">
\[\begin{split}\sum_{j=0}^N A_{i,j}c_j &amp;= b_i,\quad i=0,\ldots,N,\\
A_{i,j} &amp;= (\varphi_i,\varphi_j),\\
b_i &amp;= (f,\varphi_i),\end{split}\]</div>
<p>where the inner product of two functions <span class="math">\(f(x,y)\)</span> and <span class="math">\(g(x,y)\)</span> is defined
completely analogously to the 1D case <a href="#equation-fem:approx:LS:innerprod">(12)</a>:</p>
<div class="math">
\[(f,g) = \int_\Omega f(x,y)g(x,y) dx dy\]</div>
<div class="section" id="constructing-2d-basis-functions-from-1d-functions">
<h3>Constructing 2D basis functions from 1D functions<a class="headerlink" href="#constructing-2d-basis-functions-from-1d-functions" title="Permalink to this headline">¶</a></h3>
<p>One straightforward
way to construct a basis in 2D is to combine
1D basis functions. Say we have the 1D basis</p>
<div class="math">
\[\{ \hat\varphi_0(x),\ldots,\hat\varphi_{N_x}(x)\}
\thinspace .\]</div>
<p>We can now form 2D basis functions as products of 1D basis functions:
<span class="math">\(\hat\varphi_p(x)\hat\varphi_q(y)\)</span> for <span class="math">\(p=0,\ldots,N_x\)</span> and <span class="math">\(q=0,\ldots,N_y\)</span>.
We can either work with double indices,
<span class="math">\(\varphi_{p,q}(x,y) = \hat\varphi_p(x)\hat\varphi_q(y)\)</span>, and write</p>
<div class="math">
\[u = \sum_{p=0}^{N_y}\sum_{q=0}^{N_x} c_{p,q}\varphi_{p,q}(x,y),\]</div>
<p>or we may transform the double index <span class="math">\((p,q)\)</span> to a single index <span class="math">\(i\)</span>,
using <span class="math">\(i=p N_y + q\)</span> or <span class="math">\(i=q N_x + p\)</span>.</p>
<p>Suppose we choose <span class="math">\(\hat\varphi_p(x)=x^p\)</span>, and try an approximation with
<span class="math">\(N_x=N_y=1\)</span>:</p>
<div class="math">
\[\varphi_{0,0}=1,\quad \varphi_{1,0}=x, \quad \varphi_{0,1}=y,
\quad \varphi_{1,1}=xy
\thinspace .\]</div>
<p>Using a mapping to one index like <span class="math">\(i=q N_x + p\)</span>, we get</p>
<div class="math">
\[\varphi_0=1,\quad \varphi_1=x, \quad \varphi_2=y,\quad\varphi_3 =xy
\thinspace .\]</div>
</div>
<div class="section" id="hand-calculations">
<h3>Hand calculations<a class="headerlink" href="#hand-calculations" title="Permalink to this headline">¶</a></h3>
<p>With the specific choice <span class="math">\(f(x,y) = (1+x^2)(1+2y^2)\)</span> on
<span class="math">\(\Omega = [0,L_x]\times [0,L_y]\)</span>, we can perform actual calculations:</p>
<div class="math">
\[\begin{split}A_{0,0} &amp;= (\varphi_0,\varphi_0) = \int_0^{L_y}\int_{0}^{L_x}
\varphi_0(x,y)^2 dx dy = \int_0^{L_y}\int_{0}^{L_x}dx dy = L_xL_y,\\
A_{1,0} &amp;= (\varphi_1,\varphi_0) = \int_0^{L_y}\int_{0}^{L_x} x dxdy =
\frac{1}{2}L_x^2L_y,\\
A_{0,1} &amp;= (\varphi_0,\varphi_1) = \int_0^{L_y}\int_{0}^{L_x} y dxdy =
\frac{1}{2}L_y^2L_x,\\
A_{0,1} &amp;= (\varphi_0,\varphi_1) = \int_0^{L_y}\int_{0}^{L_x} xy dxdy =
\int_0^{L_y}ydy \int_{0}^{L_x} xdx
\frac{1}{4}L_y^2L_x^2
\thinspace .\end{split}\]</div>
<p>The right-hand side vector has the entries</p>
<div class="math">
\[\begin{split}b_{0} &amp;= (\varphi_0,f) = \int_0^{L_y}\int_{0}^{L_x}1\cdot (1+x^2)(1+2y^2) dxdy
= \int_0^{L_y}(1+2y^2)dy \int_{0}^{L_x} (1+x^2)dx\\
&amp;= (L_y + \frac{2}{3}L_y^3)(L_x + \frac{1}{3}L_x^3)\\
b_{1} &amp;= (\varphi_1,f) = \int_0^{L_y}\int_{0}^{L_x} x(1+x^2)(1+2y^2) dxdy =
\int_0^{L_y}(1+2y^2)dy \int_{0}^{L_x} x(1+x^2)dx\\
&amp;= (L_y + \frac{2}{3}L_y^3)(\frac{1}{2}L_x^2 + \frac{1}{4}L_x^4)\\
b_{2} &amp;= (\varphi_2,f) = \int_0^{L_y}\int_{0}^{L_x} y(1+x^2)(1+2y^2) dxdy =
\int_0^{L_y}y(1+2y^2)dy \int_{0}^{L_x} (1+x^2)dx\\
&amp;= (\frac{1}{2}L_y + \frac{1}{2}L_y^4)(L_x + \frac{1}{3}L_x^3)\\
b_{3} &amp;= (\varphi_2,f) = \int_0^{L_y}\int_{0}^{L_x} xy(1+x^2)(1+2y^2) dxdy =
\int_0^{L_y}y(1+2y^2)dy \int_{0}^{L_x} x(1+x^2)dx\\
&amp;= (\frac{1}{2}L_y^2 + \frac{1}{2}L_y^4)(\frac{1}{2}L_x^2 + \frac{1}{4}L_x^4)
\thinspace .\end{split}\]</div>
<p>There is a general pattern in these calculations that we can explore.
An arbitrary matrix entry has the formula</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= (\varphi_i,\varphi_j) = \int_0^{L_y}\int_{0}^{L_x}
\varphi_i\varphi_j dx dy \\
&amp;= \int_0^{L_y}\int_{0}^{L_x}
\varphi_{p,q}\varphi_{r,s} dx dy
= \int_0^{L_y}\int_{0}^{L_x}
\hat\varphi_p(x)\hat\varphi_q(y)\hat\varphi_r(x)\hat\varphi_s(y) dx dy\\
&amp;= \int_0^{L_y} \hat\varphi_q(y)\hat\varphi_s(y)dy
\int_{0}^{L_x} \hat\varphi_p(x) \hat\varphi_r(x) dx\\
&amp;= \hat A^{(x)}_{p,r}\hat A^{(y)}_{q,s},\end{split}\]</div>
<p>where</p>
<div class="math">
\[\hat A^{(x)}_{p,r} = \int_{0}^{L_x} \hat\varphi_p(x) \hat\varphi_r(x) dx,
\quad
\hat A^{(y)}_{q,s} = \int_0^{L_y} \hat\varphi_q(y)\hat\varphi_s(y)dy,\]</div>
<p>are matrix entries for one-dimensional approximations. Moreover,
<span class="math">\(i=q N_y+q\)</span> and <span class="math">\(j=s N_y+r\)</span>.</p>
<p>With <span class="math">\(\hat\varphi_p(x)=x^p\)</span> we have</p>
<div class="math">
\[\hat A^{(x)}_{p,r} = \frac{1}{p+r+1}L_x^{p+r+1},\quad
\hat A^{(y)}_{q,s} = \frac{1}{q+s+1}L_y^{q+s+1},\]</div>
<p>and</p>
<div class="math">
\[A_{i,j} = \hat A^{(x)}_{p,r} \hat A^{(y)}_{q,s} =
\frac{1}{p+r+1}L_x^{p+r+1} \frac{1}{q+s+1}L_y^{q+s+1},\]</div>
<p>for <span class="math">\(p,r=0,\ldots,N_x\)</span> and <span class="math">\(q,s=0,\ldots,N_y\)</span>.</p>
<p>Corresponding reasoning for the right-hand side leads to</p>
<div class="math">
\[\begin{split}b_i &amp;= (\varphi_i,f) = \int_0^{L_y}\int_{0}^{L_x}\varphi_i f\,dxdx\\
&amp;= \int_0^{L_y}\int_{0}^{L_x}\hat\varphi_p(x)\hat\varphi_q(y) f\,dxdx\\
&amp;= \int_0^{L_y}\hat\varphi_q(y) (1+2y^2)dy
\int_0^{L_y}\hat\varphi_p(x) x^p (1+x^2)dx\\
&amp;= \int_0^{L_y} y^q (1+2y^2)dy
\int_0^{L_y}x^p (1+x^2)dx\\
&amp;= (\frac{1}{q+1} L_y^{q+1} + \frac{2}{q+3}x^{q+3})
(\frac{1}{p+1} L_y^{p+1} + \frac{2}{p+3}x^{p+3})\end{split}\]</div>
<p>Choosing <span class="math">\(L_x=L_y=2\)</span>, we have</p>
<div class="math">
\[\begin{split}A =
\left[\begin{array}{cccc}
4 &amp; 4 &amp; 4 &amp; 4\\
4 &amp; \frac{16}{3} &amp; 4 &amp; \frac{16}{3}\\
4 &amp; 4 &amp; \frac{16}{3} &amp; \frac{16}{3}\\
4 &amp; \frac{16}{3} &amp; \frac{16}{3} &amp; \frac{64}{9}
\end{array}\right],\quad
b = \left[\begin{array}{c}
\frac{308}{9}\\\frac{140}{3}\\44\\60\end{array}\right],
\quad c = \left[
\begin{array}{c}
-\frac{1}{9}, \\
\frac{4}{3}, \\
 - \frac{2}{3}, \\
 8
\end{array}\right]
\thinspace .\end{split}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-ubilinear"><em>Approximation of a 2D quadratic function (left) by a 2D bilinear function (right) using the Galerkin or least squares method</em></a> illustrates the result.</p>
<div class="figure" id="fem-approx-fe-2d-fig-ubilinear">
<img alt="_images/approx2D_bilinear.png" src="_images/approx2D_bilinear.png" style="width: 800px;" />
<p class="caption"><em>Approximation of a 2D quadratic function (left) by a 2D bilinear function (right) using the Galerkin or least squares method</em></p>
</div>
</div>
</div>
<div class="section" id="implementation-3">
<span id="fem-approx-2d-global-code"></span><h2>Implementation  (3)<a class="headerlink" href="#implementation-3" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="docutils literal"><span class="pre">least_squares</span></tt> function from
the section <a class="reference internal" href="#fem-approx-global-orth"><em>Orthogonal basis functions</em></a> and/or the
file <a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/fe_approx1D.py">approx1D.py</a>
can with very small modifications solve 2D approximation problems.
First, let <tt class="docutils literal"><span class="pre">Omega</span></tt> now be a list of the intervals in <span class="math">\(x\)</span> and <span class="math">\(y\)</span> direction.
For example, <span class="math">\(\Omega = [0,L_x]\times [0,L_y]\)</span> can be represented
by <tt class="docutils literal"><span class="pre">Omega</span> <span class="pre">=</span> <span class="pre">[[0,</span> <span class="pre">L_x],</span> <span class="pre">[0,</span> <span class="pre">L_y]]</span></tt>.</p>
<p>Second, the symbolic integration must be extended to 2D:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="n">integrand</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span>
                 <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span>
                 <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>provided <tt class="docutils literal"><span class="pre">integrand</span></tt> is an expression involving the <tt class="docutils literal"><span class="pre">sympy</span></tt> symbols <tt class="docutils literal"><span class="pre">x</span></tt>
and <tt class="docutils literal"><span class="pre">y</span></tt>.
The 2D version of numerical integration becomes</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
    <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span>
                       <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span>
                       <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
<p>The right-hand side integrals are modified in a similar way.</p>
<p>Third, we must construct a list of 2D basis functions, e.g.,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Nx</span><span class="p">,</span> <span class="n">Ny</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="o">**</span><span class="n">i</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="n">j</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ny</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">sines</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Nx</span><span class="p">,</span> <span class="n">Ny</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">sm</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ny</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<p>The complete code appears in
<a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/fe_approx2D.py">approx2D.py</a>.</p>
<p>The previous hand calculation where a quadratic <span class="math">\(f\)</span> was approximated by
a bilinear function can be computed symbolically by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Omega</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">8*x*y - 2*x/3 + 4*y/3 - 1/9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">2*x**2*y**2 + x**2 + 2*y**2 + 1</span>
</pre></div>
</div>
<p>We may continue with adding higher powers to the basis and check that
with <span class="math">\(N_x\geq 2\)</span> and <span class="math">\(N_y\geq 2\)</span> we recover the exact function <span class="math">\(f\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">taylor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span>
<span class="go">2*x**2*y**2 + x**2 + 2*y**2 + 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">u</span><span class="o">-</span><span class="n">f</span>
<span class="go">0</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="finite-elements-in-2d-and-3d">
<h1>Finite elements in 2D and 3D<a class="headerlink" href="#finite-elements-in-2d-and-3d" title="Permalink to this headline">¶</a></h1>
<p>Finite element approximation is particularly powerful in 2D and 3D because
the method can handle a geometrically complex domain <span class="math">\(\Omega\)</span> with ease.
The principal idea is, as in 1D, to divide the domain into cells
use polynomials for approximating a function over a cell.
Two popular cell shapes are triangles and the quadrilaterals.
Figures <a class="reference internal" href="#fem-approx-fe-2d-fig-rectp1"><em>Examples on 2D P1 elements</em></a>, <a class="reference internal" href="#fem-approx-fe-2d-fig-circp1"><em>Examples on 2D P1 elements in a deformed geometry</em></a>,
and <a class="reference internal" href="#fem-approx-fe-2d-fig-rectq1"><em>Examples on 2D Q1 elements</em></a> provide examples. P1 elements
means linear functions (<span class="math">\(a_0 + a_1x + a_2y\)</span>) over triangles, while Q1 elements
have bilinear functions (<span class="math">\(a_0 + a_1x + a_2y + a_3xy\)</span>) over rectangular cells.
Higher-order elements can easily be defined.</p>
<div class="figure" id="fem-approx-fe-2d-fig-rectp1">
<img alt="_images/mesh2D_rect_P1.png" src="_images/mesh2D_rect_P1.png" style="width: 800px;" />
<p class="caption"><em>Examples on 2D P1 elements</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-circp1">
<img alt="_images/mesh2D_quarter_circle.png" src="_images/mesh2D_quarter_circle.png" style="width: 400px;" />
<p class="caption"><em>Examples on 2D P1 elements in a deformed geometry</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-rectq1">
<img alt="_images/mesh2D_rect_Q1.png" src="_images/mesh2D_rect_Q1.png" style="width: 400px;" />
<p class="caption"><em>Examples on 2D Q1 elements</em></p>
</div>
<div class="section" id="basis-functions-over-triangles-in-the-physical-domain">
<h2>Basis functions over triangles in the physical domain<a class="headerlink" href="#basis-functions-over-triangles-in-the-physical-domain" title="Permalink to this headline">¶</a></h2>
<p>Cells with triangular shape will be in main focus here.  With the P1
triangular element, <span class="math">\(u\)</span> is a linear function over each cell, with
discontinuous derivatives at the cell boundaries, as depicted in
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-femfunc"><em>Example on piecewise linear 2D functions defined on triangles</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-femfunc">
<img alt="_images/demo2D_4x3r.png" src="_images/demo2D_4x3r.png" style="width: 400px;" />
<p class="caption"><em>Example on piecewise linear 2D functions defined on triangles</em></p>
</div>
<p>We give the vertices of the cells global and local numbers as in 1D.
The degrees of freedom in the P1 element are the function values at
a set of nodes, which are the three vertices.
The basis function <span class="math">\(\varphi_i(x,y)\)</span> is then 1 at the vertex with global vertex
number <span class="math">\(i\)</span> and zero at all other vertices.
On an element, the three degrees of freedom uniquely determine
the linear basis functions in that element, as usual.
The global
<span class="math">\(\varphi_i(x,y)\)</span> function is then a combination of the linear functions
(planar surfaces)
over all the neighboring cells
that have vertex number <span class="math">\(i\)</span> in common. Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-basphi"><em>Example on a piecewise linear 2D basis function over a patch of triangles</em></a>
tries to illustrate the shape of such a &#8220;pyramid&#8221;-like function.</p>
<div class="figure" id="fem-approx-fe-2d-fig-basphi">
<img alt="_images/demo2D_basisfunc.png" src="_images/demo2D_basisfunc.png" style="width: 400px;" />
<p class="caption"><em>Example on a piecewise linear 2D basis function over a patch of triangles</em></p>
</div>
<div class="section" id="element-matrices-and-vectors">
<h3>Element matrices and vectors<a class="headerlink" href="#element-matrices-and-vectors" title="Permalink to this headline">¶</a></h3>
<p>As in 1D, we split the integral over <span class="math">\(\Omega\)</span> into a sum of integrals
over cells. Also as in 1D, <span class="math">\(\varphi_i\)</span> overlaps <span class="math">\(\varphi_j\)</span>
(i.e., <span class="math">\(\varphi_i\varphi_j\neq 0\)</span>) if and only if
<span class="math">\(i\)</span> and <span class="math">\(j\)</span> are vertices in the same cell. Therefore, the integral
of <span class="math">\(\varphi_i\varphi_j\)</span> over an element is nonzero only when <span class="math">\(i\)</span> and <span class="math">\(j\)</span>
run over the vertex numbers in the element. These nonzero contributions
to the coefficient matrix are, as in 1D, collected in an element matrix.
The size of the element matrix becomes <span class="math">\(3\times 3\)</span> since there are
three degrees of freedom
that <span class="math">\(i\)</span> and <span class="math">\(j\)</span> run over. Again, as in 1D, we number the
local vertices in a cell, starting at 0, and add the entries in
the element matrix into the global system matrix, exactly as in 1D.
All details and code appear below.</p>
</div>
</div>
<div class="section" id="basis-functions-over-triangles-in-the-reference-cell">
<h2>Basis functions over triangles in the reference cell<a class="headerlink" href="#basis-functions-over-triangles-in-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<p>As in 1D, we can define the basis functions and the degrees of freedom
in a reference cell and then use a mapping from the reference coordinate
system to the physical coordinate system.
We also have a mapping of local degrees of freedom numbers to global degrees
of freedom numbers.
.. (<tt class="docutils literal"><span class="pre">dof_map</span></tt>).</p>
<p>The reference cell in an <span class="math">\((X,Y)\)</span> coordinate system has vertices
<span class="math">\((0,0)\)</span>, <span class="math">\((1,0)\)</span>, and <span class="math">\((0,1)\)</span>, corresponding to local vertex numbers
0, 1, and 2, respectively. The P1 element has linear functions
<span class="math">\(\tilde\varphi_r(X,Y)\)</span> as basis functions, <span class="math">\(r=0,1,2\)</span>.
Since a linear function <span class="math">\(\tilde\varphi_r(X,Y)\)</span> in 2D is on
the form <span class="math">\(C_{r,0} + C_{r,1}X + C_{r,2}Y\)</span>, and hence has three
parameters <span class="math">\(C_{r,0}\)</span>, <span class="math">\(C_{r,1}\)</span>, and <span class="math">\(C_{r,2}\)</span>, we need three
degrees of freedom. These are in general taken as the function values at a
set of nodes. For the P1 element the set of nodes is the three vertices.
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p12d"><em>2D P1 element</em></a> displays the geometry of the
element and the location of the nodes.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p12d">
<img alt="_images/P1_2d.png" src="_images/P1_2d.png" style="width: 100px;" />
<p class="caption"><em>2D P1 element</em></p>
</div>
<p>Requiring <span class="math">\(\tilde\varphi_r=1\)</span> at node number <span class="math">\(r\)</span> and
<span class="math">\(\tilde\varphi_r=0\)</span> at the two other nodes, gives three linear equations to
determine <span class="math">\(C_{r,0}\)</span>, <span class="math">\(C_{r,1}\)</span>, and <span class="math">\(C_{r,2}\)</span>. The result is</p>
<div class="math">
\[\begin{split}\tilde\varphi_0(X,Y) &amp;= 1 - X - Y,\\
\tilde\varphi_1(X,Y) &amp;= X,\\
\tilde\varphi_2(X,Y) &amp;= Y\end{split}\]</div>
<p>Higher-order approximations are obtained by increasing the polynomial order,
adding additional nodes, and letting the degrees of freedom be
function values at the nodes. Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p22d"><em>2D P2 element</em></a>
shows the location of the six nodes in the P2 element.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p22d">
<img alt="_images/P2_2d.png" src="_images/P2_2d.png" style="width: 100px;" />
<p class="caption"><em>2D P2 element</em></p>
</div>
<p>A polynomial of degree <span class="math">\(p\)</span> in <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> has <span class="math">\(n_p=(p+1)(p+2)/2\)</span> terms
and hence needs <span class="math">\(n_p\)</span> nodes. The values at the nodes constitute <span class="math">\(n_p\)</span>
degrees of freedom. The location of the nodes for
<span class="math">\(\tilde\varphi_r\)</span> up to degree 6 is displayed in Figure
<a class="reference internal" href="#fem-approx-fe-2d-fig-p162d"><em>2D P1, P2, P3, P4, P5, and P6 elements</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p162d">
<img alt="_images/P1-6_2d.png" src="_images/P1-6_2d.png" style="width: 400px;" />
<p class="caption"><em>2D P1, P2, P3, P4, P5, and P6 elements</em></p>
</div>
<p>The generalization to 3D is straightforward: the reference element is a
<a class="reference external" href="http://en.wikipedia.org/wiki/Tetrahedron">tetrahedron</a>
with vertices <span class="math">\((0,0,0)\)</span>, <span class="math">\((1,0,0)\)</span>, <span class="math">\((0,1,0)\)</span>, and <span class="math">\((0,0,1)\)</span>
in a <span class="math">\(X,Y,Z\)</span> reference coordinate system. The P1 element has its degrees
of freedom as four nodes, which are the four vertices, see Figure
<a class="reference internal" href="#fem-approx-fe-2d-fig-p1-123d"><em>P1 elements in 1D, 2D, and 3D</em></a>. The P2 element adds additional
nodes along the edges of the cell, yielding a total of 10 nodes and
degrees of freedom, see
Figure <a class="reference internal" href="#fem-approx-fe-2d-fig-p2-123d"><em>P2 elements in 1D, 2D, and 3D</em></a>.</p>
<div class="figure" id="fem-approx-fe-2d-fig-p1-123d">
<img alt="_images/P1-1d2d3d.png" src="_images/P1-1d2d3d.png" style="width: 400px;" />
<p class="caption"><em>P1 elements in 1D, 2D, and 3D</em></p>
</div>
<div class="figure" id="fem-approx-fe-2d-fig-p2-123d">
<img alt="_images/P2-1d2d3d.png" src="_images/P2-1d2d3d.png" style="width: 400px;" />
<p class="caption"><em>P2 elements in 1D, 2D, and 3D</em></p>
</div>
<span class="target" id="index-48"></span><span class="target" id="index-49"></span><span class="target" id="index-50"></span><p id="index-51">The interval in 1D, the triangle in 2D, the tetrahedron in 3D, and
its generalizations to higher space dimensions are known
as <em>simplex</em> cells (the geometry) or <em>simplex</em> elements (the geometry,
basis functions, degrees of freedom, etc.). The plural forms
<a class="reference external" href="http://en.wikipedia.org/wiki/Simplex">simplices</a> and
simplexes are
also a much used shorter terms when referring to this type of cells or elements.
The side of a simplex is called a <em>face</em>, while the tetrahedron also
has <em>edges</em>.</p>
<p><em>Acknowledgment.</em> Figures <a class="reference internal" href="#fem-approx-fe-2d-fig-p12d"><em>2D P1 element</em></a> to <a class="reference internal" href="#fem-approx-fe-2d-fig-p2-123d"><em>P2 elements in 1D, 2D, and 3D</em></a>
are created by Anders Logg and taken from the <a class="reference external" href="https://launchpad.net/fenics-book">FEniCS book</a>: <em>Automated Solution of Differential Equations by the Finite Element Method</em>, edited by A. Logg, K.-A. Mardal, and G. N. Wells, published
by <a class="reference external" href="http://www.springer.com/mathematics/computational+science+%26+engineering/book/978-3-642-23098-1">Springer</a>, 2012.</p>
</div>
<div class="section" id="affine-mapping-of-the-reference-cell">
<h2>Affine mapping of the reference cell<a class="headerlink" href="#affine-mapping-of-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\tilde\varphi_r^{(1)}\)</span> denote the basis functions associated
with the P1 element in 1D, 2D, or 3D, and let <span class="math">\(\pmb{x}_{q(e,r)}\)</span> be
the physical coordinates of local vertex number <span class="math">\(r\)</span> in cell <span class="math">\(e\)</span>.
Furthermore,
let <span class="math">\(\pmb{X}\)</span> be a point in the reference coordinate system corresponding
to the point <span class="math">\(\pmb{x}\)</span> in the physical coordinate system.
The affine mapping of any <span class="math">\(\pmb{X}\)</span> onto <span class="math">\(\pmb{x}\)</span> is
then defined by</p>
<div class="math" id="equation-fem:approx:fe:affine:map">
<span id="index-52"></span><span class="eqno">(29)</span>\[     \pmb{x} = \sum_{r} \tilde\varphi_r^{(1)}(\pmb{X})\pmb{x}_{q(e,r)},\]</div>
<p>where <span class="math">\(r\)</span> runs over the local vertex numbers in the cell.
The affine mapping maps the straight or planar faces of the reference cell onto
straight or planar faces in the physical coordinate system. The mapping can
be used for both P1 and higher-order elements.</p>
<div class="figure" id="fem-approx-fe-map-fig-2dp1">
<img alt="_images/ElmT3n2D_map.png" src="_images/ElmT3n2D_map.png" style="width: 400px;" />
<p class="caption"><em>Affine mapping of a P1 element</em></p>
</div>
</div>
<div class="section" id="isoparametric-mapping-of-the-reference-cell">
<h2>Isoparametric mapping of the reference cell<a class="headerlink" href="#isoparametric-mapping-of-the-reference-cell" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-53"></span><p id="index-54">Instead of using the P1 basis functions in the mapping
<a href="#equation-fem:approx:fe:affine:map">(29)</a>,
we may use the basis functions of the actual element:</p>
<div class="math" id="equation-fem:approx:fe:isop:map">
<span class="eqno">(30)</span>\[     \pmb{x} = \sum_{r} \tilde\varphi_r(\pmb{X})\pmb{x}_{q(e,r)},\]</div>
<p>where <span class="math">\(r\)</span> runs over all nodes, i.e., all points associated with the
degrees of freedom. This is called an <em>isoparametric mapping</em>.
For P1 elements it is identical to the affine mapping
<a href="#equation-fem:approx:fe:affine:map">(29)</a>, but for higher-order elements
the mapping of the straight or planar faces of the reference cell will
result in a <em>curved</em> face in the physical coordinate system.
For example, when we use the basis functions of the triangular P2 element
in 2D in <a href="#equation-fem:approx:fe:isop:map">(30)</a>, the straight faces of the
reference triangle are mapped onto curved faces of parabolic shape in
the physical coordinate system, see Figure <a class="reference internal" href="#fem-approx-fe-map-fig-2dp2"><em>Isoparametric mapping of a P2 element</em></a>.</p>
<div class="figure" id="fem-approx-fe-map-fig-2dp2">
<img alt="_images/ElmT6n2D_map.png" src="_images/ElmT6n2D_map.png" style="width: 400px;" />
<p class="caption"><em>Isoparametric mapping of a P2 element</em></p>
</div>
<p>From <a href="#equation-fem:approx:fe:affine:map">(29)</a> or
<a href="#equation-fem:approx:fe:isop:map">(30)</a> it is easy to realize that the
vertices are correctly mapped. Consider a vertex with local number
also a much used term when referring to this type of cells or elements$s$.
Then <span class="math">\(\tilde\varphi_s=1\)</span> at this vertex and zero at the others.
This means that only one term in the sum is nonzero and <span class="math">\(\pmb{x}=\pmb{x}_{q(e,s)}\)</span>,
which is the coordinate of this vertex in the global coordinate system.</p>
</div>
<div class="section" id="computing-integrals">
<h2>Computing integrals<a class="headerlink" href="#computing-integrals" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\tilde\Omega^r\)</span> denote the reference cell and <span class="math">\(\Omega^{(e)}\)</span>
the cell in the physical coordinate system. The transformation of
the integral from the physical to the reference coordinate system reads</p>
<div class="math">
\[\begin{split}\int_{\Omega^{(e)}}\varphi_i (\pmb{x}) \varphi_j (\pmb{x}) d\pmb{x} &amp;=
\int_{\tilde\Omega^r} \tilde\varphi_i (\pmb{X}) \tilde\varphi_j (\pmb{X})
\det J\, d\pmb{X},\\
\int_{\Omega^{(e)}}\varphi_i (\pmb{x}) f(\pmb{x}) d\pmb{x} &amp;=
\int_{\tilde\Omega^r} \tilde\varphi_i (\pmb{X}) f(\pmb{x}(\pmb{X})) \det J\, d\pmb{X},\end{split}\]</div>
<p>where <span class="math">\(d\pmb{x} = dx dy\)</span> in 2D and <span class="math">\(d\pmb{x} = dx dy dz\)</span> in 3D, with a similar
definition of <span class="math">\(d\pmb{X}\)</span>. The quantity <span class="math">\(\det J\)</span> is the determinant of the
Jacobian of the mapping <span class="math">\(\pmb{x}(\pmb{X})\)</span>. In 2D,</p>
<div class="math" id="equation-fem:approx:fe:2D:mapping:J:detJ">
<span class="eqno">(31)</span>\[\begin{split}     J = \left[\begin{array}{cc}
     \frac{\partial x}{\partial X} &amp; \frac{\partial x}{\partial Y}\\
     \frac{\partial y}{\partial X} &amp; \frac{\partial y}{\partial Y}
     \end{array}\right], \quad
     \det J = \frac{\partial x}{\partial X}\frac{\partial y}{\partial Y}
     - \frac{\partial x}{\partial Y}\frac{\partial y}{\partial X}
     \thinspace .\end{split}\]</div>
<p>With the affine mapping
<a href="#equation-fem:approx:fe:affine:map">(29)</a>, <span class="math">\(\det J=2\Delta\)</span>, where <span class="math">\(\Delta\)</span> is
the area or volume of the cell in the physical coordinate system.</p>
<p><em>Remark.</em> Observe that finite elements in 2D and 3D builds on the same
<em>ideas</em> and <em>concepts</em> as in 1D, but there is simply more to compute because the
specific mathematical formulas in 2D and 3D are more complicated.</p>
</div>
</div>
<div class="section" id="exercises-1">
<h1>Exercises  (1)<a class="headerlink" href="#exercises-1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="exercise-1-linear-algebra-refresher-i">
<span id="fem-approx-exer-linalg1"></span><h2>Exercise 1: Linear algebra refresher I<a class="headerlink" href="#exercise-1-linear-algebra-refresher-i" title="Permalink to this headline">¶</a></h2>
<p>Look up the topic of <em>vector space</em> in your favorite linear algebra
book or search for the term at Wikipedia.
Prove that vectors in the plane (<span class="math">\(a,b\)</span>) form a vector space
by showing that all the axioms of a vector space
are satisfied. Similarly,
prove that all linear functions of the form <span class="math">\(ax+b\)</span> constitute a vector space.</p>
</div>
<div class="section" id="exercise-2-linear-algebra-refresher-ii">
<span id="fem-approx-exer-linalg2"></span><h2>Exercise 2: Linear algebra refresher II<a class="headerlink" href="#exercise-2-linear-algebra-refresher-ii" title="Permalink to this headline">¶</a></h2>
<p>As an extension of <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a>, check out
the topic of <em>inner vector spaces</em>. Show that both examples
of spaces in <a class="reference internal" href="#fem-approx-exer-linalg1"><em>Exercise 1: Linear algebra refresher I</em></a> can be equipped with an
inner product and show that the choice of inner product satisfied the
general requirements of an inner product in a vector space.</p>
</div>
<div class="section" id="exercise-3-approximate-a-three-dimensional-vector-in-a-plane">
<span id="fem-approx-exer-vec-3dby2d"></span><h2>Exercise 3: Approximate a three-dimensional vector in a plane<a class="headerlink" href="#exercise-3-approximate-a-three-dimensional-vector-in-a-plane" title="Permalink to this headline">¶</a></h2>
<p>Given <span class="math">\(\pmb{f} = (1,1,1)\)</span> in <span class="math">\(\mathbb{R}^3\)</span>, find the best approximation vector
<span class="math">\(\pmb{u}\)</span> in the plane spanned by the unit vectors <span class="math">\((1,0)\)</span> and <span class="math">\((0,1)\)</span>.
Repeat the calculations using the vectors <span class="math">\((2,1)\)</span> and <span class="math">\((1,2)\)</span>.
Filename: <tt class="docutils literal"><span class="pre">vec111_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-4-approximate-the-exponential-function-by-power-functions">
<span id="fem-approx-exer-exp-powers"></span><h2>Exercise 4: Approximate the exponential function by power functions<a class="headerlink" href="#exercise-4-approximate-the-exponential-function-by-power-functions" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(V\)</span> be a function space with basis functions
<span class="math">\(x^k\)</span>, <span class="math">\(k=0,1,\ldots,N\)</span>.
Find the best approximation to <span class="math">\(f(x)=e^x\)</span> among all functions in <span class="math">\(V\)</span>,
using <span class="math">\(N=8\)</span> and the <tt class="docutils literal"><span class="pre">least_squares</span></tt> function from
the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a>.
Filename: <tt class="docutils literal"><span class="pre">exp_by_powers.py</span></tt>.</p>
</div>
<div class="section" id="exercise-5-approximate-a-high-frequency-sine-function-by-lower-frequency-sines">
<span id="fem-approx-exer-sine-hibylow"></span><h2>Exercise 5: Approximate a high frequency sine function by lower frequency sines<a class="headerlink" href="#exercise-5-approximate-a-high-frequency-sine-function-by-lower-frequency-sines" title="Permalink to this headline">¶</a></h2>
<p>Find the best approximation of <span class="math">\(f(x) = \sin (20x)\)</span> on <span class="math">\([0, 2\pi]\)</span> in
the space <span class="math">\(V\)</span> with basis</p>
<div class="math">
\[\{ \sin x,\ \sin 2x, \sin 3x \},\]</div>
<p>using the <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> function from
the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>. Plot <span class="math">\(f(x)\)</span> and its approximation.
Filename: <tt class="docutils literal"><span class="pre">hilow_sine_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-6-fourier-series-as-a-least-squares-approximation">
<span id="fem-approx-exer-fourier"></span><h2>Exercise 6: Fourier series as a least squares approximation<a class="headerlink" href="#exercise-6-fourier-series-as-a-least-squares-approximation" title="Permalink to this headline">¶</a></h2>
<p>Given a function <span class="math">\(f(x)\)</span> on an interval <span class="math">\([0,L]\)</span>, find the formula
for the coefficients of the Fourier series of <span class="math">\(f\)</span>:</p>
<div class="math">
\[f(x) = a_0 + \sum_{j=1}^\infty a_j\cos \left(j\frac{\pi x}{L}\right)
+ \sum_{j=1}^\infty b_j\sin \left(j\frac{\pi x}{L}\right)\thinspace .\]</div>
<p>Let an infinite-dimensional vector space <span class="math">\(V\)</span> have the basis functions
<span class="math">\(\cos j\frac{\pi x}{L}\)</span> for <span class="math">\(j=0,1,\dots,\infty\)</span> and :math:<a href="#id4"><span class="problematic" id="id5">`</span></a>sin jfrac{pi</p>
<blockquote>
<div>x}{L}` for <span class="math">\(j=1,\dots,\infty\)</span>.  Show that the least squares</div></blockquote>
<p>approximation method from the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> leads to a
linear system whose solution coincides with the standard formulas for
the coefficients in a Fourier series of <span class="math">\(f(x)\)</span> (see also
the section <a class="reference internal" href="#fem-approx-global-fourier"><em>Fourier series</em></a>). You may choose</p>
<div class="math">
\[\varphi_{2i} = \cos\left( i\frac{\pi}{L}x\right),\quad
\varphi_{2i+1} = \sin\left( i\frac{\pi}{L}x\right),\]</div>
<p>for <span class="math">\(i=0,1,\ldots,N\rightarrow\infty\)</span>.</p>
<p>Choose <span class="math">\(f(x) = \tanh(s(x-\frac{1}{2}))\)</span> on <span class="math">\(\Omega=[0,1]\)</span>, which is
a smooth function, but with considerable steepness around <span class="math">\(x=1/2\)</span>
as <span class="math">\(s\)</span> grows in size.
Calculate the coefficients in the Fourier expansion by
solving the linear system, arising from the least squares or Galerkin
methods, by hand. Plot
some truncated versions of the series together with <span class="math">\(f(x)\)</span> to show how
the series expansion converges for <span class="math">\(s=10\)</span> and <span class="math">\(s=100\)</span>.
Filename: <tt class="docutils literal"><span class="pre">Fourier_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-7-approximate-a-function-by-lagrange-polynomials">
<span id="fem-approx-exer-tanh"></span><h2>Exercise 7: Approximate a <span class="math">\(\tanh\)</span> function by Lagrange polynomials<a class="headerlink" href="#exercise-7-approximate-a-function-by-lagrange-polynomials" title="Permalink to this headline">¶</a></h2>
<p>Use interpolation (or collocation) with uniformly distributed
points and Chebychev nodes to approximate</p>
<div class="math">
\[f(x) = \tanh(s(x-\frac{1}{2}))\]</div>
<p>by Lagrange polynomials for <span class="math">\(s=10,100\)</span> and <span class="math">\(N=3,6,9,11\)</span>.
Filename: <tt class="docutils literal"><span class="pre">tanh_Lagrange_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-8-define-finite-element-meshes">
<span id="fem-approx-fe-exer-defmesh"></span><h2>Exercise 8: Define finite element meshes<a class="headerlink" href="#exercise-8-define-finite-element-meshes" title="Permalink to this headline">¶</a></h2>
<p>Consider a domain <span class="math">\(\Omega =[0,2]\)</span> divided into the three elements
<span class="math">\([0,1]\)</span>, <span class="math">\([1,1.2]\)</span>, and <span class="math">\([1.2,2]\)</span>, with two nodes in each element
(P1 elements).
Suggest two different element numberings and global node numberings
for this mesh and set up the corresponding <tt class="docutils literal"><span class="pre">nodes</span></tt> and <tt class="docutils literal"><span class="pre">elements</span></tt>
lists in each case.</p>
<p>Thereafter, subdivide the element <span class="math">\([1.2,2]\)</span> into two new equal-sized elements.
Add the new node and the two new elements to each of the <tt class="docutils literal"><span class="pre">nodes</span></tt> and
<tt class="docutils literal"><span class="pre">elements</span></tt> lists.
Filename: <tt class="docutils literal"><span class="pre">fe_numberings.py.</span></tt>.</p>
</div>
<div class="section" id="exercise-9-construct-matrix-sparsity-patterns">
<span id="fem-approx-fe-exer-defmesh-sparsity"></span><h2>Exercise 9: Construct matrix sparsity patterns<a class="headerlink" href="#exercise-9-construct-matrix-sparsity-patterns" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="#fem-approx-fe-exer-defmesh"><em>Exercise 8: Define finite element meshes</em></a> describes a element mesh
with a total of five elements, but with two different element and
node orderings. For each of the two orderings,
make a <span class="math">\(5\times 5\)</span> matrix and fill in the entries that will be nonzero.
Filename: <tt class="docutils literal"><span class="pre">fe_sparsity_pattern.pdf</span></tt>.</p>
<p><em>Hint.</em> A matrix entry <span class="math">\((i,j)\)</span> is nonzero if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes in the
same element.</p>
</div>
<div class="section" id="exercise-10-perform-symbolic-finite-element-computations">
<span id="fem-approx-fe-exer-asinwt-symbolic"></span><h2>Exercise 10: Perform symbolic finite element computations<a class="headerlink" href="#exercise-10-perform-symbolic-finite-element-computations" title="Permalink to this headline">¶</a></h2>
<p>Find formulas for the coefficient matrix and right-hand side
when approximating <span class="math">\(f(x) = sin (x)\)</span> on
<span class="math">\(\Omega=[0, \pi]\)</span> by two P1 elements of size <span class="math">\(\pi/2\)</span>.
Solve the system and compare <span class="math">\(u(\pi/2\)</span> with
the exact value 1.</p>
<p>Filename: <tt class="docutils literal"><span class="pre">sin_approx_P1.py</span></tt>.</p>
</div>
<div class="section" id="exercise-11-approximate-a-function-by-p1-and-p2-elements">
<span id="id6"></span><h2>Exercise 11: Approximate a <span class="math">\(\tanh\)</span> function by P1 and P2 elements<a class="headerlink" href="#exercise-11-approximate-a-function-by-p1-and-p2-elements" title="Permalink to this headline">¶</a></h2>
<p>Given</p>
<div class="math">
\[f(x) = \tanh(s(x-\frac{1}{2}))\]</div>
<p>use the Galerkin or least squares method with finite elements to find
an approximate function <span class="math">\(u(x)\)</span>. Choose <span class="math">\(s=40\)</span> and try
<span class="math">\(n_e=4,8,16\)</span> P1 elements and
<span class="math">\(n_e=2,4,8\)</span> P2 elements.
Integrate <span class="math">\(f\varphi_i\)</span> numerically.
Filename: <tt class="docutils literal"><span class="pre">tanh_fe_P1P2_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-12-approximate-a-function-by-p3-and-p4-elements">
<span id="fem-approx-exer-tanh2"></span><h2>Exercise 12: Approximate a <span class="math">\(\tanh\)</span> function by P3 and P4 elements<a class="headerlink" href="#exercise-12-approximate-a-function-by-p3-and-p4-elements" title="Permalink to this headline">¶</a></h2>
<p>Solve <em class="xref std std-ref">fem:approx:exer:tanh</em> using <span class="math">\(n_e=1,2,4\)</span> P3 and P4
elements. How will a collocation/interpolation method work in
this case with the same number of nodes?
Filename: <tt class="docutils literal"><span class="pre">tanh_fe_P3P4_approx.py</span></tt>.</p>
</div>
<div class="section" id="exercise-13-investigate-the-approximation-errors-in-finite-elements">
<span id="fem-approx-fe-exer-asinwt-interpol-error"></span><h2>Exercise 13: Investigate the approximation errors in finite elements<a class="headerlink" href="#exercise-13-investigate-the-approximation-errors-in-finite-elements" title="Permalink to this headline">¶</a></h2>
<p>A fundamental question is how accurate the finite element approximation
is in terms of the cell length <span class="math">\(h\)</span> and the degree <span class="math">\(d\)</span> of the basis
functions. We can investigate this empirically by choosing an <span class="math">\(f\)</span>
function, say <span class="math">\(f(x) = A\sin (\omega x)\)</span> on
<span class="math">\(\Omega=[0, 2\pi/\omega]\)</span>, and compute the approximation error
for a series of <span class="math">\(h\)</span> and <span class="math">\(d\)</span> values. The theory predicts that the
error should behave as <span class="math">\(h^{d+1}\)</span>. Use experiments to verify this
asymptotic behavior (i.e., for small enough <span class="math">\(h\)</span>).
Filename: <tt class="docutils literal"><span class="pre">Asinwt_interpolation_error.py</span></tt>.</p>
</div>
<div class="section" id="exercise-14-approximate-a-step-function-by-finite-elements">
<span id="fem-approx-fe-exer-heaviside"></span><h2>Exercise 14: Approximate a step function by finite elements<a class="headerlink" href="#exercise-14-approximate-a-step-function-by-finite-elements" title="Permalink to this headline">¶</a></h2>
<p>Approximate the step function</p>
<div class="math">
\[\begin{split}f(x) = \left\lbrace\begin{array}{ll}
1 &amp; x &lt; {1/2},\\
2 &amp; x \geq {1/2}
\end{array}\right.\end{split}\]</div>
<p>by 2, 4, and 8 P1 and P2 elements. Compare
approximations visually.
Filename: <tt class="docutils literal"><span class="pre">`Heaviside_approx_P1P2.py</span></tt>.`.</p>
<p><em>Hint.</em> This <span class="math">\(f\)</span> can also be expressed in terms of the Heaviside function <span class="math">\(H(x)\)</span>:
<span class="math">\(f(x) = H(x-{1/2})\)</span>.
Therefore, <span class="math">\(f\)</span> can be defined by <tt class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">sm.Heaviside(x</span> <span class="pre">-</span>&nbsp; <span class="pre">sm.Rational(1,2))</span></tt>,
making the <tt class="docutils literal"><span class="pre">approximate</span></tt> function in the
<tt class="docutils literal"><span class="pre">fe_approx1D.py</span></tt> module an obvious candidate to solve the
problem. However, <tt class="docutils literal"><span class="pre">sympy</span></tt> does not handle symbolic integration
with this particular integrand, and the <tt class="docutils literal"><span class="pre">approximate</span></tt> function faces a problem
when converting <tt class="docutils literal"><span class="pre">f</span></tt> to a Python function (for plotting) since
<tt class="docutils literal"><span class="pre">Heaviside</span></tt> is not an available function in <tt class="docutils literal"><span class="pre">numpy</span></tt>. It is better to make
special-purpose code for this case or perform all
caluclations by hand.</p>
</div>
<div class="section" id="exercise-15-2d-approximation-with-orthogonal-functions">
<span id="fem-approx-fe-exer-2dsines-symbolic"></span><h2>Exercise 15: 2D approximation with orthogonal functions<a class="headerlink" href="#exercise-15-2d-approximation-with-orthogonal-functions" title="Permalink to this headline">¶</a></h2>
<p>Assume we have basis functions <span class="math">\(\varphi_i(x,y)\)</span> in 2D that are
orthogonal
such that <span class="math">\((\varphi_i,\varphi_j)=0\)</span> when <span class="math">\(i\neq j\)</span>.
The function <tt class="docutils literal"><span class="pre">least_squares</span></tt> in the
file <a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/fe_approx2D.py">approx2D.py</a> will then spend much time on computing off-diagonal terms
in the coefficient matrix that we know are zero.
To speed up the computations, make a
version <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> that utilizes the orthogonality among the
basis functions. Apply the function to approximate</p>
<div class="math">
\[f(x,y) = x(1-x)y(1-y)e^{-x-y}\]</div>
<p>on <span class="math">\(\Omega = [0,1]\times [0,1]\)</span> via basis functions</p>
<div class="math">
\[\varphi_i(x,y) = \sin (p\pi x)\sin(q\pi y),\quad i=q N_x + p
\thinspace .\]</div>
<p>Filename: <tt class="docutils literal"><span class="pre">approx2D_lsorth_sin.py</span></tt>.</p>
<p><em>Hint.</em> Get ideas from the function <tt class="docutils literal"><span class="pre">least_squares_orth</span></tt> in
the section <a class="reference internal" href="#fem-approx-global-orth"><em>Orthogonal basis functions</em></a> and
file <a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/fe_approx1D.py">approx1D.py</a>.</p>
</div>
<div class="section" id="exercise-16-use-the-trapezoidal-rule-and-p1-elements">
<span id="fem-approx-fe-exer-1d-trapez"></span><h2>Exercise 16: Use the Trapezoidal rule and P1 elements<a class="headerlink" href="#exercise-16-use-the-trapezoidal-rule-and-p1-elements" title="Permalink to this headline">¶</a></h2>
<p>Consider approximation of some <span class="math">\(f(x)\)</span> on an interval <span class="math">\(\Omega\)</span> using
the least squares or Galerkin methods with P1 elements. Derive
the element matrix and vector using the
Trapezoidal rule <a href="#equation-fem:approx:fe:numint1:trapez">(28)</a> for calculating
integrals on the reference element. Assemble the contributions, assuming
a uniform cell partitioning, and show that the resulting linear system
has the form <span class="math">\(c_i=f(x_{i})\)</span> for <span class="math">\(i=0,\ldots,N\)</span>.
Filename: <tt class="docutils literal"><span class="pre">fe_trapez.pdf</span></tt>.</p>
</div>
</div>
<div class="section" id="basic-principles-for-approximating-differential-equations">
<span id="fem-deq-1d-principles"></span><h1>Basic principles for approximating differential equations<a class="headerlink" href="#basic-principles-for-approximating-differential-equations" title="Permalink to this headline">¶</a></h1>
<p>The finite element method is a very flexible approach for solving partial
differential equations. Its two most attractive features are the ease
of handling domains of complex shape in two and three dimensions and
the ease of constructing higher-order discretization methods. The
finite element method is usually applied for discretization in space,
and therefore spatial problems will be our focus in the coming sections.
Extensions to time-dependent problems may, for instance, use finite difference
approximations in time.</p>
<p>Before studying how finite element methods are used to tackle differential
equation, we first look at how global basis functions and the
least squares, Galerkin, and collocation principles can be used to solve
differential equations.</p>
<div class="section" id="differential-equation-models">
<span id="fem-deq-1d-models"></span><h2>Differential equation models<a class="headerlink" href="#differential-equation-models" title="Permalink to this headline">¶</a></h2>
<p>Let us consider an abstract differential equation for a function <span class="math">\(u(x)\)</span> of
one variable, written as</p>
<div class="math">
\[{\cal L}(u) = 0,\quad x\in\Omega\thinspace .\]</div>
<p>Here are a few examples on possible choices of <span class="math">\({\cal L}(u)\)</span>, of
increasing complexity:</p>
<div class="math">
\[\begin{split}{\cal L}(u) &amp;= \frac{d^2u}{dx^2} - f(x),
\\
{\cal L}(u) &amp;= \frac{d}{dx}\left(a(x)\frac{du}{dx}\right) + f(x),
\\
{\cal L}(u) &amp;= \frac{d}{dx}\left(a(u)\frac{du}{dx}\right) - \alpha u + f(x),
\\
{\cal L}(u) &amp;= \frac{d}{dx}\left(a(u)\frac{du}{dx}\right) + f(u,x)\end{split}\]\[\thinspace .\]</div>
<p>Both <span class="math">\(a(x)\)</span> and <span class="math">\(f(x)\)</span> are considered as specified functions,
while <span class="math">\(\alpha\)</span> is a prescribed parameter.  Differential equations
corresponding to (<em class="xref std std-ref">fem:deq:1D:L1</em>)-(<em class="xref std std-ref">fem:deq:1D:L2</em>) arise in
diffusion phenomena, such as steady transport of heat in solids and
flow of viscous fluids between flat plates. The form
(<em class="xref std std-ref">fem:deq:1D:L3</em>) arises when transient diffusion or wave
phenomenon are discretized in time by finite differences. The equation
(<em class="xref std std-ref">fem:deq:1D:L4</em>) appear in chemical models when diffusion of a
substance is combined with chemical reactions. Also in biology,
(<em class="xref std std-ref">fem:deq:1D:L4</em>) plays an important role, both for spreading of
species and in models involving generation and
propagation of electrical signals.</p>
<p>Let <span class="math">\(\Omega =[0,L]\)</span> be the domain in one space dimension.
In addition to the differential equation, <span class="math">\(u\)</span> must fulfill
boundary conditions at the boundaries of the domain, <span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span>.
When <span class="math">\({\cal L}\)</span> contains up to second-order derivatives, as in the
examples above, <span class="math">\(m=1\)</span>, we need one boundary condition at each of
the (two) boundary points, here abstractly specified as</p>
<div class="math">
\[{\cal B}_0(u)=0,\ x=0,\quad {\cal B}_1(u)=0,\ x=L\]</div>
<p>There are three common choices of boundary conditions:</p>
<div class="math">
\[\begin{split}{\cal B}_i(u) &amp;= u - g,\quad \hbox{(Dirichlet condition)},\\
{\cal B}_i(u) &amp;= -a \frac{du}{dx} - g,\quad \hbox{(Neumann condition)},\\
{\cal B}_i(u) &amp;= -a \frac{du}{dx} - a(u-g),\quad \hbox{(Robin condition)}
\thinspace .\end{split}\]</div>
<p>Here, <span class="math">\(g\)</span> and <span class="math">\(a\)</span> are specified quantities.</p>
<p>From now on we shall use <span class="math">\(u_{\small\mbox{e}}(x)\)</span> as symbol for the <em>exact</em> solution,
fulfilling</p>
<div class="math">
\[{\cal L}(u_{\small\mbox{e}})=0,\quad x\in\Omega,\]</div>
<p>while <span class="math">\(u(x)\)</span> denotes an <em>approximate</em> solution of the differential
equation. We must immediately remark that
in the literature about the finite element method,
is common to use <span class="math">\(u\)</span> as the exact solution and <span class="math">\(u_h\)</span> as the
approximate solution, where <span class="math">\(h\)</span> is a discretization parameter. However,
the vast part of the present text is about the approximate solutions,
and having a subscript <span class="math">\(h\)</span> attached all the time
is cumbersome. Of equal importance is the close correspondence between
implementation and mathematics that we strive to achieve in this book:
when it is natural to use <tt class="docutils literal"><span class="pre">u</span></tt> and not <tt class="docutils literal"><span class="pre">u_h</span></tt> in
code, we let the mathematical notation be dictated by the code&#8217;s
preferred notation. After all, it is the powerful computer implementations
of the finite element method that justifies studying the mathematical
formulation and aspects of the method.</p>
<p>A common model problem used much in the forthcoming examples is</p>
<div class="math" id="equation-fem:deq:1D:model1">
<span class="eqno">(32)</span>\[     -u''(x) = f(x),\quad x\in\Omega=[0,L],\quad u(0)=0,\ u(L)=D
     \thinspace .\]</div>
<p>The specific choice of <span class="math">\(f(x)=2\)</span> gives the solution</p>
<div class="math">
\[u_{\small\mbox{e}}(x) = x(\frac{D}{L}+L-x)
\thinspace .\]</div>
<p>A closely related problem with a different boundary condition at
<span class="math">\(x=0\)</span> reads</p>
<div class="math" id="equation-fem:deq:1D:model2">
<span class="eqno">(33)</span>\[     -u''(x) = f(x),\quad x\in\Omega=[0,L],\quad u'(0)=C,\ u(L)=D\thinspace .\]</div>
<p>A third variant has a variable coefficient,</p>
<div class="math" id="equation-fem:deq:1D:model3">
<span class="eqno">(34)</span>\[     -(a(x)u'(x))' = f(x),\quad x\in\Omega=[0,L],\quad u'(0)=C,\ u(L)=D\thinspace .\]</div>
</div>
<div class="section" id="residual-minimizing-principles">
<span id="fem-deq-1d-residual-min"></span><h2>Residual-minimizing principles<a class="headerlink" href="#residual-minimizing-principles" title="Permalink to this headline">¶</a></h2>
<p>The fundamental idea is to seek an approximate solution
<span class="math">\(u\)</span> in some space <span class="math">\(V\)</span> with basis</p>
<div class="math">
\[\{ \varphi_0(x),\ldots,\varphi_N(x)\},\]</div>
<p>which means that <span class="math">\(u\)</span> can always be expressed as</p>
<div class="math">
\[u(x) = \sum_{j=0}^N c_j\varphi_j(x),\]</div>
<p>for some unknown coefficients <span class="math">\(c_0,\ldots,c_N\)</span>.
(Later, in the section <a class="reference internal" href="#fem-deq-1d-essbc"><em>Boundary conditions: specified value</em></a>, we will see that if we specify boundary values of <span class="math">\(u\)</span> different
from zero, we must look for an approximate solution
<span class="math">\(u(x) = B(x) + \sum_{j=0}^N c_j\varphi_j(x)\)</span>,
where <span class="math">\(\sum_{j}c_j\varphi_j\in V\)</span> and <span class="math">\(B(x)\)</span> is some function for
incorporating the right boundary values. Because of <span class="math">\(B(x)\)</span>, <span class="math">\(u\)</span> will not
necessarily lie in <span class="math">\(V\)</span>. This modification does not imply any difficulties.)
As in
the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a>, we need principles for deriving <span class="math">\(N+1\)</span> equations to determine the
<span class="math">\(N+1\)</span> unknowns <span class="math">\(c_0,\ldots,c_N\)</span>.
A key idea of the section <a class="reference internal" href="#fem-approx-global"><em>Approximation of functions</em></a> was to minimize the
approximation error <span class="math">\(e=u-f\)</span>. That principle is not so useful here since
the approximation error <span class="math">\(e=u_{\small\mbox{e}} - u\)</span> is unknown to us when <span class="math">\(u_{\small\mbox{e}}\)</span> is
unknown. The only general indicator we have on the quality of the approximate
solution is to what degree <span class="math">\(u\)</span> fulfills the differential equation.
Inserting <span class="math">\(u=\sum_j c_j \varphi_j\)</span> into <span class="math">\({\cal L}(u)\)</span> reveals that the
result is not zero, because <span class="math">\(u\)</span> is only likely to equal <span class="math">\(u_{\small\mbox{e}}\)</span>.
The nonzero result,</p>
<div class="math" id="index-55">
\[R = {\cal L}(u) = {\cal L}(\sum_j c_j \varphi_j),\]</div>
<p>is called the <em>residual</em> and measures the
error in fulfilling the governing equation.
Various principles for determining <span class="math">\(c_0,\ldots,c_N\)</span> try to minimize
<span class="math">\(R\)</span> in some sense. Note that <span class="math">\(R\)</span> varies with <span class="math">\(x\)</span> and
the <span class="math">\(c_0,\ldots,c_N\)</span> parameters. We may write this dependence
explicitly as</p>
<div class="math">
\[R = R(x; c_0,\ldots,c_N)\thinspace .\]</div>
<div class="section" id="the-least-squares-method-4">
<h3>The least squares method  (4)<a class="headerlink" href="#the-least-squares-method-4" title="Permalink to this headline">¶</a></h3>
<p>The least-squares method aims to find <span class="math">\(c_0,\ldots,c_N\)</span> so that
the integrated square of the residual,</p>
<div class="math">
\[\int_{\Omega} R^2 dx\]</div>
<p>is minimized. By introducing
an inner product of two functions <span class="math">\(f\)</span> and <span class="math">\(g\)</span>
on <span class="math">\(\Omega\)</span> as</p>
<div class="math">
\[(f,g) = \int_{\Omega} f(x)g(x) dx,\]</div>
<p>the least-squares method can be defined as</p>
<div class="math">
\[\min_{c_0,\ldots,c_N} E = (R,R)\thinspace .\]</div>
<p>Differentiating with respect to the free parameters <span class="math">\(c_0,\ldots,c_N\)</span>
gives the <span class="math">\(N+1\)</span> equations</p>
<div class="math" id="equation-fem:deq:1D:LS:eq1">
<span class="eqno">(35)</span>\[     \int_{\Omega} 2R\frac{\partial R}{\partial c_i} dx = 0\quad
     \Leftrightarrow\quad (R,\frac{\partial R}{\partial c_i})=0,\quad
     i=0,\ldots,N\thinspace .\]</div>
</div>
<div class="section" id="the-galerkin-method-1">
<h3>The Galerkin method  (1)<a class="headerlink" href="#the-galerkin-method-1" title="Permalink to this headline">¶</a></h3>
<p>The least-squares
principle is equivalent to demanding the error to be orthogonal to
the space <span class="math">\(V\)</span> when approximating a function <span class="math">\(f\)</span> by <span class="math">\(u\in V\)</span>.
With a differential equation
we do not know the true error so we must instead require the residual <span class="math">\(R\)</span>
to be orthogonal to <span class="math">\(V\)</span>. This idea implies
seeking <span class="math">\(c_0,\ldots,c_N\)</span> such that</p>
<div class="math" id="equation-fem:deq:1D:Galerkin0">
<span class="eqno">(36)</span>\[     (R,v)=0,\quad \forall v\in V\thinspace .\]</div>
<p>This is the Galerkin method for differential equations.
As shown in
<a href="#equation-fem:approx:vec:Np1dim:Galerkin">(9)</a> and
<a href="#equation-fem:approx:vec:Np1dim:Galerkin0">(10)</a>,
this statement is equivalent to <span class="math">\(R\)</span> being orthogonal to the <span class="math">\(N+1\)</span>
basis functions only:</p>
<div class="math" id="equation-fem:deq:1D:Galerkin">
<span class="eqno">(37)</span>\[     (R,\varphi_i)=0,\quad i=0,\ldots,N,\]</div>
<p>resulting in <span class="math">\(N+1\)</span> equations for determining <span class="math">\(c_0,\ldots,c_N\)</span>.</p>
</div>
<div class="section" id="the-method-of-weighted-residuals">
<h3>The Method of Weighted Residuals<a class="headerlink" href="#the-method-of-weighted-residuals" title="Permalink to this headline">¶</a></h3>
<p>A generalization of the Galerkin method is to demand that <span class="math">\(R\)</span>
is orthogonal to some space <span class="math">\(W\)</span>, but not necessarily the same
space as <span class="math">\(V\)</span> where we seek the unknown function.
This generalization is naturally called the <em>method of weighted residuals</em>:</p>
<div class="math" id="equation-fem:deq:1D:WRM0">
<span class="eqno">(38)</span>\[     (R,v)=0,\quad \forall v\in W\thinspace .\]</div>
<p>If <span class="math">\(\{w_0,\ldots,w_N\}\)</span> is a basis for <span class="math">\(W\)</span>, we can equivalently
express the method of weighted residuals as</p>
<div class="math" id="equation-fem:deq:1D:WRM">
<span class="eqno">(39)</span>\[     (R,w_i)=0,\quad i=0,\ldots,N\thinspace .\]</div>
<p>The result is <span class="math">\(N+1\)</span> equations for <span class="math">\(c_0,\ldots,c_N\)</span>.</p>
<p>The least-squares method can also be viewed as a weighted residual
method with <span class="math">\(w_i = \partial R/\partial c_i\)</span>.</p>
</div>
<div class="section" id="variational-formulation">
<span id="index-56"></span><h3>Variational Formulation<a class="headerlink" href="#variational-formulation" title="Permalink to this headline">¶</a></h3>
<p>Formulations like <a href="#equation-fem:deq:1D:WRM0">(38)</a> (or
<a href="#equation-fem:deq:1D:WRM">(39)</a>) and <a href="#equation-fem:deq:1D:Galerkin0">(36)</a>
(or <a href="#equation-fem:deq:1D:Galerkin">(37)</a>) are known as
<em>variational formulations</em>.
These equations are in this text primarily used for a numerical approximation
<span class="math">\(u\in V\)</span>, where <span class="math">\(V\)</span> is a <em>finite-dimensional</em> space with dimension
<span class="math">\(N+1\)</span>. However, we may also let <span class="math">\(V\)</span> be an <em>infinite-dimensional</em> space
containing the exact solution <span class="math">\(u_{\small\mbox{e}}(x)\)</span> such that also <span class="math">\(u_{\small\mbox{e}}\)</span>
fulfills a variational formulation. The variational formulation is in
that case a mathematical way of stating the problem and acts as an
alternative to the usual formulation of a differential equation with
initial and/or boundary conditions.</p>
<span class="target" id="index-57"></span><span class="target" id="index-58"></span><span class="target" id="index-59"></span></div>
<div class="section" id="test-and-trial-functions">
<span id="index-60"></span><h3>Test and Trial Functions<a class="headerlink" href="#test-and-trial-functions" title="Permalink to this headline">¶</a></h3>
<p>In the context of the Galerkin method and the method of weighted residuals it is
common to use the name <em>trial function</em> for the approximate <span class="math">\(u =
\sum_j c_j \varphi_j\)</span>.
.. Sometimes the functions that spans the space where <span class="math">\(u\)</span> lies are also called</p>
<p>The space containing the trial function is known as the <em>trial space</em>.
The function <span class="math">\(v\)</span> entering the orthogonality requirement in
the Galerkin method and the method of weighted residuals is called
<em>test function</em>, and so are the <span class="math">\(\varphi_i\)</span> or <span class="math">\(w_i\)</span> functions that are
used as weights in the inner products with the residual.  The space
where the test functions comes from is naturally called the
<em>test space</em>.</p>
<p>We see that in the method of weighted residuals the test and trial spaces
are different and so are the test and trial functions.
In the Galerkin method the test and trial spaces are the same (so far).
Later in the section <a class="reference internal" href="#fem-deq-1d-essbc"><em>Boundary conditions: specified value</em></a> we shall see that boundary
conditions may lead to a difference between the test and trial spaces
in the Galerkin method.</p>
<p><em>Remark.</em> It may be subject to debate whether
it is only the form of <a href="#equation-fem:deq:1D:WRM0">(38)</a> or <a href="#equation-fem:deq:1D:Galerkin0">(36)</a>
after integration by parts, as explained in the section <a class="reference internal" href="#fem-deq-1d-varform"><em>Integration by parts</em></a>,
that qualifies for the term variational formulation. The result after
integration by parts is what is obtained after taking the <em>first
variation</em> of an optimization problem, see the section <a class="reference internal" href="#fem-deq-1d-optimization"><em>Variational problems and optimization of functionals</em></a>. However, here we use variational formulation as a common term for
formulations which, in contrast to the differential equation <span class="math">\(R=0\)</span>,
instead demand that an average of <span class="math">\(R\)</span> is zero: <span class="math">\((R,v)=0\)</span> for all <span class="math">\(v\)</span> in some space.</p>
</div>
<div class="section" id="the-collocation-method-1">
<h3>The collocation method  (1)<a class="headerlink" href="#the-collocation-method-1" title="Permalink to this headline">¶</a></h3>
<p>The idea of the collocation method is to demand that <span class="math">\(R\)</span> vanishes
at <span class="math">\(N+1\)</span> selected points <span class="math">\(x_{0},\ldots,x_{N}\)</span> in <span class="math">\(\Omega\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:collocation">
<span class="eqno">(40)</span>\[     R(x_{i}; c_0,\ldots,c_N)=0,\quad i=0,\ldots,N\thinspace .\]</div>
<p>The collocation method can also be viewed as a method of weighted residuals
with Dirac delta functions as weighting functions.
Let <span class="math">\(\delta (x-x_{i})\)</span> be the Dirac delta function centered around
<span class="math">\(x=x_{i}\)</span> with the properties that <span class="math">\(\delta (x-x_{i})=0\)</span> for <span class="math">\(x\neq x_{i}\)</span>
and</p>
<div class="math" id="equation-fem:deq:1D:Dirac">
<span class="eqno">(41)</span>\[     \int_{\Omega} f(x)\delta (x-x_{i}) dx = f(x_{i}),\quad x_{i}\in\Omega\thinspace .\]</div>
<p>Intuitively, we may think of <span class="math">\(\delta (x-x_{i})\)</span> as a very peak-shaped
function around <span class="math">\(x=x_{i}\)</span> with integral 1, roughly visualized
in Figure <a class="reference internal" href="#fem-deq-1d-fig-dirac"><em>Approximation of delta functions by narrow Gaussian functions</em></a>.
Because of <a href="#equation-fem:deq:1D:Dirac">(41)</a>, we can let <span class="math">\(w_i=\delta(x-x_{i})\)</span>
be weighting functions in the method of weighted residuals,
and <a href="#equation-fem:deq:1D:WRM">(39)</a> becomes equivalent to
<a href="#equation-fem:deq:1D:collocation">(40)</a>.</p>
<div class="figure" id="fem-deq-1d-fig-dirac">
<img alt="_images/delta_func_weight.png" src="_images/delta_func_weight.png" style="width: 400px;" />
<p class="caption"><em>Approximation of delta functions by narrow Gaussian functions</em></p>
</div>
</div>
<div class="section" id="the-subdomain-collocation-method">
<h3>The subdomain collocation method<a class="headerlink" href="#the-subdomain-collocation-method" title="Permalink to this headline">¶</a></h3>
<p>The idea of this approach is to demand the integral of <span class="math">\(R\)</span> to vanish
over <span class="math">\(N+1\)</span> subdomains <span class="math">\(\Omega_i\)</span> of <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[\int_{\Omega_i} R\, dx=0,\quad i=0,\ldots,N\thinspace .\]</div>
<p>This statement can also be expressed as a weighted residual method</p>
<div class="math">
\[\int_{\Omega} Rw_i\, dx=0,\quad i=0,\ldots,N,\]</div>
<p>where <span class="math">\(w_i=1\)</span> for <span class="math">\(x\in\Omega_i\)</span> and <span class="math">\(w_i=0\)</span> otherwise.</p>
</div>
</div>
<div class="section" id="examples-on-using-the-principles">
<span id="fem-deq-1d-ex-sines"></span><h2>Examples on using the principles<a class="headerlink" href="#examples-on-using-the-principles" title="Permalink to this headline">¶</a></h2>
<p>Let us now apply global basis functions to illustrate the principles
for minimizing <span class="math">\(R\)</span>. Our choice of basis functions <span class="math">\(\varphi_i\)</span>
for <span class="math">\(V\)</span> is</p>
<div class="math" id="equation-fem:deq:1D:ex:sines:phi">
<span class="eqno">(42)</span>\[     \varphi_i(x) = \sin\left((i+1)\pi\frac{x}{L}\right),\quad i=0,\ldots,N\thinspace .\]</div>
<p>The following property of these functions becomes useful in the
forthcoming calculations:</p>
<div class="math">
\[\begin{split}\int\limits_0^L \sin\left((i+1)\pi\frac{x}{L}\right)\sin\left((j+1)\pi\frac{x}{L}\right)\, dx = \left\lbrace
\begin{array}{ll} \frac{1}{2} L &amp; i=j  \\ 0, &amp; i\neq j
\end{array}\right.\end{split}\]</div>
<p>provided <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are integers.</p>
<p>We address the model problem <a href="#equation-fem:deq:1D:model1">(32)</a>. One immediate
difficulty is that with the above choice of basis functions,
<span class="math">\(u(1)=\sum_j c_j \sin((i+1)\pi)=0\)</span> regardless of the coefficients
<span class="math">\(c_0,\ldots,c_N\)</span>. We therefore set <span class="math">\(u(L)=D=0\)</span> so that <span class="math">\(u(x)\)</span> fulfills the
boundary conditions <span class="math">\(u(0)=u(L)=0\)</span>. Later, in
the section <a class="reference internal" href="#fem-deq-1d-essbc"><em>Boundary conditions: specified value</em></a>, we shall see how we can deal with the
condition <span class="math">\(u(L)=D\neq 0\)</span>.</p>
<div class="section" id="the-residual">
<h3>The residual<a class="headerlink" href="#the-residual" title="Permalink to this headline">¶</a></h3>
<p>We can readily calculate the following explicit expression for the
residual:</p>
<div class="math" id="equation-fem:deq:1D:ex:sines:res">
<span class="eqno">(43)</span>\[\begin{split}     R(x;c_0,\ldots,c_N) &amp;= u''(x) + f(x),\nonumber\\
     &amp;= \frac{d^2}{dx^2}\left(\sum_{j=0}^N c_j\varphi_j(x)\right)
     + f(x),\nonumber\\
     &amp;= -\sum_{j=0}^N c_j\varphi_j''(x) + f(x)\thinspace .\end{split}\]</div>
</div>
<div class="section" id="the-least-squares-method-5">
<h3>The least squares method  (5)<a class="headerlink" href="#the-least-squares-method-5" title="Permalink to this headline">¶</a></h3>
<p>The equations <a href="#equation-fem:deq:1D:LS:eq1">(35)</a>
in the least squares method require an expression for
<span class="math">\(\partial R/\partial c_i\)</span>. We have</p>
<div class="math">
\[\frac{\partial R}{\partial c_i} =
\frac{\partial}{\partial c_i}
\left(\sum_{j=0}^N c_j\varphi_j''(x) + f(x)\right)
= \varphi_i''(x)\thinspace .\]</div>
<p>The governing equations for <span class="math">\(c_0,\ldots,c_N\)</span> are then</p>
<div class="math">
\[(\sum_j c_j \varphi_j'' + f,\varphi_i'')=0,\quad i=0,\ldots,N,\]</div>
<p>which can be rearranged as</p>
<div class="math">
\[\sum_{j=0}^N(\varphi_i'',\varphi_j'')c_j = -(f,\varphi_i''),\quad i=0,\ldots,N\thinspace .\]</div>
<p>This is nothing but a linear system</p>
<div class="math">
\[\sum_{j=0}^NA_{i,j}c_j = b_i,\quad i=0,\ldots,N,\]</div>
<p>with</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= (\varphi_i'',\varphi_j'')\nonumber\\
&amp; = \pi^4(i+1)^2(j+1)^2L^{-4}\int_0^L \sin\left((i+1)\pi\frac{x}{L}\right)\sin\left((j+1)\pi\frac{x}{L}\right)\, dx\nonumber\\
&amp;= \left\lbrace
\begin{array}{ll} {1\over2}L^{-3}\pi^4(i+1)^4 &amp; i=j  \\ 0, &amp; i\neq j
\end{array}\right.
\\
b_i &amp;= -(f,\varphi_i'') = (i+1)^2\pi^2L^{-2}\int_0^Lf(x)\sin\left((i+1)\pi\frac{x}{L}\right)\, dx\end{split}\]</div>
<p>Since the coefficient matrix is diagonal we can easily solve for</p>
<div class="math" id="equation-fem:deq:1D:ex:sines:solution">
<span class="eqno">(44)</span>\[     c_i = \frac{2L}{\pi^2(i+1)^2}\int_0^Lf(x)\sin\left((i+1)\pi\frac{x}{L}\right)\, dx\thinspace .\]</div>
<p>With the special choice of <span class="math">\(f(x)=2\)</span> the integral becomes</p>
<div class="math">
\[\frac{L\cos(\pi i) + L}{\pi (i+1)},\]</div>
<p>according to <a class="reference external" href="http://wolframalpha.com">WolframAlpha</a>
(use <tt class="docutils literal"><span class="pre">j</span></tt> and not <tt class="docutils literal"><span class="pre">i</span></tt>, which means <span class="math">\(=\sqrt{-1}\)</span>,
when asking). Hence,</p>
<div class="math">
\[c_i = \frac{4L^2(1+(-1)^i)}{\pi^3(i+1)^3}\thinspace .\]</div>
<p>Now, <span class="math">\(1+(-1)^i=0\)</span> for <span class="math">\(i\)</span> odd, so only the coefficients with even index
are nonzero. Introducing <span class="math">\(i=2k\)</span> for <span class="math">\(k=0,\ldots,N/2\)</span> to count the
relevant indices, we get the solution</p>
<div class="math">
\[u(x) = \sum_{k=0}^{N/2} \frac{8L^2}{\pi^3(2k+1)^3}\sin\left((2k+1)\pi\frac{x}{L}\right)\thinspace .\]</div>
<p>The coefficients decay very fast: <span class="math">\(c_2 = c_0/27\)</span>, <span class="math">\(c_4=c_0/125\)</span>.
The solution will therefore be dominated by the first term,</p>
<div class="math">
\[u(x) \approx \frac{8L^2}{\pi^3}\sin\left(\pi\frac{x}{L}\right)\thinspace .\]</div>
</div>
<div class="section" id="the-galerkin-method-2">
<h3>The Galerkin method  (2)<a class="headerlink" href="#the-galerkin-method-2" title="Permalink to this headline">¶</a></h3>
<p>The Galerkin principle <a href="#equation-fem:deq:1D:Galerkin0">(36)</a>
applied to <a href="#equation-fem:deq:1D:model1">(32)</a> consists of inserting
our special residual <a href="#equation-fem:deq:1D:ex:sines:res">(43)</a> in
<a href="#equation-fem:deq:1D:Galerkin0">(36)</a></p>
<div class="math">
\[(u''+f,v)=0,\quad \forall v\in V,\]</div>
<p>or</p>
<div class="math">
\[(u'',v) = -(f,v),\quad\forall v\in V\thinspace .\]</div>
<p>This is the variational formulation, based on the Galerkin principle,
of our differential equation.
The <span class="math">\(\forall v\in V\)</span> requirement is equivalent to
demanding the equation <span class="math">\((u'',v) = -(f,v)\)</span> to be fulfilled for all
basis functions <span class="math">\(v=\varphi_i\)</span>, <span class="math">\(i=0,\ldots,N\)</span> (cf.
<a href="#equation-fem:deq:1D:Galerkin0">(36)</a> and <a href="#equation-fem:deq:1D:Galerkin">(37)</a>).
This gives</p>
<div class="math">
\[(\sum_{j=0}^N c_j\varphi_j'', \varphi_i)=-(f,\varphi_i),\quad i=0,\ldots,N\thinspace .\]</div>
<p>This equation can be rearranged to a form that explicitly shows
that we get a linear system for the unknowns <span class="math">\(c_0,=\ldots,c_N\)</span>:</p>
<div class="math">
\[\sum_{j=0}^N (\varphi_i,\varphi_j'')c_j = (f, \varphi_i),\quad i=0,\ldots,N\thinspace .\]</div>
<p>For the particular choice of the basis functions <a href="#equation-fem:deq:1D:ex:sines:phi">(42)</a>
we get in fact the same linear system
as in the least squares method
(because <span class="math">\(\varphi''= -(i+1)^2\pi^2L^{-2}\varphi\)</span>).</p>
</div>
<div class="section" id="the-collocation-method-2">
<h3>The collocation method  (2)<a class="headerlink" href="#the-collocation-method-2" title="Permalink to this headline">¶</a></h3>
<p>For the collocation method <a href="#equation-fem:deq:1D:collocation">(40)</a> we need to
decide upon a set of <span class="math">\(N+1\)</span> collocation points in <span class="math">\(\Omega\)</span>. A simple
choice is to use uniformly spaced points: <span class="math">\(x_{i}=i\Delta x\)</span>, where
<span class="math">\(\Delta x = L/N\)</span> in our case (<span class="math">\(N\geq 1\)</span>). However, these points
lead to at least two rows in the matrix consisting of zeros
(since <span class="math">\(\varphi_i(x_{0})=0\)</span> and <span class="math">\(\varphi_i(x_{N})=0\)</span>), thereby making the matrix
singular and non-invertible. This forces us to choose some other
collocation points, e.g., random points or points uniformly distributed
in the interior of <span class="math">\(\Omega\)</span>.
Demanding the residual to vanish
at these points leads, in our model problem <a href="#equation-fem:deq:1D:model1">(32)</a>, to
the equations</p>
<div class="math">
\[-\sum_{j=0}^N c_j\varphi_j''(x_{i}) = f(x_{i}),\quad i=0,\ldots,N,\]</div>
<p>which is seen to be a linear system with entries</p>
<div class="math">
\[A_{i,j}=-\varphi_j''(x_{i})=
(j+1)^2\pi^2L^{-2}\sin\left((j+1)\pi \frac{x_i}{L}\right),\]</div>
<p>in the coefficient matrix and entries
<span class="math">\(b_i=2\)</span> for the right-hand side (when <span class="math">\(f(x)=2\)</span>).</p>
<p>The special case of <span class="math">\(N=0\)</span>
can sometimes be of interest. A natural choice is then the midpoint
<span class="math">\(x_{0}=L/2\)</span> of the domain, resulting in
<span class="math">\(A_{0,0} = -\varphi_0''(x_{0}) = \pi^2L^{-2}\)</span>, <span class="math">\(f(x_0)=2\)</span>,
and hence <span class="math">\(c_0=2L^2/\pi^2\)</span>.</p>
</div>
<div class="section" id="comparison">
<h3>Comparison<a class="headerlink" href="#comparison" title="Permalink to this headline">¶</a></h3>
<p>In the present model problem, with <span class="math">\(f(x)=2\)</span>, the exact solution is
<span class="math">\(u(x)=x(L-x)\)</span>, while for <span class="math">\(N=0\)</span> the Galerkin and least squares method
result in <span class="math">\(u(x)=8L^2\pi^{-3}\sin (\pi x/L)\)</span> and the
collocation method leads to <span class="math">\(u(x)=2L^2\pi^{-2}\sin (\pi x/L)\)</span>.
Since all methods fulfill the boundary conditions <span class="math">\(u(0)=u(L)=0\)</span>, we
expect the largest discrepancy to occur at the midpoint of the domain:
<span class="math">\(x=L/2\)</span>. The error at the midpoint becomes <span class="math">\(-0.008L^2\)</span> for the
Galerkin and least squares method, and <span class="math">\(0.047L^2\)</span> for the collocation
method.</p>
</div>
</div>
<div class="section" id="integration-by-parts">
<span id="fem-deq-1d-varform"></span><h2>Integration by parts<a class="headerlink" href="#integration-by-parts" title="Permalink to this headline">¶</a></h2>
<p id="index-61">A problem arises if we want to use the finite element functions from
the section <a class="reference internal" href="#fem-approx-fe"><em>Finite element basis functions</em></a> to solve our model problem <a href="#equation-fem:deq:1D:model1">(32)</a>
by the least squares, Galerkin, or collocation methods: the piecewise
polynomials <span class="math">\(\varphi_i(x)\)</span> have discontinuous derivatives at the
cell boundaries which makes it problematic to compute
<span class="math">\(\varphi_i''(x)\)</span>.  This fact actually makes the least squares and
collocation methods less suitable for finite element approximation of
the unknown function. (By rewriting the equation <span class="math">\(-u''=f\)</span> as a
system of two first-order equations, <span class="math">\(u'=v\)</span> and <span class="math">\(-v'=f\)</span>, the
least squares method can be applied. Also, differentiating discontinuous
functions can actually be handled by distribution theory in
mathematics.)  The Galerkin method and the method of
weighted residuals can, however, be applied together with finite
element basis functions if we use <em>integration by parts</em>
as a means for transforming a second-order derivative to a first-order
one.</p>
<p>Consider the model problem <a href="#equation-fem:deq:1D:model1">(32)</a> and its
Galerkin formulation</p>
<div class="math">
\[-(u'',v) = (f,v)\quad\forall v\in V\thinspace .\]</div>
<p>Using integration by parts in the Galerkin method,
we can move a derivative on <span class="math">\(u\)</span> to <span class="math">\(v\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:intbyparts">
<span class="eqno">(45)</span>\[\begin{split}     \int_0^L u''(x)v(x) dx &amp;= - \int_0^Lu'(x)v'(x)dx
     + [vu']_0^L\nonumber\\
     &amp;= - \int_0^Lu'(x)v'(x) dx
     + u'(L)v(L) - u'(0)v(0)\thinspace .\end{split}\]</div>
<p>Usually, one integrates the problem at the stage where the <span class="math">\(u\)</span> and <span class="math">\(v\)</span>
functions enter the formulation.
Alternatively, but less common, we can integrate by parts in the expressions for
the matrix entries:</p>
<div class="math" id="equation-fem:deq:1D:intbyparts0">
<span class="eqno">(46)</span>\[\begin{split}     \int_0^L\varphi_i(x)\varphi_j''(x) dx &amp;= - \int_0^L\varphi_i'(x)\varphi_j'(x) dx
     + [\varphi_i\varphi_j']_0^L\nonumber\\
     &amp;= - \int_0^L\varphi_i'(x)\varphi_j'(x) dx
     + \varphi_i(L)\varphi_j'(L) - \varphi_i(0)\varphi_j'(0)\thinspace .\end{split}\]</div>
<p>Integration by parts serves to reduce the order of the derivatives and
to make the coefficient matrix symmetric since
<span class="math">\((\varphi_i',\varphi_j') = (\varphi_i',\varphi_j')\)</span>. The symmetry property depends
on the type of terms that enter the differential equation.
As will be seen later in the section <a class="reference internal" href="#fem-deq-1d-bc-nat"><em>Boundary conditions: specified derivative</em></a>,
integration by parts also provides a method for implementing
boundary conditions involving <span class="math">\(u'\)</span>.</p>
<p>With the choice <a href="#equation-fem:deq:1D:ex:sines:phi">(42)</a> of basis functions we see
that the &#8220;boundary terms&#8221; <span class="math">\(\varphi_i(L)\varphi_j'(L)\)</span> and <span class="math">\(\varphi_i(0)\varphi_j'(0)\)</span>
vanish since <span class="math">\(\varphi_i(0)=\varphi_i(L)=0\)</span>. A boundary term associated with
a location at the boundary where we have Dirichlet conditions will always
vanish because <span class="math">\(\varphi_i=0\)</span> at such locations.</p>
<span class="target" id="index-62"></span><p id="index-63">Since the variational formulation after integration by parts make
weaker demands on the differentiability of <span class="math">\(u\)</span> and the basis
functions <span class="math">\(\varphi_i\)</span>,
the resulting integral formulation is referred to as a <em>weak form</em> of
the differential equation problem. The original variational formulation
with second-order derivatives, or the differential equation problem
with second-order derivative, is then the <em>strong form</em>, with
stronger requirements on the differentiability of the functions.</p>
<p>For differential equations with second-order derivatives, expressed as
variational formulations and solved by finite element methods, we will
always perform integration by parts to arrive at expressions involving
only first-order derivatives.</p>
</div>
<div class="section" id="boundary-function">
<span id="fem-deq-1d-essbc-bfunc"></span><h2>Boundary function<a class="headerlink" href="#boundary-function" title="Permalink to this headline">¶</a></h2>
<p>So far we have assumed zero Dirichlet boundary conditions, typically
<span class="math">\(u(0)=u(L)=0\)</span>, and we have demanded that <span class="math">\(\varphi_i(0)\varphi_i(L)=0\)</span>
for <span class="math">\(i=0,\ldots,N\)</span>. What about a boundary condition like <span class="math">\(u(L)=D\neq0\)</span>?
This condition immediately faces a problem with
<span class="math">\(u=\sum_{j=0}^N c_j \varphi_j\)</span>, because <span class="math">\(u(L)=0\)</span> since all the
basis functions vanish at <span class="math">\(x=L\)</span>.</p>
<p>A boundary condition of the form <span class="math">\(u(L)=D\)</span> can be implemented by
demanding that all <span class="math">\(\varphi_i(L)=0\)</span>, but adding a
<em>boundary function</em> <span class="math">\(B(x)\)</span> with the right boundary value, <span class="math">\(B(L)=D\)</span>, to
the expansion for <span class="math">\(u\)</span>:</p>
<div class="math">
\[u(x) = B(x) + \sum_{j=0}^N c_j\varphi_j(x)
\thinspace .\]</div>
<p>This <span class="math">\(u\)</span> gets the right value at <span class="math">\(x=L\)</span>:</p>
<div class="math">
\[u(L) = B(L) + \sum_{j=0}^N c_j\varphi_j(L) = B(L) = D\thinspace .\]</div>
<p>The idea is that for any boundary where <span class="math">\(u\)</span> is known we demand <span class="math">\(\varphi_i\)</span> to
vanish and construct a function <span class="math">\(B(x)\)</span> to attain the boundary value of <span class="math">\(u\)</span>.
There are no restrictions how <span class="math">\(B(x)\)</span> varies with <span class="math">\(x\)</span> in the interior of the
domain, so this variation needs to be constructed in some way.</p>
<p>For example, with <span class="math">\(u(0)=0\)</span> and
<span class="math">\(u(L)=D\)</span>, we can choose <span class="math">\(B(x)=x D/L\)</span>, since <span class="math">\(B(0)=0\)</span> and <span class="math">\(B(L)=D\)</span>.
The unknown function is then sought on the form</p>
<div class="math" id="equation-fem:deq:1D:essBC:Bfunc:u1">
<span class="eqno">(47)</span>\[     u(x) = \frac{x}{L}D + \sum_{j=0}^N c_j\varphi_j(x),\]</div>
<p>with <span class="math">\(\varphi_i(0)=\varphi_i(L)=0\)</span>.</p>
<p>The <span class="math">\(B(x)\)</span> function can be chosen in many ways as long as its boundary
values are correct. For example, <span class="math">\(B(x)=D(x/L)^p\)</span> for any power <span class="math">\(p\)</span>
will work fine in the above example.
As another example, consider a domain <span class="math">\(\Omega = [a,b]\)</span>
where the boundary conditions are <span class="math">\(u(a)=U_a\)</span> and <span class="math">\(u(b)=U_b\)</span>.  A class
of possible <span class="math">\(B(x)\)</span> functions is</p>
<div class="math">
\[\begin{split}B(x)=U_a + \frac{U_b-U_a}{(b-a)^p}(x-a)^p,\quad p&gt;0
\thinspace .\end{split}\]</div>
<p>To summarize, the procedure goes as follows.
Let <span class="math">\(\partial\Omega_E\)</span> be the part(s) of the boundary
<span class="math">\(\partial\Omega\)</span> of the domain <span class="math">\(\Omega\)</span> where <span class="math">\(u\)</span> is specified.
Set <span class="math">\(\varphi_i=0\)</span> at the points in <span class="math">\(\partial\Omega_E\)</span> and seek <span class="math">\(u\)</span>
as</p>
<div class="math" id="equation-fem:deq:1D:essBC:Bfunc:u2">
<span class="eqno">(48)</span>\[     u(x) = B(x) + \sum_{j=0}^N c_j\varphi_j(x),\]</div>
<p>where <span class="math">\(B(x)\)</span> equals the boundary conditions on <span class="math">\(u\)</span> at <span class="math">\(\partial\Omega_E\)</span>.</p>
<p><em>Remark.</em> With the <span class="math">\(B(x)\)</span> term, <span class="math">\(u\)</span> does not in general lie in <span class="math">\(V=\hbox{span}\,
\{\varphi_0,\ldots,\varphi_N\}\)</span> anymore. Moreover, when a prescribed value
of <span class="math">\(u\)</span> at the boundary, say <span class="math">\(u(a)=U_a\)</span> is different from zero, it does
not make sense to say that <span class="math">\(u\)</span> lies in a vector space, because
this space does not obey the requirements of addition and scalar multiplication.
For example,
<span class="math">\(2u\)</span> does not lie in the space since its boundary value is <span class="math">\(2U_a\)</span>,
which is incorrect. It only makes sense to split <span class="math">\(u\)</span> in two parts,
as done above, and have the unknown part <span class="math">\(\sum_j c_j \varphi_j\)</span> in a
proper function space.
.. Sometimes it is said that <span class="math">\(u\)</span> is in the <em>affine space</em> <span class="math">\(B+V\)</span>.</p>
</div>
<div class="section" id="abstract-notation-for-variational-formulations">
<span id="fem-deq-1d-varform-abstract"></span><h2>Abstract notation for variational formulations<a class="headerlink" href="#abstract-notation-for-variational-formulations" title="Permalink to this headline">¶</a></h2>
<p>We have seen that variational formulations end up with a formula involving
<span class="math">\(u\)</span> and <span class="math">\(v\)</span>, such as <span class="math">\((u',v')\)</span> and a formula involving <span class="math">\(v\)</span> and known
functions, such as <span class="math">\((f,v)\)</span>. A common notation is to introduce an abstract
variational statement written as <span class="math">\(a(u,v)=L(v)\)</span>,
where <span class="math">\(a(u,v)\)</span> is a so-called <em>bilinear form</em> involving all the terms
that contain both the test and trial
function, while <span class="math">\(L(v)\)</span> is a <em>linear form</em> containing all the terms without
the trial function. For example, the statement</p>
<div class="math">
\[\int_{\Omega} u' v'dx = \int_Omega fvdx\quad\hbox{or}\quad (u',v') = (f,v)
\quad\forall v\in V\]</div>
<p>can be written in abstract form: <em>find :math:`u` such that</em></p>
<div class="math">
\[a(u,v) = L(v)\quad \forall v\in V,\]</div>
<p>where we have the definitions</p>
<div class="math">
\[a(u,v) = (u',v'),\quad L(v) = (f,v)\thinspace .\]</div>
<p>The term <em>linear</em> means that <span class="math">\(L(\alpha_1 v_1 + \alpha_2 v_2)
=\alpha_1 L(v_1) + \alpha_2 L(v_2)\)</span> for two test functions <span class="math">\(v_1\)</span> and <span class="math">\(v_2\)</span>, and
scalar parameters <span class="math">\(\alpha_1\)</span> and <span class="math">\(\alpha_2\)</span>. Similarly, the term <em>bilinear</em>
means that <span class="math">\(a(u,v)\)</span> are linear in both its arguments:</p>
<div class="math">
\[a(\alpha_1 u_1 + \alpha_2 u_2, v) = \alpha_1 u(u_1,v) + \alpha_2 a(u_2, v),
\quad
a(u, \alpha_1 v_1 + \alpha_2 v_2) = \alpha_1 u(u,v_1) + \alpha_2 a(u, v_2)
\thinspace .\]</div>
<p>In nonlinear problems these linearity properties do not hold in general
and the abstract notation is then <span class="math">\(F(u;v)=0\)</span>.</p>
<p>The matrix system associated with <span class="math">\(a(u,v)=L(v)\)</span> can also be written in
an abstract form by inserting <span class="math">\(v=\varphi_i\)</span> and <span class="math">\(u=\sum_j c_j\varphi_j\)</span>
in <span class="math">\(a(u,v)=L(v)\)</span>. Using the linear properties, the system becomes</p>
<div class="math">
\[\sum_{j=0}^N a(\varphi_j,\varphi_i) c_j = L(\varphi_i),\quad i=0,\ldots,N
\thinspace .\]</div>
<p>From this we see that the matrix element <span class="math">\(A_{i,j}\)</span> equals
<span class="math">\(a(\varphi_j,\varphi_i)\)</span>. In many problems, <span class="math">\(a(u,v)\)</span> is symmetric so that
<span class="math">\(a(\varphi_j,\varphi_i) = a(\varphi_i,\varphi_j)\)</span>.</p>
<p>The abstract notation <span class="math">\(a(u,v)=L(v)\)</span> for linear problems
is much used in the literature and
in description of finite element software (in particular the
<a class="reference external" href="http://fenicsproject.org">FEniCS</a> documentation). We shall
frequently summarize variational forms using this notation.</p>
</div>
<div class="section" id="more-examples-on-variational-formulations">
<span id="fem-deq-1d-varform-ex"></span><h2>More examples on variational formulations<a class="headerlink" href="#more-examples-on-variational-formulations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="variable-coefficient">
<h3>Variable coefficient<a class="headerlink" href="#variable-coefficient" title="Permalink to this headline">¶</a></h3>
<p>Consider the problem</p>
<div class="math">
\[-\frac{d}{dx}\left( a(x)\frac{du}{dx}\right) = f(x),\quad x\in\Omega =[0,L],\
u(0)=C,\ u(L)=D\thinspace .\]</div>
<p>There are two new features of this problem compared with
previous examples: a variable
coefficient <span class="math">\(a(x)\)</span> and nonzero Dirichlet conditions at both boundary points.</p>
<p>Let us first deal with the boundary conditions. We seek</p>
<div class="math">
\[u(x) = B(x) + \sum_{j=0}^N c_j\varphi_i(x),\]</div>
<p>with <span class="math">\(\varphi_i(0)=\varphi_i(L)=0\)</span> for <span class="math">\(i=0,\ldots,N\)</span>. The function <span class="math">\(B(x)\)</span>
must then fulfill <span class="math">\(B(0)=C\)</span> and <span class="math">\(B(L)=D\)</span>. How <span class="math">\(B\)</span> varies in between
<span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span> is not of importance. One possible choice is</p>
<div class="math">
\[B(x) = xD + (L-x)C
\thinspace .\]</div>
<p>A Galerkin formulation is obtained by inserting the expression for <span class="math">\(u\)</span>
and demanding the residual to be orthogonal to all <span class="math">\(v\in V\)</span>:</p>
<div class="math">
\[(-\frac{d}{dx}\left( a\frac{du}{dx}\right) -f, v) = 0,\quad \forall v\in V,\]</div>
<p>or written with explicit integrals,</p>
<div class="math">
\[\int_{\Omega} \left(\frac{d}{dx}\left( a\frac{du}{dx}\right) -f\right)v dx = 0,\quad \forall v\in V \thinspace .\]</div>
<p>We proceed with integration by parts to lower the derivative from
second to first order:</p>
<div class="math">
\[-\int_{\Omega} \frac{d}{dx}\left( a(x)\frac{du}{dx}\right) vdx
= \int_{\Omega} a(x)\frac{du}{dx}\frac{dv}{dx}dx -
\left[a\frac{du}{dx}v\right]_0^L
\thinspace .\]</div>
<p>Since all functions in <span class="math">\(v\)</span> have the property <span class="math">\(v(0)=v(L)=0\)</span>, the boundary
term vanishes. The variational formulation is then</p>
<div class="math">
\[\int_{\Omega} a(x)\frac{du}{dx}\frac{dv}{dx}dx = \int_{\Omega} f(x)vdx,\quad
\forall v\in V,\]</div>
<p>or using the inner product notation and more compact notation for
derivatives:</p>
<div class="math">
\[(a u',v') = (f,v),\quad \forall v\in V
\thinspace .\]</div>
<p>The corresponding abstract notation reads</p>
<div class="math">
\[a(u,v)=L(v)\quad\forall v\in V,\]</div>
<p>with</p>
<div class="math">
\[a(u,v)= (au',v'),\quad L(v)=(f,v) \thinspace .\]</div>
<p>Note that the <span class="math">\(a\)</span> in the notation <span class="math">\(a(\cdot,\cdot)\)</span> is not to be mixed with the
variable coefficient <span class="math">\(a\)</span> in the differential equation.</p>
<p>We may insert <span class="math">\(u\)</span> and <span class="math">\(v\)</span> expressed by basis functions to derive the
linear system. Insertion gives</p>
<div class="math">
\[(aB' + a\sum_{j=0}^N c_j \varphi_j', \varphi_i) =
(f,\varphi_i), \quad i=0,\ldots,N \thinspace .\]</div>
<p>We then isolate the <span class="math">\(c_j\)</span> coefficients on the left-hand side and move all
known terms to the right-hand side:</p>
<div class="math">
\[\sum_{j=0}^N (a\varphi_j', \varphi_i)c_j  =
(f-(D-C),\varphi_i), \quad i=0,\ldots,N
\thinspace .\]</div>
<p>This equation is recognized as a linear system <span class="math">\(\sum_j A_{i,j}c_j=b_i\)</span>
with</p>
<div class="math">
\[\begin{split}A_{i,j} &amp;= (a\varphi_j', \varphi_i) = \int_{\Omega} a(x)\varphi_j'(x),
\varphi_i(x)dx,\\
b_i &amp;= (f+C-D,\varphi_i) = \int_{\Omega} (f(x) + C- D)\varphi_i(x)dx
\thinspace .\end{split}\]</div>
</div>
<div class="section" id="first-order-derivative-in-the-equation-and-boundary-condition">
<h3>First-order derivative in the equation and boundary condition<a class="headerlink" href="#first-order-derivative-in-the-equation-and-boundary-condition" title="Permalink to this headline">¶</a></h3>
<p>The next problem to formulate in variational form reads</p>
<div class="math">
\[-u''(x) + bu'(x) = f(x),\quad x\in\Omega =[0,L],\
u(0)=C,\ u'(L)=E\thinspace .\]</div>
<p>The new features are a first-order derivative <span class="math">\(u'\)</span> in the equation
and the boundary
condition involving the derivative: <span class="math">\(u'(L)=E\)</span>.
Since we have a Dirichlet condition at <span class="math">\(x=0\)</span>,
we force <span class="math">\(\varphi_i(0)=0\)</span> and use a boundary function <span class="math">\(B(x)=C(L-x)\)</span>
to take care of the condition <span class="math">\(u(0)=C\)</span>. Because there is no Dirichlet
condition on <span class="math">\(x=L\)</span> we do not make any requirements to <span class="math">\(\varphi_i(L)\)</span>.
The expansion for <span class="math">\(u\)</span> becomes</p>
<div class="math">
\[u = C(1-x) + \sum_{j=0}^N c_j \varphi_i(x)
\thinspace .\]</div>
<p>The variational formulation arises from multiplying the equation by
a test function <span class="math">\(v\in V\)</span> and integrating over <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[(-u'' + bu' - f, v) = 0,\quad\forall v\in V\]</div>
<p>We apply integration by parts to the <span class="math">\(u''v\)</span> term only. Although we could
also integrate <span class="math">\(u' v\)</span> by parts, this is not common.
The result becomes</p>
<div class="math">
\[(u' + bu',v') = (f,v) + [u' v]_0^L, \quad\forall v\in V \thinspace .\]</div>
<p>Now, <span class="math">\(v(0)=0\)</span> so <span class="math">\([u' v]_0^L = u'(L)v(L) = E v(L)\)</span>. We realize that when
integrating by parts, <em>the boundary term can be used to implement
Neumann conditions</em>.</p>
<span class="target" id="index-64"></span><p id="index-65">Another very important result is that <em>omitting the boundary term</em>
implies, in general, that we actually impose the condition <span class="math">\(u'=0\)</span> unless there
is a Dirichlet condition at that point! This result has great
practical consequences, because it is easy to forget the boundary
term, and this mistake implicitly
sets a boundary condition. Since Neumann conditions can be incorporated
without doing anything, or simply inserting the condition in a
boundary term, such conditions are known as <em>natural boundary conditions</em>.
Dirichlet conditions requires more essential steps in the mathematical
formulation and are
therefore known as <em>essential boundary conditions</em>.</p>
<p>The variational form now reads</p>
<div class="math">
\[(u',v') + (bu',v) = (f+C,v) + E v(L), \quad\forall v\in V \thinspace .\]</div>
<p>In the abstract notation we have</p>
<div class="math">
\[a(u,v)=L(v)\quad\forall v\in V,\]</div>
<p>with the particular formulas</p>
<div class="math">
\[a(u,v)=(u',v') + (bu',v),\quad L(v)= (f+C,v) + E v(L)\thinspace .\]</div>
<p>The expressions for the matrix and right-hand side entries in the
associated linear system can be directly found from the <span class="math">\(a(u,v)\)</span> and
<span class="math">\(L(v)\)</span> formulas as explained in the section <a class="reference internal" href="#fem-deq-1d-varform-abstract"><em>Abstract notation for variational formulations</em></a>:</p>
<div class="math">
\[A_{i,j} = a(\varphi_j,\varphi_i) = (\varphi_j',\varphi_i') +
(b\varphi_j',\varphi_i),\]</div>
<p>and</p>
<div class="math">
\[b_i = L(\varphi_i) = (f+C,\varphi_i) + E\varphi_i(L)\thinspace .\]</div>
<p>Observe that in this case, the coefficient matrix is not symmetric,
because</p>
<div class="math">
\[A_{i,j}= (b\varphi_j',\varphi_i)=\int_{\Omega} b\varphi_j'\varphi_i dx
 \neq \int_{\Omega} b \varphi_i' \varphi_jdx = (\varphi_i',b\varphi_j)=A_{j,i}
\thinspace .\]</div>
<p>For finite element basis functions, it is worth noticing that the boundary term
<span class="math">\(E\varphi_i(L)\)</span> is nonzero only in the entry <span class="math">\(b_N\)</span> since all
<span class="math">\(\varphi_i\)</span>, <span class="math">\(i\neq N\)</span>, are zero at <span class="math">\(x=L\)</span>, provided the degrees of freedom
are numbered from left to right in 1D so that <span class="math">\(x_{N}=L\)</span>.</p>
</div>
</div>
<div class="section" id="example-on-handling-dirichlet-and-neumann-conditions">
<h2>Example on handling Dirichlet and Neumann conditions<a class="headerlink" href="#example-on-handling-dirichlet-and-neumann-conditions" title="Permalink to this headline">¶</a></h2>
<p>Let perform the necessary calculations to solve</p>
<div class="math">
\[-u''(x)=f(x),\quad x\in \Omega=[0,1],\quad u'(0)=C,\ u(1)=D,\]</div>
<p>using a global polynomial basis <span class="math">\(\varphi_i\sim x^i\)</span>.
The requirements on <span class="math">\(\varphi_i\)</span> is that <span class="math">\(\varphi_i(1)=0\)</span>, because <span class="math">\(u\)</span> is
specified at <span class="math">\(x=1\)</span>, so a proper set of polynomial basis functions are
<span class="math">\(\varphi_i(x)=(1-x)^{i+1}\)</span>, <span class="math">\(i=0,\ldots,N\)</span>. A suitable <span class="math">\(B(x)\)</span> function
to handle the boundary condition <span class="math">\(u(1)=D\)</span> is <span class="math">\(B(x)=D x\)</span>.
The variational formulation
is given by <a href="#equation-fem:deq:1D:natBC">(59)</a>. With <span class="math">\(N=1\)</span> we can calculate
the global matrix system to be</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}
1 &amp; 1\\
1 &amp; 4/3
\end{array}\right)
\left(\begin{array}{c}
c_0\\
c_1
\end{array}\right)
=
\left(\begin{array}{c}
1+D-E\\
2/3 + D - E
\end{array}\right)\end{split}\]</div>
<p>The solution becomes <span class="math">\(c_0=2+D-E\)</span> and <span class="math">\(c_1=-1\)</span>, resulting in</p>
<div class="math">
\[u(x) = x D + (2+D-E)(1-x) - (1-x^2),\]</div>
<p>The exact solution is easily obtained by
integrating twice and applying the boundary conditions:</p>
<div class="math">
\[u_{\small\mbox{e}} (x) = 1 - x^2 + E(x-1) + D\thinspace .\]</div>
<p>We observe that the numerical solution coincides with the exact one, which
is to be expected since the expansion for <span class="math">\(u\)</span> contains the
exact solution as special case.</p>
<div class="section" id="nonlinear-terms">
<h3>Nonlinear terms<a class="headerlink" href="#nonlinear-terms" title="Permalink to this headline">¶</a></h3>
<p>Finally, we show that the techniques used above to derive variational
forms also apply in nonlinear cases. Here is a model problem with
a nonlinear coefficient and right-hand side:</p>
<div class="math">
\[-(a(u)u')' = f(u),\quad x\in [0,L],\ u(0)=0,\ u'(L)=E
\thinspace .\]</div>
<p>Using the Galerkin principle, we multiply by <span class="math">\(v\in V\)</span> and integrate,</p>
<div class="math">
\[-\int_0^L \frac{d}{dx}\left(a(u)\frac{du}{dx}\right)vdx =
\int_0^L f(u)vdx\quad\forall v\in V
\thinspace .\]</div>
<p>The integration by parts does not differ from the case where we had an
<span class="math">\(a(x)\)</span> and not an <span class="math">\(a(u)\)</span>:</p>
<div class="math">
\[\int_0^L a(u)\frac{du}{dx}\frac{dv}{dx}vdx =
\int_0^L f(u)vdx + [vu']_0^L\quad\forall v\in V
\thinspace .\]</div>
<p>We require that <span class="math">\(v(0)=0\)</span> since <span class="math">\(u(0)\)</span> is known. The other term, <span class="math">\(v(L)u'(L)\)</span>,
is used to impose the other boundary condition <span class="math">\(u'(L)=E\)</span>, resulting in</p>
<div class="math">
\[\int_0^L a(u)\frac{du}{dx}\frac{dv}{dx}vdx =
\int_0^L f(u)vdx + vE\quad\forall v\in V,\]</div>
<p>or alternatively written more compactly as</p>
<div class="math">
\[(a(u)u', v') = (f(u),v) + vE\quad\forall v\in V
\thinspace .\]</div>
<p>Since the problem is nonlinear, we cannot identify <span class="math">\(a(u,v)\)</span> and <span class="math">\(L(v)\)</span>.
An abstract notation is typically <em>find :math:`u` such that</em></p>
<div class="math">
\[F(u;v) = 0\quad\forall v\in V,\]</div>
<p>with</p>
<div class="math">
\[F(u;v) = (a(u)u', v') - (f(u),v) - vE
\thinspace .\]</div>
<p>By inserting <span class="math">\(u=\sum_j c_j\varphi_j\)</span> we get a <em>nonlinear system of
algebraic equations</em> for the unknowns <span class="math">\(c_0,\ldots,c_N\)</span>. Such systems must
be solved by constructing a sequence of linear systems whose solutions
converge to the solution of the nonlinear system. Frequently applied
methods are Picard iteration and Newton&#8217;s method.</p>
</div>
</div>
<div class="section" id="variational-problems-and-optimization-of-functionals">
<span id="fem-deq-1d-optimization"></span><h2>Variational problems and optimization of functionals<a class="headerlink" href="#variational-problems-and-optimization-of-functionals" title="Permalink to this headline">¶</a></h2>
<p>If <span class="math">\(a(u,v)=a(v,u)\)</span>, it can be shown that the variational statement
<span class="math">\(a(u,v)=L(v)\quad\forall v\in V\)</span> is equivalent to minimizing the functional</p>
<div class="math">
\[F(v) = \frac{1}{2}a(v,v) - L(v)\]</div>
<p>over all functions <span class="math">\(v\in V\)</span>. That is,</p>
<div class="math">
\[F(u)\leq F(v)\quad \forall v\in V\thinspace .\]</div>
<p>Inserting a <span class="math">\(v=\sum_j c_j\varphi_j\)</span> turns minimization of <span class="math">\(F(v)\)</span> into
minimization of a quadratic function</p>
<div class="math">
\[\bar F(c_0,\ldots,c_N) = \sum_{j=0}^N\sum_{i=0}^N a(\varphi_i,\varphi_j)c_ic_j - \sum_{j=0}^N L(\varphi_j)c_j\]</div>
<p>of <span class="math">\(N+1\)</span> parameters.</p>
<p>Many traditional applications of the finite element method, especially
in solid mechanics and structural analysis, start with formulating <span class="math">\(F(v)\)</span>
from physical principles, such as minimization of energy, and then
proceeds with deriving <span class="math">\(a(u,v)=L(v)\)</span>, which is the equation usually desired
in implementations.</p>
</div>
</div>
<div class="section" id="computing-with-finite-elements">
<span id="fem-deq-1d-fem1"></span><h1>Computing with finite elements<a class="headerlink" href="#computing-with-finite-elements" title="Permalink to this headline">¶</a></h1>
<p>The purpose of this section is to demonstrate in detail how
the finite element method can the be applied to the model problem</p>
<div class="math">
\[-u''(x) = 2,\quad x\in (0,L),\ u(0)=u(L)=0,\]</div>
<p>with variational formulation</p>
<div class="math">
\[(u',v') = (2,v)\quad\forall v\in V\thinspace .\]</div>
<p>The variational formulation is derived in <a href="#equation-fem:deq:1D:intbyparts">(45)</a>.</p>
<p>Since <span class="math">\(u\)</span> is known to be zero
at the end points of the interval, we can utilize a sum over
the basis functions associated with internal nodes only:</p>
<div class="math">
\[u(x) = \sum_{j=1}^{N-1}c_j\varphi_j(x)\thinspace .\]</div>
<p>Observe that <span class="math">\(u(0)\)</span> and <span class="math">\(u(L)\)</span> are zero since
<span class="math">\(\varphi_0\)</span> and <span class="math">\(\varphi_N\)</span> are left out of the sum: the remaining
<span class="math">\(\varphi_i\)</span> are all zero at <span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span>. This means that
only <span class="math">\(c_1,\ldots,c_{N-1}\)</span> are unknowns and the variational
statement in <a href="#equation-fem:deq:1D:intbyparts">(45)</a> holds only for
<span class="math">\(i=1,\ldots,N-1\)</span>.
For simplicity, we introduce uniformly spaced nodes, numbered from left
to right:</p>
<div class="math">
\[x_{i} = i h,\quad h=L/N,\quad i=0,\ldots,N\thinspace .\]</div>
<p>The simplest choice of elements is P1 elements with piecewise
linear functions. The nodes then coincides with the cell vertices and
<span class="math">\(\Omega^{(e)}=[x_{e}, x_{e+1}]\)</span>.</p>
<div class="section" id="computation-in-the-global-physical-domain">
<h2>Computation in the global physical domain<a class="headerlink" href="#computation-in-the-global-physical-domain" title="Permalink to this headline">¶</a></h2>
<p>We shall first perform a computation in the <span class="math">\(x\)</span>
coordinate system because the integrals can be easily computed
here by simple, visual,
geometric considerations. This is called a global approach
since we work in the <span class="math">\(x\)</span> coordinate system and compute integrals on
the global domain <span class="math">\([0,L]\)</span>.</p>
<p>The entries in the coefficient matrix and right-hand side are</p>
<div class="math">
\[A_{i,j}=\int_0^L\varphi_i'(x)\varphi_j'(x) dx,\quad
b_i=\int_0^L2\varphi_i(x) dx
\thinspace .\]</div>
<p>The <span class="math">\(\varphi_i(x)\)</span> function
is specified in
<a href="#equation-fem:approx:fe:phi:1:formula2">(20)</a>.
However,
we need the derivative of <span class="math">\(\varphi_i(x)\)</span> to compute the coefficient matrix.
These are</p>
<div class="math" id="equation-fem:approx:fe:Dphi:1:formula2">
<span class="eqno">(49)</span>\[\begin{split}     \varphi_i'(x) = \left\lbrace\begin{array}{ll}
     0, &amp; x &lt; x_{i-1},\\
     h^{-1},
     &amp; x_{i-1} \leq x &lt; x_{i},\\
     -h^{-1},
     &amp; x_{i} \leq x &lt; x_{i+1},\\
     0, &amp; x\geq x_{i+1}
     \end{array}
     \right.\end{split}\]</div>
<p>Figure <a class="reference internal" href="#fem-approx-fe-fig-dp1"><em>Illustration of the derivative of piecewise linear basis functions associated with nodes in cell 1</em></a> shows <span class="math">\(\varphi_1'(X)\)</span> and <span class="math">\(\varphi_2'(X)\)</span>.</p>
<div class="figure" id="fem-approx-fe-fig-dp1">
<img alt="_images/mpl_fe_dbasis_p1_4e_lab.png" src="_images/mpl_fe_dbasis_p1_4e_lab.png" style="width: 600px;" />
<p class="caption"><em>Illustration of the derivative of piecewise linear basis functions associated with nodes in cell 1</em></p>
</div>
<p>We realize that <span class="math">\(\varphi_i'\)</span> and <span class="math">\(\varphi_j'\)</span> has no overlap, and hence their
product vanishes, unless <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are nodes belonging to the same
element. The only nonzero contributions to the coefficient matrix are
therefore</p>
<div class="math">
\[\begin{split}A_{i-1,i} &amp;=\int_0^L\varphi_{i-1}'(x)\varphi_i'(x) dx,\\
A_{i,i}&amp;=\int_0^L\varphi_{i}'(x)^2 dx, \\
A_{i,i+1}&amp;=\int_0^L\varphi_{i}'(x)\varphi_{i+1}'(x) dx,\end{split}\]</div>
<p>for <span class="math">\(i=1,\ldots,N-1\)</span>.
We see that <span class="math">\(\varphi_{i-1}'(x)\)</span> and <span class="math">\(\varphi_i'(x)\)</span> have overlap of one
cell <span class="math">\(\Omega^{(i-1)}=[x_{i-1},x_{i}]\)</span> and that their product
then is <span class="math">\(-1/h^{2}\)</span>. The integrand is constant and therefore
<span class="math">\(A_{i-1,i}=-h^{-2}h=-h^{-1}\)</span>.
A similar reasoning can be applied to
<span class="math">\(A_{i+1,i}\)</span>, which also becomes <span class="math">\(-h^{-1}\)</span>. The integral of
<span class="math">\(\varphi_i'(x)^2\)</span> gets contributions from two cells,
<span class="math">\(\Omega^{(i-1)}=[x_{i-1},x_{i}]\)</span> and
<span class="math">\(\Omega^{(i)}=[x_{i},x_{i+1}]\)</span>, but <span class="math">\(\varphi_i'(x)^2=h^{-2}\)</span> in
both cells, and the length of the integration interval is <span class="math">\(2h\)</span> so
we get
<span class="math">\(A_{i,i}=2h^{-1}\)</span>. The right-hand side involves an integral of <span class="math">\(\varphi_i(x)\)</span>,
<span class="math">\(i=1,\ldots,N-1\)</span>,
which is just the area under a hat function of height 1 and width
<span class="math">\(2h\)</span>, i.e., equal to <span class="math">\(h\)</span>. Hence, <span class="math">\(b_i=2h\)</span>.</p>
<p>Note that there are no entries <span class="math">\(A_{0,0}\)</span> and <span class="math">\(A_{N,N}\)</span>
since <span class="math">\(c_0\)</span> and <span class="math">\(c_N\)</span> are left out of the matrix system.
The equation system to be solved only involves the unknowns <span class="math">\(c_1,\ldots,c_{N-1}\)</span>,
the right-hand side coefficients <span class="math">\(b_1,\ldots,b_{N-1}\)</span>, and
the matrix entries <span class="math">\(A_{1,1}\)</span>, <span class="math">\(A_{1,2}\)</span>, <span class="math">\(A_{2,1}\)</span>, <span class="math">\(A_{2,2}\)</span>, <span class="math">\(\ldots\)</span>,
<span class="math">\(A_{N-1,N-1}\)</span>, and <span class="math">\(A_{N-1,N-1}\)</span>. We can collect these numbers in
a matrix system that takes the following form:</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob">
<span class="eqno">(50)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     2 &amp; -1 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; -1 &amp; 2
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_1 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N-1}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     2h \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     2h
     \end{array}
     \right)\end{split}\]</div>
<p>Since we know that <span class="math">\(c_j\)</span> equals <span class="math">\(u(x_{j})\)</span>, we can introduce the
notation <span class="math">\(u_j\)</span> for the value of <span class="math">\(u\)</span> at node <span class="math">\(j\)</span>. The
<span class="math">\(i\)</span>-th equation in this system is then</p>
<div class="math" id="equation-fem:deq:1D:fem:ex1">
<span class="eqno">(51)</span>\[     -\frac{1}{h}u_{i-1} + \frac{2}{h}u_{i} - \frac{1}{h}u_{i+1} = 2h\thinspace .\]</div>
<p>A finite difference discretization of <span class="math">\(-u''(x)=2\)</span> by a centered,
second-order finite difference approximation <span class="math">\(u''(x_i)\approx [D_x D_x u]_i\)</span>
with <span class="math">\(\Delta x = h\)</span>
yields</p>
<div class="math">
\[-\frac{u_{i-1} + 2u_{i} - u_{i+1}}{h^2} = 2,\]</div>
<p>which is, in fact, equivalent to <a href="#equation-fem:deq:1D:fem:ex1">(51)</a> if
<a href="#equation-fem:deq:1D:fem:ex1">(51)</a> is divided by <span class="math">\(h\)</span>.
Therefore, the finite difference and the finite element method are
equivalent in this simple test problem. Sometimes a finite element method
generates the finite difference equations on a uniform mesh, and sometimes
the finite element method generates equations that are different.
The differences are modest, but may influence the numerical quality of
the solution significantly, especially in time-dependent problems.
.. There will be many examples illustrating this point.</p>
</div>
<div class="section" id="elementwise-computations-2">
<h2>Elementwise computations  (2)<a class="headerlink" href="#elementwise-computations-2" title="Permalink to this headline">¶</a></h2>
<p>We now employ the element by element (or cell by cell)
computational procedure as
explained in
the sections <a class="reference internal" href="#fem-approx-fe-elementwise"><em>Assembly of elementwise computations</em></a>, <a class="reference internal" href="#fem-approx-fe-mapping"><em>Mapping to a reference element</em></a>,
and <a class="reference internal" href="#fem-approx-fe-intg-ref"><em>Integration over a reference element</em></a>.
All integrals need to be mapped to the local reference coordinate system
(<span class="math">\(X\)</span>) according to the section <a class="reference internal" href="#fem-approx-fe-mapping"><em>Mapping to a reference element</em></a>.
In the present case, the matrix entries contain derivatives
with respect to <span class="math">\(x\)</span>,</p>
<div class="math">
\[A_{i,j}^{(e)}=\int_{\Omega^{(e)}} \varphi_i'(x)\varphi_j'(x) dx
= \int_{-1}^1 \frac{d}{dx}\tilde\varphi_r(X)\frac{d}{dx}\tilde\varphi_s(X)
\frac{h}{2} dX,\quad i=q(e,r),\ j=q(e,s),\ r,s=1,2
\thinspace .\]</div>
<p>The basis functions <span class="math">\(\tilde\varphi_r(X)\)</span> are known as functions of <span class="math">\(X\)</span>.
However, we now
need to find the derivative of <span class="math">\(\tilde\varphi_r(X)\)</span> with respect to <span class="math">\(x\)</span>.
Given</p>
<div class="math">
\[\tilde\varphi_0(X)=\frac{1}{2}(1-X),\quad\tilde\varphi_1(X)=\frac{1}{2}(1+X),\]</div>
<p>we can easily compute <span class="math">\(d\tilde\varphi_r/ dX\)</span>:</p>
<div class="math">
\[\frac{d\tilde\varphi_0}{dX} = -\frac{1}{2},\quad  \frac{d\tilde\varphi_1}{dX} = \frac{1}{2}\thinspace .\]</div>
<p>From the chain rule,</p>
<div class="math">
\[\frac{d\tilde\varphi_r}{dx} = \frac{d\tilde\varphi_r}{dX}\frac{dX}{dx}
= \frac{2}{h}\frac{d\tilde\varphi_r}{dX}\thinspace .\]</div>
<p>The transformed integral is then</p>
<div class="math">
\[A_{i,j}^{(e)}=\int_{\Omega^{(e)}} \varphi_i'(x)\varphi_j'(x) dx
= \int_{-1}^1 \frac{2}{h}\frac{d\tilde\varphi_r}{dX}\frac{2}{h}\frac{d\tilde\varphi_s}{dX}
\frac{h}{2} dX
\thinspace .\]</div>
<p>The right-hand side is transformed according to</p>
<div class="math">
\[b_i^{(e)} = \int_{\Omega^{(e)}} 2\varphi_i(x) dx =
\int_{-1}^12\tilde\varphi_r(X)\frac{h}{2} dX,\quad i=q(e,r),\ r=1,2
\thinspace .\]</div>
<p>Specifically for P1 elements we arrive at the following calculations for
the element matrix entries:</p>
<div class="math">
\[\begin{split}\tilde A_{0,0}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(-\frac{1}{2}\right)
\frac{2}{h}\left(-\frac{1}{2}\right)\frac{2}{h} dX = \frac{1}{h}\\
\tilde A_{0,1}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(-\frac{1}{2}\right)
\frac{2}{h}\left(\frac{1}{2}\right)\frac{2}{h} dX = -\frac{1}{h}\\
\tilde A_{1,0}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(\frac{1}{2}\right)
\frac{2}{h}\left(-\frac{1}{2}\right)\frac{2}{h} dX = -\frac{1}{h}\\
\tilde A_{1,1}^{(e)} &amp;= \int_{-1}^1\frac{2}{h}\left(\frac{1}{2}\right)
\frac{2}{h}\left(\frac{1}{2}\right)\frac{2}{h} dX = \frac{1}{h}\end{split}\]</div>
<p>The element vector entries become</p>
<div class="math">
\[\begin{split}\tilde b_0^{(e)} &amp;= \int_{-1}^12\frac{1}{2}(1-X)\frac{h}{2} dX = h\\
\tilde b_1^{(e)} &amp;= \int_{-1}^12\frac{1}{2}(1+X)\frac{h}{2} dX = h\thinspace .\end{split}\]</div>
<p>Expressing these entries in matrix and vector notation, we have</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm">
<span class="eqno">(52)</span>\[\begin{split}     \tilde A^{(e)} =\frac{1}{h}\left(\begin{array}{cc}
     1 &amp; -1\\
     -1 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(e)} = h\left(\begin{array}{c}
     1\\
     1
     \end{array}\right)\thinspace .\end{split}\]</div>
<p>The next step is to assemble the contributions from the various elements.
Since only the unknowns <span class="math">\(c_1,\ldots,c_{N-1}\)</span> enter the linear system,
we assembly only <span class="math">\(\tilde A^{(0)}_{1,1}\)</span> and <span class="math">\(\tilde A^{(N-1)}_{0,0}\)</span> from the
first and last element, respectively. The result becomes
identical to <a href="#equation-fem:deq:1D:ex1:Ab:glob">(50)</a>, which is not surprising since
the procedures are mathematically equivalent.</p>
<p>A fundamental problem with the matrix system we have assembled is that
the boundary conditions are not incorporated if <span class="math">\(D\neq 0\)</span>.
The next sections deals with this issue.</p>
</div>
</div>
<div class="section" id="boundary-conditions-specified-value">
<span id="fem-deq-1d-essbc"></span><h1>Boundary conditions: specified value<a class="headerlink" href="#boundary-conditions-specified-value" title="Permalink to this headline">¶</a></h1>
<p>We have to take special actions to incorporate Dirichlet conditions,
such as <span class="math">\(u(L)=D\)</span>,
into the computational procedures. The present section outlines
alternative, but mathematically equivalent, methods.</p>
<div class="section" id="general-construction-of-a-boundary-function">
<span id="id11"></span><h2>General construction of a boundary function<a class="headerlink" href="#general-construction-of-a-boundary-function" title="Permalink to this headline">¶</a></h2>
<p>In the section <em class="xref std std-ref">fem:deq:1D:essBC:Bfunc</em> we introduced a boundary function <span class="math">\(B(x)\)</span>
to deal with nonzero Dirichlet boundary conditions for <span class="math">\(u\)</span>. The
construction of such a function is not always trivial, especially not
in multiple dimensions. However, a simple and general construction
idea exists when the
basis functions have the property</p>
<div class="math">
\[\begin{split}\varphi_i(x_{j}) = \left\lbrace\begin{array}{ll}
1, &amp; i=j,\\
0, &amp; i\neq j,
\end{array}\right.\end{split}\]</div>
<p>where <span class="math">\(x_{j}\)</span> is a boundary point. Examples on such
functions are the Lagrange interpolating polynomials and finite
element functions. With <span class="math">\(\Omega = [0,L]\)</span>, <span class="math">\(u(0)=U_0\)</span>,
and <span class="math">\(u(L)=U_N\)</span> we can then let</p>
<div class="math">
\[B(x) = U_0\varphi_0(x) + U_N\varphi_N(x)\thinspace .\]</div>
<p>Since <span class="math">\(\varphi_0(x_0=0)=1\)</span> and <span class="math">\(\varphi_N(x_0=0)=0\)</span>, we have <span class="math">\(B(0)=U_0\)</span>.
Similarly, since
<span class="math">\(\varphi_0(x_N=L)=0\)</span> and <span class="math">\(\varphi_N(x_N=L)=1\)</span>, we have <span class="math">\(B(L)=U_N\)</span>.</p>
<p>In fact, the construction of <span class="math">\(B(x)\)</span> identifies <span class="math">\(c_0=U_0\)</span> and <span class="math">\(c_N=U_N\)</span>.
The remaining parameters <span class="math">\(c_1,\ldots,c_{N-1}\)</span> therefore the unknowns in
the linear system.
For the unknown <span class="math">\(u(x)\)</span> we then let the expansion be</p>
<div class="math">
\[u(x) = U_0\varphi_0(x) + U_N\varphi_N(x) + \sum_{j=1}^{N-1} c_j\varphi_j(x)\thinspace .\]</div>
<p>In the case where
<span class="math">\(u\)</span> has a Dirichlet boundary condition at only one boundary point,
<span class="math">\(B(x)\)</span> contains just the term corresponding to that point and
the sum <span class="math">\(\sum_j c_j \varphi_j\)</span> runs over the rest of the points.
This construction of <span class="math">\(B\)</span> can easily be generalized to two- and three-dimensional
problems for which the construction is particularly powerful, because it
allows us <span class="math">\(u\)</span> to easily fulfill boundary values on a boundary of any geometrical
complexity.</p>
<div class="section" id="example-3">
<h3>Example  (3)<a class="headerlink" href="#example-3" title="Permalink to this headline">¶</a></h3>
<p>Let us see how our previous model problem <span class="math">\(-u''=2\)</span>, <span class="math">\(u(0)=0\)</span>, <span class="math">\(u(L)=D\)</span>,
is affected by a <span class="math">\(B(x)\)</span> to incorporate boundary values.
The expansion for <span class="math">\(u(x)\)</span> reads</p>
<div class="math">
\[u(x) = 0\cdot\varphi_0(x) + D\varphi_N(x) +
\sum_{j=1}^{N-1} c_j\varphi_j(x)
\thinspace .\]</div>
<p>Inserting this expression in <span class="math">\(-(u'',\varphi_i)=(f,\varphi_i)\)</span> and
integrating by parts results in a linear system with</p>
<div class="math">
\[A_{i,j} = \int_0^L \varphi_i'(x)\varphi_j'(x) dx,\quad
b_i = \int_0^L (f(x) - D\varphi_N'(x))\varphi_i(x) dx,\]</div>
<p>for <span class="math">\(i,j = 1,\ldots,N-1\)</span>.
The integral <span class="math">\(D\int_0^L \varphi_N'(x))\varphi_i(x) dx\)</span> can only get
a nonzero contribution from the last cell, <span class="math">\(\Omega^{(N-1)}=[x_{N-1},x_{N}]\)</span>
since <span class="math">\(\varphi_N(x)=0\)</span> on all other cells. Moreover,
<span class="math">\(\varphi_N'(x)\varphi_i(x) dx\)</span> only for <span class="math">\(i=N-1\)</span> and <span class="math">\(i=N\)</span>, but the latter
value is not included anymore. From the explanations of the
calculations in the section <a class="reference internal" href="#fem-approx-global-linearsystem"><em>Calculating the linear system</em></a> we find that
<span class="math">\(\int_0^L \varphi_N(x))\varphi_{N-1}(x) dx\)</span> must equal <span class="math">\(h/6\)</span>, resulting
in the need to add <span class="math">\(-D h/6\)</span> to <span class="math">\(b_{N-1}\)</span>.</p>
<p>As an alternative,
we now turn to <em>elementwise computations</em> and realize that <span class="math">\(B(x)=D\varphi_{N}=0\)</span>
on all cells except the last one. On the last cell we regard
the local degree of freedom <span class="math">\(c_1\)</span> as known (<span class="math">\(c_1=D\)</span>). There is only one unknown
in a P1 element and the element matrix is therefore a <span class="math">\(1\times 1\)</span> matrix.
We have <span class="math">\(\tilde A_{0,0}^{(N-1)} = 1/h\)</span> as in the other elements, while</p>
<div class="math">
\[\tilde b_0^{(N-1)} = \int_{-1}^1 (f - D\tilde\varphi_1)\tilde\varphi_0\frac{h}{2}
= h - D h/6
\thinspace .\]</div>
<p>When assembling these contributions, we see that <span class="math">\(b_{N-1}\)</span> gets an
extra term <span class="math">\(-D h/6\)</span>, as in the computations in the physical domain.</p>
</div>
</div>
<div class="section" id="modification-of-the-linear-system">
<span id="fem-deq-1d-essbc-bfunc-modsys"></span><h2>Modification of the linear system<a class="headerlink" href="#modification-of-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>From an implementational point of view, there is a convenient alternative
to adding the <span class="math">\(B(x)\)</span> function and considering only the <span class="math">\(c_i\)</span> coefficients
corresponding to nodes without Dirichlet conditions as unknowns.
Since Dirichlet values of <span class="math">\(u\)</span> basically means that we know the
corresponding <span class="math">\(c_i\)</span> values, we may assemble the entire linear system for
all degrees of freedom, without taking Dirichlet conditions into account,
and then modify the linear system such that the <span class="math">\(c_i\)</span> values corresponding
to Dirichlet conditions get their right values.</p>
<p>Consider the computation of the global coefficient matrix
(<em class="xref std std-ref">fem:deq:1D:P1:Acb</em>). If we include all the <span class="math">\(c_0,\ldots,c_N\)</span>
values in the system, we have some additional matrix entries
from the first and last cell. We start with</p>
<div class="math">
\[A_{0,0}=\int_0^L \left(\frac{d\varphi_0}{dx}\right)^2 dx = \frac{1}{h},\]</div>
<p>because the interval of integration, with nonzero contributions,
is just the first cell (and not two
cells as for the other <span class="math">\(A_{i,j}\)</span> associated with cells not touching the
boundaries). Similarly, in the last cell we get <span class="math">\(A_{N,N}=1/h\)</span>.
Furthermore, <span class="math">\(A_{0,1}=\int_0^L\varphi_0\varphi_1' dx=-1/h\)</span>.
A similar reasoning is used for
<span class="math">\(A_{N-1,N}=\int_0^L\varphi_{N-1}\varphi_{N}' dx=-1/h\)</span>.</p>
<p>Regarding the right-hand side, we must include <span class="math">\(b_0\)</span> and <span class="math">\(b_N\)</span>.
Because <span class="math">\(\varphi_0=0\)</span> on all cells except the first one and
<span class="math">\(\varphi_N=0\)</span> on all cells except the last one, <span class="math">\(b_0\)</span> and <span class="math">\(b_N\)</span> only involves
integration over the first and last element, respectively:</p>
<div class="math">
\[\begin{split}b_0 &amp;= \int_0^L 2\varphi_0(x) dx = h,\\
b_N &amp;= \int_0^L 2\varphi_N(x) dx = h
\thinspace .\end{split}\]</div>
<p>The complete matrix system, involving all degrees of freedom, takes the form</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob2">
<span class="eqno">(53)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; -1 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; -1 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     h \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h\vdots\\
     h
     \end{array}
     \right)\end{split}\]</div>
<p>The idea now is that we replace the first and last equation by the
equations <span class="math">\(c_0=0\)</span> and <span class="math">\(c_N=D\)</span>, which guarantees that the boundary
values of <span class="math">\(u\)</span> becomes correct. This action changes the system to</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob3">
<span class="eqno">(54)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; 0 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     -1 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; -1 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 0 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     0 \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h\\
     D
     \end{array}
     \right)\end{split}\]</div>
</div>
<div class="section" id="symmetric-modification-of-the-linear-system">
<h2>Symmetric modification of the linear system<a class="headerlink" href="#symmetric-modification-of-the-linear-system" title="Permalink to this headline">¶</a></h2>
<p>The original matrix system <a href="#equation-fem:deq:1D:ex1:Ab:glob">(50)</a> is symmetric,
but the modifications in <a href="#equation-fem:deq:1D:ex1:Ab:glob3">(54)</a> destroy
the symmetry. Our described modification will in general destroy an
initial symmetry in the matrix system. This is not a particular
computational disadvantage for tridiagonal systems arising in 1D
problems, but may be more serious in 2D and 3D when the systems are
large and exploiting symmetry can be very important for the solution method.
Therefore, a modification that preserves symmetry is frequently applied.</p>
<p>Let <span class="math">\(c_k\)</span> be a coefficient corresponding to a known value <span class="math">\(K\)</span>.
We want to replace equation <span class="math">\(k\)</span> in the system by <span class="math">\(c_k=K\)</span>, i.e.,
insert zeroes in row number <span class="math">\(k\)</span> in the coefficient matrix,
set 1 on the diagonal, and replace <span class="math">\(b_k\)</span> by <span class="math">\(K\)</span>.
A symmetry-preserving modification consists in first
subtracting column number <span class="math">\(k\)</span> in the coefficient matrix, i.e., <span class="math">\(A_{i,k}\)</span>
for <span class="math">\(i=0,\ldots,N\)</span>, times the boundary value <span class="math">\(K\)</span>, from the
right-hand side: <span class="math">\(b_i \leftarrow b_i - A_{i,k}K\)</span>. Then we put
zeroes in row number <span class="math">\(k\)</span> <em>and</em> column number <span class="math">\(k\)</span> in the coefficient matrix,
and finally set <span class="math">\(b_k=K\)</span>.</p>
<p>This modification goes as follows for the above system. First we
subtract the first column in the coefficient matrix, times the boundary
value, from the right-hand side. Because <span class="math">\(c_0=0\)</span>, this subtraction
has no effect. Then we subtract the last column, times the boundary value <span class="math">\(D\)</span>,
from the right-hand side. This action results in <span class="math">\(b_{N-1}=2h+D/h\)</span> and
<span class="math">\(b_N=h-2D/h\)</span>. Thereafter, we place zeros in the first and last row and
column in the coefficient matrix and 1 on the two corresponding diagonal
entries. Finally, we set <span class="math">\(b_0=0\)</span> and <span class="math">\(b_N=D\)</span>. The result becomes</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:glob3:symm">
<span class="eqno">(55)</span>\[\begin{split}     \frac{1}{h}\left(
     \begin{array}{ccccccccc}
     1 &amp; 0 &amp; 0
     &amp;\cdots &amp;
     \cdots &amp; \cdots &amp; \cdots &amp;
     \cdots &amp; 0 \\
     0 &amp; 2 &amp; -1 &amp; \ddots &amp;   &amp; &amp;  &amp; &amp;  \vdots \\
     0 &amp; -1 &amp; 2 &amp; -1 &amp;
     \ddots &amp; &amp;  &amp;  &amp; \vdots \\
     \vdots &amp; \ddots &amp;  &amp; \ddots &amp; \ddots &amp; 0 &amp;  &amp; &amp; \vdots \\
     \vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\
     \vdots &amp; &amp;  &amp; 0 &amp; -1 &amp; 2 &amp; -1 &amp; \ddots &amp; \vdots \\
     \vdots &amp; &amp; &amp;  &amp; \ddots &amp; \ddots &amp; \ddots &amp;\ddots  &amp; 0 \\
     \vdots &amp; &amp; &amp; &amp;  &amp;\ddots  &amp; \ddots &amp;\ddots  &amp; 0 \\
     0 &amp;\cdots &amp; \cdots &amp;\cdots &amp; \cdots &amp; \cdots  &amp; 0 &amp; 0 &amp; 1
     \end{array}
     \right)
     \left(
     \begin{array}{c}
     c_0 \\
     \vdots\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots\\
     c_{N}
     \end{array}
     \right)
     =
     \left(
     \begin{array}{c}
     0 \\
     2h\\
     \vdots\\
     \vdots \\
     \vdots \\
     \vdots \\
     \vdots \\
     2h +D/h\\
     D
     \end{array}
     \right)\end{split}\]</div>
</div>
<div class="section" id="modification-of-the-element-matrix-and-vector">
<h2>Modification of the element matrix and vector<a class="headerlink" href="#modification-of-the-element-matrix-and-vector" title="Permalink to this headline">¶</a></h2>
<p>The modifications of the global linear system can alternatively
be done for the element matrix and vector. (The assembled
system will get <span class="math">\(n\)</span> on the main diagonal if <span class="math">\(n\)</span> elements contribute
to the same unknown, but the factor <span class="math">\(n\)</span> will also appear on the
right-hand side and hence cancel out.)</p>
<p>We have, in the present computational example, the element matrix and vector
<a href="#equation-fem:deq:1D:ex1:Ab:elm">(52)</a>. The modifications are needed in
cells where one of the degrees of freedom is known. Here, this means
the first and last cell. In the first cell, local degree of freedom number 0
is known and the modification becomes</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:0">
<span class="eqno">(56)</span>\[\begin{split}     \tilde A^{(0)} =
     A = \frac{1}{h}\left(\begin{array}{cc}
     1 &amp; 0\\
     -1 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(0)} = \left(\begin{array}{c}
     0\\
     h
     \end{array}\right)\thinspace .\end{split}\]</div>
<p>In the last cell we set</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:N">
<span class="eqno">(57)</span>\[\begin{split}     \tilde A^{(N-1)} =
     A = \frac{1}{h}\left(\begin{array}{cc}
     1 &amp; -1\\
     0 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(N-1)} = \left(\begin{array}{c}
     h\\
     D
     \end{array}\right)\thinspace .\end{split}\]</div>
<p>We can also perform the symmetric modification. This operation affects
only the last cell with a nonzero Dirichlet condition. The result
becomes</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:N:symm">
<span class="eqno">(58)</span>\[\begin{split}     \tilde A^{(N-1)} =
     A = \frac{1}{h}\left(\begin{array}{cc}
     1 &amp; 0\\
     0 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(N-1)} = \left(\begin{array}{c}
     h + D/h\\
     D
     \end{array}\right)\thinspace .\end{split}\]</div>
<p>The reader should assemble the element matrices and vectors and
check that the result coincides with the system
<a href="#equation-fem:deq:1D:ex1:Ab:glob3:symm">(55)</a>.</p>
</div>
</div>
<div class="section" id="boundary-conditions-specified-derivative">
<span id="fem-deq-1d-bc-nat"></span><h1>Boundary conditions: specified derivative<a class="headerlink" href="#boundary-conditions-specified-derivative" title="Permalink to this headline">¶</a></h1>
<p>Suppose our model problem <span class="math">\(-u''(x)=f(x)\)</span> features
the boundary conditions <span class="math">\(u'(0)=C\)</span> and <span class="math">\(u(L)=D\)</span>.
As already indicated in the section <a class="reference internal" href="#fem-deq-1d-varform-ex"><em>More examples on variational formulations</em></a>,
the former condition can be incorporated through the boundary term
that arises from integration by parts. This details of this method will now be
illustrated in the context of finite elements.</p>
<div class="section" id="the-variational-formulation">
<h2>The variational formulation<a class="headerlink" href="#the-variational-formulation" title="Permalink to this headline">¶</a></h2>
<p>Starting with the Galerkin method,</p>
<div class="math">
\[\int_0^L(u''(x)+f(x))\varphi_i(x) dx = 0,\quad i=0,\ldots,N,\]</div>
<p>integrating <span class="math">\(u''\varphi_i\)</span> by parts results in</p>
<div class="math">
\[\int_0^Lu'(x)'\varphi_i'(x) dx -(u'(L)\varphi_i(L) - u'(0)\varphi_i(0)) =
\int_0^L f(x)\varphi_i(x) dx,\]</div>
<p>for <span class="math">\(i=0,\ldots,N\)</span>.
The first boundary term vanishes since
<span class="math">\(\varphi_i(L)=0\)</span> when <span class="math">\(u(L)\)</span> is known.
Or, if we prefer to modify the linear system and include <span class="math">\(\varphi_N\)</span> in
the calculations (<span class="math">\(\varphi_N(L)=1\neq 0\)</span>), it appears that the
only nonzero term <span class="math">\(u'(L)\varphi_N(L)\)</span> is erased on the right-hand side
when we set <span class="math">\(b_N=D\)</span>. With either approach to incorporating Dirichlet
conditions, the term <span class="math">\(u'(L)\varphi_i(L)\)</span>
does not contribute to the final matrix system.</p>
<p>The second boundary
term, <span class="math">\(u'(0)\varphi_i(0)\)</span>, can be used to implement the condition <span class="math">\(u'(0)=C\)</span>,
provided <span class="math">\(\varphi_i(0)\neq 0\)</span> for some <span class="math">\(i\)</span> (but with finite elements
we fortunately have <span class="math">\(\varphi_0(0)=1\)</span>).
The variational formulation then becomes</p>
<div class="math">
\[\int_0^Lu'(x)\varphi_i'(x) dx + E\varphi_i(0) =
\int_0^L f(x)\varphi_i(x) dx,\quad i=0,\ldots,N\thinspace .\]</div>
<p>Inserting</p>
<div class="math">
\[u(x) = B(x) + \sum_{j=0}^{N-1} c_j\varphi_j(x),
\quad B(x) = D\varphi_N(x),\]</div>
<p>leads to the linear system</p>
<div class="math" id="equation-fem:deq:1D:natBC">
<span class="eqno">(59)</span>\[     \sum_{j=0}^{N-1}\left(
     \int_0^L \varphi_i'(x)\varphi_j'(x) dx \right)c_j =
     \int_0^L\left(f(x)\varphi_i(x) -D\varphi_N'(x)\varphi_i(x)\right) dx
      - E\varphi_i(0),\]</div>
<p>for <span class="math">\(i=0,\ldots,N-1\)</span>.
Alternatively, we may just work with</p>
<div class="math">
\[u(x) = \sum_{j=0}^{N} c_j\varphi_j(x),\]</div>
<p>and modify the last equation to <span class="math">\(c_N=D\)</span> in the linear system.
The linear system to be assembled then corresponds to
<a href="#equation-fem:deq:1D:natBC">(59)</a> with the <span class="math">\(D\varphi_N'\)</span> term removed, and
<span class="math">\(j=N\)</span> must be included in the summation. Similarly, the equation
corresponding to <span class="math">\(i=N\)</span> must be included:</p>
<div class="math" id="equation-fem:deq:1D:natBC2">
<span class="eqno">(60)</span>\[     \sum_{j=0}^{N}\left(
     \int_0^L \varphi_i'(x)\varphi_j'(x) dx \right)c_j =
     \int_0^L\left(f(x)\varphi_i(x)\right) dx
      - E\varphi_i(0),\quad i=0,\ldots,N
     \thinspace .\]</div>
<p>We now turn to actual computations with P1 finite elements.
The focus is on how the linear system and
the element matrices and vectors are modified by the
condition <span class="math">\(u'(0)=C\)</span>.</p>
</div>
<div class="section" id="direct-computation-of-the-global-linear-system">
<h2>Direct computation of the global linear system<a class="headerlink" href="#direct-computation-of-the-global-linear-system" title="Permalink to this headline">¶</a></h2>
<p>Consider first the approach where Dirichlet conditions are incorporated
by a <span class="math">\(B(x)\)</span> function and leaving out the known degrees of freedom
from the linear system. The relevant formula for the linear
system is given by <a href="#equation-fem:deq:1D:natBC">(59)</a>.
There are two differences compared to the extensively
computed case where <span class="math">\(u(0)=0\)</span>. Because we do not have a Dirichlet
condition at the left boundary, we need to extend the linear system
<a href="#equation-fem:deq:1D:ex1:Ab:glob">(50)</a> with an equation corresponding to <span class="math">\(i=0\)</span>.
According to the section <a class="reference internal" href="#fem-deq-1d-essbc-bfunc-modsys"><em>Modification of the linear system</em></a>, this
consists of including <span class="math">\(A_{0,0}=1/h\)</span>, <span class="math">\(A_{0,1}=-1/h\)</span>, and <span class="math">\(b_0=h\)</span>.
Second, we need to include
the extra term
<span class="math">\(-E\varphi_i(0)\)</span> on the right-hand side. Since all <span class="math">\(\varphi_i(0)=0\)</span>
for <span class="math">\(i=1,\ldots,N\)</span>, this term reduces to <span class="math">\(-E\varphi_0(0)=-E\)</span> and
affects only the first equation (<span class="math">\(i=0\)</span>). We simply add <span class="math">\(-E\)</span> to <span class="math">\(b_0\)</span>
such that <span class="math">\(b_0=h - E\)</span>.</p>
<p>Next we consider the technique where we modify the linear system to
incorporate Dirichlet conditions. The only difference from the
case in the section <a class="reference internal" href="#fem-deq-1d-essbc-bfunc-modsys"><em>Modification of the linear system</em></a> is simply the
extra term <span class="math">\(-E\)</span> in the <span class="math">\(b_0\)</span> entry so we can just add this
value and continue with modifying the last equation to incorporate
<span class="math">\(c_N=D\)</span>.</p>
</div>
<div class="section" id="elementwise-computations-3">
<h2>Elementwise computations  (3)<a class="headerlink" href="#elementwise-computations-3" title="Permalink to this headline">¶</a></h2>
<p>In the case we compute with one element at a time, we need to see how the
<span class="math">\(u'(0)=C\)</span> condition affects the element matrix and vector.
As above for the case of forming a global system directly,
the extra term <span class="math">\(-E\varphi_i(0)\)</span> in the variational formulation
only affects the element vector in the first element.
On the reference cell, <span class="math">\(-E\varphi_i(0)\)</span> is transformed to
<span class="math">\(-E\tilde\varphi_r(-1)\)</span>, where <span class="math">\(r\)</span> counts local degrees of freedom.
Only <span class="math">\(\tilde\varphi_0(-1)\neq 0\)</span> so we are left with the contribution
<span class="math">\(-E\tilde\varphi_0(-1)=-E\)</span> to <span class="math">\(\tilde b^{(0)}_0\)</span>:</p>
<div class="math" id="equation-fem:deq:1D:ex1:Ab:elm:bc:nat">
<span class="eqno">(61)</span>\[\begin{split}     \tilde A^{(0)} =
     A = \frac{1}{h}\left(\begin{array}{cc}
     1 &amp; 1\\
     -1 &amp; 1
     \end{array}\right),\quad
     \tilde b^{(0)} = \left(\begin{array}{c}
     h - E\\
     h
     \end{array}\right)\thinspace .\end{split}\]</div>
<p>No other element matrices or vectors are affected.</p>
</div>
</div>
<div class="section" id="implementation-4">
<span id="fem-deq-1d-code-global"></span><h1>Implementation  (4)<a class="headerlink" href="#implementation-4" title="Permalink to this headline">¶</a></h1>
<p>It is tempting to create a
program with symbolic calculations to perform all the steps in the
computational machinery,
both for automating the work and for documenting the complete algorithms.
As we have seen, there are quite many details involved with
finite element computations and incorporation of boundary conditions.
An implementation will also act as a structured summary of all these details.</p>
<div class="section" id="global-basis-functions-2">
<h2>Global basis functions  (2)<a class="headerlink" href="#global-basis-functions-2" title="Permalink to this headline">¶</a></h2>
<p>A function similar to <tt class="docutils literal"><span class="pre">least_squares</span></tt> from
the section <a class="reference internal" href="#fem-approx-global-ls-code"><em>Implementation of the least squares method</em></a> can easily be made. However, in the
approximation problem the formulas for the entries in the
linear system are fixed, while when we solve a differential equation
the formulas are only known by the user of the function, since
the formulas must be derived by a Galerkin or least squares principle
and depend on the differential equation at hand.
We therefore require that the user prepares a function
<tt class="docutils literal"><span class="pre">integrand_lhs(phi,</span> <span class="pre">i,</span> <span class="pre">j)</span></tt> for returning the integrand of the
integral that contributes to matrix entry <span class="math">\((i,j)\)</span>.
The <tt class="docutils literal"><span class="pre">phi</span></tt> variable is a Python dictionary holding the basis
functions and their derivatives in symbolic form. That is,
<tt class="docutils literal"><span class="pre">phi[q]</span></tt> is a list of</p>
<div class="math">
\[\{\frac{d^q\varphi_0}{dx^q},\ldots,\frac{d^q\varphi_N}{dx^q}\}
\thinspace .\]</div>
<p>Similarly, <tt class="docutils literal"><span class="pre">integrand_rhs(phi,</span> <span class="pre">i)</span></tt> returns the integrand
for cell <span class="math">\(i\)</span> in the right-hand side vector.
Since we also have contributions to this vector (and potentially also the
matrix) from boundary terms without any integral, we introduce two
additional functions, <tt class="docutils literal"><span class="pre">boundary_lhs(phi,</span> <span class="pre">i,</span> <span class="pre">j)</span></tt> and
<tt class="docutils literal"><span class="pre">boundary_rhs(phi,</span> <span class="pre">i)</span></tt> for returning terms in the variational
formulation that are not to be integrated over the domain <span class="math">\(\Omega\)</span>.</p>
<p>The linear system can now be computed and solved symbolically by
the following function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="n">integrand_lhs</span><span class="p">,</span> <span class="n">integrand_rhs</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
          <span class="n">boundary_lhs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">boundary_rhs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="n">boundary_lhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>   <span class="c"># assume symmetry</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">boundary_rhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
<p>It turns out that symbolic solution of differential
equations, discretized by a Galerkin or least squares method
with global basis functions,
is of limited interest beyond the simplest problems.
Symbolic integration might be very time consuming or impossible, not
only in <tt class="docutils literal"><span class="pre">sympy</span></tt> but also in
<a class="reference external" href="http://wolframalpha.com">WolframAlpha</a>
(which applies the perhaps most powerful symbolic integration
software available today: Mathematica). Numerical integration
as an option is therefore desirable.</p>
<p>The extended <tt class="docutils literal"><span class="pre">solve</span></tt> function below tries to combine symbolic and
numerical integration.  The latter can be enforced by the user, or it
can be invoked after a non-successful symbolic integration (being
detected by an <tt class="docutils literal"><span class="pre">Integral</span></tt> object as the result of the integration, see
also the section <a class="reference internal" href="#fem-approx-global-lagrange"><em>Lagrange polynomials</em></a>). Note that for a
numerical integration, symbolic expressions must be converted to
Python functions (using <tt class="docutils literal"><span class="pre">lambdify</span></tt>), and the expressions cannot contain
other symbols than <tt class="docutils literal"><span class="pre">x</span></tt>. The real <tt class="docutils literal"><span class="pre">solve</span></tt> routine in the
<a class="reference external" href="https://github.com/hplgit/INF5620/blob/gh-pages/src/fem/varform1D.py">varform1D.py</a>
file has error checking and meaningful error messages in such cases.
The <tt class="docutils literal"><span class="pre">solve</span></tt> code below is a condensed version of the real one, with
the purpose of showing how to automate the Galerkin or least squares
method for solving differential equations in 1D with global basis functions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="n">integrand_lhs</span><span class="p">,</span> <span class="n">integrand_rhs</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
          <span class="n">boundary_lhs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">boundary_rhs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">numint</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Symbol</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">numint</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                    <span class="n">numint</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c"># force num.int. hereafter</span>
            <span class="k">if</span> <span class="n">numint</span><span class="p">:</span>
                <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
                <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
            <span class="k">if</span> <span class="n">boundary_lhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">integrand_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">numint</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="n">numint</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">if</span> <span class="n">numint</span><span class="p">:</span>
            <span class="n">integrand</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">lambdify</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">integrand</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">mpmath</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">integrand</span><span class="p">,</span> <span class="p">[</span><span class="n">Omega</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Omega</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="k">if</span> <span class="n">boundary_rhs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">I</span> <span class="o">+=</span> <span class="n">boundary_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">LUsolve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="k">return</span> <span class="n">u</span>
</pre></div>
</div>
</div>
<div class="section" id="example-constant-right-hand-side">
<h2>Example: constant right-hand side<a class="headerlink" href="#example-constant-right-hand-side" title="Permalink to this headline">¶</a></h2>
<p>To demonstrate the code above, we address</p>
<div class="math">
\[-u''(x)=b,\quad x\in\Omega=[0,1],\quad u(1)=1,\ u(0)=0,\]</div>
<p>with <span class="math">\(b\)</span> as a (symbolic) constant. A possible choice of space <span class="math">\(V\)</span>,
where the basis functions satisfy
the requirements <span class="math">\(\varphi_i(0)=\varphi_i(1)=0\)</span>, is</p>
<div class="math">
\[V = \hbox{span}\,\{\varphi_i(x) = x^{i+1}(1-x)\}_{i=0}^N\thinspace .\]</div>
<p>We also need a <span class="math">\(B(x)\)</span> function to take care of the known boundary
values of <span class="math">\(u\)</span>. Any function <span class="math">\(B(x)=1-x^p\)</span>, <span class="math">\(p\in\mathbb{R}\)</span>, is a candidate.
One arbitrary choice from this family
is <span class="math">\(B(x)=1-x^3\)</span>. The unknown function is then written as
a sum of a known (<span class="math">\(B\)</span>) and an unknown (<span class="math">\(\bar u\)</span>) function:</p>
<div class="math">
\[u(x) = B(x) + \bar u (x),\quad \bar u(x) = \sum_{j=0}^N c_j\varphi_j(x)\thinspace .\]</div>
<p>Let us use the Galerkin method to derive the variational formulation.
Multiplying the differential
equation by <span class="math">\(v\)</span> and integrate by parts yield</p>
<div class="math">
\[\int_0^1 u'v' dx = \int_0^1 fv dx\quad\forall v\in V,\]</div>
<p>and with <span class="math">\(u=B + \bar u\)</span>,</p>
<div class="math">
\[\int_0^1 \bar u'v' dx = \int_0^1 (f-B')v dx\quad\forall v\in V\thinspace .\]</div>
<p>Inserting <span class="math">\(\bar u = \sum_{j}c_j\varphi_j\)</span>, we get the linear system</p>
<div class="math">
\[\sum_{j=0}^N\left(\int_0^1\varphi_i'\varphi_j' dx\right)c_j = \int_0^1(f-B')\varphi_i dx,
\quad i=0,\ldots,N\thinspace .\]</div>
<p>The application can be coded as follows in <tt class="docutils literal"><span class="pre">sympy</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;x b&#39;</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">b</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span>
<span class="n">dBdx</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c"># Compute basis functions and their derivatives</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">phi</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]}</span>
<span class="n">phi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">sm</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">phi_i</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">phi_i</span> <span class="ow">in</span> <span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

<span class="k">def</span> <span class="nf">integrand_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">phi</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">integrand_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">dBdx</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

<span class="n">Omega</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">u_bar</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">integrand_lhs</span><span class="p">,</span> <span class="n">integrand_rhs</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span>
              <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">numint</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">B</span> <span class="o">+</span> <span class="n">u_bar</span>
<span class="k">print</span> <span class="s">&#39;solution u:&#39;</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
</pre></div>
</div>
<p>The printout of <tt class="docutils literal"><span class="pre">u</span></tt> reads <tt class="docutils literal"><span class="pre">-b*x**2/2</span> <span class="pre">+</span> <span class="pre">b*x/2</span> <span class="pre">-</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">1</span></tt>.
Note that expanding <tt class="docutils literal"><span class="pre">u</span></tt> and then simplifying is in the present case
desirable to get a compact, final expression with <tt class="docutils literal"><span class="pre">sympy</span></tt>.
A non-expanded <tt class="docutils literal"><span class="pre">u</span></tt> might be preferable in other cases - this depends on
the problem in question.</p>
<p>The exact solution <span class="math">\(u_{\small\mbox{e}}(x)\)</span> can be derived by the following
<tt class="docutils literal"><span class="pre">sympy</span></tt> code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Solve -u&#39;&#39;=f by integrating f twice</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">f2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="c"># Add integration constants</span>
<span class="n">C1</span><span class="p">,</span> <span class="n">C2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">&#39;C1 C2&#39;</span><span class="p">)</span>
<span class="n">u_e</span> <span class="o">=</span> <span class="o">-</span><span class="n">f2</span> <span class="o">+</span> <span class="n">C1</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">C2</span>
<span class="c"># Find C1 and C2 from the boundary conditions u(0)=0, u(1)=1</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">u_e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">u_e</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">])</span>
<span class="c"># Form the exact solution</span>
<span class="n">u_e</span> <span class="o">=</span> <span class="o">-</span><span class="n">f2</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="n">C1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="n">C2</span><span class="p">]</span>
<span class="k">print</span> <span class="s">&#39;analytical solution:&#39;</span><span class="p">,</span> <span class="n">u_e</span>
<span class="k">print</span> <span class="s">&#39;error:&#39;</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_e</span><span class="p">)</span>
</pre></div>
</div>
<p>The last line prints <tt class="docutils literal"><span class="pre">0</span></tt>, which is not surprising when
<span class="math">\(u_{\small\mbox{e}}(x)\)</span> is a parabola and our approximate <span class="math">\(u\)</span> contains polynomials up to
degree 4. It suffices to have <span class="math">\(N=1\)</span>, i.e., polynomials of degree
2, to recover the exact solution.</p>
<p>We can play around with the code and test that with <span class="math">\(f\sim x^p\)</span>,
the solution is a polynomial of degree <span class="math">\(p+2\)</span>, and <span class="math">\(N=p+1\)</span> guarantees
that the approximate solution is exact.</p>
<p>Although the symbolic code is capable of integrating many choices of <span class="math">\(f(x)\)</span>,
the symbolic expressions for <span class="math">\(u\)</span> quickly become lengthy and non-informative,
so numerical integration in the code, and hence numerical answers,
have the greatest application potential.</p>
</div>
<div class="section" id="finite-elements">
<h2>Finite elements<a class="headerlink" href="#finite-elements" title="Permalink to this headline">¶</a></h2>
<p>Implementation of the finite element algorithms for differential
equations follows closely the algorithm for approximation of functions.
The new additional ingredients are</p>
<ol class="arabic simple">
<li>other types of integrands (as implied by the variational formulation)</li>
<li>additional boundary terms in the variational formulation for
Neumann boundary conditions</li>
<li>modification of element matrices and vectors due to Dirichlet
boundary conditions</li>
</ol>
<p>Point 1 and 2 can be taken care of by letting the user supply
functions defining the integrands and boundary terms on the
left- and right-hand side of the equation system:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">integrand_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">boundary_lhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">integrand_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">boundary_rhs</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <tt class="docutils literal"><span class="pre">phi</span></tt> is a dictionary where <tt class="docutils literal"><span class="pre">phi[q]</span></tt> holds a list of
the derivatives of order <tt class="docutils literal"><span class="pre">q</span></tt> of the basis functions at the
an evaluation point; <tt class="docutils literal"><span class="pre">r</span></tt> and <tt class="docutils literal"><span class="pre">s</span></tt> are indices for the corresponding
entries in the element matrix and vector, and <tt class="docutils literal"><span class="pre">x</span></tt> is the global
coordinate value corresponding to the current evaluation point.</p>
<p>Given a mesh represented by <tt class="docutils literal"><span class="pre">vertices</span></tt>, <tt class="docutils literal"><span class="pre">cells</span></tt>, and <tt class="docutils literal"><span class="pre">dof_map</span></tt> as
explained before, we can write a pseudo Python code to list all
the steps in the computational algorithm for finite element solution
of a differential equation.</p>
<div class="highlight-python"><pre>&lt;Declare global matrix and rhs: A, b&gt;

for e in range(len(cells)):

    # Compute element matrix and vector
    n = len(dof_map[e])  # no of dofs in this element
    h = vertices[cells[e][1]] - vertices[cells[e][1]]
    &lt;Declare element matrix and vector: A_e, b_e&gt;

    # Integrate over the reference cell
    points, weights = &lt;numerical integration rule&gt;
    for X, w in zip(points, weights):
        phi = &lt;basis functions and derivatives at X&gt;
        detJ = h/2
        x = &lt;affine mapping from X&gt;
        for r in range(n):
            for s in range(n):
                A_e[r,s] += integrand_lhs(phi, r, s, x)*detJ*w
            b_e[r] += integrand_rhs(phi, r, x)*detJ*w

    # Add boundary terms
    for r in range(n):
        for s in range(n):
            A_e[r,s] += boundary_lhs(phi, r, s, x)*detJ*w
        b_e[r] += boundary_rhs(phi, r, x)*detJ*w

    # Incorporate essential boundary conditions
    for r in range(n):
        global_dof = dof_map[e][r]
        if global_dof in essbc_dofs:
            # dof r is subject to an essential condition
            value = essbc_docs[global_dof]
            # Symmetric modification
            b_e -= value*A_e[:,r]
            A_e[r,:] = 0
            A_e[:,r] = 0
            A_e[r,r] = 1
            b_e[r] = value

    # Assemble
    for r in range(n):
        for s in range(n):
            A[dof_map[e][r], dof_map[e][r]] += A_e[r,s]
        b[dof_map[e][r] += b_e[r]

&lt;solve linear system&gt;</pre>
</div>
</div>
</div>
<div class="section" id="variational-formulations-in-2d-and-3d">
<span id="fem-deq-2d-varform"></span><h1>Variational formulations in 2D and 3D<a class="headerlink" href="#variational-formulations-in-2d-and-3d" title="Permalink to this headline">¶</a></h1>
<p>The major difference between deriving variational formulations in 2D and 3D
compared to 1D is the rule for integrating by parts.
A typical second-order term in a PDE may be written in dimension-independent
notation as</p>
<div class="math">
\[\nabla^2 u \quad\hbox{or}\quad \nabla\left( a(\pmb{x})\nabla u\right)
\thinspace .\]</div>
<p>The explicit forms in a 2D problem become</p>
<div class="math">
\[\nabla^2 u = \nabla\cdot\nabla u =
\frac{\partial^2 u}{\partial x^2} +
\frac{\partial^2 u}{\partial y^2},\]</div>
<p>and</p>
<div class="math">
\[\nabla\left( a(\pmb{x})\nabla u\right) =
\frac{\partial}{\partial x}\left( a(x,y)\frac{\partial u}{\partial x}\right) +
\frac{\partial}{\partial y}\left( a(x,y)\frac{\partial u}{\partial y}\right)
\thinspace .\]</div>
<p>The general rule for integrating by parts is</p>
<div class="math" id="equation-fem:deq:2D:int:by:parts">
<span class="eqno">(62)</span>\[     -\int_{\Omega} \nabla\cdot (a(\pmb{x})\nabla u) v\, \mathrm{d}x =
     \int_{\Omega} a(\pmb{x})\nabla u\cdot\nabla v \, \mathrm{d}x -
     \int_{\partial\Omega} a\frac{\partial u}{\partial n} v \, \mathrm{d}s,\]</div>
<p>where <span class="math">\(\partial\Omega\)</span> is the boundary of <span class="math">\(\Omega\)</span> and
<span class="math">\(\partial u/\partial n = \pmb{n}\cdot\nabla u\)</span> is the derivative
of <span class="math">\(u\)</span> in the outward normal direction, <span class="math">\(\pmb{n}\)</span> being an outward
unit normal to <span class="math">\(\partial\Omega\)</span>.</p>
<p>Note that <a href="#equation-fem:deq:2D:int:by:parts">(62)</a> obviously applies to a constant
<span class="math">\(a\)</span>, which is what we have if the PDE has a Laplace term <span class="math">\(a\nabla^2 u\)</span>.</p>
<p>Let us divide the boundary into two parts:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(\partial\Omega_N\)</span>, where we have Neumann conditions
<span class="math">\(-a\frac{\partial u}{\partial n} = g\)</span>, and</li>
<li><span class="math">\(\partial\Omega_D\)</span>, where we have Dirichlet conditions
<span class="math">\(u = u_0\)</span>.</li>
</ul>
</div></blockquote>
<p>The test functions <span class="math">\(v\)</span> are required to vanish on <span class="math">\(\partial\Omega_D\)</span>.</p>
<p>Here is a quite general linear PDE arising in many problems:</p>
<div class="math">
\[\begin{split}\pmb{v}\cdot\nabla u + \alpha u &amp;= \nabla\left( a\nabla u\right) + f,
\quad\pmb{x}\in\Omega,\\
u &amp;= u_0,\quad\pmb{x}\in\partial\Omega_D,\\
-a\frac{\partial u}{\partial n} &amp;= g,\quad\pmb{x}\in\partial\Omega_N
\thinspace .\end{split}\]</div>
<p>The vector field <span class="math">\(\pmb{v}\)</span> and the scalar functions <span class="math">\(a\)</span>, <span class="math">\(\alpha\)</span>, <span class="math">\(f\)</span>, <span class="math">\(u_0\)</span>, and
<span class="math">\(g\)</span> may vary with the spatial coordinate <span class="math">\(\pmb{x}\)</span> and must be known.</p>
<p>Such a second-order PDE needs exactly one boundary condition at each
point of the boundary, so <span class="math">\(\partial\Omega_N\cup\partial\Omega_D\)</span>
must be the complete boundary <span class="math">\(\partial\Omega\)</span>.</p>
<p>The unknown function can be expanded as</p>
<div class="math">
\[u = u_0 + \sum_{j=0}^N c_j\varphi_j \thinspace .\]</div>
<p>The variational formula is obtained from Galerkin&#8217;s method, which
technically implies multiplying the PDE by a test
function <span class="math">\(v\)</span> and integrating over <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[\int_{\Omega} (\pmb{v}\cdot\nabla u + \alpha u)v\, \mathrm{d}x =
\int_{\Omega} (\nabla\left( a\nabla u\right)\, \mathrm{d}x + fv \, \mathrm{d}x
\thinspace .\]</div>
<p>The second-order term is integrated by parts:</p>
<div class="math">
\[\int_{\Omega} (\nabla\left( a\nabla u\right)\, \mathrm{d}x =
-\int_{\Omega} a\nabla u\cdot\nabla v\, \mathrm{d}x
+ \int_{\partial\Omega} a\frac{\partial u}{\partial n} v\, \mathrm{d}s,\]</div>
<p>resulting in</p>
<div class="math">
\[\int_{\Omega} (\pmb{v}\cdot\nabla u + \alpha u)v\, \mathrm{d}x =
-\int_{\Omega} a\nabla u\cdot\nabla v\, \mathrm{d}x
+ \int_{\partial\Omega} a\frac{\partial u}{\partial n} v\, \mathrm{d}s
+ \int_{\Omega} fv \, \mathrm{d}x
\thinspace .\]</div>
<p>The boundary term can be developed further by noticing that <span class="math">\(v\neq 0\)</span>
only on <span class="math">\(\partial\Omega_N\)</span>,</p>
<div class="math">
\[\int_{\partial\Omega} a\frac{\partial u}{\partial n} v\, \mathrm{d}s
= \int_{\partial\Omega_N} a\frac{\partial u}{\partial n} v\, \mathrm{d}s,\]</div>
<p>and that on <span class="math">\(\partial\Omega_N\)</span>, we have the condition
<span class="math">\(a\frac{\partial u}{\partial n}=-g\)</span>, so the term becomes</p>
<div class="math">
\[-\int_{\partial\Omega_N} gv\, \mathrm{d}s\thinspace .\]</div>
<p>The variational form is then</p>
<div class="math">
\[\int_{\Omega} (\pmb{v}\cdot\nabla u + \alpha u)v\, \mathrm{d}x =
-\int_{\Omega} a\nabla u\cdot\nabla v \, \mathrm{d}x
- \int_{\partial\Omega} g v\, \mathrm{d}s
+ \int_{\Omega} fv \, \mathrm{d}x
\thinspace .\]</div>
<p>Instead of using the integral signs we may use the inner product
notation <span class="math">\((\cdot,\cdot)\)</span>:</p>
<div class="math">
\[(\pmb{v}\cdot\nabla u, v) + (\alpha u,v) =
- (a\nabla u,\nabla v) - (g,v)_{N} + (f,v)
\thinspace .\]</div>
<p>The subscript <span class="math">\({}_N\)</span> in <span class="math">\((g,v)_{N}\)</span> is a notation for a line or surface
integral over <span class="math">\(\partial\Omega_N\)</span>.</p>
<p>Inserting the <span class="math">\(u\)</span> expansion results in</p>
<div class="math">
\[\begin{split}\sum_{j=0}^N ((\pmb{v}\cdot\nabla \varphi_j, \varphi_i) &amp;+ (\alpha \varphi_j ,\varphi_i) + (a\nabla \varphi_j,\nabla \varphi_i))c_j = \\
&amp; (g,\varphi_i)_{N} + (f,\varphi_i) -
(\pmb{v}\cdot\nabla u_0, \varphi_i) + (\alpha u_0 ,\varphi_i) +
(a\nabla u_0,\nabla \varphi_i)
\thinspace .\end{split}\]</div>
<p>This is a linear system with matrix entries</p>
<div class="math">
\[A_{i,j} = (\pmb{v}\cdot\nabla \varphi_j, \varphi_i) + (\alpha \varphi_j ,\varphi_i) + (a\nabla \varphi_j,\nabla \varphi_i)\]</div>
<p>and right-hand side entries</p>
<div class="math">
\[b_i = (g,\varphi_i)_{N} + (f,\varphi_i) -
(\pmb{v}\cdot\nabla u_0, \varphi_i) + (\alpha u_0 ,\varphi_i) +
(a\nabla u_0,\nabla \varphi_i),\]</div>
<p>for <span class="math">\(i,j=0,\ldots,N\)</span>.</p>
<p>In the finite element method, we usually express <span class="math">\(u_0\)</span> in terms of
basis functions and restrict <span class="math">\(i\)</span> and <span class="math">\(j\)</span> to run over the degrees of
freedom that are not prescribed as Dirichlet conditions.
However, we can also keep all the <span class="math">\(c_j\)</span>, <span class="math">\(j=0,\ldots,N\)</span>, as unknowns
drop the <span class="math">\(u_0\)</span> in the expansion for <span class="math">\(u\)</span>, and incorporate all the
known <span class="math">\(c_j\)</span> values in the linear system. This has been explained
in detail in the 1D case.</p>
<div class="section" id="transformation-to-a-reference-cell-in-2d-and-3d">
<h2>Transformation to a reference cell in 2D and 3D<a class="headerlink" href="#transformation-to-a-reference-cell-in-2d-and-3d" title="Permalink to this headline">¶</a></h2>
<p>We consider an integral of the type</p>
<div class="math">
\[\int_{{\Omega}^{(e)}} a(\pmb{x})\nabla\varphi_i\cdot\nabla\varphi_j\, \mathrm{d}x\]</div>
<p>in the physical domain.
Suppose we want to calculate this integral over a reference cell,
denoted by <span class="math">\(\tilde\Omega^r\)</span>, in a coordinate system with coordinates
<span class="math">\(\pmb{X} = (X_0, X_1)\)</span> (2D) or <span class="math">\(\pmb{X} = (X_0, X_1, X_2)\)</span> (3D).
The mapping between a point <span class="math">\(\pmb{X}\)</span> in the reference coordinate system  and
the corresponding point <span class="math">\(\pmb{x}\)</span> in the physical coordinate system is
given by a vector relation <span class="math">\(\pmb{x}(\pmb{X})\)</span>.
The corresponding Jacobian, <span class="math">\(J\)</span>, of this mapping has entries</p>
<div class="math">
\[J_{i,j}=\frac{\partial x_j}{\partial X_i}\thinspace .\]</div>
<p>The change of variables requires <span class="math">\(\, \mathrm{d}x\)</span> to be replaced by <span class="math">\(\det J\, \mathrm{d}X\)</span>.
The derivatives in the <span class="math">\(\nabla\)</span> operator in the variational form are
with respect to <span class="math">\(\pmb{x}\)</span>, which we may denote by <span class="math">\(\nabla_{\pmb{x}}\)</span>.
The <span class="math">\(\varphi_i(\pmb{x})\)</span> functions in the integral
are replaced by local basis functions <span class="math">\(\tilde\varphi_r(\pmb{X})\)</span> so
the integral features <span class="math">\(\nabla_{\pmb{x}}\tilde\varphi_r(\pmb{X})\)</span>. We readily have
<span class="math">\(\nabla_{\pmb{X}}\tilde\varphi_r(\pmb{X})\)</span> from formulas for the basis functions, but
the desired quantity <span class="math">\(\nabla_{\pmb{x}}\tilde\varphi_r(\pmb{X})\)</span> requires some efforts
to compute. All the details are now given.</p>
<p>Let <span class="math">\(i=q(e,r)\)</span> and consider two space dimensions. By the chain rule,</p>
<div class="math">
\[\frac{\partial \tilde\varphi_r}{\partial X} =
\frac{\partial \varphi_i}{\partial X} =
\frac{\partial \varphi_i}{\partial x}\frac{\partial x}{\partial X} +
\frac{\partial \varphi_i}{\partial y}\frac{\partial y}{\partial X},\]</div>
<p>and</p>
<div class="math">
\[\frac{\partial \tilde\varphi_r}{\partial Y} =
\frac{\partial \varphi_i}{\partial Y} =
\frac{\partial \varphi_i}{\partial x}\frac{\partial x}{\partial Y} +
\frac{\partial \varphi_i}{\partial y}\frac{\partial y}{\partial Y}
\thinspace .\]</div>
<p>We can write this as a vector equation</p>
<div class="math">
\[\begin{split}\left[\begin{array}{c}
\frac{\partial \tilde\varphi_r}{\partial X}\\
\frac{\partial \tilde\varphi_r}{\partial Y}
\end{array}\right]
=
\left[\begin{array}{cc}
\frac{\partial x}{\partial X} &amp; \frac{\partial y}{\partial X}\\
\frac{\partial x}{\partial Y} &amp; \frac{\partial y}{\partial Y}
\end{array}\right]
\left[\begin{array}{c}
\frac{\partial \varphi_i}{\partial x}\\
\frac{\partial \varphi_i}{\partial y}
\end{array}\right]\end{split}\]</div>
<p>Identifying</p>
<div class="math">
\[\begin{split}\nabla_{\pmb{X}}\tilde\varphi_r = \left[\begin{array}{c}
\frac{\partial \tilde\varphi_r}{\partial X}\\
\frac{\partial \tilde\varphi_r}{\partial Y}
\end{array}\right],
\quad
J =
\left[\begin{array}{cc}
\frac{\partial x}{\partial X} &amp; \frac{\partial y}{\partial X}\\
\frac{\partial x}{\partial Y} &amp; \frac{\partial y}{\partial Y}
\end{array}\right],
\quad
\nabla_{\pmb{x}}\varphi_r =
\left[\begin{array}{c}
\frac{\partial \varphi_i}{\partial x}\\
\frac{\partial \varphi_i}{\partial y}
\end{array}\right],\end{split}\]</div>
<p>we have the relation</p>
<div class="math">
\[\nabla_{\pmb{X}}\tilde\varphi_r = J\cdot\nabla_{\pmb{x}}\varphi_i,\]</div>
<p>which we can solve with respect to <span class="math">\(\nabla_{\pmb{x}}\varphi_i\)</span>:</p>
<div class="math">
\[\nabla_{\pmb{x}}\varphi_i = J^{-1}\cdot\nabla_{\pmb{X}}\tilde\varphi_r\thinspace .\]</div>
<p>This means that we have the following transformation of the
integral in the physical domain to its counterpart over the reference cell:</p>
<div class="math">
\[\int_{\Omega}^{(e)} a(\pmb{x})\nabla_{\pmb{x}}\varphi_i\cdot\nabla_{\pmb{x}}\varphi_j\, \mathrm{d}x
\int_{\tilde\Omega^r} a(\pmb{x}(\pmb{X}))(J^{-1}\cdot\nabla_{\pmb{X}}\tilde\varphi_r)\cdot
(J^{-1}\cdot\nabla\tilde\varphi_s)\det J\, \mathrm{d}X\]</div>
</div>
<div class="section" id="numerical-integration-2">
<h2>Numerical integration  (2)<a class="headerlink" href="#numerical-integration-2" title="Permalink to this headline">¶</a></h2>
<p>Integrals are normally computed by numerical integration rules.
For multi-dimensional cells, various families of rules exist.
All of them are similar to what is shown in 1D:
<span class="math">\(\int fdx\approx \sum_jw_if(\pmb{x}_j)\)</span>, where <span class="math">\(w_j\)</span> are weights and
<span class="math">\(\pmb{x}_j\)</span> are corresponding points.</p>
</div>
<div class="section" id="convenient-formulas-for-p1-elements-in-2d">
<h2>Convenient formulas for P1 elements in 2D<a class="headerlink" href="#convenient-formulas-for-p1-elements-in-2d" title="Permalink to this headline">¶</a></h2>
<p>We shall now provide some formulas for piecewise linear <span class="math">\(\varphi_i\)</span> functions
and their integrals <em>in the physical coordinate system</em>.
These formulas make it convenient to compute with P1 elements without
the need to work in the reference coordinate system and deal with mappings
and Jacobians.
A lot of computational and algorithmic details are hidden by this approach.</p>
<p>Let <span class="math">\(\Omega^{(e)}\)</span> be cell number <span class="math">\(e\)</span>, and let the three vertices
have global vertex numbers <span class="math">\(I\)</span>, <span class="math">\(j\)</span>, and <span class="math">\(K\)</span>.
The corresponding coordinates are
<span class="math">\((x_{I},y_{I})\)</span>, <span class="math">\((x_{J},y_{J})\)</span>, and <span class="math">\((x_{K},y_{K})\)</span>.
The basis function <span class="math">\(\varphi_I\)</span> over <span class="math">\(\Omega^{(e)}\)</span> have the explicit
formula</p>
<div class="math" id="equation-fem:approx:fe:2D:phi:I">
<span class="eqno">(63)</span>\[     \varphi_I (x,y) = \frac{1}{2}\Delta \left( \alpha_I + \beta_Ix
     + \gamma_Iy\right),\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\alpha_I &amp;= x_{J}y_{K} - x_{K}y_{J},
\\
\beta_I &amp;= y_{J} - y_{K},
\\
\gamma_I &amp;= x_{K} - x_{J},
\\
2\Delta &amp;= \det\left(\begin{array}{rrr}
1 &amp; x_{I} &amp; y_{I} \\
1 &amp; x_{J} &amp; y_{J} \\
1 &amp; x_{K} &amp; y_{K} \end{array}\right)
\thinspace .\end{split}\]</div>
<p>The quantity <span class="math">\(\Delta\)</span> is the area of the cell.</p>
<p>The following formula is often convenient when computing element matrices
and vectors:</p>
<div class="math" id="equation-fem:approx:fe:2D:phi:integral">
<span class="eqno">(64)</span>\[     \int_{\Omega^{(e)}} \varphi_I^{p}\varphi_J^{q}\varphi_K^{r} dx dy =
     {p!q!r!\over (p+q+r+2)!}2\Delta\]\[     \thinspace .\]</div>
<p>(Note that the <span class="math">\(q\)</span> in this formula is not to be mixed with the <span class="math">\(q(e,r)\)</span>
mapping of degrees of freedom.)</p>
<p>As an example, the element matrix entry
<span class="math">\(\int_{\Omega^{(e)}} \varphi_I\varphi_J\, \mathrm{d}x\)</span>
can be computed by setting
<span class="math">\(p=q=1\)</span> and <span class="math">\(r=0\)</span>, when <span class="math">\(I\neq J\)</span>, yielding <span class="math">\(\Delta/12\)</span>, and
<span class="math">\(p=2\)</span> and <span class="math">\(q=r=0\)</span>, when <span class="math">\(I=J\)</span>, resulting in <span class="math">\(\Delta/6\)</span>.
We collect these numbers in a local element matrix:</p>
<div class="math">
\[\begin{split}\frac{\Delta}{12}
\left[\begin{array}{ccc}
2 &amp; 1 &amp; 1\\
1 &amp; 2 &amp; 1\\
1 &amp; 1 &amp; 2
\end{array}\right]\end{split}\]</div>
<p>The common element matrix entry <span class="math">\(\int_{\Omega^{(e)}} \nabla\varphi_I\cdot\nabla\varphi_J\, \mathrm{d}x\)</span>, arising from a Laplace term <span class="math">\(\nabla^u\)</span>, can also easily be
computed by the formulas above. We have</p>
<div class="math">
\[\nabla\varphi_I\cdot\nabla\varphi_J =
\frac{\Delta^2}{4}(\beta_I\beta_J + \gamma_I\gamma_J) = \hbox{const},\]</div>
<p>so that the element matrix entry becomes
<span class="math">\(\frac{1}{4}(\Delta^3\beta_I\beta_J + \gamma_I\gamma_J)\)</span>.</p>
<p>From an implementational point of view, one will work with local vertex
numbers <span class="math">\(r=1,2,3\)</span>, parameterize the coefficients in the basis
functions by <span class="math">\(r\)</span>, and look up vertex coordinates through <span class="math">\(q(e,r)\)</span>.</p>
</div>
</div>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><ul>
<li><p class="first">When approximating <span class="math">\(f\)</span> by <span class="math">\(u = \sum_j c_j\varphi_j\)</span>, the least squares
method and the Galerkin/projection method give the same result.
The interpolation/collocation method is simpler and yields different
(mostly inferior) results.</p>
</li>
<li><p class="first">Fourier series expansion can be viewed as a least squares or Galerkin
approximation procedure with sine and cosine functions.</p>
</li>
<li><p class="first">Basis functions should optimally be orthogonal or almost orthogonal,
because this gives little round-off errors when solving the linear
system, and the coefficient matrix becomes diagonal or sparse.</p>
</li>
<li><p class="first">Finite element basis functions are <em>piecewise</em> polynomials, normally
with discontinuous derivatives at the cell boundaries. The basis
functions overlap very little, leading to stable numerics and sparse
matrices.</p>
</li>
<li><p class="first">To use the finite element method for differential equations, we use
the Galerkin method or the method of weighted residuals
to arrive at a variational form. Technically, the differential equation
is multiplied by a test function and integrated over the domain.
Second-order derivatives are integrated by parts to allow for typical finite
element basis functions that have discontinuous derivatives.</p>
</li>
<li><p class="first">The least squares method is not much used for finite element solution
of differential equations of second order, because
it then involves second-order derivatives which cause trouble for
basis functions with discontinuous derivatives.</p>
</li>
<li><p class="first">We have worked with two common finite element terminologies and
associated data structures
(both are much used, especially the first one, while the other is more
general):</p>
<blockquote>
<div><ol class="arabic simple">
<li><em>elements</em>, <em>nodes</em>, and <em>mapping between local and global
node numbers</em></li>
<li>an extended element concept consisting of <em>cell</em>, <em>vertices</em>,
<em>degrees of freedom</em>, <em>local basis functions</em>,
<em>geometry mapping</em>, and <em>mapping between
local and global degrees of freedom</em></li>
</ol>
</div></blockquote>
</li>
<li><p class="first">The meaning of the word &#8220;element&#8221; is multi-fold: the geometry of a finite
element (also known as a cell), the geometry and its basis functions,
or all information listed under point 2 above.</p>
</li>
<li><p class="first">One normally computes integrals in the finite element method element
by element (cell by cell), either in a local reference coordinate
system or directly in the physical domain.</p>
</li>
<li><p class="first">The advantage of working in the reference coordinate system is that
the mathematical expressions for the basis functions depend on the
element type only, not the geometry of that element in the physical
domain.  The disadvantage is that a mapping must be used, and
derivatives must be transformed from reference to physical
coordinates.</p>
</li>
<li><p class="first">Element contributions to the global linear system are collected in
an element matrix and vector, which must be assembled into the
global system using the degree of freedom mapping (<tt class="docutils literal"><span class="pre">dof_map</span></tt>) or
the node numbering mapping (<tt class="docutils literal"><span class="pre">elements</span></tt>), depending on which terminology
that is used.</p>
</li>
<li><p class="first">Dirichlet conditions, involving prescribed values of <span class="math">\(u\)</span> at the
boundary, are implemented either via a boundary function that take
on the right Dirichlet values, while the basis functions vanish at
such boundaries. In the finite element method, one has a general
expression for the boundary function, but one can also incorporate
Dirichlet conditions in the element matrix and vector or in the
global matrix system.</p>
</li>
<li><p class="first">Neumann conditions, involving prescribed values of the derivative
(or flux) of <span class="math">\(u\)</span>, are incorporated in boundary terms arising from
integrating terms with second-order derivatives by part.
Forgetting to account for the boundary terms implies the
condition <span class="math">\(\partial u/\partial n=0\)</span> at parts of the boundary where
no Dirichlet condition is set.</p>
</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="exercises-2">
<h1>Exercises  (2)<a class="headerlink" href="#exercises-2" title="Permalink to this headline">¶</a></h1>
<div class="section" id="exercise-17-compute-the-deflection-of-a-cable-with-sine-functions">
<span id="fem-deq-exer-tension-cable"></span><h2>Exercise 17: Compute the deflection of a cable with sine functions<a class="headerlink" href="#exercise-17-compute-the-deflection-of-a-cable-with-sine-functions" title="Permalink to this headline">¶</a></h2>
<p>A hanging cable of length <span class="math">\(L\)</span>
with significant tension has a downward deflection <span class="math">\(w(x)\)</span>
governed by</p>
<p>Solve</p>
<div class="math">
\[T w''(x) = ell(x),\]</div>
<p>where <span class="math">\(T\)</span> is the tension in the cable
and <span class="math">\(\ell(x)\)</span> the load per unit length.
The cable is fixed at <span class="math">\(x=0\)</span> and <span class="math">\(x=L\)</span> so the boundary conditions become
<span class="math">\(T(0)=T(L)=0\)</span>. We assume a constant load <span class="math">\(\ell(x)=\hbox{const}\)</span>.</p>
<p>The solution is expected to be symmetric around <span class="math">\(x=L/2\)</span>. Formulating
the problem for <span class="math">\(x\in [0,L/2]\)</span> and then scaling it, results in
the scaled problem for the dimensionless vertical deflection <span class="math">\(u\)</span>:</p>
<div class="math">
\[u'' = 1,\quad x\in (0,1),\quad u(0)=0,\ u'(1)=0\thinspace\]</div>
<p>Introduce the function space spanned by <span class="math">\(\varphi_i=\sin ((i+1)\pi x/2)\)</span>,
<span class="math">\(i=1,\ldots,N\)</span>.
Use a Galerkin and a least squares method to find the coefficients
<span class="math">\(c_j\)</span> in <span class="math">\(u(x)=\sum_j c_j\varphi_j\)</span>.
Find the error in the maximum deflection at <span class="math">\(x=1\)</span> when only one
basis function is used (<span class="math">\(N=0\)</span>).</p>
<p>What happens if we choose basis functions
<span class="math">\(\varphi_i=\sin ((i+1)\pi x)\)</span>?
Filename: <tt class="docutils literal"><span class="pre">cable_sin.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-18-check-integration-by-parts">
<span id="fem-deq-exer-intg-parts"></span><h2>Exercise 18: Check integration by parts<a class="headerlink" href="#exercise-18-check-integration-by-parts" title="Permalink to this headline">¶</a></h2>
<p>Consider the Galerkin method for the problem involving <span class="math">\(u\)</span>
in <a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 17: Compute the deflection of a cable with sine functions</em></a>.
Show that the formulas for <span class="math">\(c_j\)</span> are independent of whether we perform
integration by parts or not.
Filename: <tt class="docutils literal"><span class="pre">integr_by_parts.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-19-compute-the-deflection-of-a-cable-with-2-p1-elements">
<span id="id13"></span><h2>Exercise 19: Compute the deflection of a cable with 2 P1 elements<a class="headerlink" href="#exercise-19-compute-the-deflection-of-a-cable-with-2-p1-elements" title="Permalink to this headline">¶</a></h2>
<p>Solve the problem for <span class="math">\(u\)</span> in <a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 17: Compute the deflection of a cable with sine functions</em></a>
using two P1 linear elements.
Filename: <tt class="docutils literal"><span class="pre">cable_2P1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-20-compute-the-deflection-of-a-cable-with-1-p2-element">
<span id="id14"></span><h2>Exercise 20: Compute the deflection of a cable with 1 P2 element<a class="headerlink" href="#exercise-20-compute-the-deflection-of-a-cable-with-1-p2-element" title="Permalink to this headline">¶</a></h2>
<p>Solve the problem for <span class="math">\(u\)</span> in <a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 17: Compute the deflection of a cable with sine functions</em></a>
using one P2 linear element.
Filename: <tt class="docutils literal"><span class="pre">cable_1P2.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-21-compute-the-deflection-of-a-cable-with-a-step-load">
<span id="id15"></span><h2>Exercise 21: Compute the deflection of a cable with a step load<a class="headerlink" href="#exercise-21-compute-the-deflection-of-a-cable-with-a-step-load" title="Permalink to this headline">¶</a></h2>
<p>We consider the deflection of a tension cable as described in
<a class="reference internal" href="#fem-deq-exer-tension-cable"><em>Exercise 17: Compute the deflection of a cable with sine functions</em></a>. Now the load is <span class="math">\(\ell_1\)</span>
for <span class="math">\(x&lt;L/2\)</span> and <span class="math">\(\ell_2\)</span> for <span class="math">\(x\geq L/2\)</span>. This load is not symmetric
with respect to the midpoint <span class="math">\(x=L/2\)</span> so the solution loses its symmetry
and we must solve</p>
<div class="math">
\[\begin{split}u'' =\left\lbrace\begin{array}{ll}
1, &amp; x &lt;1/2,\\
0, &amp; x \geq 1/2
\end{array}\right.
\quad x\in (0,1),\quad u(0)=0,\ u(1)=0
\thinspace .\end{split}\]</div>
<p>Filename: <tt class="docutils literal"><span class="pre">cable_discont_load.pdf</span></tt>.</p>
<p><em>a)</em> Use <span class="math">\(\varphi_i = \sin((i+1)\pi x)\)</span>, <span class="math">\(i=0,\ldots,N\)</span> and the Galerkin method
without integration by parts. Derive a formula
for <span class="math">\(c_j\)</span> in the solution expansion <span class="math">\(u=\sum_j c_j\varphi_j\)</span>.
Plot how fast the coefficients <span class="math">\(c_j\)</span> tend to zero (on a log scale).</p>
<p><em>b)</em> Solve the problem with P1 finite elements.
Plot the solution for <span class="math">\(n_e=2,4,8\)</span> elements.
.. &#8212; end of exercise</p>
</div>
<div class="section" id="exercise-22-show-equivalence-between-linear-systems">
<span id="fem-deq-exer-aub-essbc-equiv"></span><h2>Exercise 22: Show equivalence between linear systems<a class="headerlink" href="#exercise-22-show-equivalence-between-linear-systems" title="Permalink to this headline">¶</a></h2>
<p>Incorporation of Dirichlet conditions can either be done by
introducing an expansion <span class="math">\(u(x)=U_0\varphi_0 + U_N\varphi_N + \sum_{j=1}^{N-1}
c_j\varphi_j\)</span> and considering <span class="math">\(c_1,\dots,c_{N-1}\)</span> as unknowns, <em>or</em>
one can assemble the matrix system with <span class="math">\(u(x)=\sum_{j=0}^{N}
c_j\varphi_j\)</span> and afterwards replace the rows corresponding to known
<span class="math">\(c_j\)</span> values by the boundary conditions.
The purpose of this exercise is to show the equivalence of these two
approaches. Consider 1) the system <a href="#equation-fem:deq:1D:ex1:Ab:glob3">(54)</a>
modified for the boundary value <span class="math">\(u(L)=D\)</span> as explained in
the section <em class="xref std std-ref">fem:deq:1D:essBC:Bfunc</em>, and 2) the system
<a href="#equation-fem:deq:1D:ex1:Ab:glob3">(54)</a> where all <span class="math">\(c_0,\ldots,c_N\)</span> are
involved. Show that eliminating <span class="math">\(c_1\)</span> and <span class="math">\(c_N\)</span> from
<a href="#equation-fem:deq:1D:ex1:Ab:glob3">(54)</a> results in the other system.</p>
</div>
<div class="section" id="exercise-23-compute-with-a-non-uniform-mesh">
<span id="fem-deq-exer-1d-mesh-nonuniform"></span><h2>Exercise 23: Compute with a non-uniform mesh<a class="headerlink" href="#exercise-23-compute-with-a-non-uniform-mesh" title="Permalink to this headline">¶</a></h2>
<p>Derive the linear system for the problem <span class="math">\(-u''=2\)</span> on <span class="math">\([0,1]\)</span>,
with <span class="math">\(u(0)=0\)</span> and <span class="math">\(u(1)=1\)</span>, using P1 elements and a <em>non-uniform</em>
mesh. The vertices have coordinates <span class="math">\(x_{0}=0 &lt; x_{1} &lt;\cdots &lt; x_{N}=1\)</span>,
and the length of cell number <span class="math">\(e\)</span> is <span class="math">\(h_e = x_{e+1} -x_{e}\)</span>.</p>
<p>It is of interest to compare the discrete equations for the finite element
method in a non-uniform mesh with the corresponding discrete equations
arising from a finite difference method. Repeat the reasoning for
the finite difference formula <span class="math">\(u''(x_i) \approx [D_x D_x u]_i\)</span> and
use it to find a natural discretization of <span class="math">\(u''(x_i)\)</span> on a non-uniform
mesh.</p>
</div>
<div class="section" id="exercise-24-solve-a-1d-finite-element-problem-by-hand">
<span id="fem-deq-exer-1d-gen-problem1"></span><h2>Exercise 24: Solve a 1D finite element problem by hand<a class="headerlink" href="#exercise-24-solve-a-1d-finite-element-problem-by-hand" title="Permalink to this headline">¶</a></h2>
<p>The following 1D problem is a very simple, yet relevant, model
for convective transport in fluids:</p>
<div class="math">
\[u' = \epsilon u'' ,\quad u(0)=0,\ u(1)=1,\ x\in [0,1]
\thinspace .\]</div>
<p>Filename: <tt class="docutils literal"><span class="pre">convdiff1D_P1.pdf</span></tt>.</p>
<p><em>a)</em> Find the analytical solution to this problem.
(Introduce <span class="math">\(w=u'\)</span>, solve the first-order differential equation for <span class="math">\(w(x)\)</span>,
and integrate once more.)</p>
<p><em>b)</em> Derive the variational form of this problem.</p>
<p><em>c)</em> Introduce a finite element mesh with uniform partitioning.
Use P1 elements and compute the element matrix and vector for
a general element.</p>
<p><em>d)</em> Incorporate the boundary conditions and
assemble the element contributions.</p>
<p><em>e)</em> Identify the resulting linear system as a finite difference discretization
of the differential equation using</p>
<div class="math">
\[[D_{2x}u = \epsilon D_xD_x u]_i \thinspace .\]</div>
<p><em>f)</em> Compute the numerical solution and plot it together with the exact solution
for a mesh with 20 elements and
<span class="math">\(\epsilon=0.1, 0.01\)</span>.
.. &#8212; end of exercise</p>
</div>
<div class="section" id="exercise-25-compute-with-variable-coefficients-and-p1-elements-by-hand">
<span id="fem-deq-exer-1d-gen-problem2"></span><h2>Exercise 25: Compute with variable coefficients and P1 elements by hand<a class="headerlink" href="#exercise-25-compute-with-variable-coefficients-and-p1-elements-by-hand" title="Permalink to this headline">¶</a></h2>
<p>Consider the problem</p>
<div class="math" id="equation-fem:deq:1D:model4">
<span class="eqno">(65)</span>\[     -\frac{d}{dx}\left( a(x)\frac{du}{dx}\right) + \gamma u = f(x),
     \quad x\in\Omega=[0,L],\quad u(0)=\alpha,\ u'(L)=\beta\thinspace .\]</div>
<p>We choose <span class="math">\(a(x)=1+x^2\)</span>. Then</p>
<div class="math">
\[u(x) = \alpha + \beta(1+L^2)\tan^{-1}(x),\]</div>
<p>is an exact solution if</p>
<div class="math">
\[f(x) = \gamma u
\thinspace .\]</div>
<p>Derive a variational formulation and compute general expressions for the
element matrix and vector in an arbitrary element, using P1 elements
and a uniform partitioning of <span class="math">\([0,L]\)</span>. The right-hand side
integral is challenging and can be computed by a numerical integration
rule. The Trapezoidal rule <a href="#equation-fem:approx:fe:numint1:trapez">(28)</a>
gives particularly simple expressions.
Filename: <tt class="docutils literal"><span class="pre">tanh1D_P1.pdf</span></tt>.</p>
</div>
<div class="section" id="exercise-26-solve-a-2d-poisson-equation-using-polynomials-and-sines">
<span id="fem-deq-exer-2d-torsion-xy-sin"></span><h2>Exercise 26: Solve a 2D Poisson equation using polynomials and sines<a class="headerlink" href="#exercise-26-solve-a-2d-poisson-equation-using-polynomials-and-sines" title="Permalink to this headline">¶</a></h2>
<p>The classical problem of applying a torque to the ends of a rod
can be modeled by a Poisson equation defined in the cross section <span class="math">\(\Omega\)</span>:</p>
<div class="math">
\[-\nabla^2 u = 2,\quad (x,y)\in\Omega,\]</div>
<p>with <span class="math">\(u=0\)</span> on <span class="math">\(\partial\Omega\)</span>. Exactly the same problem arises for
the deflection of a membrane with shape <span class="math">\(\Omega\)</span> under a constant load.</p>
<p>For a circular cross section one can readily
find an analytical solution. For a rectangular cross section the analytical
approach ends up with a sine series. The idea in this exercise is to
use a single basis function to obtain an approximate answer.</p>
<p>We assume for simplicity that the cross section is the unit square:
<span class="math">\(\Omega = [0,1]\times [0,1]\)</span>.
Filename: <tt class="docutils literal"><span class="pre">torsion_sin_xy.pdf</span></tt>.</p>
<p><em>a)</em> We consider the basis
<span class="math">\(\varphi_{p,q}(x,y) = \sin((p+1)\pi x)\sin (q\pi y)\)</span>, <span class="math">\(p,q=0,\ldots,n\)</span>.
These basis functions fulfill the Dirichlet condition.
Use a Galerkin method and <span class="math">\(n=0\)</span>.</p>
<p><em>b)</em> The basis function involving sine functions are orthogonal.
Use this property in the Galerkin method
to derive the coefficients <span class="math">\(c_{p,q}\)</span> in a
formula <span class="math">\(u=\sum_p\sum_q c_{p,q}\varphi_{p,q}(x,y)\)</span>.</p>
<p><em>c)</em> Another possible basis is
<span class="math">\(\varphi_i(x,y) = (x(1-x)y(1-y))^{i+1}\)</span>, <span class="math">\(i=0,\ldots,N\)</span>.
Use the Galerkin method to compute the solution for <span class="math">\(N=0\)</span>.
Which choice of a single basis function is best,
<span class="math">\(u\sim x(1-x)y(1-y)\)</span> or <span class="math">\(u\sim \sin(\pi x)\sin(\pi y)\)</span>?
In order to answer the question,
it is necessary to search the web or the literature for an accurate
estimate of the maximum <span class="math">\(u\)</span> value at <span class="math">\(x=y=1/2\)</span>.
.. &#8212; end of exercise</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Basic finite element methods</a></li>
<li><a class="reference internal" href="#approximation-of-vectors">Approximation of vectors</a><ul>
<li><a class="reference internal" href="#approximation-of-planar-vectors">Approximation of planar vectors</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-1">The least squares method  (1)</a></li>
<li><a class="reference internal" href="#the-galerkin-or-projection-method-1">The Galerkin or projection method  (1)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-general-vectors">Approximation of general vectors</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-2">The least squares method  (2)</a></li>
<li><a class="reference internal" href="#the-galerkin-or-projection-method-2">The Galerkin or projection method  (2)</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-functions">Approximation of functions</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-3">The least squares method  (3)</a></li>
<li><a class="reference internal" href="#the-galerkin-or-projection-method-3">The Galerkin or projection method  (3)</a></li>
<li><a class="reference internal" href="#example-linear-approximation">Example: linear approximation</a></li>
<li><a class="reference internal" href="#implementation-of-the-least-squares-method">Implementation of the least squares method</a></li>
<li><a class="reference internal" href="#perfect-approximation">Perfect approximation</a></li>
<li><a class="reference internal" href="#ill-conditioning">Ill-conditioning</a></li>
<li><a class="reference internal" href="#fourier-series">Fourier series</a></li>
<li><a class="reference internal" href="#orthogonal-basis-functions">Orthogonal basis functions</a></li>
<li><a class="reference internal" href="#the-collocation-interpolation-method">The collocation (interpolation) method</a><ul>
<li><a class="reference internal" href="#example-1">Example  (1)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lagrange-polynomials">Lagrange polynomials</a><ul>
<li><a class="reference internal" href="#successful-example">Successful example</a></li>
<li><a class="reference internal" href="#less-successful-example">Less successful example</a></li>
<li><a class="reference internal" href="#remedy-for-strong-oscillations">Remedy for strong oscillations</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#finite-element-basis-functions">Finite element basis functions</a><ul>
<li><a class="reference internal" href="#elements-and-nodes">Elements and nodes</a><ul>
<li><a class="reference internal" href="#example-2">Example  (2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-basis-functions">The basis functions</a><ul>
<li><a class="reference internal" href="#construction-principles">Construction principles</a></li>
<li><a class="reference internal" href="#properties-of">Properties of <span class="math">\(\varphi_i\)</span></a></li>
<li><a class="reference internal" href="#example-on-quadratic">Example on quadratic <span class="math">\(\varphi_i\)</span></a></li>
<li><a class="reference internal" href="#example-on-linear">Example on linear <span class="math">\(\varphi_i\)</span></a></li>
<li><a class="reference internal" href="#example-on-cubic">Example on cubic <span class="math">\(\varphi_i\)</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#calculating-the-linear-system">Calculating the linear system</a></li>
<li><a class="reference internal" href="#assembly-of-elementwise-computations">Assembly of elementwise computations</a></li>
<li><a class="reference internal" href="#mapping-to-a-reference-element">Mapping to a reference element</a></li>
<li><a class="reference internal" href="#integration-over-a-reference-element">Integration over a reference element</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-1">Implementation  (1)</a><ul>
<li><a class="reference internal" href="#integration">Integration</a></li>
<li><a class="reference internal" href="#linear-system-assembly-and-solution">Linear system assembly and solution</a></li>
<li><a class="reference internal" href="#example-on-computing-approximations">Example on computing approximations</a></li>
<li><a class="reference internal" href="#the-structure-of-the-coefficient-matrix">The structure of the coefficient matrix</a></li>
<li><a class="reference internal" href="#applications">Applications</a></li>
<li><a class="reference internal" href="#sparse-matrix-storage-and-solution">Sparse matrix storage and solution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comparison-of-finite-element-and-finite-difference-approximation">Comparison of finite element and finite difference approximation</a><ul>
<li><a class="reference internal" href="#collocation-or-interpolation">Collocation or interpolation</a></li>
<li><a class="reference internal" href="#finite-difference-approximation-of-given-functions">Finite difference approximation of given functions</a></li>
<li><a class="reference internal" href="#finite-difference-interpretation-of-a-finite-element-approximation">Finite difference interpretation of a finite element approximation</a></li>
<li><a class="reference internal" href="#making-finite-elements-behave-as-finite-differences">Making finite elements behave as finite differences</a><ul>
<li><a class="reference internal" href="#elementwise-computations-1">Elementwise computations  (1)</a></li>
<li><a class="reference internal" href="#terminology">Terminology</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#a-generalized-element-concept">A generalized element concept</a><ul>
<li><a class="reference internal" href="#cells-vertices-and-degrees-of-freedom">Cells, vertices, and degrees of freedom</a></li>
<li><a class="reference internal" href="#extended-finite-element-concept">Extended finite element concept</a></li>
<li><a class="reference internal" href="#implementation-2">Implementation  (2)</a></li>
<li><a class="reference internal" href="#cubic-hermite-polynomials">Cubic Hermite polynomials</a></li>
</ul>
</li>
<li><a class="reference internal" href="#numerical-integration-1">Numerical integration  (1)</a><ul>
<li><a class="reference internal" href="#newton-cotes-rules">Newton-Cotes rules</a></li>
<li><a class="reference internal" href="#gauss-legendre-rules-with-optimized-points">Gauss-Legendre rules with optimized points</a></li>
</ul>
</li>
<li><a class="reference internal" href="#approximation-of-functions-in-2d">Approximation of functions in 2D</a><ul>
<li><a class="reference internal" href="#global-basis-functions-1">Global basis functions  (1)</a><ul>
<li><a class="reference internal" href="#constructing-2d-basis-functions-from-1d-functions">Constructing 2D basis functions from 1D functions</a></li>
<li><a class="reference internal" href="#hand-calculations">Hand calculations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-3">Implementation  (3)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#finite-elements-in-2d-and-3d">Finite elements in 2D and 3D</a><ul>
<li><a class="reference internal" href="#basis-functions-over-triangles-in-the-physical-domain">Basis functions over triangles in the physical domain</a><ul>
<li><a class="reference internal" href="#element-matrices-and-vectors">Element matrices and vectors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#basis-functions-over-triangles-in-the-reference-cell">Basis functions over triangles in the reference cell</a></li>
<li><a class="reference internal" href="#affine-mapping-of-the-reference-cell">Affine mapping of the reference cell</a></li>
<li><a class="reference internal" href="#isoparametric-mapping-of-the-reference-cell">Isoparametric mapping of the reference cell</a></li>
<li><a class="reference internal" href="#computing-integrals">Computing integrals</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises-1">Exercises  (1)</a><ul>
<li><a class="reference internal" href="#exercise-1-linear-algebra-refresher-i">Exercise 1: Linear algebra refresher I</a></li>
<li><a class="reference internal" href="#exercise-2-linear-algebra-refresher-ii">Exercise 2: Linear algebra refresher II</a></li>
<li><a class="reference internal" href="#exercise-3-approximate-a-three-dimensional-vector-in-a-plane">Exercise 3: Approximate a three-dimensional vector in a plane</a></li>
<li><a class="reference internal" href="#exercise-4-approximate-the-exponential-function-by-power-functions">Exercise 4: Approximate the exponential function by power functions</a></li>
<li><a class="reference internal" href="#exercise-5-approximate-a-high-frequency-sine-function-by-lower-frequency-sines">Exercise 5: Approximate a high frequency sine function by lower frequency sines</a></li>
<li><a class="reference internal" href="#exercise-6-fourier-series-as-a-least-squares-approximation">Exercise 6: Fourier series as a least squares approximation</a></li>
<li><a class="reference internal" href="#exercise-7-approximate-a-function-by-lagrange-polynomials">Exercise 7: Approximate a <span class="math">\(\tanh\)</span> function by Lagrange polynomials</a></li>
<li><a class="reference internal" href="#exercise-8-define-finite-element-meshes">Exercise 8: Define finite element meshes</a></li>
<li><a class="reference internal" href="#exercise-9-construct-matrix-sparsity-patterns">Exercise 9: Construct matrix sparsity patterns</a></li>
<li><a class="reference internal" href="#exercise-10-perform-symbolic-finite-element-computations">Exercise 10: Perform symbolic finite element computations</a></li>
<li><a class="reference internal" href="#exercise-11-approximate-a-function-by-p1-and-p2-elements">Exercise 11: Approximate a <span class="math">\(\tanh\)</span> function by P1 and P2 elements</a></li>
<li><a class="reference internal" href="#exercise-12-approximate-a-function-by-p3-and-p4-elements">Exercise 12: Approximate a <span class="math">\(\tanh\)</span> function by P3 and P4 elements</a></li>
<li><a class="reference internal" href="#exercise-13-investigate-the-approximation-errors-in-finite-elements">Exercise 13: Investigate the approximation errors in finite elements</a></li>
<li><a class="reference internal" href="#exercise-14-approximate-a-step-function-by-finite-elements">Exercise 14: Approximate a step function by finite elements</a></li>
<li><a class="reference internal" href="#exercise-15-2d-approximation-with-orthogonal-functions">Exercise 15: 2D approximation with orthogonal functions</a></li>
<li><a class="reference internal" href="#exercise-16-use-the-trapezoidal-rule-and-p1-elements">Exercise 16: Use the Trapezoidal rule and P1 elements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#basic-principles-for-approximating-differential-equations">Basic principles for approximating differential equations</a><ul>
<li><a class="reference internal" href="#differential-equation-models">Differential equation models</a></li>
<li><a class="reference internal" href="#residual-minimizing-principles">Residual-minimizing principles</a><ul>
<li><a class="reference internal" href="#the-least-squares-method-4">The least squares method  (4)</a></li>
<li><a class="reference internal" href="#the-galerkin-method-1">The Galerkin method  (1)</a></li>
<li><a class="reference internal" href="#the-method-of-weighted-residuals">The Method of Weighted Residuals</a></li>
<li><a class="reference internal" href="#variational-formulation">Variational Formulation</a></li>
<li><a class="reference internal" href="#test-and-trial-functions">Test and Trial Functions</a></li>
<li><a class="reference internal" href="#the-collocation-method-1">The collocation method  (1)</a></li>
<li><a class="reference internal" href="#the-subdomain-collocation-method">The subdomain collocation method</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-on-using-the-principles">Examples on using the principles</a><ul>
<li><a class="reference internal" href="#the-residual">The residual</a></li>
<li><a class="reference internal" href="#the-least-squares-method-5">The least squares method  (5)</a></li>
<li><a class="reference internal" href="#the-galerkin-method-2">The Galerkin method  (2)</a></li>
<li><a class="reference internal" href="#the-collocation-method-2">The collocation method  (2)</a></li>
<li><a class="reference internal" href="#comparison">Comparison</a></li>
</ul>
</li>
<li><a class="reference internal" href="#integration-by-parts">Integration by parts</a></li>
<li><a class="reference internal" href="#boundary-function">Boundary function</a></li>
<li><a class="reference internal" href="#abstract-notation-for-variational-formulations">Abstract notation for variational formulations</a></li>
<li><a class="reference internal" href="#more-examples-on-variational-formulations">More examples on variational formulations</a><ul>
<li><a class="reference internal" href="#variable-coefficient">Variable coefficient</a></li>
<li><a class="reference internal" href="#first-order-derivative-in-the-equation-and-boundary-condition">First-order derivative in the equation and boundary condition</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-on-handling-dirichlet-and-neumann-conditions">Example on handling Dirichlet and Neumann conditions</a><ul>
<li><a class="reference internal" href="#nonlinear-terms">Nonlinear terms</a></li>
</ul>
</li>
<li><a class="reference internal" href="#variational-problems-and-optimization-of-functionals">Variational problems and optimization of functionals</a></li>
</ul>
</li>
<li><a class="reference internal" href="#computing-with-finite-elements">Computing with finite elements</a><ul>
<li><a class="reference internal" href="#computation-in-the-global-physical-domain">Computation in the global physical domain</a></li>
<li><a class="reference internal" href="#elementwise-computations-2">Elementwise computations  (2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#boundary-conditions-specified-value">Boundary conditions: specified value</a><ul>
<li><a class="reference internal" href="#general-construction-of-a-boundary-function">General construction of a boundary function</a><ul>
<li><a class="reference internal" href="#example-3">Example  (3)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#modification-of-the-linear-system">Modification of the linear system</a></li>
<li><a class="reference internal" href="#symmetric-modification-of-the-linear-system">Symmetric modification of the linear system</a></li>
<li><a class="reference internal" href="#modification-of-the-element-matrix-and-vector">Modification of the element matrix and vector</a></li>
</ul>
</li>
<li><a class="reference internal" href="#boundary-conditions-specified-derivative">Boundary conditions: specified derivative</a><ul>
<li><a class="reference internal" href="#the-variational-formulation">The variational formulation</a></li>
<li><a class="reference internal" href="#direct-computation-of-the-global-linear-system">Direct computation of the global linear system</a></li>
<li><a class="reference internal" href="#elementwise-computations-3">Elementwise computations  (3)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-4">Implementation  (4)</a><ul>
<li><a class="reference internal" href="#global-basis-functions-2">Global basis functions  (2)</a></li>
<li><a class="reference internal" href="#example-constant-right-hand-side">Example: constant right-hand side</a></li>
<li><a class="reference internal" href="#finite-elements">Finite elements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#variational-formulations-in-2d-and-3d">Variational formulations in 2D and 3D</a><ul>
<li><a class="reference internal" href="#transformation-to-a-reference-cell-in-2d-and-3d">Transformation to a reference cell in 2D and 3D</a></li>
<li><a class="reference internal" href="#numerical-integration-2">Numerical integration  (2)</a></li>
<li><a class="reference internal" href="#convenient-formulas-for-p1-elements-in-2d">Convenient formulas for P1 elements in 2D</a></li>
</ul>
</li>
<li><a class="reference internal" href="#summary">Summary</a></li>
<li><a class="reference internal" href="#exercises-2">Exercises  (2)</a><ul>
<li><a class="reference internal" href="#exercise-17-compute-the-deflection-of-a-cable-with-sine-functions">Exercise 17: Compute the deflection of a cable with sine functions</a></li>
<li><a class="reference internal" href="#exercise-18-check-integration-by-parts">Exercise 18: Check integration by parts</a></li>
<li><a class="reference internal" href="#exercise-19-compute-the-deflection-of-a-cable-with-2-p1-elements">Exercise 19: Compute the deflection of a cable with 2 P1 elements</a></li>
<li><a class="reference internal" href="#exercise-20-compute-the-deflection-of-a-cable-with-1-p2-element">Exercise 20: Compute the deflection of a cable with 1 P2 element</a></li>
<li><a class="reference internal" href="#exercise-21-compute-the-deflection-of-a-cable-with-a-step-load">Exercise 21: Compute the deflection of a cable with a step load</a></li>
<li><a class="reference internal" href="#exercise-22-show-equivalence-between-linear-systems">Exercise 22: Show equivalence between linear systems</a></li>
<li><a class="reference internal" href="#exercise-23-compute-with-a-non-uniform-mesh">Exercise 23: Compute with a non-uniform mesh</a></li>
<li><a class="reference internal" href="#exercise-24-solve-a-1d-finite-element-problem-by-hand">Exercise 24: Solve a 1D finite element problem by hand</a></li>
<li><a class="reference internal" href="#exercise-25-compute-with-variable-coefficients-and-p1-elements-by-hand">Exercise 25: Compute with variable coefficients and P1 elements by hand</a></li>
<li><a class="reference internal" href="#exercise-26-solve-a-2d-poisson-equation-using-polynomials-and-sines">Exercise 26: Solve a 2D Poisson equation using polynomials and sines</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Basic finite element methods</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="index.html" title="Basic finite element methods"
             >previous</a> |</li>
        <li><a href="index.html">Basic finite element methods 1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2012, H. P. Langtangen.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>