

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Model extensions &mdash; Introduction to computing with finite difference methods</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Introduction to computing with finite difference methods" href="index.html" />
    <link rel="next" title="Applications of exponential decay models" href="._part0008_main_decay.html" />
    <link rel="prev" title="Analysis of finite difference equations" href="._part0006_main_decay.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="._part0008_main_decay.html" title="Applications of exponential decay models"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="._part0006_main_decay.html" title="Analysis of finite difference equations"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Introduction to computing with finite difference methods</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="model-extensions">
<h1>Model extensions<a class="headerlink" href="#model-extensions" title="Permalink to this headline">¶</a></h1>
<p>It is time to consider generalizations of the simple decay model
<span class="math">\(u=-au\)</span> and also to look at additional numerical solution methods.</p>
<div class="section" id="generalization-including-a-variable-coefficient">
<h2>Generalization: including a variable coefficient<a class="headerlink" href="#generalization-including-a-variable-coefficient" title="Permalink to this headline">¶</a></h2>
<p>In the ODE for decay, <span class="math">\(u'=-au\)</span>, we now consider the case where <span class="math">\(a\)</span>
depends on time:</p>
<div class="math" id="equation-decay:problem:a">
<span class="eqno">(1)</span>\[     u'(t) = -a(t)u(t),\quad t\in (0,T],\quad u(0)=I \thinspace .\]</div>
<p>A Forward Euler scheme consist of evaluating <a href="#equation-decay:problem:a">(1)</a>
at <span class="math">\(t=t_n\)</span> and approximating the derivative with a forward
difference <span class="math">\([D^+_t u]^n\)</span>:</p>
<div class="math">
\[\frac{u^{n+1} - u^n}{\Delta t} = -a(t_n)u^n
\thinspace .\]</div>
<p>The Backward Euler scheme becomes</p>
<div class="math">
\[\frac{u^{n} - u^{n-1}}{\Delta t} = -a(t_n)u^n
\thinspace .\]</div>
<p>The Crank-Nicolson method builds on sampling the ODE at
<span class="math">\(t_{n+\frac{1}{2}}\)</span>. We can evaluate <span class="math">\(a\)</span> at <span class="math">\(t_{n+\frac{1}{2}}\)</span>
and use an average for <span class="math">\(u\)</span> at
times <span class="math">\(t_n\)</span> and <span class="math">\(t_{n+1}\)</span>:</p>
<div class="math">
\[\frac{u^{n+1} - u^{n}}{\Delta t} = -a(t_{n+\frac{1}{2}})\frac{1}{2}(u^n + u^{n+1})
\thinspace .\]</div>
<p>Alternatively, we can use an average for the product <span class="math">\(au\)</span>:</p>
<div class="math">
\[\frac{u^{n+1} - u^{n}}{\Delta t} = -\frac{1}{2}(a(t_n)u^n + a(t_{n+1})u^{n+1})
\thinspace .\]</div>
<p>The <span class="math">\(\theta\)</span>-rule unifies the three mentioned schemes. One version is to
have <span class="math">\(a\)</span> evaluated at <span class="math">\(t_{n+\theta}\)</span>,</p>
<div class="math">
\[\frac{u^{n+1} - u^{n}}{\Delta t} = -a((1-\theta)t_n + \theta t_{n+1})((1-\theta) u^n + \theta u^{n+1})
\thinspace .\]</div>
<p>Another possibility is to apply a weighted average for the product <span class="math">\(au\)</span>,</p>
<div class="math">
\[\frac{u^{n+1} - u^{n}}{\Delta t} = -(1-\theta) a(t_n)u^n - \theta
a(t_{n+1})u^{n+1}
\thinspace .\]</div>
<p>With the finite difference operator notation the Forward Euler and Backward
Euler schemes can be summarized as</p>
<div class="math">
\[\lbrack D^+_t u = -au\rbrack^n,\]</div>
<div class="math">
\[\lbrack D^-_t u = -au\rbrack^n
\thinspace .\]</div>
<p>The Crank-Nicolson and <span class="math">\(\theta\)</span> schemes depend on whether we evaluate
<span class="math">\(a\)</span> at the sample point for the ODE or if we use an average. The
various versions are written as</p>
<div class="math">
\[\lbrack D_t u = -a\overline{u}^t\rbrack^{n+\frac{1}{2}},\]</div>
<div class="math">
\[\lbrack D_t u = -\overline{au}^t\rbrack^{n+\frac{1}{2}},\]</div>
<div class="math">
\[\lbrack D_t u = -a\overline{u}^{t,\theta}\rbrack^{n+\theta},\]</div>
<div class="math">
\[\lbrack D_t u = -\overline{au}^{t,\theta}\rbrack^{n+\theta}
\thinspace .\]</div>
</div>
<div class="section" id="generalization-including-a-source-term">
<span id="decay-source"></span><h2>Generalization: including a source term<a class="headerlink" href="#generalization-including-a-source-term" title="Permalink to this headline">¶</a></h2>
<p>A further extension of the model ODE is to include a source term <span class="math">\(b(t)\)</span>:</p>
<div class="math" id="equation-decay:problem:ab">
<span class="eqno">(2)</span>\[     u'(t) = -a(t)u(t) + b(t),\quad t\in (0,T],\quad u(0)=I
     \thinspace .\]</div>
<div class="section" id="schemes">
<h3>Schemes<a class="headerlink" href="#schemes" title="Permalink to this headline">¶</a></h3>
<p>The time point where we sample the ODE determines where <span class="math">\(b(t)\)</span> is
evaluated. For the Crank-Nicolson scheme and the <span class="math">\(\theta\)</span>-rule we
have a choice of whether to evaluate <span class="math">\(a(t)\)</span> and <span class="math">\(b(t)\)</span> at the
correct point or use an average. The chosen strategy becomes
particularly clear if we write up the schemes in the operator notation:</p>
<div class="math">
\[\lbrack D^+_t u = -au + b\rbrack^n,\]</div>
<div class="math">
\[\lbrack D^-_t u = -au + b\rbrack^n,\]</div>
<div class="math">
\[\lbrack D_t u   = -a\overline{u}^t + b\rbrack^{n+\frac{1}{2}},\]</div>
<div class="math">
\[\lbrack D_t u   = \overline{-au+b}^t\rbrack^{n+\frac{1}{2}},\]</div>
<div class="math">
\[\lbrack D_t u   = -a\overline{u}^{t,\theta} + b\rbrack^{n+\theta},\]</div>
<div class="math" id="equation-decay:problem:ab:theta:avg:all:op">
<span class="eqno">(3)</span>\[     \lbrack D_t u   = \overline{-au+b}^{t,\theta}\rbrack^{n+\theta}\]\[     \thinspace .\]</div>
</div>
</div>
<div class="section" id="implementation-of-the-generalized-model-problem">
<span id="decay-general"></span><h2>Implementation of the generalized model problem<a class="headerlink" href="#implementation-of-the-generalized-model-problem" title="Permalink to this headline">¶</a></h2>
<div class="section" id="deriving-the-rule-formula">
<h3>Deriving the <span class="math">\(\theta\)</span>-rule formula<a class="headerlink" href="#deriving-the-rule-formula" title="Permalink to this headline">¶</a></h3>
<p>Writing out the <span class="math">\(\theta\)</span>-rule in <a href="#equation-decay:problem:ab:theta:avg:all:op">(3)</a>,
using <a href="#equation-decay:fd1:Du:theta">(?)</a>
and <a href="#equation-decay:fd1:wmean:a">(?)</a>, we get</p>
<div class="math" id="equation-decay:problem:ab:theta:avg:all">
<span class="eqno">(4)</span>\[     \frac{u^{n+1}-u^n}{\Delta t} = \theta(-a^{n+1}u^{n+1} + b^{n+1}))
     + (1-\theta)(-a^nu^{n} + b^n)),\]</div>
<p>where <span class="math">\(a^n\)</span> means evaluating <span class="math">\(a\)</span> at <span class="math">\(t=t_n\)</span> and similar for
<span class="math">\(a^{n+1}\)</span>, <span class="math">\(b^n\)</span>, and <span class="math">\(b^{n+1}\)</span>.
We solve for <span class="math">\(u^{n+1}\)</span>:</p>
<div class="math">
\[u^{n+1} = ((1 - \Delta t(1-\theta)a^n)u^n
+ \Delta t(\theta b^{n+1} + (1-\theta)b^n))(1 + \Delta t\theta a^{n+1})^{-1}
\thinspace .\]</div>
</div>
<div class="section" id="the-python-code">
<h3>The Python code<a class="headerlink" href="#the-python-code" title="Permalink to this headline">¶</a></h3>
<p>Here is a suitable implementation of <a href="#equation-decay:problem:ab:theta:avg:all">(4)</a>
where <span class="math">\(a(t)\)</span> and <span class="math">\(b(t)\)</span> are given as
Python functions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">solver</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve u&#39;=-a(t)*u + b(t), u(0)=I,</span>
<span class="sd">    for t in (0,T] with steps of dt.</span>
<span class="sd">    a and b are Python functions of t.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>            <span class="c"># avoid integer division</span>
    <span class="n">Nt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">dt</span><span class="p">))</span>     <span class="c"># no of time intervals</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">Nt</span><span class="o">*</span><span class="n">dt</span>                 <span class="c"># adjust T to fit time step dt</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>           <span class="c"># array of u[n] values</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>  <span class="c"># time mesh</span>

    <span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span>                  <span class="c"># assign initial condition</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Nt</span><span class="p">):</span>    <span class="c"># n=0,1,...,Nt-1</span>
        <span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dt</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">n</span><span class="p">]))</span><span class="o">*</span><span class="n">u</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+</span> \
                  <span class="n">dt</span><span class="o">*</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">b</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">b</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">n</span><span class="p">])))</span><span class="o">/</span>\
                  <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">dt</span><span class="o">*</span><span class="n">theta</span><span class="o">*</span><span class="n">a</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">t</span>
</pre></div>
</div>
<p>This function is found in the file <a class="reference external" href="http://tinyurl.com/jvzzcfn/decay/decay_vc.py">decay_vc.py</a> (<tt class="docutils literal"><span class="pre">vc</span></tt> stands for &#8220;variable coefficients&#8221;).</p>
</div>
<div class="section" id="coding-of-variable-coefficients">
<h3>Coding of variable coefficients<a class="headerlink" href="#coding-of-variable-coefficients" title="Permalink to this headline">¶</a></h3>
<p>The <tt class="docutils literal"><span class="pre">solver</span></tt> function shown above demands the arguments <tt class="docutils literal"><span class="pre">a</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> to
be Python functions of time <tt class="docutils literal"><span class="pre">t</span></tt>, say</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">a</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a_0</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">tp</span> <span class="k">else</span> <span class="n">k</span><span class="o">*</span><span class="n">a_0</span>

<span class="k">def</span> <span class="nf">b</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Here, <tt class="docutils literal"><span class="pre">a(t)</span></tt> has three parameters <tt class="docutils literal"><span class="pre">a0</span></tt>, <tt class="docutils literal"><span class="pre">tp</span></tt>, and <tt class="docutils literal"><span class="pre">k</span></tt>,
which must be global variables.
A better implementation is to represent <tt class="docutils literal"><span class="pre">a</span></tt> by a class where the
parameters are attributes and a <em>special method</em> <tt class="docutils literal"><span class="pre">__call__</span></tt> evaluates <span class="math">\(a(t)\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">A</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">a0</span><span class="p">,</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">a0</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tp</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">a0</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">A</span><span class="p">(</span><span class="n">a0</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c"># a behaves as a function a(t)</span>
</pre></div>
</div>
<p id="index-0">For quick tests it is cumbersome to write a complete function or a class.
The <em>lambda function</em> construction in Python is then convenient. For example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">a</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">a_0</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">tp</span> <span class="k">else</span> <span class="n">k</span><span class="o">*</span><span class="n">a_0</span>
</pre></div>
</div>
<p>is equivalent to the <tt class="docutils literal"><span class="pre">def</span> <span class="pre">a(t):</span></tt> definition above. In general,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="o">...</span><span class="p">:</span> <span class="n">expressin</span>
</pre></div>
</div>
<p>is equivalent to</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">expression</span>
</pre></div>
</div>
<p>One can use lambda functions directly in calls. Say we want to
solve <span class="math">\(u'=-u+1\)</span>, <span class="math">\(u(0)=2\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">solver</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
<p>A lambda function can appear anywhere where a variable can appear.</p>
</div>
</div>
<div class="section" id="verifying-a-constant-solution">
<span id="decay-verify-trivial"></span><h2>Verifying a constant solution<a class="headerlink" href="#verifying-a-constant-solution" title="Permalink to this headline">¶</a></h2>
<p>A very useful partial verification method is to construct a test
problem with a very simple solution, usually <span class="math">\(u=\hbox{const}\)</span>.
Especially the initial debugging of a program code can benefit greatly
from such tests, because 1) all relevant numerical methods will
exactly reproduce a constant solution, 2) many of the intermediate
calculations are easy to control for a constant <span class="math">\(u\)</span>, and 3) even a
constant <span class="math">\(u\)</span> can uncover many bugs in an implementation.</p>
<p>The only constant solution for the problem <span class="math">\(u'=-au\)</span> is <span class="math">\(u=0\)</span>, but too
many bugs can escape from that trivial solution.  It is much better to
search for a problem where <span class="math">\(u=C=\hbox{const}\neq 0\)</span>.  Then <span class="math">\(u'=-a(t)u
+ b(t)\)</span> is more appropriate: with <span class="math">\(u=C\)</span> we can choose any <span class="math">\(a(t)\)</span> and
set <span class="math">\(b=a(t)C\)</span> and <span class="math">\(I=C\)</span>. An appropriate nose test is</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">nose.tools</span> <span class="kn">as</span> <span class="nn">nt</span>

<span class="k">def</span> <span class="nf">test_constant_solution</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test problem where u=u_const is the exact solution, to be</span>
<span class="sd">    reproduced (to machine precision) by any relevant method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">exact_solution</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">u_const</span>

    <span class="k">def</span> <span class="nf">a</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">2.5</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">t</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>  <span class="c"># can be arbitrary</span>

    <span class="k">def</span> <span class="nf">b</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">a</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">*</span><span class="n">u_const</span>

    <span class="n">u_const</span> <span class="o">=</span> <span class="mf">2.15</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">;</span> <span class="n">I</span> <span class="o">=</span> <span class="n">u_const</span><span class="p">;</span> <span class="n">dt</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">Nt</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c"># enough with a few steps</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">solver</span><span class="p">(</span><span class="n">I</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">Nt</span><span class="o">*</span><span class="n">dt</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">u</span>
    <span class="n">u_e</span> <span class="o">=</span> <span class="n">exact_solution</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">u_e</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>  <span class="c"># max deviation</span>
    <span class="n">nt</span><span class="o">.</span><span class="n">assert_almost_equal</span><span class="p">(</span><span class="n">difference</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">places</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
<p>An interesting question is what type of bugs that will make the
computed <span class="math">\(u^n\)</span> deviate from the exact solution <span class="math">\(C\)</span>.
Fortunately, the updating formula and the initial condition must
be absolutely correct for the test to pass! Any attempt to make
a wrong indexing in terms like <tt class="docutils literal"><span class="pre">a(t[n])</span></tt> or any attempt to
introduce an erroneous factor in the formula creates a solution
that is different from <span class="math">\(C\)</span>.</p>
</div>
<div class="section" id="verification-via-manufactured-solutions">
<span id="decay-mms"></span><h2>Verification via manufactured solutions<a class="headerlink" href="#verification-via-manufactured-solutions" title="Permalink to this headline">¶</a></h2>
<span class="target" id="index-1"></span><p id="index-2">Following the idea of the previous section, we can choose any formula
as the exact solution, insert the formula in the ODE problem and fit
the data <span class="math">\(a(t)\)</span>, <span class="math">\(b(t)\)</span>, and <span class="math">\(I\)</span> to make the chosen
formula fulfill the equation. This
powerful technique for generating exact solutions is very useful for
verification purposes and known as the <em>method of manufactured
solutions</em>, often abbreviated MMS.</p>
<p>One common choice of solution is a linear function in the independent
variable(s). The rationale behind such a simple variation is that
almost any relevant numerical solution method for differential
equation problems is able to reproduce the linear function exactly to
machine precision (if <span class="math">\(u\)</span> is about unity in size; precision is lost if
<span class="math">\(u\)</span> take on large values, see <a class="reference internal" href="main_decay.html#decay-fd2-exer-precision"><em>Exercise 11: Experiment with precision in tests and the size of </em></a>).
The linear solution also makes some stronger demands to the
numerical method and the implementation than the constant solution
used in the section <a class="reference internal" href="main_decay.html#decay-verify-trivial"><em>Verifying a constant solution</em></a>, at least in more
complicated applications. However, the constant solution is often
ideal for initial debugging before proceeding with a linear solution.</p>
<p>We choose a linear solution <span class="math">\(u(t) = ct + d\)</span>. From the initial condition it
follows that <span class="math">\(d=I\)</span>.
Inserting this <span class="math">\(u\)</span> in the ODE results in</p>
<div class="math">
\[c = -a(t)u + b(t) \thinspace .\]</div>
<p>Any function <span class="math">\(u=ct+I\)</span> is then a correct solution if we choose</p>
<div class="math">
\[b(t) = c + a(t)(ct + I) \thinspace .\]</div>
<p>With this <span class="math">\(b(t)\)</span> there are no restrictions on <span class="math">\(a(t)\)</span> and <span class="math">\(c\)</span>.</p>
<p>Let prove that such a linear solution obeys the numerical
schemes. To this end, we must check that <span class="math">\(u^n = ca(t_n)(ct_n+I)\)</span>
fulfills the discrete equations. For these calculations, and
later calculations involving linear solutions inserted in
finite difference schemes, it is convenient to
compute the action of a difference operator on a linear function <span class="math">\(t\)</span>:</p>
<div class="math" id="equation-decay:fd2:Dop:tn:fw">
<span class="eqno">(5)</span>\[     \lbrack D_t^+ t\rbrack^n = \frac{t_{n+1}-t_n}{\Delta t}=\frac{(n+1)\Delta t - n\Delta t}{\Delta t}=1,\\]</div>
<div class="math" id="equation-decay:fd2:Dop:tn:bw">
<span class="eqno">(6)</span>\[     \lbrack D_t^- t\rbrack^n = \frac{t_{n}-t_{n-1}}{\Delta t}=\frac{n\Delta t - (n-1)\Delta t}{\Delta t}=1,\\]</div>
<div class="math" id="equation-decay:fd2:Dop:tn:cn">
<span class="eqno">(7)</span>\[     \lbrack D_t t\rbrack^n = \frac{t_{n+\frac{1}{2}}-t_{n-\frac{1}{2}}}{\Delta t}=\frac{(n+\frac{1}{2})\Delta t - (n-\frac{1}{2})\Delta t}{\Delta t}=1\]\[     \thinspace .\]</div>
<p>Clearly, all three finite difference approximations to the derivative are
exact for <span class="math">\(u(t)=t\)</span> or its mesh function counterpart <span class="math">\(u^n = t_n\)</span>.</p>
<p>The difference equation for the Forward Euler scheme</p>
<div class="math">
\[[D^+_t u = -au + b]^n,\]</div>
<p>with <span class="math">\(a^n=a(t_n)\)</span>, <span class="math">\(b^n=c + a(t_n)(ct_n + I)\)</span>, and <span class="math">\(u^n=ct_n + I\)</span>
then results in</p>
<div class="math">
\[c = -a(t_n)(ct_n+I) + c + a(t_n)(ct_n + I) = c\]</div>
<p>which is always fulfilled. Similar calculations can be done for the
Backward Euler and Crank-Nicolson schemes, or the <span class="math">\(\theta\)</span>-rule for
that matter. In all cases, <span class="math">\(u^n=ct_n +I\)</span> is an exact solution of
the discrete equations. That is why we should expect that
<span class="math">\(u^n - u_{\small\mbox{e}}(t_n) =0\)</span> mathematically and <span class="math">\(|u^n - u_{\small\mbox{e}}(t_n)|\)</span> less
than a small number about the machine precision for <span class="math">\(n=0,\ldots,N_t\)</span>.</p>
<p>The following function offers an implementation of this verification
test based on a linear exact solution:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">test_linear_solution</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test problem where u=c*t+I is the exact solution, to be</span>
<span class="sd">    reproduced (to machine precision) by any relevant method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">exact_solution</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">c</span><span class="o">*</span><span class="n">t</span> <span class="o">+</span> <span class="n">I</span>

    <span class="k">def</span> <span class="nf">a</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">t</span><span class="o">**</span><span class="mf">0.5</span>  <span class="c"># can be arbitrary</span>

    <span class="k">def</span> <span class="nf">b</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">c</span> <span class="o">+</span> <span class="n">a</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">*</span><span class="n">exact_solution</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">;</span> <span class="n">I</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span> <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span> <span class="n">c</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span>
    <span class="n">T</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">Nt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">dt</span><span class="p">)</span>  <span class="c"># no of steps</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">solver</span><span class="p">(</span><span class="n">I</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">Nt</span><span class="o">*</span><span class="n">dt</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
    <span class="n">u_e</span> <span class="o">=</span> <span class="n">exact_solution</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">u_e</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>  <span class="c"># max deviation</span>
    <span class="k">print</span> <span class="n">difference</span>
    <span class="c"># No of decimal places for comparison depend on size of c</span>
    <span class="n">nt</span><span class="o">.</span><span class="n">assert_almost_equal</span><span class="p">(</span><span class="n">difference</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">places</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
<p>Any error in the updating formula makes this test fail!</p>
<p>Choosing more complicated formulas as the exact solution, say
<span class="math">\(\cos(t)\)</span>, will not make the numerical and exact solution
coincide to machine precision, because finite differencing of
<span class="math">\(\cos(t)\)</span> does not exactly yield the exact derivative <span class="math">\(-\sin(t)\)</span>.
In such cases, the verification procedure
must be based on measuring the convergence rates as exemplified in
the section <a class="reference internal" href="main_decay.html#decay-convergence-rate"><em>Computing convergence rates</em></a>. Convergence rates can be
computed as long as one has
an exact solution of a problem that the solver can be tested on, but
this can always be obtained by the method of manufactured solutions.</p>
</div>
<div class="section" id="extension-to-systems-of-odes">
<h2>Extension to systems of ODEs<a class="headerlink" href="#extension-to-systems-of-odes" title="Permalink to this headline">¶</a></h2>
<p>Many ODE models involves more than one unknown function and more
than one equation. Here is an example of two unknown functions <span class="math">\(u(t)\)</span>
and <span class="math">\(v(t)\)</span> (modeling, e.g., the radioactive decay of two substances):</p>
<div class="math">
\[u' = -a_u u + a_vv,\]</div>
<div class="math">
\[v' = -a_vv + a_uu,\]</div>
<p>for constants <span class="math">\(a_u, a_v&gt;0\)</span>.
Applying the Forward Euler method to each equation results in simple
updating formula</p>
<div class="math">
\[u^{n+1} = u^n + \Delta t (-a_u u^n + a_vv^n),\]</div>
<div class="math">
\[v^{n+1} = u^n + \Delta t (-a_vv^n + a_uu^n)
\thinspace .\]</div>
<p>On the other hand, the Crank-Nicolson or Backward Euler schemes result in a
<span class="math">\(2\times 2\)</span> linear system for the new unknowns. The latter schemes gives</p>
<div class="math">
\[u^{n+1} = u^n + \Delta t (-a_u u^{n+1} + a_vv^{n+1}),\]</div>
<div class="math">
\[v^{n+1} = v^n + \Delta t (-a_vv^{n+1} + a_uu^{n+1}){\thinspace .}\]</div>
<p>Collecting <span class="math">\(u^{n+1}\)</span> as well as <span class="math">\(v^{n+1}\)</span> on the left-hand side results
in</p>
<div class="math">
\[(1 + \Delta t a_u)u^{n+1} + a_vv^{n+1}) = u^n ,\]</div>
<div class="math">
\[a_uu^{n+1} + (1 + \Delta t a_v) v^{n+1} = v^n ,\]</div>
<p>which is a system of two coupled, linear, algebraic equations in two
unknowns.</p>
</div>
</div>
<div class="section" id="general-first-order-odes">
<h1>General first-order ODEs<a class="headerlink" href="#general-first-order-odes" title="Permalink to this headline">¶</a></h1>
<p>We now turn the attention to general, nonlinear ODEs and systems of
such ODEs.  Our focus is on numerical methods that can be readily
reused for time-discretization PDEs, and diffusion PDEs in particular.
The methods are just briefly listed, and we refer to the rich literature
for more detailed descriptions and analysis - the books
<a class="reference internal" href="main_decay.html#ref2">[Ref2]</a> <a class="reference internal" href="main_decay.html#ref3">[Ref3]</a> <a class="reference internal" href="main_decay.html#ref4">[Ref4]</a> <a class="reference internal" href="main_decay.html#ref5">[Ref5]</a> are all excellent resources on numerical methods for ODEs.
We also demonstrate the Odespy Python interface to a range
of different software for general first-order ODE systems.</p>
<div class="section" id="generic-form">
<h2>Generic form<a class="headerlink" href="#generic-form" title="Permalink to this headline">¶</a></h2>
<p>ODEs are commonly written in the generic form</p>
<div class="math" id="equation-decay:ode:general">
<span class="eqno">(8)</span>\[     u' = f(u,t),\quad u(0)=I,\]</div>
<p>where <span class="math">\(f(u,t)\)</span>  is some prescribed function.
As an example, our most
general exponential decay model <a href="#equation-decay:problem:ab">(2)</a> has
<span class="math">\(f(u,t)=-a(t)u(t) + b(t)\)</span>.</p>
<p>The unknown <span class="math">\(u\)</span> in <a href="#equation-decay:ode:general">(8)</a> may either be
a scalar function of time <span class="math">\(t\)</span>, or a vector valued function of <span class="math">\(t\)</span> in
case of a <em>system of ODEs</em> with <span class="math">\(m\)</span> unknown components:</p>
<div class="math">
\[u(t) = (u^{(0)}(t),u^{(1)}(t),\ldots,u^{(m-1)}(t)) \thinspace .\]</div>
<p>In that case, the right-hand side is vector-valued function with <span class="math">\(m\)</span>
components,</p>
<div class="math">
\[\begin{split}f(u, t) = ( &amp; f^{(0)}(u^{(0)}(t),\ldots,u^{(m-1)}(t)),\\
            &amp; f^{(1)}(u^{(0)}(t),\ldots,u^{(m-1)}(t)),\\
            &amp; \vdots,\\
            &amp; f^{(m-1)}(u^{(0)}(t),\ldots,u^{(m-1)}(t)))
\thinspace .\end{split}\]</div>
<p>Actually, any system of ODEs can
be written in the form <a href="#equation-decay:ode:general">(8)</a>, but higher-order
ODEs then need auxiliary unknown functions to enable conversion to
a first-order system.</p>
</div>
<div class="section" id="some-popular-schemes-for-odes">
<h2>Some popular schemes for ODEs<a class="headerlink" href="#some-popular-schemes-for-odes" title="Permalink to this headline">¶</a></h2>
<p>Next we list some well-known methods for <span class="math">\(u'=f(u,t)\)</span>, valid both for
a single ODE (scalar <span class="math">\(u\)</span>) and systems of ODEs (vector <span class="math">\(u\)</span>).
The choice of methods is inspired by the kind of schemes that are
popular also for partial differential equations.</p>
<span class="target" id="index-3"></span><div class="section" id="the-rule">
<span id="index-4"></span><h3>The <span class="math">\(\theta\)</span>-rule<a class="headerlink" href="#the-rule" title="Permalink to this headline">¶</a></h3>
<p>The <span class="math">\(\theta\)</span>-rule scheme applied to <span class="math">\(u'=f(u,t)\)</span> becomes</p>
<div class="math" id="equation-decay:fd2:theta">
<span class="eqno">(9)</span>\[     \frac{u^{n+1}-u^n}{\Delta t} = \theta f(u^{n+1},t_{n+1}) +
     (1-\theta)f(u^n, t_n){\thinspace .}\]</div>
<p>Bringing the unknown <span class="math">\(u^{n+1}\)</span> to the left-hand side and the known terms
on the right-hand side gives</p>
<span class="target" id="index-5"></span><span class="target" id="index-6"></span><span class="target" id="index-7"></span><div class="math" id="index-8">
\[!bt\]\[u^{n+1} - \Delta t \theta f(u^{n+1},t_{n+1}) =
u^n + \Delta t(1-\theta)f(u^n, t_n){\thinspace .}\]</div>
<p>For a general <span class="math">\(f\)</span> (not linear in <span class="math">\(u\)</span>), this equation is <em>nonlinear</em> in
the unknown <span class="math">\(u^{+1}\)</span> unless <span class="math">\(\theta = 0\)</span>. For a scalar ODE (<span class="math">\(m=1\)</span>),
we have to solve a single nonlinear algebraic equation for <span class="math">\(u^{n+1}\)</span>,
while for a system of ODEs, we get a system of coupled, nonlinear
algebraic equations. Newton&#8217;s method is a popular solution approach
in both cases. Note that with the Forward Euler scheme (<span class="math">\(\theta =0\)</span>)
we do not have to deal with nonlinear equations, because in that
case we have an explicit updating formula for <span class="math">\(u^{n+1}\)</span>. This is known
as an <em>explicit</em> scheme. With <span class="math">\(\theta\neq 1\)</span> we have to solve
systems of algebraic equations, and the scheme is said to be <em>implicit</em>.</p>
</div>
<div class="section" id="implicit-2-step-backward-scheme">
<h3>Implicit 2-step backward scheme<a class="headerlink" href="#implicit-2-step-backward-scheme" title="Permalink to this headline">¶</a></h3>
<p>The implicit backward method with 2 steps applies a
three-level backward difference as approximation to <span class="math">\(u'(t)\)</span>,</p>
<div class="math">
\[u'(t_{n+1}) \approx \frac{3u^{n+1} - 4u^{n} + u^{n-1}}{2\Delta t},\]</div>
<p>which is an approximation of order <span class="math">\(\Delta t^2\)</span> to the first derivative.
The resulting scheme for <span class="math">\(u'=f(u,t)\)</span> reads</p>
<div class="math" id="equation-decay:fd2:bw:2step  u^{n+1} = \frac{4}{3}u^n - \frac{1}{3}u^{n-1} + \frac{2}{3}\Delta t f(u^{n+1}, t_{n+1}) \thinspace .">
</div>
<p>Higher-order versions of the scheme <a href="#equation-decay:fd2:bw:2step">(?)</a> can
be constructed by including more time levels. These schemes are known
as the Backward Differentiation Formulas (BDF), and the particular
version <a href="#equation-decay:fd2:bw:2step">(?)</a> is often referred to as BDF2.</p>
<p>Note that the scheme <a href="#equation-decay:fd2:bw:2step">(?)</a> is implicit and requires
solution of nonlinear equations when <span class="math">\(f\)</span> is nonlinear in <span class="math">\(u\)</span>.  The
standard 1st-order Backward Euler method or the Crank-Nicolson scheme
can be used for the first step.</p>
</div>
<div class="section" id="the-leapfrog-scheme">
<span id="index-9"></span><h3>The Leapfrog scheme<a class="headerlink" href="#the-leapfrog-scheme" title="Permalink to this headline">¶</a></h3>
<p>The derivative of <span class="math">\(u\)</span> at some point <span class="math">\(t_n\)</span> can be approximated by
a central difference over two time steps,</p>
<div class="math">
\[u'(t_n)\approx \frac{u^{n+1}-u^{n-1}}{2\Delta t} = [D_{2t}u]^n\]</div>
<p>which is an approximation of second order in <span class="math">\(\Delta t\)</span>. The scheme
can then be written as</p>
<div class="math">
\[[D_{2t}u=f(u,t)]^n,\]</div>
<p>in operator notation. Solving for <span class="math">\(u^{n+1}\)</span> gives</p>
<div class="math" id="equation-decay:fd2:leapfrog">
<span class="eqno">(11)</span>\[     u^{n+1} = u^{n-1} + \Delta t f(u^n, t_n)
     \thinspace .\]</div>
<p>Observe that <a href="#equation-decay:fd2:leapfrog">(11)</a> is an explicit scheme, and that
a nonlinear <span class="math">\(f\)</span> (in <span class="math">\(u\)</span>) is trivial to handle since it only involves
the known <span class="math">\(u^n\)</span> value.
Some other scheme must be used as starter to compute <span class="math">\(u^1\)</span>, preferably
the Forward Euler scheme since it is also explicit.</p>
</div>
<div class="section" id="the-filtered-leapfrog-scheme">
<span id="index-10"></span><h3>The filtered Leapfrog scheme<a class="headerlink" href="#the-filtered-leapfrog-scheme" title="Permalink to this headline">¶</a></h3>
<p>Unfortunately, the Leapfrog scheme <a href="#equation-decay:fd2:leapfrog">(11)</a>
will develop growing oscillations with time (see <a class="reference internal" href="main_decay.html#decay-fd2-exer-leapfrog1"><em>Problem 4: Implement and investigate the Leapfrog scheme</em></a>). A remedy for such undesired oscillations
is to introduce a <em>filtering technique</em>. First, a standard Leapfrog
step is taken, according to <a href="#equation-decay:fd2:leapfrog">(11)</a>, and then
the previous <span class="math">\(u^n\)</span> value is adjusted according to</p>
<div class="math" id="equation-decay:fd2:leapfrog:filtered">
<span class="eqno">(12)</span>\[     u^n\ \leftarrow\ u^n + \gamma (u^{n-1} - 2u^n + u^{n+1})\]\[     \thinspace .\]</div>
<p>The <span class="math">\(\gamma\)</span>-terms will effectively damp oscillations in the solution,
especially those with short wavelength (like point-to-point oscillations).
A common choice of <span class="math">\(\gamma\)</span> is 0.6 (a value used in the
famous NCAR Climate Model).</p>
<span class="target" id="index-11"></span></div>
<div class="section" id="nd-order-runge-kutta-scheme">
<span id="index-12"></span><h3>2nd-order Runge-Kutta scheme<a class="headerlink" href="#nd-order-runge-kutta-scheme" title="Permalink to this headline">¶</a></h3>
<p>The two-step scheme</p>
<div class="math" id="equation-decay:fd2:RK2:s1">
<span class="eqno">(13)</span>\[     u^* = u^n + \Delta t f(u^n, t_n),\]</div>
<div class="math" id="equation-decay:fd2:RK2:s2">
<span class="eqno">(14)</span>\[     u^{n+1} = u^n + \Delta t \frac{1}{2} \left( f(u^n, t_n) + f(u^*, t_{n+1})
     \right),\]</div>
<p>essentially applies a Crank-Nicolson method <a href="#equation-decay:fd2:RK2:s2">(14)</a>
to the ODE, but replaces
the term <span class="math">\(f(u^{n+1}, t_{n+1})\)</span> by a prediction
<span class="math">\(f(u^{*}, t_{n+1})\)</span> based on a Forward Euler step <a href="#equation-decay:fd2:RK2:s1">(13)</a>.
The scheme <a href="#equation-decay:fd2:RK2:s1">(13)</a>-<a href="#equation-decay:fd2:RK2:s2">(14)</a> is
known as Huen&#8217;s method, but is also a 2nd-order Runge-Kutta method.
The scheme is explicit, and the error is expected to behave as <span class="math">\(\Delta t^2\)</span>.</p>
</div>
<div class="section" id="a-2nd-order-taylor-series-method">
<span id="index-13"></span><h3>A 2nd-order Taylor-series method<a class="headerlink" href="#a-2nd-order-taylor-series-method" title="Permalink to this headline">¶</a></h3>
<p>One way to compute <span class="math">\(u^{n+1}\)</span> given <span class="math">\(u^n\)</span> is to use a Taylor polynomial.
We may write up a polynomial of 2nd degree:</p>
<div class="math">
\[u^{n+1} = u^n + u'(t_n)\Delta t + \frac{1}{2}u''(t_n)\Delta t^2
\thinspace .\]</div>
<p>From the equation <span class="math">\(u'=f(u,t)\)</span> it follows that the derivatives of <span class="math">\(u\)</span>
can be expressed in terms of <span class="math">\(f\)</span> and its derivatives:</p>
<div class="math">
\[\begin{split}u'(t_n) &amp;=f(u^n,t_n),\\
u''(t_n) &amp;=
\frac{\partial f}{\partial u}(u^n,t_n) u'(t_n) + \frac{\partial f}{\partial t}\\
&amp;=  f(u^n,t_n)\frac{\partial f}{\partial u}(u^n,t_n)  +
\frac{\partial f}{\partial t},\end{split}\]</div>
<p>resulting in the scheme</p>
<div class="math" id="equation-decay:fd2:Taylor2">
<span class="eqno">(15)</span>\[     u^{n+1} = u^n + f(u^n,t_n)\Delta t + \frac{1}{2}\left(
     f(u^n,t_n)\frac{\partial f}{\partial u}(u^n,t_n)  +
     \frac{\partial f}{\partial t}\right)\Delta t^2
     \thinspace .\]</div>
<p>More terms in the series could be included in the Taylor polynomial to
obtain methods of higher order than 2.</p>
</div>
<div class="section" id="nd-order-adams-bashforth-scheme">
<span id="index-14"></span><h3>2nd-order Adams-Bashforth scheme<a class="headerlink" href="#nd-order-adams-bashforth-scheme" title="Permalink to this headline">¶</a></h3>
<p>The following method is known as the 2nd-order Adams-Bashforth scheme:</p>
<div class="math" id="equation-decay:fd2:AB2">
<span class="eqno">(16)</span>\[     u^{n+1} = u^n + \frac{1}{2}\Delta t\left( 3f(u^n, t_n) - f(u^{n-1}, t_{n-1})
     \right)
     \thinspace .\]</div>
<p>The scheme is explicit and requires another one-step scheme to compute
<span class="math">\(u^1\)</span> (the Forward Euler scheme or Heun&#8217;s method, for instance).
As the name implies, the scheme is of order <span class="math">\(\Delta t^2\)</span>.</p>
</div>
<div class="section" id="rd-order-adams-bashforth-scheme">
<span id="index-15"></span><h3>3rd-order Adams-Bashforth scheme<a class="headerlink" href="#rd-order-adams-bashforth-scheme" title="Permalink to this headline">¶</a></h3>
<p>Another explicit scheme, involving four time levels, is the
3rd-order Adams-Bashforth scheme</p>
<div class="math" id="equation-decay:fd2:AB3">
<span class="eqno">(17)</span>\[     u^{n+1} = u^n + \frac{1}{12}\left( 23f(u^n, t_n) - 16 f(u^{n-1},t_{n-1})
     + 5f(u^{n-2}, t_{n-2})\right)
     \thinspace .\]</div>
<p>The numerical error is of order <span class="math">\(\Delta t^3\)</span>, and the scheme needs
some method for computing <span class="math">\(u^1\)</span> and <span class="math">\(u^2\)</span>.</p>
<p>More general, higher-order Adams-Bashforth schemes (also called
<em>explicit Adams methods</em>) compute <span class="math">\(u^{n+1}\)</span> as a linear combination
of <span class="math">\(f\)</span> at <span class="math">\(k\)</span> previous time steps:</p>
<div class="math">
\[u^{n+1} = u^n + \sum_{j=0}^k \beta_jf(u^{n-j},t_{n-j}),\]</div>
<p>where <span class="math">\(\beta_j\)</span> are known coefficients.</p>
<span class="target" id="index-16"></span></div>
<div class="section" id="th-order-runge-kutta-scheme">
<span id="index-17"></span><h3>4th-order Runge-Kutta scheme<a class="headerlink" href="#th-order-runge-kutta-scheme" title="Permalink to this headline">¶</a></h3>
<p>The perhaps most widely used method to solve ODEs is the 4th-order
Runge-Kutta method, often called RK4.
Its derivation is a nice illustration of common
numerical approximation strategies, so let us go through the
steps in detail.</p>
<p>The starting point is to integrate the ODE
<span class="math">\(u'=f(u,t)\)</span> from <span class="math">\(t_n\)</span> to <span class="math">\(t_{n+1}\)</span>:</p>
<div class="math">
\[u(t_{n+1}) - u(t_n) = \int\limits_{t_{n}}^{t_{n+1}} f(u(t),t)dt{\thinspace .}\]</div>
<p>We want to compute <span class="math">\(u(t_{n+1})\)</span> and regard <span class="math">\(u(t_n)\)</span> as known.
The task is to find good approximations for the integral, since the
integrand involves the unknown <span class="math">\(u\)</span> between <span class="math">\(t_n\)</span> and <span class="math">\(t_{n+1}\)</span>.</p>
<p>The integral can be approximated by the famous
<a class="reference external" href="http://en.wikipedia.org/wiki/Simpson's_rule">Simpson&#8217;s rule</a>:</p>
<div class="math">
\[\int\limits_{t_{n}}^{t_{n+1}} f(u(t),t)dt
\approx \frac{\Delta t}{6}\left( f^n + 4f^{n+1/2} + f^{n+1}\right){\thinspace .}\]</div>
<p>The problem now is that we do not know <span class="math">\(f^{n+1/2}=f(u^{n+1/2},t_{n+1/2})\)</span>
and <span class="math">\(f^{n+1}=(u^{n+1},t_{n+1})\)</span> as we know only <span class="math">\(u^n\)</span> and hence <span class="math">\(f^n\)</span>.
The idea is to use various approximations for <span class="math">\(f^{n+1/2}\)</span> and
<span class="math">\(f^{n+1}\)</span> based on using well-known schemes for the ODE in the
intervals <span class="math">\([t_n,t_{n+1/2}]\)</span> and <span class="math">\([t_n, t_{n+1}]\)</span>.
We split the integral approximation into four terms:</p>
<div class="math">
\[\int\limits_{t_{n}}^{t_{n+1}} f(u(t),t)dt
\approx \frac{\Delta t}{6}\left( f^n + 2\hat{f}^{n+1/2}
+ 2\tilde{f}^{n+1/2} + \bar{f}^{n+1}\right),\]</div>
<p>where <span class="math">\(\hat{f}^{n+1/2}\)</span>, <span class="math">\(\tilde{f}^{n+1/2}\)</span>, and <span class="math">\(\bar{f}^{n+1}\)</span>
are approximations to <span class="math">\(f^{n+1/2}\)</span> and
<span class="math">\(f^{n+1}\)</span> that can be based on already computed quantities.
For <span class="math">\(\hat{f}^{n+1/2}\)</span> we can apply
an approximation to <span class="math">\(u^{n+1/2}\)</span> using the Forward Euler
method with step <span class="math">\(\frac{1}{2}\Delta t\)</span>:</p>
<div class="math" id="equation-decay:fd2:RK4:hatf">
<span class="eqno">(18)</span>\[     \hat{f}^{n+1/2} = f(u^n + \frac{1}{2}{\Delta t} f^n, t_{n+1/2})\]</div>
<p>Since this gives us a prediction of <span class="math">\(f^{n+1/2}\)</span>, we can for
<span class="math">\(\tilde{f}^{n+1/2}\)</span> try a Backward Euler method to approximate <span class="math">\(u^{n+1/2}\)</span>:</p>
<div class="math" id="equation-decay:fd2:RK4:tildef">
<span class="eqno">(19)</span>\[     \tilde{f}^{n+1/2} = f(u^n + \frac{1}{2}\Delta t\hat{f}^{n+1/2}, t_{n+1/2}){\thinspace .}\]</div>
<p>With <span class="math">\(\tilde{f}^{n+1/2}\)</span> as a hopefully good approximation to
<span class="math">\(f^{n+1/2}\)</span>, we can for the final term <span class="math">\(\bar{f}^{n+1}\)</span> use
a Crank-Nicolson method to approximate <span class="math">\(u^{n+1}\)</span>:</p>
<div class="math" id="equation-decay:fd2:RK4:barf">
<span class="eqno">(20)</span>\[     \bar{f}^{n+1} = f(u^n + \Delta t \hat{f}^{n+1/2}, t_{n+1}){\thinspace .}\]</div>
<p>We have now used the Forward and Backward Euler methods as well as the
Crank-Nicolson method in the context of Simpson&#8217;s rule. The hope is
that the combination of these methods yields an overall time-stepping
scheme from <span class="math">\(t_n\)</span> to <span class="math">\(t_n{+1}\)</span> that is much more accurate than the
<span class="math">\({{\cal O}(\Delta t)}\)</span> and <span class="math">\({{\cal O}(\Delta t^2)}\)</span> of the individual steps.
This is indeed true: the overall accuracy is <span class="math">\({{\cal O}(\Delta t^4)}\)</span>!</p>
<p>To summarize, the 4th-order Runge-Kutta method becomes</p>
<div class="math">
\[u^{n+1} = u^n +
\frac{\Delta t}{6}\left( f^n + 2\hat{f}^{n+1/2}
+ 2\tilde{f}^{n+1/2} + \bar{f}^{n+1}\right),\]</div>
<p>where the quantities on the right-hand side are computed from
<a href="#equation-decay:fd2:RK4:hatf">(18)</a>-<a href="#equation-decay:fd2:RK4:barf">(20)</a>. Note that
the scheme is fully explicit so there is never any need to solve linear or
nonlinear algebraic
equations. However, the stability is conditional and depends on <span class="math">\(f\)</span>.
There is a whole range of <em>implicit</em> Runge-Kutta methods that
are unconditionally stable, but require solution of algebraic
equations involving <span class="math">\(f\)</span> at each time step.</p>
<p>The simplest way to explore more sophisticated methods for ODEs is to
apply one of the many high-quality software packages that exist, as the
next section explains.</p>
</div>
</div>
<div class="section" id="the-odespy-software">
<h2>The Odespy software<a class="headerlink" href="#the-odespy-software" title="Permalink to this headline">¶</a></h2>
<p>A wide range of the methods and software exist for solving <a href="#equation-decay:ode:general">(8)</a>.
Many of methods are accessible through a unified Python interface offered
by the <a class="reference external" href="https://github.com/hplgit/odespy">Odespy</a> package.
Odespy features simple Python implementations of the most fundamental
schemes as well as Python interfaces to several famous packages for
solving ODEs: <a class="reference external" href="https://computation.llnl.gov/casc/odepack/odepack_home.html">ODEPACK</a>, <a class="reference external" href="https://computation.llnl.gov/casc/odepack/odepack_home.html">Vode</a>,
<a class="reference external" href="http://www.netlib.org/ode/rkc.f">rkc.f</a>, <a class="reference external" href="http://www.netlib.org/ode/rkf45.f">rkf45.f</a>, <a class="reference external" href="http://www.unige.ch/~hairer/software.html">Radau5</a>, as well
as the ODE solvers in <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html">SciPy</a>, <a class="reference external" href="http://docs.sympy.org/dev/modules/mpmath/calculus/odes.html">SymPy</a>, and <a class="reference external" href="http://olivierverdier.github.com/odelab/">odelab</a>.</p>
<p>The usage of Odespy follows this setup for the ODE <span class="math">\(u'=-au\)</span>,
<span class="math">\(u(0)=I\)</span>, <span class="math">\(t\in (0,T]\)</span>, here solved
by the famous 4th-order Runge-Kutta method, using <span class="math">\(\Delta t=1\)</span>
and <span class="math">\(N_t=6\)</span> steps:</p>
<div class="highlight-text"><div class="highlight"><pre>def f(u, t):
    return -a*u

import odespy
import numpy as np

I = 1; a = 0.5; Nt = 6; dt = 1
solver = odespy.RK4(f)
solver.set_initial_condition(I)
t_mesh = np.linspace(0, Nt*dt, Nt+1)
u, t = solver.solve(t_mesh)
</pre></div>
</div>
<p>The previously listed methods for ODEs are all accessible in
Odespy:</p>
<blockquote>
<div><ul class="simple">
<li>the <span class="math">\(\theta\)</span>-rule: <tt class="docutils literal"><span class="pre">ThetaRule</span></tt></li>
<li>special cases of the <span class="math">\(\theta\)</span>-rule: <tt class="docutils literal"><span class="pre">ForwardEuler</span></tt>, <tt class="docutils literal"><span class="pre">BackwardEuler</span></tt>,
<tt class="docutils literal"><span class="pre">CrankNicolson</span></tt></li>
<li>the 2nd- and 4th-order Runge-Kutta methods: <tt class="docutils literal"><span class="pre">RK2</span></tt> and <tt class="docutils literal"><span class="pre">RK4</span></tt></li>
<li>The BDF methods and the Adam-Bashforth methods:
<tt class="docutils literal"><span class="pre">Vode</span></tt>, <tt class="docutils literal"><span class="pre">Lsode</span></tt>, <tt class="docutils literal"><span class="pre">Lsoda</span></tt>, <tt class="docutils literal"><span class="pre">lsoda_scipy</span></tt></li>
<li>The Leapfrog scheme: <tt class="docutils literal"><span class="pre">Leapfrog</span></tt> and <tt class="docutils literal"><span class="pre">LeapfrogFiltered</span></tt></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="example-runge-kutta-methods">
<h2>Example: Runge-Kutta methods<a class="headerlink" href="#example-runge-kutta-methods" title="Permalink to this headline">¶</a></h2>
<p>Since all solvers have the same interface in Odespy, modulo different set of
parameters to the solvers&#8217; constructors, one can easily make a list of
solver objects and run a loop for comparing (a lot of) solvers. The
code below, found in complete form in <a class="reference external" href="http://tinyurl.com/jvzzcfn/decay/decay_odespy.py">decay_odespy.py</a>,
compares the famous Runge-Kutta methods of orders 2, 3, and 4
with the exact solution of the decay equation
<span class="math">\(u'=-au\)</span>.
Since we have quite long time steps, we have included the only
relevant <span class="math">\(\theta\)</span>-rule for large time steps, the Backward Euler scheme
(<span class="math">\(\theta=1\)</span>), as well.
Figure <a class="reference internal" href="main_decay.html#decay-odespy-fig1"><em>Behavior of different schemes for the decay equation</em></a> shows the results.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scitools.std</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">u</span>

<span class="n">I</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">dt</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">0.75</span>
<span class="n">Nt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">dt</span><span class="p">))</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Nt</span><span class="o">*</span><span class="n">dt</span><span class="p">,</span> <span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">solvers</span> <span class="o">=</span> <span class="p">[</span><span class="n">odespy</span><span class="o">.</span><span class="n">RK2</span><span class="p">(</span><span class="n">f</span><span class="p">),</span>
           <span class="n">odespy</span><span class="o">.</span><span class="n">RK3</span><span class="p">(</span><span class="n">f</span><span class="p">),</span>
           <span class="n">odespy</span><span class="o">.</span><span class="n">RK4</span><span class="p">(</span><span class="n">f</span><span class="p">),</span>
           <span class="n">odespy</span><span class="o">.</span><span class="n">BackwardEuler</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">nonlinear_solver</span><span class="o">=</span><span class="s">&#39;Newton&#39;</span><span class="p">)]</span>

<span class="n">legends</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">solver</span> <span class="ow">in</span> <span class="n">solvers</span><span class="p">:</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">set_initial_condition</span><span class="p">(</span><span class="n">I</span><span class="p">)</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="s">&#39;on&#39;</span><span class="p">)</span>
    <span class="n">legends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">solver</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>

<span class="c"># Compare with exact solution plotted on a very fine mesh</span>
<span class="n">t_fine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="mi">10001</span><span class="p">)</span>
<span class="n">u_e</span> <span class="o">=</span> <span class="n">I</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t_fine</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_fine</span><span class="p">,</span> <span class="n">u_e</span><span class="p">,</span> <span class="s">&#39;-&#39;</span><span class="p">)</span> <span class="c"># avoid markers by specifying line type</span>
<span class="n">legends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">&#39;exact&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">legends</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Time step: </span><span class="si">%g</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">dt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition-visualization-tip admonition">
<p class="first admonition-title">Visualization tip</p>
<p>We use SciTools for
plotting here, but importing <tt class="docutils literal"><span class="pre">matplotlib.pyplot</span></tt> as <tt class="docutils literal"><span class="pre">plt</span></tt> instead
also works. However, plain use of Matplotlib as done here results in
curves with different colors, which may be hard to distinguish on
black-and-white paper. Using SciTools, curves are
automatically given colors <em>and</em> markers, thus making curves easy
to distinguish on screen with colors and on black-and-white paper.
The automatic adding of markers is normally a bad idea for a
very mesh since all the markers get cluttered, but SciTools limits
the number of markers in such cases.
For the exact solution we use a very fine mesh, but in the code
above we specify the line type as a solid line (<tt class="docutils literal"><span class="pre">-</span></tt>), which means
no markers and just a color to be automatically determined by
the backend used for plotting (Matplotlib by default, but
SciTools gives the opportunity to use other backends
to produce the plot, e.g., Gnuplot or Grace).</p>
<p class="last">Also note the that the legends
are based on the class names of the solvers, and in Python the name of
a the class type (as a string) of an object <tt class="docutils literal"><span class="pre">obj</span></tt> is obtained by
<tt class="docutils literal"><span class="pre">obj.__class__.__name__</span></tt>.</p>
</div>
<div class="figure" id="decay-odespy-fig1">
<img alt="_images/decay_odespy1_png.png" src="_images/decay_odespy1_png.png" style="width: 600px;" />
<p class="caption"><em>Behavior of different schemes for the decay equation</em></p>
</div>
<p>The runs in Figure <a class="reference internal" href="main_decay.html#decay-odespy-fig1"><em>Behavior of different schemes for the decay equation</em></a>
and other experiments reveal that the 2nd-order Runge-Kutta
method (<tt class="docutils literal"><span class="pre">RK2</span></tt>) is unstable for <span class="math">\(\Delta t&gt;1\)</span> and decays slower than the
Backward Euler scheme for large and moderate <span class="math">\(\Delta t\)</span> (see <a class="reference internal" href="main_decay.html#decay-exer-rk2-taylor-analysis"><em>Exercise 15: Analyze explicit 2nd-order methods</em></a> for an analysis).  However, for
fine <span class="math">\(\Delta t = 0.25\)</span> the 2nd-order Runge-Kutta method approaches
the exact solution faster than the Backward Euler scheme.  That is,
the latter scheme does a better job for larger <span class="math">\(\Delta t\)</span>, while the
higher order scheme is superior for smaller <span class="math">\(\Delta t\)</span>. This is a
typical trend also for most schemes for ordinary and partial
differential equations.</p>
<p>The 3rd-order Runge-Kutta method (<tt class="docutils literal"><span class="pre">RK3</span></tt>) has also artifacts in form
of oscillatory behavior for the larger <span class="math">\(\Delta t\)</span> values, much
like that of the Crank-Nicolson scheme. For finer <span class="math">\(\Delta t\)</span>,
the 3rd-order Runge-Kutta method converges quickly to the exact
solution.</p>
<p>The 4th-order Runge-Kutta method (<tt class="docutils literal"><span class="pre">RK4</span></tt>) is slightly inferior
to the Backward Euler scheme on the coarsest mesh, but is then
clearly superior to all the other schemes. It is definitely the
method of choice for all the tested schemes.</p>
<div class="section" id="remark-about-using-the-rule-in-odespy">
<h3>Remark about using the <span class="math">\(\theta\)</span>-rule in Odespy<a class="headerlink" href="#remark-about-using-the-rule-in-odespy" title="Permalink to this headline">¶</a></h3>
<p>The Odespy package assumes that the ODE is written as <span class="math">\(u'=f(u,t)\)</span> with
an <span class="math">\(f\)</span> that is possibly nonlinear in <span class="math">\(u\)</span>. The <span class="math">\(\theta\)</span>-rule for
<span class="math">\(u'=f(u,t)\)</span> leads to</p>
<div class="math">
\[u^{n+1} = u^{n} + \Delta t\left(\theta f(u^{n+1}, t_{n+1})
+ (1-\theta) f(u^{n}, t_{n})\right),\]</div>
<p>which is a <em>nonlinear equation</em> in <span class="math">\(u^{n+1}\)</span>. Odespy&#8217;s implementation
of the <span class="math">\(\theta\)</span>-rule (<tt class="docutils literal"><span class="pre">ThetaRule</span></tt>) and the specialized Backward Euler
(<tt class="docutils literal"><span class="pre">BackwardEuler</span></tt>) and Crank-Nicolson (<tt class="docutils literal"><span class="pre">CrankNicolson</span></tt>) schemes
must invoke iterative methods for
solving the nonlinear equation in <span class="math">\(u^{n+1}\)</span>. This is done even when
<span class="math">\(f\)</span> is linear in <span class="math">\(u\)</span>, as in the model problem <span class="math">\(u'=-au\)</span>, where we can
easily solve for <span class="math">\(u^{n+1}\)</span> by hand.  Therefore, we need to specify
use of Newton&#8217;s method to the equations.
(Odespy allows other methods than Newton&#8217;s to be used, for instance
Picard iteration, but that method is not suitable. The reason is that it
applies the Forward Euler scheme to generate a start value for
the iterations. Forward Euler may give very wrong solutions
for large <span class="math">\(\Delta t\)</span> values. Newton&#8217;s method, on the other hand,
is insensitive to the start value in <em>linear problems</em>.)</p>
</div>
</div>
<div class="section" id="example-adaptive-runge-kutta-methods">
<h2>Example: Adaptive Runge-Kutta methods<a class="headerlink" href="#example-adaptive-runge-kutta-methods" title="Permalink to this headline">¶</a></h2>
<p id="index-18">Odespy offers solution methods that can adapt the size of <span class="math">\(\Delta t\)</span>
with time to match a desired accuracy in the solution. Intuitively,
small time steps will be chosen in areas where the solution is changing
rapidly, while larger time steps can be used where the solution
is slowly varying. Some kind of <em>error estimator</em> is used to
adjust the next time step at each time level.</p>
<span class="target" id="index-19"></span><p id="index-20">A very popular adaptive method for solving ODEs is the Dormand-Prince
Runge-Kutta method of order 4 and 5. The 5th-order method is used as a
reference solution and the difference between the 4th- and 5th-order
methods is used as an indicator of the error in the numerical
solution.  The Dormand-Prince method is the default choice in MATLAB&#8217;s
widely used <tt class="docutils literal"><span class="pre">ode45</span></tt> routine.</p>
<p>We can easily set up Odespy to use the Dormand-Prince method and
see how it selects the optimal time steps. To this end, we request
only one time step from <span class="math">\(t=0\)</span> to <span class="math">\(t=T\)</span> and ask the method to
compute the necessary non-uniform time mesh to meet a certain
error tolerance. The code goes like</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">odespy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">decay_mod</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c">#import matplotlib.pyplot as plt</span>
<span class="kn">import</span> <span class="nn">scitools.std</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">u</span>

<span class="k">def</span> <span class="nf">exact_solution</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">I</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>

<span class="n">I</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">tol</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">odespy</span><span class="o">.</span><span class="n">DormandPrince</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.1</span><span class="o">*</span><span class="n">tol</span><span class="p">)</span>

<span class="n">Nt</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c"># just one step - let the scheme find its intermediate points</span>
<span class="n">t_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Nt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_fine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="mi">10001</span><span class="p">)</span>

<span class="n">solver</span><span class="o">.</span><span class="n">set_initial_condition</span><span class="p">(</span><span class="n">I</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">t_mesh</span><span class="p">)</span>

<span class="c"># u and t will only consist of [I, u^Nt] and [0,T]</span>
<span class="c"># solver.u_all and solver.t_all contains all computed points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">solver</span><span class="o">.</span><span class="n">t_all</span><span class="p">,</span> <span class="n">solver</span><span class="o">.</span><span class="n">u_all</span><span class="p">,</span> <span class="s">&#39;ko&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="s">&#39;on&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_fine</span><span class="p">,</span> <span class="n">exact_solution</span><span class="p">(</span><span class="n">t_fine</span><span class="p">),</span> <span class="s">&#39;b-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s">&#39;tol=</span><span class="si">%.0E</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">tol</span><span class="p">,</span> <span class="s">&#39;exact&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">&#39;tmp_odespy_adaptive.png&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Running four cases with tolerances <span class="math">\(10^{-1}\)</span>, <span class="math">\(10^{-3}\)</span>, <span class="math">\(10^{-5}\)</span>,
and <span class="math">\(10^{-7}\)</span>, gives the results in Figure <a class="reference internal" href="main_decay.html#decay-odespy-fig2"><em>Choice of adaptive time mesh by the Dormand-Prince method for different tolerances</em></a>.
Intuitively, one would expect denser points in the beginning of
the decay and larger time steps when the solution flattens out.</p>
<div class="figure" id="decay-odespy-fig2">
<img alt="_images/decay_DormandPrince_adaptivity.png" src="_images/decay_DormandPrince_adaptivity.png" style="width: 800px;" />
<p class="caption"><em>Choice of adaptive time mesh by the Dormand-Prince method for different tolerances</em></p>
</div>
</div>
</div>
<div class="section" id="exercises-3">
<h1>Exercises  (3)<a class="headerlink" href="#exercises-3" title="Permalink to this headline">¶</a></h1>
<div class="section" id="exercise-11-experiment-with-precision-in-tests-and-the-size-of">
<span id="decay-fd2-exer-precision"></span><h2>Exercise 11: Experiment with precision in tests and the size of <span class="math">\(u\)</span><a class="headerlink" href="#exercise-11-experiment-with-precision-in-tests-and-the-size-of" title="Permalink to this headline">¶</a></h2>
<p>It is claimed in the section <a class="reference internal" href="main_decay.html#decay-mms"><em>Verification via manufactured solutions</em></a> that most numerical methods will
reproduce a linear exact solution to machine precision. Test this
assertion using the nose test function <tt class="docutils literal"><span class="pre">test_linear_solution</span></tt> in the
<a class="reference external" href="http://tinyurl.com/jvzzcfn/decay/decay_vc.py">decay_vc.py</a> program.
Vary the parameter <tt class="docutils literal"><span class="pre">c</span></tt> from very small, via <tt class="docutils literal"><span class="pre">c=1</span></tt> to many larger values,
and print out the maximum difference between the numerical solution
and the exact solution. What is the relevant value of the <tt class="docutils literal"><span class="pre">places</span></tt>
(or <tt class="docutils literal"><span class="pre">delta</span></tt>) argument to <tt class="docutils literal"><span class="pre">nose.tools.assert_almost_equal</span></tt> in each
case?
Filename: <tt class="docutils literal"><span class="pre">test_precision.py</span></tt>.</p>
</div>
<div class="section" id="exercise-12-implement-the-2-step-backward-scheme">
<span id="decay-fd2-exer-bw2"></span><h2>Exercise 12: Implement the 2-step backward scheme<a class="headerlink" href="#exercise-12-implement-the-2-step-backward-scheme" title="Permalink to this headline">¶</a></h2>
<p>Implement the 2-step backward method <a href="#equation-decay:fd2:bw:2step">(?)</a> for the
model <span class="math">\(u'(t) = -a(t)u(t) + b(t)\)</span>, <span class="math">\(u(0)=I\)</span>.  Allow the first step to
be computed by either the Backward Euler scheme or the Crank-Nicolson
scheme. Verify the implementation by choosing <span class="math">\(a(t)\)</span> and <span class="math">\(b(t)\)</span> such
that the exact solution is linear in <span class="math">\(t\)</span> (see the section <a class="reference internal" href="main_decay.html#decay-mms"><em>Verification via manufactured solutions</em></a>). Show mathematically that a linear solution is indeed a
solution of the discrete equations.</p>
<p>Compute convergence rates (see the section <a class="reference internal" href="main_decay.html#decay-convergence-rate"><em>Computing convergence rates</em></a>) in
a test case <span class="math">\(a=\hbox{const}\)</span> and <span class="math">\(b=0\)</span>, where we easily have an exact
solution, and determine if the choice of a first-order scheme
(Backward Euler) for the first step has any impact on the overall
accuracy of this scheme. The expected error goes like <span class="math">\({{\cal O}(\Delta t^2)}\)</span>.
Filename: <tt class="docutils literal"><span class="pre">decay_backward2step.py</span></tt>.</p>
</div>
<div class="section" id="exercise-13-implement-the-2nd-order-adams-bashforth-scheme">
<span id="decay-fd2-exer-ab2"></span><h2>Exercise 13: Implement the 2nd-order Adams-Bashforth scheme<a class="headerlink" href="#exercise-13-implement-the-2nd-order-adams-bashforth-scheme" title="Permalink to this headline">¶</a></h2>
<p>Implement the 2nd-order Adams-Bashforth method <a href="#equation-decay:fd2:AB2">(16)</a>
for the decay problem <span class="math">\(u'=-a(t)u + b(t)\)</span>, <span class="math">\(u(0)=I\)</span>, <span class="math">\(t\in (0, T]\)</span>.
Use the Forward Euler method for the first step such that the overall
scheme is explicit. Verify the implementation using an exact
solution that is linear in time.
Analyze the scheme by searching for solutions <span class="math">\(u^n=A^n\)</span> when <span class="math">\(a=\hbox{const}\)</span>
and <span class="math">\(b=0\)</span>. Compare this second-order secheme to the Crank-Nicolson scheme.
Filename: <tt class="docutils literal"><span class="pre">decay_AdamBashforth2.py</span></tt>.</p>
</div>
<div class="section" id="exercise-14-implement-the-3rd-order-adams-bashforth-scheme">
<span id="decay-fd2-exer-ab3"></span><h2>Exercise 14: Implement the 3rd-order Adams-Bashforth scheme<a class="headerlink" href="#exercise-14-implement-the-3rd-order-adams-bashforth-scheme" title="Permalink to this headline">¶</a></h2>
<p>Implement the 3rd-order Adams-Bashforth method <a href="#equation-decay:fd2:AB3">(17)</a>
for the decay problem <span class="math">\(u'=-a(t)u + b(t)\)</span>, <span class="math">\(u(0)=I\)</span>, <span class="math">\(t\in (0, T]\)</span>.
Since the scheme is explicit, allow it to be started by two steps with
the Forward Euler method.  Investigate experimentally the case where
<span class="math">\(b=0\)</span> and <span class="math">\(a\)</span> is a constant: Can we have oscillatory solutions for
large <span class="math">\(\Delta t\)</span>?
Filename: <tt class="docutils literal"><span class="pre">decay_AdamBashforth3.py</span></tt>.</p>
</div>
<div class="section" id="exercise-15-analyze-explicit-2nd-order-methods">
<span id="decay-exer-rk2-taylor-analysis"></span><h2>Exercise 15: Analyze explicit 2nd-order methods<a class="headerlink" href="#exercise-15-analyze-explicit-2nd-order-methods" title="Permalink to this headline">¶</a></h2>
<p>Show that the schemes <a href="#equation-decay:fd2:RK2:s2">(14)</a> and
<a href="#equation-decay:fd2:Taylor2">(15)</a> are identical in the case <span class="math">\(f(u,t)=-a\)</span>, where
<span class="math">\(a&gt;0\)</span> is a constant. Assume that the numerical solution reads
<span class="math">\(u^n=A^n\)</span> for some unknown amplification factor <span class="math">\(A\)</span> to be determined.
Find <span class="math">\(A\)</span> and derive stability criteria. Can the scheme produce
oscillatory solutions of <span class="math">\(u'=-au\)</span>? Plot the numerical and exact
amplification factor.
Filename: <tt class="docutils literal"><span class="pre">decay_RK2_Taylor2.py</span></tt>.</p>
</div>
<div class="section" id="problem-4-implement-and-investigate-the-leapfrog-scheme">
<span id="decay-fd2-exer-leapfrog1"></span><h2>Problem 4: Implement and investigate the Leapfrog scheme<a class="headerlink" href="#problem-4-implement-and-investigate-the-leapfrog-scheme" title="Permalink to this headline">¶</a></h2>
<p>A Leapfrog scheme
for the ODE <span class="math">\(u'(t) = -a(t)u(t) + b(t)\)</span> is defined by</p>
<div class="math">
\[\brack D_{2t}u = -au+b\rbrack^n{\thinspace .}\]</div>
<p>A separate scheme is needed to compute <span class="math">\(u^1\)</span>, and the Forward Euler
scheme is a candidate.</p>
<p><em>a)</em> Implement the Leapfrog scheme for the model equation.</p>
<p><em>b)</em> Show mathematically that a linear solution in <span class="math">\(t\)</span> fulfills the
Forward Euler scheme for the first step and the Leapfrog scheme
for the subsequent steps. Use this linear solution to verify
the implementation, and automate the verification through a nose test.</p>
<p><em>c)</em> Create a manufactured solution <span class="math">\(u(t)=\sin(t)\)</span> for the ODE
<span class="math">\(u'=-au+b\)</span>.
Compute the convergence rate of the Leapfrog scheme using this
manufactured solution. The expected convergence rate of the
Leapfrog scheme is <span class="math">\({{\cal O}(\Delta t^2)}\)</span>. Does the use of a
1st-order method for the first step impact the convergence rate?</p>
<p><em>d)</em> Set up a set of experiments to demonstrate that the Leapfrog scheme
<a href="#equation-decay:fd2:leapfrog">(11)</a> is associated with numerical artifacts
(instabilities). Document the main results from this investigation.</p>
<p><em>e)</em> Analyze and explain the
instabilities of the Leapfrog scheme <a href="#equation-decay:fd2:leapfrog">(11)</a>:</p>
<blockquote>
<div><ul class="simple">
<li>Choose <span class="math">\(a=\mbox{const}\)</span> and <span class="math">\(b=0\)</span>.</li>
<li>Assume that an exact solution of the discrete equations has
the form <span class="math">\(u^n=A^n\)</span>, where <span class="math">\(A\)</span> is an amplification factor to
be determined.</li>
<li>Compute <span class="math">\(A\)</span> either by and or with the aid of <tt class="docutils literal"><span class="pre">sympy</span></tt>.
The polynomial for <span class="math">\(A\)</span> has two roots, <span class="math">\(A_1\)</span> and <span class="math">\(A_2\)</span>. We let
<span class="math">\(u^n\)</span> be a linear combination <span class="math">\(u^n=C_1A_1^n + C_2A_2^n\)</span>.</li>
<li>Show that one of the roots is the explanation of the instability.</li>
<li>Determine <span class="math">\(C_1\)</span> and <span class="math">\(C_2\)</span> and compare <span class="math">\(A\)</span> with the exact
expression, using a Taylor series approximation.</li>
</ul>
</div></blockquote>
<p><em>f)</em> Since the original Leapfrog scheme
is unconditionally unstable
as time grows, it demands some stabilization.
This can be done by filtering, where we first find <span class="math">\(u^{n+1}\)</span>
from the original Leapfrog scheme and then replace <span class="math">\(u^{n+1}\)</span>
by the average <span class="math">\(\gamma (u^{n-1} - 2u^n + u^{n+1}\)</span>, where <span class="math">\(\gamma\)</span>
can be taken as 0.6.
Implement the filtered Leapfrog
scheme and check that it can handle tests where the original
Leapfrog scheme is unstable.</p>
<p>Filenames: <tt class="docutils literal"><span class="pre">decay_leapfrog.py</span></tt>, <tt class="docutils literal"><span class="pre">decay_leapfrog.pdf</span></tt>.</p>
</div>
<div class="section" id="problem-5-make-a-unified-implementation-of-many-schemes">
<span id="decay-fd2-exer-uni"></span><h2>Problem 5: Make a unified implementation of many schemes<a class="headerlink" href="#problem-5-make-a-unified-implementation-of-many-schemes" title="Permalink to this headline">¶</a></h2>
<p>Consider the linear ODE problem <span class="math">\(u'(t)=-a(t)u(t) + b(t)\)</span>, <span class="math">\(u(0)=I\)</span>.
Explicit schemes for this problem can be written in the general form</p>
<div class="math" id="equation-decay:analysis:exer:sumcj">
<span class="eqno">(21)</span>\[     u^{n+1} = \sum_{j=0}^m c_ju^{n-j},\]</div>
<p>for some choice of <span class="math">\(c_0,\ldots,c_m\)</span>.
Find expressions for the <span class="math">\(c_j\)</span> coefficients in case of the
<span class="math">\(\theta\)</span>-rule, the three-level backward scheme,
the Leapfrog scheme, the 2nd-order Runge-Kutta method,
and the 3rd-order Adams-Bashforth scheme.</p>
<p>Make a class <tt class="docutils literal"><span class="pre">ExpDecay</span></tt> that implements the
general updating formula <a href="#equation-decay:analysis:exer:sumcj">(21)</a>.
The formula cannot be applied for <span class="math">\(n&lt;m\)</span>, and for those <span class="math">\(n\)</span> values, other
schemes must be used. Assume for simplicity that we just
repeat Crank-Nicolson steps until <a href="#equation-decay:analysis:exer:sumcj">(21)</a> can be used.
Use a subclass
to specify the list <span class="math">\(c_0,\ldots,c_m\)</span> for a particular method, and
implement subclasses for all the mentioned schemes.
Verify the implementation by testing with a linear solution, which should
be exactly reproduced by all methods.
Filename: <tt class="docutils literal"><span class="pre">decay_schemes_oo.py</span></tt>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Model extensions</a><ul>
<li><a class="reference internal" href="#generalization-including-a-variable-coefficient">Generalization: including a variable coefficient</a></li>
<li><a class="reference internal" href="#generalization-including-a-source-term">Generalization: including a source term</a><ul>
<li><a class="reference internal" href="#schemes">Schemes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-of-the-generalized-model-problem">Implementation of the generalized model problem</a><ul>
<li><a class="reference internal" href="#deriving-the-rule-formula">Deriving the <span class="math">\(\theta\)</span>-rule formula</a></li>
<li><a class="reference internal" href="#the-python-code">The Python code</a></li>
<li><a class="reference internal" href="#coding-of-variable-coefficients">Coding of variable coefficients</a></li>
</ul>
</li>
<li><a class="reference internal" href="#verifying-a-constant-solution">Verifying a constant solution</a></li>
<li><a class="reference internal" href="#verification-via-manufactured-solutions">Verification via manufactured solutions</a></li>
<li><a class="reference internal" href="#extension-to-systems-of-odes">Extension to systems of ODEs</a></li>
</ul>
</li>
<li><a class="reference internal" href="#general-first-order-odes">General first-order ODEs</a><ul>
<li><a class="reference internal" href="#generic-form">Generic form</a></li>
<li><a class="reference internal" href="#some-popular-schemes-for-odes">Some popular schemes for ODEs</a><ul>
<li><a class="reference internal" href="#the-rule">The <span class="math">\(\theta\)</span>-rule</a></li>
<li><a class="reference internal" href="#implicit-2-step-backward-scheme">Implicit 2-step backward scheme</a></li>
<li><a class="reference internal" href="#the-leapfrog-scheme">The Leapfrog scheme</a></li>
<li><a class="reference internal" href="#the-filtered-leapfrog-scheme">The filtered Leapfrog scheme</a></li>
<li><a class="reference internal" href="#nd-order-runge-kutta-scheme">2nd-order Runge-Kutta scheme</a></li>
<li><a class="reference internal" href="#a-2nd-order-taylor-series-method">A 2nd-order Taylor-series method</a></li>
<li><a class="reference internal" href="#nd-order-adams-bashforth-scheme">2nd-order Adams-Bashforth scheme</a></li>
<li><a class="reference internal" href="#rd-order-adams-bashforth-scheme">3rd-order Adams-Bashforth scheme</a></li>
<li><a class="reference internal" href="#th-order-runge-kutta-scheme">4th-order Runge-Kutta scheme</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-odespy-software">The Odespy software</a></li>
<li><a class="reference internal" href="#example-runge-kutta-methods">Example: Runge-Kutta methods</a><ul>
<li><a class="reference internal" href="#remark-about-using-the-rule-in-odespy">Remark about using the <span class="math">\(\theta\)</span>-rule in Odespy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-adaptive-runge-kutta-methods">Example: Adaptive Runge-Kutta methods</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises-3">Exercises  (3)</a><ul>
<li><a class="reference internal" href="#exercise-11-experiment-with-precision-in-tests-and-the-size-of">Exercise 11: Experiment with precision in tests and the size of <span class="math">\(u\)</span></a></li>
<li><a class="reference internal" href="#exercise-12-implement-the-2-step-backward-scheme">Exercise 12: Implement the 2-step backward scheme</a></li>
<li><a class="reference internal" href="#exercise-13-implement-the-2nd-order-adams-bashforth-scheme">Exercise 13: Implement the 2nd-order Adams-Bashforth scheme</a></li>
<li><a class="reference internal" href="#exercise-14-implement-the-3rd-order-adams-bashforth-scheme">Exercise 14: Implement the 3rd-order Adams-Bashforth scheme</a></li>
<li><a class="reference internal" href="#exercise-15-analyze-explicit-2nd-order-methods">Exercise 15: Analyze explicit 2nd-order methods</a></li>
<li><a class="reference internal" href="#problem-4-implement-and-investigate-the-leapfrog-scheme">Problem 4: Implement and investigate the Leapfrog scheme</a></li>
<li><a class="reference internal" href="#problem-5-make-a-unified-implementation-of-many-schemes">Problem 5: Make a unified implementation of many schemes</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="._part0006_main_decay.html"
                        title="previous chapter">Analysis of finite difference equations</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="._part0008_main_decay.html"
                        title="next chapter">Applications of exponential decay models</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/._part0007_main_decay.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="._part0008_main_decay.html" title="Applications of exponential decay models"
             >next</a> |</li>
        <li class="right" >
          <a href="._part0006_main_decay.html" title="Analysis of finite difference equations"
             >previous</a> |</li>
        <li><a href="index.html">Introduction to computing with finite difference methods</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
  <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
  </div>
</div>

  </body>
</html>